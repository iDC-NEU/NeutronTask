no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
22:00:46.741394 [3] proc begin: <DistEnv 3/4 nccl>
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
22:00:46.768767 [1] proc begin: <DistEnv 1/4 nccl>
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
22:00:47.271908 [2] proc begin: <DistEnv 2/4 nccl>
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
no spmm cpp: cannot import name 'spmm_cusparse_coo' from 'spmm_cpp' (unknown location)
22:00:47.276201 [0] proc begin: <DistEnv 0/4 nccl>
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
22:00:47.977613 [3] graph loaded <COO Graph: e160M_f512_l32_t0.8, |V|: 2000000, |E|: 160000000, masks: 1600000,200000,200000><Local: 3, |V|: 500000, |E|: 2349774>
22:00:47.986764 [3] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1024 MiB |   1040 MiB |   1073 MiB |  51113 KiB |
|       from large pool |   1024 MiB |   1040 MiB |   1073 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1024 MiB |   1040 MiB |   1073 MiB |  51113 KiB |
|       from large pool |   1024 MiB |   1040 MiB |   1073 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1023 MiB |   1038 MiB |   1070 MiB |  48832 KiB |
|       from large pool |   1023 MiB |   1038 MiB |   1070 MiB |  48828 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1056 MiB |   1056 MiB |   1056 MiB |      0 B   |
|       from large pool |   1054 MiB |   1054 MiB |   1054 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14306 KiB |  19998 KiB |  57928 KiB |  43621 KiB |
|       from large pool |  14306 KiB |  19998 KiB |  51779 KiB |  37473 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       6    |       6    |       6    |       0    |
|       from large pool |       5    |       5    |       5    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |       8    |       5    |
|       from large pool |       3    |       3    |       5    |       2    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
22:00:51.692107 [2] graph loaded <COO Graph: e160M_f512_l32_t0.8, |V|: 2000000, |E|: 160000000, masks: 1600000,200000,200000><Local: 2, |V|: 500000, |E|: 15637930>
22:00:51.700221 [2] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1125 MiB |   1141 MiB |   1175 MiB |  51113 KiB |
|       from large pool |   1125 MiB |   1141 MiB |   1175 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1125 MiB |   1141 MiB |   1175 MiB |  51113 KiB |
|       from large pool |   1125 MiB |   1141 MiB |   1175 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1124 MiB |   1139 MiB |   1172 MiB |  48832 KiB |
|       from large pool |   1124 MiB |   1139 MiB |   1172 MiB |  48828 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1160 MiB |   1160 MiB |   1160 MiB |      0 B   |
|       from large pool |   1158 MiB |   1158 MiB |   1158 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  16988 KiB |  19998 KiB |  51431 KiB |  34442 KiB |
|       from large pool |  16988 KiB |  19998 KiB |  45282 KiB |  28294 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      13    |      17    |      26    |      13    |
|       from large pool |      13    |      14    |      17    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      13    |      17    |      26    |      13    |
|       from large pool |      13    |      14    |      17    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       9    |       9    |       9    |       0    |
|       from large pool |       8    |       8    |       8    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       7    |      11    |       5    |
|       from large pool |       6    |       6    |       8    |       2    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
22:00:51.916861 [1] graph loaded <COO Graph: e160M_f512_l32_t0.8, |V|: 2000000, |E|: 160000000, masks: 1600000,200000,200000><Local: 1, |V|: 500000, |E|: 31008983>
22:00:51.922613 [1] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1244 MiB |   1260 MiB |   1293 MiB |  51113 KiB |
|       from large pool |   1244 MiB |   1260 MiB |   1293 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1244 MiB |   1260 MiB |   1293 MiB |  51113 KiB |
|       from large pool |   1244 MiB |   1260 MiB |   1293 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1241 MiB |   1257 MiB |   1289 MiB |  48832 KiB |
|       from large pool |   1241 MiB |   1257 MiB |   1289 MiB |  48828 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1280 MiB |   1280 MiB |   1280 MiB |      0 B   |
|       from large pool |   1278 MiB |   1278 MiB |   1278 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  18399 KiB |  20447 KiB |  52842 KiB |  34442 KiB |
|       from large pool |  18399 KiB |  19998 KiB |  46693 KiB |  28294 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      15    |      19    |      28    |      13    |
|       from large pool |      15    |      16    |      19    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      15    |      19    |      28    |      13    |
|       from large pool |      15    |      16    |      19    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      11    |      11    |      11    |       0    |
|       from large pool |      10    |      10    |      10    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       7    |      11    |       5    |
|       from large pool |       6    |       6    |       8    |       2    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
coo torch.Size([500000, 500000])
csr torch.Size([500000, 500000])
small csr torch.Size([500000, 500000])
22:01:01.826065 [0] graph loaded <COO Graph: e160M_f512_l32_t0.8, |V|: 2000000, |E|: 160000000, masks: 1600000,200000,200000><Local: 0, |V|: 500000, |E|: 113001879>
22:01:01.834735 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1870 MiB |   1886 MiB |   1920 MiB |  51113 KiB |
|       from large pool |   1870 MiB |   1886 MiB |   1920 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1870 MiB |   1886 MiB |   1920 MiB |  51113 KiB |
|       from large pool |   1870 MiB |   1886 MiB |   1920 MiB |  51105 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1867 MiB |   1882 MiB |   1914 MiB |  48832 KiB |
|       from large pool |   1867 MiB |   1882 MiB |   1914 MiB |  48828 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1900 MiB |   1900 MiB |   1900 MiB |      0 B   |
|       from large pool |   1898 MiB |   1898 MiB |   1898 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  12184 KiB |  19998 KiB |  46627 KiB |  34442 KiB |
|       from large pool |  12184 KiB |  19998 KiB |  40478 KiB |  28294 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      17    |      21    |      30    |      13    |
|       from large pool |      17    |      18    |      21    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      17    |      21    |      30    |      13    |
|       from large pool |      17    |      18    |      21    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      13    |      13    |      13    |       0    |
|       from large pool |      12    |      12    |      12    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       3    |       7    |       5    |
|       from large pool |       2    |       2    |       4    |       2    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:01:05.603758 [0] Epoch 00000 | Loss 3.4666
22:01:05.650718 [0] Epoch: 000, Train: 0.0315, Val: 0.0310, Test: 0.0314
0.031425
22:01:06.661407 [0] Epoch 00001 | Loss 17237.3027
22:01:06.682639 [0] Epoch: 001, Train: 0.0312, Val: 0.0313, Test: 0.0314
0.031380
22:01:07.692285 [0] Epoch 00002 | Loss 5992.1909
22:01:07.714113 [0] Epoch: 002, Train: 0.0314, Val: 0.0311, Test: 0.0310
0.030970
22:01:08.721304 [0] Epoch 00003 | Loss 3341.2048
22:01:08.743774 [0] Epoch: 003, Train: 0.0314, Val: 0.0315, Test: 0.0314
0.031425
22:01:09.751309 [0] Epoch 00004 | Loss 3752.3276
22:01:09.772195 [0] Epoch: 004, Train: 0.0315, Val: 0.0312, Test: 0.0306
0.030565
22:01:10.779467 [0] Epoch 00005 | Loss 2574.0405
22:01:10.801151 [0] Epoch: 005, Train: 0.0311, Val: 0.0314, Test: 0.0312
0.031195
22:01:11.805698 [0] Epoch 00006 | Loss 1072.4933
22:01:11.826351 [0] Epoch: 006, Train: 0.0313, Val: 0.0310, Test: 0.0315
0.031455
22:01:12.832082 [0] Epoch 00007 | Loss 76.8734
22:01:12.853122 [0] Epoch: 007, Train: 0.0312, Val: 0.0311, Test: 0.0310
0.031045
22:01:13.855699 [0] Epoch 00008 | Loss 3.4651
22:01:13.877351 [0] Epoch: 008, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:14.876675 [0] Epoch 00009 | Loss 3.4651
22:01:14.898814 [0] Epoch: 009, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:15.899039 [0] Epoch 00010 | Loss 3.4651
22:01:15.919964 [0] Epoch: 010, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:16.922369 [0] Epoch 00011 | Loss 3.4651
22:01:16.942943 [0] Epoch: 011, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:17.943325 [0] Epoch 00012 | Loss 3.4651
22:01:17.963788 [0] Epoch: 012, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:18.964172 [0] Epoch 00013 | Loss 3.4651
22:01:18.984589 [0] Epoch: 013, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:19.984774 [0] Epoch 00014 | Loss 3.4651
22:01:20.005387 [0] Epoch: 014, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:21.005248 [0] Epoch 00015 | Loss 3.4651
22:01:21.025817 [0] Epoch: 015, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:22.026602 [0] Epoch 00016 | Loss 3.4651
22:01:22.047140 [0] Epoch: 016, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:23.047048 [0] Epoch 00017 | Loss 3.4651
22:01:23.067758 [0] Epoch: 017, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:24.067760 [0] Epoch 00018 | Loss 3.4651
22:01:24.089252 [0] Epoch: 018, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:25.089510 [0] Epoch 00019 | Loss 3.4651
22:01:25.110150 [0] Epoch: 019, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:26.109213 [0] Epoch 00020 | Loss 3.4651
22:01:26.130644 [0] Epoch: 020, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:27.129687 [0] Epoch 00021 | Loss 3.4651
22:01:27.150534 [0] Epoch: 021, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:28.148971 [0] Epoch 00022 | Loss 3.4651
22:01:28.169750 [0] Epoch: 022, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:29.168442 [0] Epoch 00023 | Loss 3.4651
22:01:29.189235 [0] Epoch: 023, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:30.188795 [0] Epoch 00024 | Loss 3.4651
22:01:30.210223 [0] Epoch: 024, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:31.209331 [0] Epoch 00025 | Loss 3.4651
22:01:31.230645 [0] Epoch: 025, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:32.229981 [0] Epoch 00026 | Loss 3.4651
22:01:32.251003 [0] Epoch: 026, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:33.252966 [0] Epoch 00027 | Loss 3.4651
22:01:33.273603 [0] Epoch: 027, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:34.275257 [0] Epoch 00028 | Loss 3.4651
22:01:34.295880 [0] Epoch: 028, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:35.297660 [0] Epoch 00029 | Loss 3.4651
22:01:35.318289 [0] Epoch: 029, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:36.318085 [0] Epoch 00030 | Loss 3.4651
22:01:36.338755 [0] Epoch: 030, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:37.339475 [0] Epoch 00031 | Loss 3.4651
22:01:37.359986 [0] Epoch: 031, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:38.361207 [0] Epoch 00032 | Loss 3.4651
22:01:38.381967 [0] Epoch: 032, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:39.384682 [0] Epoch 00033 | Loss 3.4651
22:01:39.405314 [0] Epoch: 033, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:40.406561 [0] Epoch 00034 | Loss 3.4651
22:01:40.427309 [0] Epoch: 034, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:41.427530 [0] Epoch 00035 | Loss 3.4651
22:01:41.448317 [0] Epoch: 035, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:42.450020 [0] Epoch 00036 | Loss 3.4651
22:01:42.470609 [0] Epoch: 036, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:43.471930 [0] Epoch 00037 | Loss 3.4651
22:01:43.492413 [0] Epoch: 037, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:44.493869 [0] Epoch 00038 | Loss 3.4651
22:01:44.514360 [0] Epoch: 038, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:45.514691 [0] Epoch 00039 | Loss 3.4651
22:01:45.535046 [0] Epoch: 039, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:46.535643 [0] Epoch 00040 | Loss 3.4651
22:01:46.556059 [0] Epoch: 040, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:47.555993 [0] Epoch 00041 | Loss 3.4651
22:01:47.576332 [0] Epoch: 041, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:48.578297 [0] Epoch 00042 | Loss 3.4651
22:01:48.599247 [0] Epoch: 042, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:49.600381 [0] Epoch 00043 | Loss 3.4651
22:01:49.620665 [0] Epoch: 043, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:50.622131 [0] Epoch 00044 | Loss 3.4651
22:01:50.642986 [0] Epoch: 044, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:51.643553 [0] Epoch 00045 | Loss 3.4651
22:01:51.664517 [0] Epoch: 045, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:52.665187 [0] Epoch 00046 | Loss 3.4651
22:01:52.685874 [0] Epoch: 046, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:53.687440 [0] Epoch 00047 | Loss 3.4651
22:01:53.708456 [0] Epoch: 047, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:54.709486 [0] Epoch 00048 | Loss 3.4651
22:01:54.729953 [0] Epoch: 048, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:55.731370 [0] Epoch 00049 | Loss 3.4651
22:01:55.751775 [0] Epoch: 049, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:56.753555 [0] Epoch 00050 | Loss 3.4651
22:01:56.774193 [0] Epoch: 050, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:57.627612 [0] Epoch 00051 | Loss 3.4651
22:01:57.648611 [0] Epoch: 051, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:58.649256 [0] Epoch 00052 | Loss 3.4651
22:01:58.670876 [0] Epoch: 052, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:01:59.525734 [0] Epoch 00053 | Loss 3.4651
22:01:59.546858 [0] Epoch: 053, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:00.548347 [0] Epoch 00054 | Loss 3.4651
22:02:00.568772 [0] Epoch: 054, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:01.424022 [0] Epoch 00055 | Loss 3.4651
22:02:01.445496 [0] Epoch: 055, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:02.466548 [0] Epoch 00056 | Loss 3.4651
22:02:02.487871 [0] Epoch: 056, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:03.342869 [0] Epoch 00057 | Loss 3.4651
22:02:03.363656 [0] Epoch: 057, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:04.364198 [0] Epoch 00058 | Loss 3.4651
22:02:04.385167 [0] Epoch: 058, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:05.238723 [0] Epoch 00059 | Loss 3.4651
22:02:05.259429 [0] Epoch: 059, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:06.260435 [0] Epoch 00060 | Loss 3.4651
22:02:06.281136 [0] Epoch: 060, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:07.134777 [0] Epoch 00061 | Loss 3.4651
22:02:07.156022 [0] Epoch: 061, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:08.157336 [0] Epoch 00062 | Loss 3.4651
22:02:08.178102 [0] Epoch: 062, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:09.030796 [0] Epoch 00063 | Loss 3.4651
22:02:09.051988 [0] Epoch: 063, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:10.051941 [0] Epoch 00064 | Loss 3.4651
22:02:10.072544 [0] Epoch: 064, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:10.924715 [0] Epoch 00065 | Loss 3.4651
22:02:10.945854 [0] Epoch: 065, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:11.946316 [0] Epoch 00066 | Loss 3.4651
22:02:11.966790 [0] Epoch: 066, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:12.818336 [0] Epoch 00067 | Loss 3.4651
22:02:12.839615 [0] Epoch: 067, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:13.838408 [0] Epoch 00068 | Loss 3.4651
22:02:13.859309 [0] Epoch: 068, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:14.712521 [0] Epoch 00069 | Loss 3.4651
22:02:14.733456 [0] Epoch: 069, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:15.733803 [0] Epoch 00070 | Loss 3.4651
22:02:15.754293 [0] Epoch: 070, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:16.606355 [0] Epoch 00071 | Loss 3.4651
22:02:16.627949 [0] Epoch: 071, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:17.627262 [0] Epoch 00072 | Loss 3.4651
22:02:17.648280 [0] Epoch: 072, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:18.500591 [0] Epoch 00073 | Loss 3.4651
22:02:18.521491 [0] Epoch: 073, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:19.520345 [0] Epoch 00074 | Loss 3.4651
22:02:19.540782 [0] Epoch: 074, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:20.395336 [0] Epoch 00075 | Loss 3.4651
22:02:20.416699 [0] Epoch: 075, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:21.418127 [0] Epoch 00076 | Loss 3.4651
22:02:21.438703 [0] Epoch: 076, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:22.292797 [0] Epoch 00077 | Loss 3.4651
22:02:22.313428 [0] Epoch: 077, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:23.314191 [0] Epoch 00078 | Loss 3.4651
22:02:23.335128 [0] Epoch: 078, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:24.187912 [0] Epoch 00079 | Loss 3.4651
22:02:24.208781 [0] Epoch: 079, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:25.209087 [0] Epoch 00080 | Loss 3.4651
22:02:25.229616 [0] Epoch: 080, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:26.083727 [0] Epoch 00081 | Loss 3.4651
22:02:26.104443 [0] Epoch: 081, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:27.106640 [0] Epoch 00082 | Loss 3.4651
22:02:27.127255 [0] Epoch: 082, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:27.983144 [0] Epoch 00083 | Loss 3.4651
22:02:28.003847 [0] Epoch: 083, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:29.007843 [0] Epoch 00084 | Loss 3.4651
22:02:29.028687 [0] Epoch: 084, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:29.883061 [0] Epoch 00085 | Loss 3.4651
22:02:29.903897 [0] Epoch: 085, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:30.905655 [0] Epoch 00086 | Loss 3.4651
22:02:30.926418 [0] Epoch: 086, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:31.781529 [0] Epoch 00087 | Loss 3.4651
22:02:31.802054 [0] Epoch: 087, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:32.805400 [0] Epoch 00088 | Loss 3.4651
22:02:32.826117 [0] Epoch: 088, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:33.680374 [0] Epoch 00089 | Loss 3.4651
22:02:33.701317 [0] Epoch: 089, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:34.704314 [0] Epoch 00090 | Loss 3.4651
22:02:34.725133 [0] Epoch: 090, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:35.577711 [0] Epoch 00091 | Loss 3.4651
22:02:35.598161 [0] Epoch: 091, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:36.599084 [0] Epoch 00092 | Loss 3.4651
22:02:36.619906 [0] Epoch: 092, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:37.473714 [0] Epoch 00093 | Loss 3.4651
22:02:37.494484 [0] Epoch: 093, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:38.495674 [0] Epoch 00094 | Loss 3.4651
22:02:38.516165 [0] Epoch: 094, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:39.369789 [0] Epoch 00095 | Loss 3.4651
22:02:39.391214 [0] Epoch: 095, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:40.391531 [0] Epoch 00096 | Loss 3.4651
22:02:40.412472 [0] Epoch: 096, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:41.264646 [0] Epoch 00097 | Loss 3.4651
22:02:41.285999 [0] Epoch: 097, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:42.286236 [0] Epoch 00098 | Loss 3.4651
22:02:42.307088 [0] Epoch: 098, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:43.162258 [0] Epoch 00099 | Loss 3.4651
22:02:43.183171 [0] Epoch: 099, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:44.184681 [0] Epoch 00100 | Loss 3.4651
22:02:44.205255 [0] Epoch: 100, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:45.059257 [0] Epoch 00101 | Loss 3.4651
22:02:45.079774 [0] Epoch: 101, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:46.081283 [0] Epoch 00102 | Loss 3.4651
22:02:46.101956 [0] Epoch: 102, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:46.956306 [0] Epoch 00103 | Loss 3.4651
22:02:46.977006 [0] Epoch: 103, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:47.978258 [0] Epoch 00104 | Loss 3.4651
22:02:47.998712 [0] Epoch: 104, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:48.851452 [0] Epoch 00105 | Loss 3.4651
22:02:48.872254 [0] Epoch: 105, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:49.874653 [0] Epoch 00106 | Loss 3.4651
22:02:49.895161 [0] Epoch: 106, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:50.749095 [0] Epoch 00107 | Loss 3.4651
22:02:50.769947 [0] Epoch: 107, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:51.770925 [0] Epoch 00108 | Loss 3.4651
22:02:51.791408 [0] Epoch: 108, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:52.644292 [0] Epoch 00109 | Loss 3.4651
22:02:52.664833 [0] Epoch: 109, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:53.664711 [0] Epoch 00110 | Loss 3.4651
22:02:53.685257 [0] Epoch: 110, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:54.539334 [0] Epoch 00111 | Loss 3.4651
22:02:54.559770 [0] Epoch: 111, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:55.561229 [0] Epoch 00112 | Loss 3.4651
22:02:55.581788 [0] Epoch: 112, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:56.435880 [0] Epoch 00113 | Loss 3.4651
22:02:56.456454 [0] Epoch: 113, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:57.455736 [0] Epoch 00114 | Loss 3.4651
22:02:57.476519 [0] Epoch: 114, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:58.329581 [0] Epoch 00115 | Loss 3.4651
22:02:58.349900 [0] Epoch: 115, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:02:59.348570 [0] Epoch 00116 | Loss 3.4651
22:02:59.369043 [0] Epoch: 116, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:00.223402 [0] Epoch 00117 | Loss 3.4651
22:03:00.244020 [0] Epoch: 117, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:01.245431 [0] Epoch 00118 | Loss 3.4651
22:03:01.265925 [0] Epoch: 118, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:02.126258 [0] Epoch 00119 | Loss 3.4651
22:03:02.147870 [0] Epoch: 119, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:03.169388 [0] Epoch 00120 | Loss 3.4651
22:03:03.190981 [0] Epoch: 120, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:04.044867 [0] Epoch 00121 | Loss 3.4651
22:03:04.065667 [0] Epoch: 121, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:05.065266 [0] Epoch 00122 | Loss 3.4651
22:03:05.085992 [0] Epoch: 122, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:05.939603 [0] Epoch 00123 | Loss 3.4651
22:03:05.960825 [0] Epoch: 123, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:06.961217 [0] Epoch 00124 | Loss 3.4651
22:03:06.981950 [0] Epoch: 124, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:07.836457 [0] Epoch 00125 | Loss 3.4651
22:03:07.857194 [0] Epoch: 125, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:08.859563 [0] Epoch 00126 | Loss 3.4651
22:03:08.880264 [0] Epoch: 126, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:09.733896 [0] Epoch 00127 | Loss 3.4651
22:03:09.754532 [0] Epoch: 127, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:10.757426 [0] Epoch 00128 | Loss 3.4651
22:03:10.778373 [0] Epoch: 128, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:11.632101 [0] Epoch 00129 | Loss 3.4651
22:03:11.652602 [0] Epoch: 129, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:12.654021 [0] Epoch 00130 | Loss 3.4651
22:03:12.674586 [0] Epoch: 130, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:13.528021 [0] Epoch 00131 | Loss 3.4651
22:03:13.548473 [0] Epoch: 131, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:14.549399 [0] Epoch 00132 | Loss 3.4651
22:03:14.569823 [0] Epoch: 132, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:15.421752 [0] Epoch 00133 | Loss 3.4651
22:03:15.442383 [0] Epoch: 133, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:16.442754 [0] Epoch 00134 | Loss 3.4651
22:03:16.463144 [0] Epoch: 134, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:17.316137 [0] Epoch 00135 | Loss 3.4651
22:03:17.337499 [0] Epoch: 135, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:18.337984 [0] Epoch 00136 | Loss 3.4651
22:03:18.359826 [0] Epoch: 136, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:19.213064 [0] Epoch 00137 | Loss 3.4651
22:03:19.233636 [0] Epoch: 137, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:20.234519 [0] Epoch 00138 | Loss 3.4651
22:03:20.255118 [0] Epoch: 138, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:21.108343 [0] Epoch 00139 | Loss 3.4651
22:03:21.128969 [0] Epoch: 139, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:22.132148 [0] Epoch 00140 | Loss 3.4651
22:03:22.152955 [0] Epoch: 140, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:23.006750 [0] Epoch 00141 | Loss 3.4651
22:03:23.027212 [0] Epoch: 141, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:24.029695 [0] Epoch 00142 | Loss 3.4651
22:03:24.050304 [0] Epoch: 142, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:24.903471 [0] Epoch 00143 | Loss 3.4651
22:03:24.923838 [0] Epoch: 143, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:25.923941 [0] Epoch 00144 | Loss 3.4651
22:03:25.944879 [0] Epoch: 144, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:26.796852 [0] Epoch 00145 | Loss 3.4651
22:03:26.817967 [0] Epoch: 145, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:27.817810 [0] Epoch 00146 | Loss 3.4651
22:03:27.838321 [0] Epoch: 146, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:28.691007 [0] Epoch 00147 | Loss 3.4651
22:03:28.712079 [0] Epoch: 147, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:29.712200 [0] Epoch 00148 | Loss 3.4651
22:03:29.733161 [0] Epoch: 148, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:30.586420 [0] Epoch 00149 | Loss 3.4651
22:03:30.606982 [0] Epoch: 149, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:31.607473 [0] Epoch 00150 | Loss 3.4651
22:03:31.627965 [0] Epoch: 150, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:32.480226 [0] Epoch 00151 | Loss 3.4651
22:03:32.500908 [0] Epoch: 151, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:33.502024 [0] Epoch 00152 | Loss 3.4651
22:03:33.522614 [0] Epoch: 152, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:34.375695 [0] Epoch 00153 | Loss 3.4651
22:03:34.396200 [0] Epoch: 153, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:35.398308 [0] Epoch 00154 | Loss 3.4651
22:03:35.418756 [0] Epoch: 154, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:36.271534 [0] Epoch 00155 | Loss 3.4651
22:03:36.292148 [0] Epoch: 155, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:37.293351 [0] Epoch 00156 | Loss 3.4651
22:03:37.314417 [0] Epoch: 156, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:38.168264 [0] Epoch 00157 | Loss 3.4651
22:03:38.188968 [0] Epoch: 157, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:39.190511 [0] Epoch 00158 | Loss 3.4651
22:03:39.211520 [0] Epoch: 158, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:40.063822 [0] Epoch 00159 | Loss 3.4651
22:03:40.084592 [0] Epoch: 159, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:41.084603 [0] Epoch 00160 | Loss 3.4651
22:03:41.105852 [0] Epoch: 160, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:41.958658 [0] Epoch 00161 | Loss 3.4651
22:03:41.979638 [0] Epoch: 161, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:42.979070 [0] Epoch 00162 | Loss 3.4651
22:03:42.999931 [0] Epoch: 162, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:43.852085 [0] Epoch 00163 | Loss 3.4651
22:03:43.873032 [0] Epoch: 163, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:44.873518 [0] Epoch 00164 | Loss 3.4651
22:03:44.894215 [0] Epoch: 164, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:45.748238 [0] Epoch 00165 | Loss 3.4651
22:03:45.768842 [0] Epoch: 165, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:46.770183 [0] Epoch 00166 | Loss 3.4651
22:03:46.790765 [0] Epoch: 166, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:47.644092 [0] Epoch 00167 | Loss 3.4651
22:03:47.664650 [0] Epoch: 167, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:48.665589 [0] Epoch 00168 | Loss 3.4651
22:03:48.686297 [0] Epoch: 168, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:49.538767 [0] Epoch 00169 | Loss 3.4651
22:03:49.559453 [0] Epoch: 169, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:50.560048 [0] Epoch 00170 | Loss 3.4651
22:03:50.580677 [0] Epoch: 170, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:51.433220 [0] Epoch 00171 | Loss 3.4651
22:03:51.454056 [0] Epoch: 171, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:52.454105 [0] Epoch 00172 | Loss 3.4651
22:03:52.475328 [0] Epoch: 172, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:53.329242 [0] Epoch 00173 | Loss 3.4651
22:03:53.349973 [0] Epoch: 173, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:54.348706 [0] Epoch 00174 | Loss 3.4651
22:03:54.369539 [0] Epoch: 174, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:55.221763 [0] Epoch 00175 | Loss 3.4651
22:03:55.242733 [0] Epoch: 175, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:56.242486 [0] Epoch 00176 | Loss 3.4651
22:03:56.263051 [0] Epoch: 176, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:57.117218 [0] Epoch 00177 | Loss 3.4651
22:03:57.137669 [0] Epoch: 177, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:58.138398 [0] Epoch 00178 | Loss 3.4651
22:03:58.158978 [0] Epoch: 178, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:03:59.012452 [0] Epoch 00179 | Loss 3.4651
22:03:59.032767 [0] Epoch: 179, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:00.032790 [0] Epoch 00180 | Loss 3.4651
22:04:00.053202 [0] Epoch: 180, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:00.906805 [0] Epoch 00181 | Loss 3.4651
22:04:00.927777 [0] Epoch: 181, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:01.944299 [0] Epoch 00182 | Loss 3.4651
22:04:01.965813 [0] Epoch: 182, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:02.833747 [0] Epoch 00183 | Loss 3.4651
22:04:02.855218 [0] Epoch: 183, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:03.857582 [0] Epoch 00184 | Loss 3.4651
22:04:03.878358 [0] Epoch: 184, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:04.733127 [0] Epoch 00185 | Loss 3.4651
22:04:04.753695 [0] Epoch: 185, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:05.755920 [0] Epoch 00186 | Loss 3.4651
22:04:05.776570 [0] Epoch: 186, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:06.631273 [0] Epoch 00187 | Loss 3.4651
22:04:06.652018 [0] Epoch: 187, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:07.654799 [0] Epoch 00188 | Loss 3.4651
22:04:07.676036 [0] Epoch: 188, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:08.531050 [0] Epoch 00189 | Loss 3.4651
22:04:08.552042 [0] Epoch: 189, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:09.556128 [0] Epoch 00190 | Loss 3.4651
22:04:09.577264 [0] Epoch: 190, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:10.432571 [0] Epoch 00191 | Loss 3.4651
22:04:10.453530 [0] Epoch: 191, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:11.455498 [0] Epoch 00192 | Loss 3.4651
22:04:11.476357 [0] Epoch: 192, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:12.330621 [0] Epoch 00193 | Loss 3.4651
22:04:12.351155 [0] Epoch: 193, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:13.353017 [0] Epoch 00194 | Loss 3.4651
22:04:13.374026 [0] Epoch: 194, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:14.228754 [0] Epoch 00195 | Loss 3.4651
22:04:14.249232 [0] Epoch: 195, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:15.251830 [0] Epoch 00196 | Loss 3.4651
22:04:15.272330 [0] Epoch: 196, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:16.126857 [0] Epoch 00197 | Loss 3.4651
22:04:16.147888 [0] Epoch: 197, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:17.150244 [0] Epoch 00198 | Loss 3.4651
22:04:17.171101 [0] Epoch: 198, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
22:04:18.024871 [0] Epoch 00199 | Loss 3.4651
22:04:18.045909 [0] Epoch: 199, Train: 0.0315, Val: 0.0312, Test: 0.0315
0.031455
Rank: 0, local vtx: 500000, local edge: 113001879
Model: CachedGCN layers: 2 dataset: e160M_f512_l32_t0.8 nprocs 4
22:04:18.049053 [0] 
timer summary:
  9.04s   5.95s     1 broadcast ForwardL1 0
137.74s  59.95s  3200 broadcast
 47.06s  54.77s  3200 spmm
  0.15s   0.05s     1 broadcast ForwardL1 1
  0.13s   0.04s     1 broadcast ForwardL1 2
  0.12s   0.03s     1 broadcast ForwardL1 3
  4.73s   0.04s   800 mm
 28.79s  16.72s   125 broadcast ForwardL2 0
  8.65s   2.68s   125 broadcast ForwardL2 1
  8.22s   2.49s   125 broadcast ForwardL2 2
  7.68s   2.24s   125 broadcast ForwardL2 3
 24.69s  16.83s   200 broadcast BackwardL2 0
  1.43s   0.42s   200 broadcast BackwardL2 1
  1.59s   0.47s   200 broadcast BackwardL2 2
  1.54s   0.47s   200 broadcast BackwardL2 3
  2.45s   1.71s   400 all_reduce
  7.25s   0.24s   200 broadcast BackwardL1 0
 13.56s   4.29s   200 broadcast BackwardL1 1
 12.83s   3.97s   200 broadcast BackwardL1 2
 11.98s   3.57s   200 broadcast BackwardL1 3
203.77s   5.95s   200 epoch
211.03s   0.30s     1 total
Rank: 3, local vtx: 500000, local edge: 2349774
Rank: 2, local vtx: 500000, local edge: 15637930
Rank: 1, local vtx: 500000, local edge: 31008983

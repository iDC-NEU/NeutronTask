20:24:21.160574 [0] proc begin: <DistEnv 0/3 nccl>
20:24:25.417031 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 77655, |E|: 39304930>
20:24:25.427296 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 493092 KiB | 494913 KiB | 498781 KiB |   5688 KiB |
|       from large pool | 491500 KiB | 493320 KiB | 496960 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1820 KiB |    228 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 522240 KiB | 522240 KiB | 522240 KiB |      0 B   |
|       from large pool | 520192 KiB | 520192 KiB | 520192 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  28151 KiB |  28151 KiB |  37225 KiB |   9074 KiB |
|       from large pool |  27697 KiB |  27697 KiB |  33580 KiB |   5883 KiB |
|       from small pool |    453 KiB |   1820 KiB |   3644 KiB |   3191 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       9    |       9    |       9    |       0    |
|       from large pool |       8    |       8    |       8    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       7    |       7    |      11    |       4    |
|       from large pool |       6    |       6    |       9    |       3    |
|       from small pool |       1    |       1    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:24:27.315416 [0] Epoch 00000 | Loss 3.8004
20:24:27.352638 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:24:27.624395 [0] Epoch 00001 | Loss 3.4369
20:24:27.629915 [0] Epoch: 001, Train: 0.1158, Val: 0.1018, Test: 0.0997
20:24:27.903089 [0] Epoch 00002 | Loss 3.2880
20:24:27.908814 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1945
20:24:28.181057 [0] Epoch 00003 | Loss 3.1591
20:24:28.186966 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:24:28.457744 [0] Epoch 00004 | Loss 3.0520
20:24:28.464491 [0] Epoch: 004, Train: 0.2965, Val: 0.2739, Test: 0.2734
20:24:28.734689 [0] Epoch 00005 | Loss 2.9471
20:24:28.740692 [0] Epoch: 005, Train: 0.3216, Val: 0.2996, Test: 0.2995
20:24:29.010438 [0] Epoch 00006 | Loss 2.8366
20:24:29.015931 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:24:29.286387 [0] Epoch 00007 | Loss 2.7157
20:24:29.291887 [0] Epoch: 007, Train: 0.4122, Val: 0.4159, Test: 0.4215
20:24:29.561633 [0] Epoch 00008 | Loss 2.5811
20:24:29.567098 [0] Epoch: 008, Train: 0.4968, Val: 0.4999, Test: 0.5063
20:24:29.835146 [0] Epoch 00009 | Loss 2.4334
20:24:29.840618 [0] Epoch: 009, Train: 0.5324, Val: 0.5318, Test: 0.5379
20:24:30.110451 [0] Epoch 00010 | Loss 2.2772
20:24:30.116215 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:24:30.385977 [0] Epoch 00011 | Loss 2.1108
20:24:30.391486 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:24:30.660640 [0] Epoch 00012 | Loss 1.9380
20:24:30.666077 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:24:30.935868 [0] Epoch 00013 | Loss 1.7631
20:24:30.941725 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:24:31.211023 [0] Epoch 00014 | Loss 1.6014
20:24:31.217279 [0] Epoch: 014, Train: 0.6305, Val: 0.6296, Test: 0.6292
20:24:31.486637 [0] Epoch 00015 | Loss 1.4665
20:24:31.492048 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:24:31.761160 [0] Epoch 00016 | Loss 1.3549
20:24:31.766688 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6841
20:24:32.035174 [0] Epoch 00017 | Loss 1.2613
20:24:32.041250 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:24:32.310299 [0] Epoch 00018 | Loss 1.1713
20:24:32.315726 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:24:32.584395 [0] Epoch 00019 | Loss 1.0767
20:24:32.589874 [0] Epoch: 019, Train: 0.7521, Val: 0.7491, Test: 0.7448
20:24:32.859081 [0] Epoch 00020 | Loss 0.9920
20:24:32.864507 [0] Epoch: 020, Train: 0.7804, Val: 0.7726, Test: 0.7677
20:24:33.132768 [0] Epoch 00021 | Loss 0.9222
20:24:33.138911 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7842
20:24:33.407871 [0] Epoch 00022 | Loss 0.8643
20:24:33.413180 [0] Epoch: 022, Train: 0.8195, Val: 0.8089, Test: 0.8046
20:24:33.681182 [0] Epoch 00023 | Loss 0.8168
20:24:33.686912 [0] Epoch: 023, Train: 0.8334, Val: 0.8219, Test: 0.8177
20:24:33.955069 [0] Epoch 00024 | Loss 0.7759
20:24:33.960356 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:24:34.229183 [0] Epoch 00025 | Loss 0.7380
20:24:34.236535 [0] Epoch: 025, Train: 0.8491, Val: 0.8363, Test: 0.8331
20:24:34.504758 [0] Epoch 00026 | Loss 0.7005
20:24:34.510057 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:24:34.779006 [0] Epoch 00027 | Loss 0.6622
20:24:34.785454 [0] Epoch: 027, Train: 0.8800, Val: 0.8747, Test: 0.8733
20:24:35.054887 [0] Epoch 00028 | Loss 0.6219
20:24:35.060110 [0] Epoch: 028, Train: 0.9001, Val: 0.9019, Test: 0.9000
20:24:35.328893 [0] Epoch 00029 | Loss 0.5795
20:24:35.334649 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:24:35.604038 [0] Epoch 00030 | Loss 0.5362
20:24:35.609409 [0] Epoch: 030, Train: 0.9091, Val: 0.9126, Test: 0.9107
20:24:35.877539 [0] Epoch 00031 | Loss 0.4958
20:24:35.883610 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:24:36.152382 [0] Epoch 00032 | Loss 0.4624
20:24:36.157618 [0] Epoch: 032, Train: 0.9163, Val: 0.9202, Test: 0.9185
20:24:36.426026 [0] Epoch 00033 | Loss 0.4368
20:24:36.432013 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:24:36.701371 [0] Epoch 00034 | Loss 0.4162
20:24:36.707206 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:24:36.976307 [0] Epoch 00035 | Loss 0.3991
20:24:36.981657 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:24:37.251731 [0] Epoch 00036 | Loss 0.3851
20:24:37.257925 [0] Epoch: 036, Train: 0.9274, Val: 0.9320, Test: 0.9291
20:24:37.525706 [0] Epoch 00037 | Loss 0.3738
20:24:37.531014 [0] Epoch: 037, Train: 0.9283, Val: 0.9322, Test: 0.9305
20:24:37.799891 [0] Epoch 00038 | Loss 0.3643
20:24:37.805567 [0] Epoch: 038, Train: 0.9291, Val: 0.9328, Test: 0.9308
20:24:38.074902 [0] Epoch 00039 | Loss 0.3556
20:24:38.081781 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9317
20:24:38.350696 [0] Epoch 00040 | Loss 0.3470
20:24:38.356369 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9328
20:24:38.625615 [0] Epoch 00041 | Loss 0.3389
20:24:38.630968 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:24:38.900371 [0] Epoch 00042 | Loss 0.3321
20:24:38.906022 [0] Epoch: 042, Train: 0.9339, Val: 0.9360, Test: 0.9352
20:24:39.174902 [0] Epoch 00043 | Loss 0.3271
20:24:39.181844 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:24:39.451017 [0] Epoch 00044 | Loss 0.3232
20:24:39.456302 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:24:39.724165 [0] Epoch 00045 | Loss 0.3190
20:24:39.729834 [0] Epoch: 045, Train: 0.9357, Val: 0.9371, Test: 0.9368
20:24:39.998977 [0] Epoch 00046 | Loss 0.3144
20:24:40.004228 [0] Epoch: 046, Train: 0.9364, Val: 0.9376, Test: 0.9374
20:24:40.272520 [0] Epoch 00047 | Loss 0.3102
20:24:40.277776 [0] Epoch: 047, Train: 0.9366, Val: 0.9380, Test: 0.9376
20:24:40.547606 [0] Epoch 00048 | Loss 0.3063
20:24:40.554487 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:24:40.823589 [0] Epoch 00049 | Loss 0.3023
20:24:40.830284 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:24:41.099319 [0] Epoch 00050 | Loss 0.2985
20:24:41.105397 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:24:41.373311 [0] Epoch 00051 | Loss 0.2950
20:24:41.379036 [0] Epoch: 051, Train: 0.9382, Val: 0.9382, Test: 0.9382
20:24:41.647709 [0] Epoch 00052 | Loss 0.2919
20:24:41.653522 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:24:41.922268 [0] Epoch 00053 | Loss 0.2892
20:24:41.927909 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9384
20:24:42.196614 [0] Epoch 00054 | Loss 0.2861
20:24:42.202028 [0] Epoch: 054, Train: 0.9394, Val: 0.9387, Test: 0.9387
20:24:42.470195 [0] Epoch 00055 | Loss 0.2832
20:24:42.475672 [0] Epoch: 055, Train: 0.9397, Val: 0.9392, Test: 0.9390
20:24:42.744701 [0] Epoch 00056 | Loss 0.2807
20:24:42.750192 [0] Epoch: 056, Train: 0.9402, Val: 0.9396, Test: 0.9394
20:24:43.019662 [0] Epoch 00057 | Loss 0.2782
20:24:43.024986 [0] Epoch: 057, Train: 0.9406, Val: 0.9398, Test: 0.9396
20:24:43.294047 [0] Epoch 00058 | Loss 0.2756
20:24:43.299367 [0] Epoch: 058, Train: 0.9410, Val: 0.9402, Test: 0.9401
20:24:43.568650 [0] Epoch 00059 | Loss 0.2729
20:24:43.574023 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:24:43.842858 [0] Epoch 00060 | Loss 0.2705
20:24:43.848114 [0] Epoch: 060, Train: 0.9421, Val: 0.9406, Test: 0.9404
20:24:44.117430 [0] Epoch 00061 | Loss 0.2683
20:24:44.122738 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9403
20:24:44.392507 [0] Epoch 00062 | Loss 0.2662
20:24:44.399663 [0] Epoch: 062, Train: 0.9427, Val: 0.9408, Test: 0.9404
20:24:44.667837 [0] Epoch 00063 | Loss 0.2641
20:24:44.674706 [0] Epoch: 063, Train: 0.9431, Val: 0.9413, Test: 0.9408
20:24:44.943972 [0] Epoch 00064 | Loss 0.2621
20:24:44.950042 [0] Epoch: 064, Train: 0.9433, Val: 0.9412, Test: 0.9409
20:24:45.218748 [0] Epoch 00065 | Loss 0.2601
20:24:45.224487 [0] Epoch: 065, Train: 0.9435, Val: 0.9417, Test: 0.9412
20:24:45.492789 [0] Epoch 00066 | Loss 0.2582
20:24:45.498511 [0] Epoch: 066, Train: 0.9439, Val: 0.9416, Test: 0.9414
20:24:45.767038 [0] Epoch 00067 | Loss 0.2563
20:24:45.772303 [0] Epoch: 067, Train: 0.9442, Val: 0.9419, Test: 0.9414
20:24:46.041466 [0] Epoch 00068 | Loss 0.2545
20:24:46.048165 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:24:46.316990 [0] Epoch 00069 | Loss 0.2529
20:24:46.322639 [0] Epoch: 069, Train: 0.9448, Val: 0.9424, Test: 0.9417
20:24:46.592183 [0] Epoch 00070 | Loss 0.2513
20:24:46.597487 [0] Epoch: 070, Train: 0.9450, Val: 0.9425, Test: 0.9420
20:24:46.866343 [0] Epoch 00071 | Loss 0.2497
20:24:46.871672 [0] Epoch: 071, Train: 0.9452, Val: 0.9423, Test: 0.9421
20:24:47.139782 [0] Epoch 00072 | Loss 0.2483
20:24:47.145521 [0] Epoch: 072, Train: 0.9455, Val: 0.9423, Test: 0.9422
20:24:47.414167 [0] Epoch 00073 | Loss 0.2468
20:24:47.419416 [0] Epoch: 073, Train: 0.9458, Val: 0.9429, Test: 0.9425
20:24:47.687281 [0] Epoch 00074 | Loss 0.2454
20:24:47.692551 [0] Epoch: 074, Train: 0.9460, Val: 0.9431, Test: 0.9426
20:24:47.961279 [0] Epoch 00075 | Loss 0.2440
20:24:47.966532 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:24:48.236966 [0] Epoch 00076 | Loss 0.2426
20:24:48.242291 [0] Epoch: 076, Train: 0.9465, Val: 0.9430, Test: 0.9424
20:24:48.510886 [0] Epoch 00077 | Loss 0.2412
20:24:48.516146 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:24:48.785252 [0] Epoch 00078 | Loss 0.2399
20:24:48.793614 [0] Epoch: 078, Train: 0.9468, Val: 0.9431, Test: 0.9425
20:24:49.062925 [0] Epoch 00079 | Loss 0.2386
20:24:49.068222 [0] Epoch: 079, Train: 0.9470, Val: 0.9429, Test: 0.9426
20:24:49.337789 [0] Epoch 00080 | Loss 0.2374
20:24:49.344456 [0] Epoch: 080, Train: 0.9472, Val: 0.9428, Test: 0.9427
20:24:49.613831 [0] Epoch 00081 | Loss 0.2362
20:24:49.619139 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9427
20:24:49.889056 [0] Epoch 00082 | Loss 0.2350
20:24:49.894476 [0] Epoch: 082, Train: 0.9476, Val: 0.9427, Test: 0.9428
20:24:50.164078 [0] Epoch 00083 | Loss 0.2339
20:24:50.169424 [0] Epoch: 083, Train: 0.9478, Val: 0.9429, Test: 0.9430
20:24:50.439415 [0] Epoch 00084 | Loss 0.2328
20:24:50.444656 [0] Epoch: 084, Train: 0.9479, Val: 0.9431, Test: 0.9431
20:24:50.714207 [0] Epoch 00085 | Loss 0.2317
20:24:50.720118 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9434
20:24:50.988346 [0] Epoch 00086 | Loss 0.2307
20:24:50.993590 [0] Epoch: 086, Train: 0.9482, Val: 0.9431, Test: 0.9435
20:24:51.263403 [0] Epoch 00087 | Loss 0.2297
20:24:51.268666 [0] Epoch: 087, Train: 0.9483, Val: 0.9430, Test: 0.9435
20:24:51.540526 [0] Epoch 00088 | Loss 0.2287
20:24:51.546900 [0] Epoch: 088, Train: 0.9487, Val: 0.9433, Test: 0.9436
20:24:51.815916 [0] Epoch 00089 | Loss 0.2277
20:24:51.821710 [0] Epoch: 089, Train: 0.9490, Val: 0.9435, Test: 0.9436
20:24:52.091170 [0] Epoch 00090 | Loss 0.2267
20:24:52.096461 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9437
20:24:52.365845 [0] Epoch 00091 | Loss 0.2258
20:24:52.371564 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9440
20:24:52.641705 [0] Epoch 00092 | Loss 0.2248
20:24:52.647065 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9440
20:24:52.916247 [0] Epoch 00093 | Loss 0.2239
20:24:52.922319 [0] Epoch: 093, Train: 0.9497, Val: 0.9440, Test: 0.9441
20:24:53.191264 [0] Epoch 00094 | Loss 0.2229
20:24:53.196841 [0] Epoch: 094, Train: 0.9499, Val: 0.9442, Test: 0.9440
20:24:53.465697 [0] Epoch 00095 | Loss 0.2221
20:24:53.471018 [0] Epoch: 095, Train: 0.9500, Val: 0.9444, Test: 0.9442
20:24:53.740236 [0] Epoch 00096 | Loss 0.2212
20:24:53.746762 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9443
20:24:54.015927 [0] Epoch 00097 | Loss 0.2203
20:24:54.021648 [0] Epoch: 097, Train: 0.9503, Val: 0.9445, Test: 0.9445
20:24:54.291100 [0] Epoch 00098 | Loss 0.2195
20:24:54.296383 [0] Epoch: 098, Train: 0.9504, Val: 0.9446, Test: 0.9447
20:24:54.564922 [0] Epoch 00099 | Loss 0.2186
20:24:54.570304 [0] Epoch: 099, Train: 0.9506, Val: 0.9447, Test: 0.9449
20:24:54.839386 [0] Epoch 00100 | Loss 0.2177
20:24:54.844653 [0] Epoch: 100, Train: 0.9508, Val: 0.9450, Test: 0.9448
20:24:55.114013 [0] Epoch 00101 | Loss 0.2169
20:24:55.119425 [0] Epoch: 101, Train: 0.9510, Val: 0.9451, Test: 0.9449
20:24:55.388476 [0] Epoch 00102 | Loss 0.2161
20:24:55.393780 [0] Epoch: 102, Train: 0.9512, Val: 0.9452, Test: 0.9450
20:24:55.662874 [0] Epoch 00103 | Loss 0.2153
20:24:55.668485 [0] Epoch: 103, Train: 0.9513, Val: 0.9452, Test: 0.9450
20:24:55.937616 [0] Epoch 00104 | Loss 0.2145
20:24:55.944528 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9450
20:24:56.214151 [0] Epoch 00105 | Loss 0.2137
20:24:56.219682 [0] Epoch: 105, Train: 0.9516, Val: 0.9454, Test: 0.9451
20:24:56.488471 [0] Epoch 00106 | Loss 0.2129
20:24:56.493745 [0] Epoch: 106, Train: 0.9517, Val: 0.9455, Test: 0.9452
20:24:56.762916 [0] Epoch 00107 | Loss 0.2122
20:24:56.768286 [0] Epoch: 107, Train: 0.9519, Val: 0.9456, Test: 0.9454
20:24:57.036584 [0] Epoch 00108 | Loss 0.2115
20:24:57.041824 [0] Epoch: 108, Train: 0.9520, Val: 0.9454, Test: 0.9453
20:24:57.311395 [0] Epoch 00109 | Loss 0.2108
20:24:57.316742 [0] Epoch: 109, Train: 0.9520, Val: 0.9455, Test: 0.9454
20:24:57.585579 [0] Epoch 00110 | Loss 0.2101
20:24:57.590857 [0] Epoch: 110, Train: 0.9523, Val: 0.9458, Test: 0.9454
20:24:57.859646 [0] Epoch 00111 | Loss 0.2094
20:24:57.865440 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:24:58.135208 [0] Epoch 00112 | Loss 0.2087
20:24:58.140446 [0] Epoch: 112, Train: 0.9525, Val: 0.9455, Test: 0.9454
20:24:58.409374 [0] Epoch 00113 | Loss 0.2080
20:24:58.414799 [0] Epoch: 113, Train: 0.9527, Val: 0.9455, Test: 0.9454
20:24:58.684084 [0] Epoch 00114 | Loss 0.2073
20:24:58.690528 [0] Epoch: 114, Train: 0.9527, Val: 0.9455, Test: 0.9454
20:24:58.959691 [0] Epoch 00115 | Loss 0.2066
20:24:58.964977 [0] Epoch: 115, Train: 0.9528, Val: 0.9456, Test: 0.9455
20:24:59.234660 [0] Epoch 00116 | Loss 0.2060
20:24:59.239984 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9455
20:24:59.508739 [0] Epoch 00117 | Loss 0.2053
20:24:59.514016 [0] Epoch: 117, Train: 0.9531, Val: 0.9458, Test: 0.9456
20:24:59.783312 [0] Epoch 00118 | Loss 0.2046
20:24:59.788591 [0] Epoch: 118, Train: 0.9532, Val: 0.9459, Test: 0.9457
20:25:00.057426 [0] Epoch 00119 | Loss 0.2040
20:25:00.062930 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:25:00.332521 [0] Epoch 00120 | Loss 0.2034
20:25:00.338501 [0] Epoch: 120, Train: 0.9534, Val: 0.9460, Test: 0.9459
20:25:00.607194 [0] Epoch 00121 | Loss 0.2028
20:25:00.612536 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9459
20:25:00.881198 [0] Epoch 00122 | Loss 0.2021
20:25:00.887227 [0] Epoch: 122, Train: 0.9536, Val: 0.9461, Test: 0.9460
20:25:01.156303 [0] Epoch 00123 | Loss 0.2015
20:25:01.162164 [0] Epoch: 123, Train: 0.9537, Val: 0.9461, Test: 0.9459
20:25:01.438959 [0] Epoch 00124 | Loss 0.2009
20:25:01.444911 [0] Epoch: 124, Train: 0.9538, Val: 0.9463, Test: 0.9459
20:25:01.719907 [0] Epoch 00125 | Loss 0.2003
20:25:01.725817 [0] Epoch: 125, Train: 0.9539, Val: 0.9462, Test: 0.9459
20:25:02.001768 [0] Epoch 00126 | Loss 0.1997
20:25:02.007920 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9459
20:25:02.284367 [0] Epoch 00127 | Loss 0.1992
20:25:02.290606 [0] Epoch: 127, Train: 0.9541, Val: 0.9467, Test: 0.9459
20:25:02.564587 [0] Epoch 00128 | Loss 0.1986
20:25:02.569990 [0] Epoch: 128, Train: 0.9543, Val: 0.9467, Test: 0.9459
20:25:02.840040 [0] Epoch 00129 | Loss 0.1980
20:25:02.845773 [0] Epoch: 129, Train: 0.9544, Val: 0.9467, Test: 0.9459
20:25:03.116086 [0] Epoch 00130 | Loss 0.1974
20:25:03.121382 [0] Epoch: 130, Train: 0.9545, Val: 0.9466, Test: 0.9459
20:25:03.390924 [0] Epoch 00131 | Loss 0.1969
20:25:03.396424 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9458
20:25:03.664960 [0] Epoch 00132 | Loss 0.1963
20:25:03.670459 [0] Epoch: 132, Train: 0.9547, Val: 0.9467, Test: 0.9458
20:25:03.939340 [0] Epoch 00133 | Loss 0.1958
20:25:03.944619 [0] Epoch: 133, Train: 0.9548, Val: 0.9468, Test: 0.9459
20:25:04.214843 [0] Epoch 00134 | Loss 0.1953
20:25:04.220606 [0] Epoch: 134, Train: 0.9549, Val: 0.9469, Test: 0.9460
20:25:04.489698 [0] Epoch 00135 | Loss 0.1947
20:25:04.494961 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9460
20:25:04.763410 [0] Epoch 00136 | Loss 0.1942
20:25:04.770056 [0] Epoch: 136, Train: 0.9551, Val: 0.9469, Test: 0.9461
20:25:05.038880 [0] Epoch 00137 | Loss 0.1937
20:25:05.044193 [0] Epoch: 137, Train: 0.9552, Val: 0.9469, Test: 0.9461
20:25:05.313267 [0] Epoch 00138 | Loss 0.1932
20:25:05.319625 [0] Epoch: 138, Train: 0.9553, Val: 0.9469, Test: 0.9461
20:25:05.588525 [0] Epoch 00139 | Loss 0.1927
20:25:05.593784 [0] Epoch: 139, Train: 0.9553, Val: 0.9471, Test: 0.9462
20:25:05.863398 [0] Epoch 00140 | Loss 0.1922
20:25:05.868686 [0] Epoch: 140, Train: 0.9554, Val: 0.9472, Test: 0.9463
20:25:06.137590 [0] Epoch 00141 | Loss 0.1917
20:25:06.142908 [0] Epoch: 141, Train: 0.9555, Val: 0.9473, Test: 0.9464
20:25:06.412871 [0] Epoch 00142 | Loss 0.1913
20:25:06.418485 [0] Epoch: 142, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:25:06.686627 [0] Epoch 00143 | Loss 0.1908
20:25:06.692138 [0] Epoch: 143, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:25:06.961022 [0] Epoch 00144 | Loss 0.1903
20:25:06.966329 [0] Epoch: 144, Train: 0.9557, Val: 0.9473, Test: 0.9464
20:25:07.235982 [0] Epoch 00145 | Loss 0.1899
20:25:07.241367 [0] Epoch: 145, Train: 0.9557, Val: 0.9473, Test: 0.9464
20:25:07.510896 [0] Epoch 00146 | Loss 0.1894
20:25:07.516182 [0] Epoch: 146, Train: 0.9558, Val: 0.9472, Test: 0.9464
20:25:07.784663 [0] Epoch 00147 | Loss 0.1890
20:25:07.790230 [0] Epoch: 147, Train: 0.9559, Val: 0.9473, Test: 0.9464
20:25:08.059336 [0] Epoch 00148 | Loss 0.1885
20:25:08.064643 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:25:08.333657 [0] Epoch 00149 | Loss 0.1881
20:25:08.339276 [0] Epoch: 149, Train: 0.9561, Val: 0.9472, Test: 0.9463
20:25:08.608747 [0] Epoch 00150 | Loss 0.1876
20:25:08.614050 [0] Epoch: 150, Train: 0.9561, Val: 0.9471, Test: 0.9464
20:25:08.883893 [0] Epoch 00151 | Loss 0.1872
20:25:08.889134 [0] Epoch: 151, Train: 0.9562, Val: 0.9471, Test: 0.9464
20:25:09.157327 [0] Epoch 00152 | Loss 0.1868
20:25:09.163503 [0] Epoch: 152, Train: 0.9563, Val: 0.9472, Test: 0.9463
20:25:09.432559 [0] Epoch 00153 | Loss 0.1863
20:25:09.438359 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9464
20:25:09.707301 [0] Epoch 00154 | Loss 0.1859
20:25:09.712659 [0] Epoch: 154, Train: 0.9565, Val: 0.9472, Test: 0.9464
20:25:09.981605 [0] Epoch 00155 | Loss 0.1855
20:25:09.986819 [0] Epoch: 155, Train: 0.9566, Val: 0.9473, Test: 0.9463
20:25:10.256876 [0] Epoch 00156 | Loss 0.1850
20:25:10.262809 [0] Epoch: 156, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:25:10.531623 [0] Epoch 00157 | Loss 0.1846
20:25:10.536900 [0] Epoch: 157, Train: 0.9567, Val: 0.9472, Test: 0.9463
20:25:10.807154 [0] Epoch 00158 | Loss 0.1842
20:25:10.812492 [0] Epoch: 158, Train: 0.9568, Val: 0.9471, Test: 0.9464
20:25:11.081085 [0] Epoch 00159 | Loss 0.1838
20:25:11.086444 [0] Epoch: 159, Train: 0.9568, Val: 0.9471, Test: 0.9464
20:25:11.355786 [0] Epoch 00160 | Loss 0.1834
20:25:11.362482 [0] Epoch: 160, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:25:11.631107 [0] Epoch 00161 | Loss 0.1830
20:25:11.637060 [0] Epoch: 161, Train: 0.9570, Val: 0.9473, Test: 0.9464
20:25:11.905811 [0] Epoch 00162 | Loss 0.1826
20:25:11.911081 [0] Epoch: 162, Train: 0.9570, Val: 0.9472, Test: 0.9465
20:25:12.180660 [0] Epoch 00163 | Loss 0.1822
20:25:12.186064 [0] Epoch: 163, Train: 0.9572, Val: 0.9471, Test: 0.9465
20:25:12.455468 [0] Epoch 00164 | Loss 0.1818
20:25:12.461464 [0] Epoch: 164, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:25:12.731029 [0] Epoch 00165 | Loss 0.1814
20:25:12.736810 [0] Epoch: 165, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:25:13.006642 [0] Epoch 00166 | Loss 0.1810
20:25:13.011991 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:25:13.280752 [0] Epoch 00167 | Loss 0.1806
20:25:13.286130 [0] Epoch: 167, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:25:13.555531 [0] Epoch 00168 | Loss 0.1802
20:25:13.560891 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:25:13.830935 [0] Epoch 00169 | Loss 0.1799
20:25:13.837574 [0] Epoch: 169, Train: 0.9578, Val: 0.9470, Test: 0.9466
20:25:14.107667 [0] Epoch 00170 | Loss 0.1795
20:25:14.113257 [0] Epoch: 170, Train: 0.9578, Val: 0.9471, Test: 0.9466
20:25:14.382403 [0] Epoch 00171 | Loss 0.1791
20:25:14.387843 [0] Epoch: 171, Train: 0.9579, Val: 0.9472, Test: 0.9467
20:25:14.656315 [0] Epoch 00172 | Loss 0.1787
20:25:14.661656 [0] Epoch: 172, Train: 0.9580, Val: 0.9473, Test: 0.9467
20:25:14.930800 [0] Epoch 00173 | Loss 0.1783
20:25:14.936338 [0] Epoch: 173, Train: 0.9581, Val: 0.9473, Test: 0.9467
20:25:15.205469 [0] Epoch 00174 | Loss 0.1780
20:25:15.210946 [0] Epoch: 174, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:25:15.480083 [0] Epoch 00175 | Loss 0.1776
20:25:15.485368 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:25:15.753985 [0] Epoch 00176 | Loss 0.1772
20:25:15.759468 [0] Epoch: 176, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:25:16.028201 [0] Epoch 00177 | Loss 0.1769
20:25:16.033530 [0] Epoch: 177, Train: 0.9583, Val: 0.9474, Test: 0.9467
20:25:16.302895 [0] Epoch 00178 | Loss 0.1765
20:25:16.308725 [0] Epoch: 178, Train: 0.9584, Val: 0.9475, Test: 0.9468
20:25:16.577169 [0] Epoch 00179 | Loss 0.1762
20:25:16.582458 [0] Epoch: 179, Train: 0.9584, Val: 0.9475, Test: 0.9467
20:25:16.851883 [0] Epoch 00180 | Loss 0.1758
20:25:16.857177 [0] Epoch: 180, Train: 0.9585, Val: 0.9475, Test: 0.9468
20:25:17.125816 [0] Epoch 00181 | Loss 0.1754
20:25:17.131152 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:25:17.400741 [0] Epoch 00182 | Loss 0.1751
20:25:17.406612 [0] Epoch: 182, Train: 0.9587, Val: 0.9475, Test: 0.9469
20:25:17.675755 [0] Epoch 00183 | Loss 0.1747
20:25:17.681194 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9469
20:25:17.949748 [0] Epoch 00184 | Loss 0.1744
20:25:17.955159 [0] Epoch: 184, Train: 0.9588, Val: 0.9475, Test: 0.9471
20:25:18.224386 [0] Epoch 00185 | Loss 0.1740
20:25:18.230237 [0] Epoch: 185, Train: 0.9588, Val: 0.9475, Test: 0.9469
20:25:18.500052 [0] Epoch 00186 | Loss 0.1737
20:25:18.505927 [0] Epoch: 186, Train: 0.9590, Val: 0.9473, Test: 0.9469
20:25:18.774338 [0] Epoch 00187 | Loss 0.1734
20:25:18.780122 [0] Epoch: 187, Train: 0.9590, Val: 0.9476, Test: 0.9469
20:25:19.048723 [0] Epoch 00188 | Loss 0.1733
20:25:19.054740 [0] Epoch: 188, Train: 0.9591, Val: 0.9472, Test: 0.9468
20:25:19.324375 [0] Epoch 00189 | Loss 0.1731
20:25:19.330269 [0] Epoch: 189, Train: 0.9590, Val: 0.9478, Test: 0.9469
20:25:19.599575 [0] Epoch 00190 | Loss 0.1730
20:25:19.605609 [0] Epoch: 190, Train: 0.9591, Val: 0.9470, Test: 0.9464
20:25:19.874990 [0] Epoch 00191 | Loss 0.1723
20:25:19.880979 [0] Epoch: 191, Train: 0.9592, Val: 0.9479, Test: 0.9470
20:25:20.150079 [0] Epoch 00192 | Loss 0.1717
20:25:20.156123 [0] Epoch: 192, Train: 0.9594, Val: 0.9475, Test: 0.9470
20:25:20.425349 [0] Epoch 00193 | Loss 0.1716
20:25:20.431369 [0] Epoch: 193, Train: 0.9595, Val: 0.9475, Test: 0.9469
20:25:20.699895 [0] Epoch 00194 | Loss 0.1714
20:25:20.705269 [0] Epoch: 194, Train: 0.9595, Val: 0.9479, Test: 0.9470
20:25:20.974854 [0] Epoch 00195 | Loss 0.1709
20:25:20.980140 [0] Epoch: 195, Train: 0.9597, Val: 0.9474, Test: 0.9469
20:25:21.248840 [0] Epoch 00196 | Loss 0.1704
20:25:21.254243 [0] Epoch: 196, Train: 0.9597, Val: 0.9474, Test: 0.9470
20:25:21.523722 [0] Epoch 00197 | Loss 0.1703
20:25:21.529048 [0] Epoch: 197, Train: 0.9597, Val: 0.9477, Test: 0.9469
20:25:21.797317 [0] Epoch 00198 | Loss 0.1700
20:25:21.802628 [0] Epoch: 198, Train: 0.9598, Val: 0.9474, Test: 0.9469
20:25:22.071515 [0] Epoch 00199 | Loss 0.1695
20:25:22.076881 [0] Epoch: 199, Train: 0.9599, Val: 0.9475, Test: 0.9470
20:25:22.079447 [0] 
timer summary:
  3.48s   0.73s   200 broadcast ForwardL1 0
 16.62s   1.31s  2400 broadcast
 35.38s   0.84s  2400 spmm
  2.59s   0.18s   200 broadcast ForwardL1 1
  2.78s   0.09s   200 broadcast ForwardL1 2
  1.17s   0.00s   800 mm
  1.27s   0.24s   200 broadcast ForwardL2 0
  1.12s   0.10s   200 broadcast ForwardL2 1
  1.16s   0.07s   200 broadcast ForwardL2 2
  0.27s   0.13s   200 broadcast BackwardL2 0
  0.23s   0.11s   200 broadcast BackwardL2 1
  0.22s   0.10s   200 broadcast BackwardL2 2
  0.26s   0.15s   400 all_reduce
  1.12s   0.09s   200 broadcast BackwardL1 0
  1.13s   0.11s   200 broadcast BackwardL1 1
  1.17s   0.07s   200 broadcast BackwardL1 2
 56.53s   0.65s   200 epoch
 61.23s   0.55s     1 total
20:26:02.500790 [0] proc begin: <DistEnv 0/3 nccl>
20:26:07.193977 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 77655, |E|: 39304930>
20:26:07.203861 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 493092 KiB | 494913 KiB | 498781 KiB |   5688 KiB |
|       from large pool | 491500 KiB | 493320 KiB | 496960 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1820 KiB |    228 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 522240 KiB | 522240 KiB | 522240 KiB |      0 B   |
|       from large pool | 520192 KiB | 520192 KiB | 520192 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  28151 KiB |  28151 KiB |  37225 KiB |   9074 KiB |
|       from large pool |  27697 KiB |  27697 KiB |  33580 KiB |   5883 KiB |
|       from small pool |    453 KiB |   1820 KiB |   3644 KiB |   3191 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       9    |       9    |       9    |       0    |
|       from large pool |       8    |       8    |       8    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       7    |       7    |      11    |       4    |
|       from large pool |       6    |       6    |       9    |       3    |
|       from small pool |       1    |       1    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:26:09.309511 [0] Epoch 00000 | Loss 3.8004
20:26:09.341625 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:26:09.614382 [0] Epoch 00001 | Loss 3.4369
20:26:09.619998 [0] Epoch: 001, Train: 0.1158, Val: 0.1018, Test: 0.0997
20:26:09.890156 [0] Epoch 00002 | Loss 3.2880
20:26:09.895645 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1945
20:26:10.166773 [0] Epoch 00003 | Loss 3.1591
20:26:10.173208 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:26:10.446409 [0] Epoch 00004 | Loss 3.0520
20:26:10.451985 [0] Epoch: 004, Train: 0.2965, Val: 0.2739, Test: 0.2734
20:26:10.723568 [0] Epoch 00005 | Loss 2.9471
20:26:10.729026 [0] Epoch: 005, Train: 0.3216, Val: 0.2996, Test: 0.2995
20:26:10.999674 [0] Epoch 00006 | Loss 2.8366
20:26:11.005128 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:26:11.278069 [0] Epoch 00007 | Loss 2.7157
20:26:11.283641 [0] Epoch: 007, Train: 0.4122, Val: 0.4159, Test: 0.4215
20:26:11.554257 [0] Epoch 00008 | Loss 2.5811
20:26:11.560102 [0] Epoch: 008, Train: 0.4968, Val: 0.4999, Test: 0.5063
20:26:11.829022 [0] Epoch 00009 | Loss 2.4334
20:26:11.834487 [0] Epoch: 009, Train: 0.5324, Val: 0.5318, Test: 0.5379
20:26:12.103496 [0] Epoch 00010 | Loss 2.2772
20:26:12.108959 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:26:12.377258 [0] Epoch 00011 | Loss 2.1108
20:26:12.382665 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:26:12.651458 [0] Epoch 00012 | Loss 1.9380
20:26:12.656761 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:26:12.925520 [0] Epoch 00013 | Loss 1.7631
20:26:12.930893 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:26:13.199216 [0] Epoch 00014 | Loss 1.6014
20:26:13.205011 [0] Epoch: 014, Train: 0.6305, Val: 0.6296, Test: 0.6292
20:26:13.473866 [0] Epoch 00015 | Loss 1.4665
20:26:13.480834 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:26:13.749943 [0] Epoch 00016 | Loss 1.3549
20:26:13.755466 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6841
20:26:14.024064 [0] Epoch 00017 | Loss 1.2613
20:26:14.030076 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:26:14.299863 [0] Epoch 00018 | Loss 1.1713
20:26:14.306051 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:26:14.574709 [0] Epoch 00019 | Loss 1.0767
20:26:14.581168 [0] Epoch: 019, Train: 0.7521, Val: 0.7491, Test: 0.7448
20:26:14.850602 [0] Epoch 00020 | Loss 0.9920
20:26:14.856644 [0] Epoch: 020, Train: 0.7804, Val: 0.7726, Test: 0.7677
20:26:15.126181 [0] Epoch 00021 | Loss 0.9222
20:26:15.132241 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7842
20:26:15.401504 [0] Epoch 00022 | Loss 0.8643
20:26:15.407513 [0] Epoch: 022, Train: 0.8195, Val: 0.8089, Test: 0.8046
20:26:15.676521 [0] Epoch 00023 | Loss 0.8168
20:26:15.682529 [0] Epoch: 023, Train: 0.8334, Val: 0.8219, Test: 0.8177
20:26:15.951595 [0] Epoch 00024 | Loss 0.7759
20:26:15.957823 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:26:16.226498 [0] Epoch 00025 | Loss 0.7380
20:26:16.232321 [0] Epoch: 025, Train: 0.8491, Val: 0.8363, Test: 0.8331
20:26:16.504864 [0] Epoch 00026 | Loss 0.7005
20:26:16.510856 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:26:16.780391 [0] Epoch 00027 | Loss 0.6622
20:26:16.786090 [0] Epoch: 027, Train: 0.8800, Val: 0.8747, Test: 0.8733
20:26:17.055727 [0] Epoch 00028 | Loss 0.6219
20:26:17.061305 [0] Epoch: 028, Train: 0.9001, Val: 0.9019, Test: 0.9000
20:26:17.333692 [0] Epoch 00029 | Loss 0.5795
20:26:17.340596 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:26:17.611024 [0] Epoch 00030 | Loss 0.5362
20:26:17.617655 [0] Epoch: 030, Train: 0.9091, Val: 0.9126, Test: 0.9107
20:26:17.888522 [0] Epoch 00031 | Loss 0.4958
20:26:17.894025 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:26:18.164062 [0] Epoch 00032 | Loss 0.4624
20:26:18.169570 [0] Epoch: 032, Train: 0.9163, Val: 0.9202, Test: 0.9185
20:26:18.439265 [0] Epoch 00033 | Loss 0.4368
20:26:18.445845 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:26:18.715170 [0] Epoch 00034 | Loss 0.4162
20:26:18.720864 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:26:18.990818 [0] Epoch 00035 | Loss 0.3991
20:26:18.997511 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:26:19.266949 [0] Epoch 00036 | Loss 0.3851
20:26:19.272629 [0] Epoch: 036, Train: 0.9274, Val: 0.9320, Test: 0.9291
20:26:19.542564 [0] Epoch 00037 | Loss 0.3738
20:26:19.549216 [0] Epoch: 037, Train: 0.9283, Val: 0.9322, Test: 0.9305
20:26:19.818185 [0] Epoch 00038 | Loss 0.3643
20:26:19.824747 [0] Epoch: 038, Train: 0.9291, Val: 0.9328, Test: 0.9308
20:26:20.095268 [0] Epoch 00039 | Loss 0.3556
20:26:20.100944 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9317
20:26:20.369529 [0] Epoch 00040 | Loss 0.3470
20:26:20.375463 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9328
20:26:20.644116 [0] Epoch 00041 | Loss 0.3389
20:26:20.649985 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:26:20.919277 [0] Epoch 00042 | Loss 0.3321
20:26:20.925809 [0] Epoch: 042, Train: 0.9339, Val: 0.9360, Test: 0.9352
20:26:21.195495 [0] Epoch 00043 | Loss 0.3271
20:26:21.201331 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:26:21.471665 [0] Epoch 00044 | Loss 0.3232
20:26:21.477082 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:26:21.747057 [0] Epoch 00045 | Loss 0.3190
20:26:21.753723 [0] Epoch: 045, Train: 0.9357, Val: 0.9371, Test: 0.9368
20:26:22.023952 [0] Epoch 00046 | Loss 0.3144
20:26:22.029431 [0] Epoch: 046, Train: 0.9364, Val: 0.9376, Test: 0.9374
20:26:22.298643 [0] Epoch 00047 | Loss 0.3102
20:26:22.304165 [0] Epoch: 047, Train: 0.9366, Val: 0.9380, Test: 0.9376
20:26:22.573707 [0] Epoch 00048 | Loss 0.3063
20:26:22.579440 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:26:22.848665 [0] Epoch 00049 | Loss 0.3023
20:26:22.853963 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:26:23.123963 [0] Epoch 00050 | Loss 0.2985
20:26:23.130658 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:26:23.399396 [0] Epoch 00051 | Loss 0.2950
20:26:23.404868 [0] Epoch: 051, Train: 0.9382, Val: 0.9382, Test: 0.9382
20:26:23.674214 [0] Epoch 00052 | Loss 0.2919
20:26:23.679681 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:26:23.948572 [0] Epoch 00053 | Loss 0.2892
20:26:23.954011 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9384
20:26:24.223847 [0] Epoch 00054 | Loss 0.2861
20:26:24.230888 [0] Epoch: 054, Train: 0.9394, Val: 0.9387, Test: 0.9387
20:26:24.499914 [0] Epoch 00055 | Loss 0.2832
20:26:24.506640 [0] Epoch: 055, Train: 0.9398, Val: 0.9392, Test: 0.9390
20:26:24.775788 [0] Epoch 00056 | Loss 0.2807
20:26:24.782275 [0] Epoch: 056, Train: 0.9402, Val: 0.9396, Test: 0.9394
20:26:25.051429 [0] Epoch 00057 | Loss 0.2782
20:26:25.056950 [0] Epoch: 057, Train: 0.9406, Val: 0.9398, Test: 0.9396
20:26:25.325941 [0] Epoch 00058 | Loss 0.2756
20:26:25.331501 [0] Epoch: 058, Train: 0.9410, Val: 0.9403, Test: 0.9401
20:26:25.600292 [0] Epoch 00059 | Loss 0.2729
20:26:25.606857 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:26:25.875965 [0] Epoch 00060 | Loss 0.2705
20:26:25.881387 [0] Epoch: 060, Train: 0.9421, Val: 0.9406, Test: 0.9404
20:26:26.151539 [0] Epoch 00061 | Loss 0.2683
20:26:26.158402 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9403
20:26:26.427250 [0] Epoch 00062 | Loss 0.2662
20:26:26.432582 [0] Epoch: 062, Train: 0.9427, Val: 0.9408, Test: 0.9404
20:26:26.700977 [0] Epoch 00063 | Loss 0.2641
20:26:26.706285 [0] Epoch: 063, Train: 0.9431, Val: 0.9413, Test: 0.9408
20:26:26.975932 [0] Epoch 00064 | Loss 0.2621
20:26:26.981230 [0] Epoch: 064, Train: 0.9432, Val: 0.9412, Test: 0.9409
20:26:27.249636 [0] Epoch 00065 | Loss 0.2601
20:26:27.254883 [0] Epoch: 065, Train: 0.9435, Val: 0.9417, Test: 0.9412
20:26:27.524465 [0] Epoch 00066 | Loss 0.2582
20:26:27.531155 [0] Epoch: 066, Train: 0.9439, Val: 0.9416, Test: 0.9414
20:26:27.800392 [0] Epoch 00067 | Loss 0.2563
20:26:27.806983 [0] Epoch: 067, Train: 0.9442, Val: 0.9419, Test: 0.9414
20:26:28.076242 [0] Epoch 00068 | Loss 0.2545
20:26:28.081483 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:26:28.349105 [0] Epoch 00069 | Loss 0.2529
20:26:28.354404 [0] Epoch: 069, Train: 0.9448, Val: 0.9424, Test: 0.9417
20:26:28.623960 [0] Epoch 00070 | Loss 0.2513
20:26:28.630592 [0] Epoch: 070, Train: 0.9450, Val: 0.9425, Test: 0.9420
20:26:28.900839 [0] Epoch 00071 | Loss 0.2497
20:26:28.906196 [0] Epoch: 071, Train: 0.9452, Val: 0.9424, Test: 0.9421
20:26:29.174608 [0] Epoch 00072 | Loss 0.2483
20:26:29.179846 [0] Epoch: 072, Train: 0.9454, Val: 0.9423, Test: 0.9422
20:26:29.447719 [0] Epoch 00073 | Loss 0.2468
20:26:29.454071 [0] Epoch: 073, Train: 0.9458, Val: 0.9429, Test: 0.9425
20:26:29.723515 [0] Epoch 00074 | Loss 0.2454
20:26:29.728875 [0] Epoch: 074, Train: 0.9461, Val: 0.9431, Test: 0.9426
20:26:29.997882 [0] Epoch 00075 | Loss 0.2440
20:26:30.003574 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:26:30.272341 [0] Epoch 00076 | Loss 0.2426
20:26:30.277689 [0] Epoch: 076, Train: 0.9465, Val: 0.9430, Test: 0.9424
20:26:30.546750 [0] Epoch 00077 | Loss 0.2412
20:26:30.552079 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:26:30.820786 [0] Epoch 00078 | Loss 0.2399
20:26:30.826020 [0] Epoch: 078, Train: 0.9468, Val: 0.9431, Test: 0.9425
20:26:31.094519 [0] Epoch 00079 | Loss 0.2386
20:26:31.099786 [0] Epoch: 079, Train: 0.9470, Val: 0.9429, Test: 0.9427
20:26:31.369191 [0] Epoch 00080 | Loss 0.2374
20:26:31.374510 [0] Epoch: 080, Train: 0.9472, Val: 0.9428, Test: 0.9427
20:26:31.644294 [0] Epoch 00081 | Loss 0.2362
20:26:31.650519 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9427
20:26:31.918919 [0] Epoch 00082 | Loss 0.2350
20:26:31.924202 [0] Epoch: 082, Train: 0.9476, Val: 0.9426, Test: 0.9428
20:26:32.192657 [0] Epoch 00083 | Loss 0.2339
20:26:32.198006 [0] Epoch: 083, Train: 0.9478, Val: 0.9429, Test: 0.9430
20:26:32.466692 [0] Epoch 00084 | Loss 0.2328
20:26:32.472111 [0] Epoch: 084, Train: 0.9479, Val: 0.9431, Test: 0.9431
20:26:32.741776 [0] Epoch 00085 | Loss 0.2317
20:26:32.748489 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9434
20:26:33.017181 [0] Epoch 00086 | Loss 0.2307
20:26:33.023073 [0] Epoch: 086, Train: 0.9482, Val: 0.9430, Test: 0.9435
20:26:33.292075 [0] Epoch 00087 | Loss 0.2297
20:26:33.297355 [0] Epoch: 087, Train: 0.9483, Val: 0.9430, Test: 0.9435
20:26:33.568137 [0] Epoch 00088 | Loss 0.2287
20:26:33.573785 [0] Epoch: 088, Train: 0.9487, Val: 0.9433, Test: 0.9436
20:26:33.843429 [0] Epoch 00089 | Loss 0.2277
20:26:33.848894 [0] Epoch: 089, Train: 0.9490, Val: 0.9435, Test: 0.9436
20:26:34.118194 [0] Epoch 00090 | Loss 0.2267
20:26:34.123723 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9437
20:26:34.392915 [0] Epoch 00091 | Loss 0.2258
20:26:34.398485 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9440
20:26:34.667236 [0] Epoch 00092 | Loss 0.2248
20:26:34.672661 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9440
20:26:34.941657 [0] Epoch 00093 | Loss 0.2239
20:26:34.947108 [0] Epoch: 093, Train: 0.9497, Val: 0.9440, Test: 0.9441
20:26:35.217097 [0] Epoch 00094 | Loss 0.2229
20:26:35.222632 [0] Epoch: 094, Train: 0.9498, Val: 0.9442, Test: 0.9440
20:26:35.491234 [0] Epoch 00095 | Loss 0.2221
20:26:35.496534 [0] Epoch: 095, Train: 0.9500, Val: 0.9444, Test: 0.9442
20:26:35.765405 [0] Epoch 00096 | Loss 0.2212
20:26:35.770658 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9443
20:26:36.040289 [0] Epoch 00097 | Loss 0.2203
20:26:36.046897 [0] Epoch: 097, Train: 0.9502, Val: 0.9445, Test: 0.9446
20:26:36.316274 [0] Epoch 00098 | Loss 0.2195
20:26:36.322942 [0] Epoch: 098, Train: 0.9504, Val: 0.9445, Test: 0.9447
20:26:36.591912 [0] Epoch 00099 | Loss 0.2186
20:26:36.597145 [0] Epoch: 099, Train: 0.9506, Val: 0.9447, Test: 0.9449
20:26:36.866508 [0] Epoch 00100 | Loss 0.2177
20:26:36.871763 [0] Epoch: 100, Train: 0.9508, Val: 0.9450, Test: 0.9448
20:26:37.140228 [0] Epoch 00101 | Loss 0.2169
20:26:37.145454 [0] Epoch: 101, Train: 0.9510, Val: 0.9451, Test: 0.9449
20:26:37.414440 [0] Epoch 00102 | Loss 0.2161
20:26:37.420434 [0] Epoch: 102, Train: 0.9511, Val: 0.9452, Test: 0.9450
20:26:37.689402 [0] Epoch 00103 | Loss 0.2153
20:26:37.694693 [0] Epoch: 103, Train: 0.9513, Val: 0.9452, Test: 0.9450
20:26:37.963516 [0] Epoch 00104 | Loss 0.2145
20:26:37.970162 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9450
20:26:38.239055 [0] Epoch 00105 | Loss 0.2137
20:26:38.245775 [0] Epoch: 105, Train: 0.9516, Val: 0.9454, Test: 0.9451
20:26:38.514607 [0] Epoch 00106 | Loss 0.2129
20:26:38.520153 [0] Epoch: 106, Train: 0.9517, Val: 0.9455, Test: 0.9453
20:26:38.788738 [0] Epoch 00107 | Loss 0.2122
20:26:38.794046 [0] Epoch: 107, Train: 0.9519, Val: 0.9456, Test: 0.9453
20:26:39.063698 [0] Epoch 00108 | Loss 0.2115
20:26:39.069236 [0] Epoch: 108, Train: 0.9520, Val: 0.9454, Test: 0.9453
20:26:39.339186 [0] Epoch 00109 | Loss 0.2108
20:26:39.344552 [0] Epoch: 109, Train: 0.9521, Val: 0.9455, Test: 0.9454
20:26:39.614496 [0] Epoch 00110 | Loss 0.2101
20:26:39.619821 [0] Epoch: 110, Train: 0.9523, Val: 0.9459, Test: 0.9454
20:26:39.888130 [0] Epoch 00111 | Loss 0.2094
20:26:39.893730 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:26:40.162488 [0] Epoch 00112 | Loss 0.2087
20:26:40.167721 [0] Epoch: 112, Train: 0.9525, Val: 0.9455, Test: 0.9454
20:26:40.436416 [0] Epoch 00113 | Loss 0.2080
20:26:40.441684 [0] Epoch: 113, Train: 0.9526, Val: 0.9455, Test: 0.9454
20:26:40.710289 [0] Epoch 00114 | Loss 0.2073
20:26:40.715771 [0] Epoch: 114, Train: 0.9527, Val: 0.9455, Test: 0.9454
20:26:40.984618 [0] Epoch 00115 | Loss 0.2066
20:26:40.989938 [0] Epoch: 115, Train: 0.9528, Val: 0.9456, Test: 0.9455
20:26:41.259233 [0] Epoch 00116 | Loss 0.2060
20:26:41.265534 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9455
20:26:41.534665 [0] Epoch 00117 | Loss 0.2053
20:26:41.540459 [0] Epoch: 117, Train: 0.9531, Val: 0.9458, Test: 0.9456
20:26:41.810320 [0] Epoch 00118 | Loss 0.2046
20:26:41.815600 [0] Epoch: 118, Train: 0.9532, Val: 0.9459, Test: 0.9457
20:26:42.084124 [0] Epoch 00119 | Loss 0.2040
20:26:42.090122 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:26:42.358481 [0] Epoch 00120 | Loss 0.2034
20:26:42.364219 [0] Epoch: 120, Train: 0.9534, Val: 0.9460, Test: 0.9459
20:26:42.632536 [0] Epoch 00121 | Loss 0.2028
20:26:42.637803 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9460
20:26:42.906856 [0] Epoch 00122 | Loss 0.2021
20:26:42.912307 [0] Epoch: 122, Train: 0.9536, Val: 0.9461, Test: 0.9460
20:26:43.180978 [0] Epoch 00123 | Loss 0.2015
20:26:43.186216 [0] Epoch: 123, Train: 0.9537, Val: 0.9462, Test: 0.9459
20:26:43.455023 [0] Epoch 00124 | Loss 0.2009
20:26:43.460249 [0] Epoch: 124, Train: 0.9538, Val: 0.9463, Test: 0.9459
20:26:43.728580 [0] Epoch 00125 | Loss 0.2003
20:26:43.733875 [0] Epoch: 125, Train: 0.9539, Val: 0.9462, Test: 0.9459
20:26:44.002790 [0] Epoch 00126 | Loss 0.1997
20:26:44.008369 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9460
20:26:44.277231 [0] Epoch 00127 | Loss 0.1992
20:26:44.283934 [0] Epoch: 127, Train: 0.9541, Val: 0.9467, Test: 0.9459
20:26:44.552200 [0] Epoch 00128 | Loss 0.1986
20:26:44.557469 [0] Epoch: 128, Train: 0.9543, Val: 0.9467, Test: 0.9459
20:26:44.826512 [0] Epoch 00129 | Loss 0.1980
20:26:44.833204 [0] Epoch: 129, Train: 0.9544, Val: 0.9467, Test: 0.9459
20:26:45.102204 [0] Epoch 00130 | Loss 0.1974
20:26:45.107547 [0] Epoch: 130, Train: 0.9545, Val: 0.9467, Test: 0.9459
20:26:45.375936 [0] Epoch 00131 | Loss 0.1969
20:26:45.381503 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9459
20:26:45.650308 [0] Epoch 00132 | Loss 0.1963
20:26:45.655798 [0] Epoch: 132, Train: 0.9547, Val: 0.9468, Test: 0.9458
20:26:45.924841 [0] Epoch 00133 | Loss 0.1958
20:26:45.930721 [0] Epoch: 133, Train: 0.9548, Val: 0.9468, Test: 0.9458
20:26:46.199153 [0] Epoch 00134 | Loss 0.1953
20:26:46.205033 [0] Epoch: 134, Train: 0.9549, Val: 0.9469, Test: 0.9459
20:26:46.472746 [0] Epoch 00135 | Loss 0.1947
20:26:46.478767 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9460
20:26:46.747480 [0] Epoch 00136 | Loss 0.1942
20:26:46.753393 [0] Epoch: 136, Train: 0.9551, Val: 0.9469, Test: 0.9460
20:26:47.022127 [0] Epoch 00137 | Loss 0.1937
20:26:47.028219 [0] Epoch: 137, Train: 0.9552, Val: 0.9470, Test: 0.9461
20:26:47.297411 [0] Epoch 00138 | Loss 0.1932
20:26:47.303229 [0] Epoch: 138, Train: 0.9552, Val: 0.9469, Test: 0.9461
20:26:47.572229 [0] Epoch 00139 | Loss 0.1927
20:26:47.578116 [0] Epoch: 139, Train: 0.9553, Val: 0.9472, Test: 0.9462
20:26:47.847519 [0] Epoch 00140 | Loss 0.1922
20:26:47.854192 [0] Epoch: 140, Train: 0.9554, Val: 0.9471, Test: 0.9463
20:26:48.124005 [0] Epoch 00141 | Loss 0.1917
20:26:48.129965 [0] Epoch: 141, Train: 0.9555, Val: 0.9472, Test: 0.9464
20:26:48.398575 [0] Epoch 00142 | Loss 0.1913
20:26:48.404489 [0] Epoch: 142, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:26:48.674291 [0] Epoch 00143 | Loss 0.1908
20:26:48.680703 [0] Epoch: 143, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:26:48.949968 [0] Epoch 00144 | Loss 0.1903
20:26:48.955567 [0] Epoch: 144, Train: 0.9557, Val: 0.9473, Test: 0.9464
20:26:49.224208 [0] Epoch 00145 | Loss 0.1899
20:26:49.230540 [0] Epoch: 145, Train: 0.9557, Val: 0.9472, Test: 0.9463
20:26:49.500352 [0] Epoch 00146 | Loss 0.1894
20:26:49.506398 [0] Epoch: 146, Train: 0.9558, Val: 0.9471, Test: 0.9464
20:26:49.775793 [0] Epoch 00147 | Loss 0.1889
20:26:49.781889 [0] Epoch: 147, Train: 0.9559, Val: 0.9473, Test: 0.9464
20:26:50.051072 [0] Epoch 00148 | Loss 0.1885
20:26:50.056310 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:26:50.324941 [0] Epoch 00149 | Loss 0.1881
20:26:50.330344 [0] Epoch: 149, Train: 0.9561, Val: 0.9472, Test: 0.9464
20:26:50.599645 [0] Epoch 00150 | Loss 0.1876
20:26:50.604926 [0] Epoch: 150, Train: 0.9561, Val: 0.9471, Test: 0.9464
20:26:50.873302 [0] Epoch 00151 | Loss 0.1872
20:26:50.878779 [0] Epoch: 151, Train: 0.9562, Val: 0.9471, Test: 0.9464
20:26:51.147480 [0] Epoch 00152 | Loss 0.1867
20:26:51.152803 [0] Epoch: 152, Train: 0.9563, Val: 0.9472, Test: 0.9463
20:26:51.421338 [0] Epoch 00153 | Loss 0.1863
20:26:51.426707 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9464
20:26:51.695987 [0] Epoch 00154 | Loss 0.1859
20:26:51.701241 [0] Epoch: 154, Train: 0.9565, Val: 0.9472, Test: 0.9463
20:26:51.969232 [0] Epoch 00155 | Loss 0.1855
20:26:51.975241 [0] Epoch: 155, Train: 0.9566, Val: 0.9473, Test: 0.9464
20:26:52.244066 [0] Epoch 00156 | Loss 0.1850
20:26:52.249338 [0] Epoch: 156, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:26:52.518024 [0] Epoch 00157 | Loss 0.1846
20:26:52.523267 [0] Epoch: 157, Train: 0.9567, Val: 0.9473, Test: 0.9463
20:26:52.791954 [0] Epoch 00158 | Loss 0.1842
20:26:52.797981 [0] Epoch: 158, Train: 0.9568, Val: 0.9471, Test: 0.9464
20:26:53.066839 [0] Epoch 00159 | Loss 0.1838
20:26:53.072132 [0] Epoch: 159, Train: 0.9569, Val: 0.9471, Test: 0.9464
20:26:53.340745 [0] Epoch 00160 | Loss 0.1834
20:26:53.346069 [0] Epoch: 160, Train: 0.9569, Val: 0.9472, Test: 0.9463
20:26:53.614930 [0] Epoch 00161 | Loss 0.1830
20:26:53.620309 [0] Epoch: 161, Train: 0.9570, Val: 0.9473, Test: 0.9464
20:26:53.889542 [0] Epoch 00162 | Loss 0.1826
20:26:53.894859 [0] Epoch: 162, Train: 0.9571, Val: 0.9471, Test: 0.9465
20:26:54.164328 [0] Epoch 00163 | Loss 0.1822
20:26:54.169697 [0] Epoch: 163, Train: 0.9572, Val: 0.9470, Test: 0.9464
20:26:54.438749 [0] Epoch 00164 | Loss 0.1818
20:26:54.444713 [0] Epoch: 164, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:26:54.712967 [0] Epoch 00165 | Loss 0.1814
20:26:54.718215 [0] Epoch: 165, Train: 0.9574, Val: 0.9470, Test: 0.9465
20:26:54.986333 [0] Epoch 00166 | Loss 0.1810
20:26:54.992366 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:26:55.260728 [0] Epoch 00167 | Loss 0.1806
20:26:55.266015 [0] Epoch: 167, Train: 0.9576, Val: 0.9470, Test: 0.9465
20:26:55.535042 [0] Epoch 00168 | Loss 0.1802
20:26:55.540550 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:26:55.809392 [0] Epoch 00169 | Loss 0.1799
20:26:55.815077 [0] Epoch: 169, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:26:56.083736 [0] Epoch 00170 | Loss 0.1795
20:26:56.089211 [0] Epoch: 170, Train: 0.9578, Val: 0.9471, Test: 0.9467
20:26:56.359374 [0] Epoch 00171 | Loss 0.1791
20:26:56.365031 [0] Epoch: 171, Train: 0.9579, Val: 0.9472, Test: 0.9467
20:26:56.634584 [0] Epoch 00172 | Loss 0.1787
20:26:56.639821 [0] Epoch: 172, Train: 0.9580, Val: 0.9473, Test: 0.9467
20:26:56.907493 [0] Epoch 00173 | Loss 0.1783
20:26:56.912997 [0] Epoch: 173, Train: 0.9581, Val: 0.9473, Test: 0.9467
20:26:57.181719 [0] Epoch 00174 | Loss 0.1780
20:26:57.187007 [0] Epoch: 174, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:26:57.454718 [0] Epoch 00175 | Loss 0.1776
20:26:57.460045 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:26:57.728982 [0] Epoch 00176 | Loss 0.1772
20:26:57.734193 [0] Epoch: 176, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:26:58.003492 [0] Epoch 00177 | Loss 0.1769
20:26:58.008836 [0] Epoch: 177, Train: 0.9583, Val: 0.9475, Test: 0.9468
20:26:58.277957 [0] Epoch 00178 | Loss 0.1765
20:26:58.283275 [0] Epoch: 178, Train: 0.9584, Val: 0.9476, Test: 0.9468
20:26:58.552398 [0] Epoch 00179 | Loss 0.1762
20:26:58.558443 [0] Epoch: 179, Train: 0.9584, Val: 0.9475, Test: 0.9468
20:26:58.828072 [0] Epoch 00180 | Loss 0.1758
20:26:58.834743 [0] Epoch: 180, Train: 0.9585, Val: 0.9475, Test: 0.9468
20:26:59.104265 [0] Epoch 00181 | Loss 0.1754
20:26:59.109566 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:26:59.379999 [0] Epoch 00182 | Loss 0.1751
20:26:59.386093 [0] Epoch: 182, Train: 0.9587, Val: 0.9476, Test: 0.9469
20:26:59.654830 [0] Epoch 00183 | Loss 0.1747
20:26:59.660105 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9469
20:26:59.928039 [0] Epoch 00184 | Loss 0.1744
20:26:59.934123 [0] Epoch: 184, Train: 0.9588, Val: 0.9475, Test: 0.9470
20:27:00.202298 [0] Epoch 00185 | Loss 0.1740
20:27:00.207590 [0] Epoch: 185, Train: 0.9589, Val: 0.9475, Test: 0.9470
20:27:00.475719 [0] Epoch 00186 | Loss 0.1737
20:27:00.481076 [0] Epoch: 186, Train: 0.9590, Val: 0.9474, Test: 0.9469
20:27:00.749076 [0] Epoch 00187 | Loss 0.1733
20:27:00.754402 [0] Epoch: 187, Train: 0.9590, Val: 0.9474, Test: 0.9471
20:27:01.023244 [0] Epoch 00188 | Loss 0.1730
20:27:01.029108 [0] Epoch: 188, Train: 0.9591, Val: 0.9474, Test: 0.9469
20:27:01.298108 [0] Epoch 00189 | Loss 0.1727
20:27:01.304017 [0] Epoch: 189, Train: 0.9592, Val: 0.9475, Test: 0.9470
20:27:01.573326 [0] Epoch 00190 | Loss 0.1724
20:27:01.578542 [0] Epoch: 190, Train: 0.9591, Val: 0.9476, Test: 0.9470
20:27:01.846365 [0] Epoch 00191 | Loss 0.1722
20:27:01.851724 [0] Epoch: 191, Train: 0.9593, Val: 0.9474, Test: 0.9468
20:27:02.126156 [0] Epoch 00192 | Loss 0.1722
20:27:02.133156 [0] Epoch: 192, Train: 0.9591, Val: 0.9478, Test: 0.9469
20:27:02.409356 [0] Epoch 00193 | Loss 0.1725
20:27:02.415306 [0] Epoch: 193, Train: 0.9590, Val: 0.9470, Test: 0.9461
20:27:02.690949 [0] Epoch 00194 | Loss 0.1718
20:27:02.696915 [0] Epoch: 194, Train: 0.9594, Val: 0.9478, Test: 0.9470
20:27:02.972889 [0] Epoch 00195 | Loss 0.1707
20:27:02.979243 [0] Epoch: 195, Train: 0.9597, Val: 0.9475, Test: 0.9471
20:27:03.256431 [0] Epoch 00196 | Loss 0.1708
20:27:03.263534 [0] Epoch: 196, Train: 0.9597, Val: 0.9476, Test: 0.9469
20:27:03.533368 [0] Epoch 00197 | Loss 0.1707
20:27:03.540130 [0] Epoch: 197, Train: 0.9596, Val: 0.9478, Test: 0.9471
20:27:03.810079 [0] Epoch 00198 | Loss 0.1699
20:27:03.815466 [0] Epoch: 198, Train: 0.9598, Val: 0.9474, Test: 0.9471
20:27:04.084902 [0] Epoch 00199 | Loss 0.1695
20:27:04.090298 [0] Epoch: 199, Train: 0.9599, Val: 0.9476, Test: 0.9470
20:27:04.092592 [0] 
timer summary:
  3.20s   0.30s   200 broadcast ForwardL1 0
 16.36s   0.91s  2400 broadcast
 35.38s   0.85s  2400 spmm
  2.61s   0.19s   200 broadcast ForwardL1 1
  2.78s   0.09s   200 broadcast ForwardL1 2
  1.18s   0.00s   800 mm
  1.26s   0.24s   200 broadcast ForwardL2 0
  1.12s   0.10s   200 broadcast ForwardL2 1
  1.17s   0.07s   200 broadcast ForwardL2 2
  0.29s   0.14s   200 broadcast BackwardL2 0
  0.21s   0.09s   200 broadcast BackwardL2 1
  0.22s   0.10s   200 broadcast BackwardL2 2
  0.29s   0.16s   400 all_reduce
  1.12s   0.09s   200 broadcast BackwardL1 0
  1.12s   0.10s   200 broadcast BackwardL1 1
  1.17s   0.07s   200 broadcast BackwardL1 2
 56.33s   0.22s   200 epoch
 61.61s   0.04s     1 total
20:27:14.956372 [0] proc begin: <DistEnv 0/3 nccl>
20:27:19.539729 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 77655, |E|: 39304930>
20:27:19.549814 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 493092 KiB | 494913 KiB | 498781 KiB |   5688 KiB |
|       from large pool | 491500 KiB | 493320 KiB | 496960 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1820 KiB |    228 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 522240 KiB | 522240 KiB | 522240 KiB |      0 B   |
|       from large pool | 520192 KiB | 520192 KiB | 520192 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  28151 KiB |  28151 KiB |  37225 KiB |   9074 KiB |
|       from large pool |  27697 KiB |  27697 KiB |  33580 KiB |   5883 KiB |
|       from small pool |    453 KiB |   1820 KiB |   3644 KiB |   3191 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       9    |       9    |       9    |       0    |
|       from large pool |       8    |       8    |       8    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       7    |       7    |      11    |       4    |
|       from large pool |       6    |       6    |       9    |       3    |
|       from small pool |       1    |       1    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:27:21.654253 [0] Epoch 00000 | Loss 3.8004
20:27:21.686430 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:27:21.962196 [0] Epoch 00001 | Loss 3.4369
20:27:21.967845 [0] Epoch: 001, Train: 0.1158, Val: 0.1018, Test: 0.0997
20:27:22.239774 [0] Epoch 00002 | Loss 3.2880
20:27:22.245822 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1945
20:27:22.519446 [0] Epoch 00003 | Loss 3.1591
20:27:22.525378 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:27:22.798229 [0] Epoch 00004 | Loss 3.0520
20:27:22.804189 [0] Epoch: 004, Train: 0.2965, Val: 0.2739, Test: 0.2734
20:27:23.076340 [0] Epoch 00005 | Loss 2.9471
20:27:23.081925 [0] Epoch: 005, Train: 0.3216, Val: 0.2996, Test: 0.2995
20:27:23.353529 [0] Epoch 00006 | Loss 2.8366
20:27:23.359372 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:27:23.631127 [0] Epoch 00007 | Loss 2.7157
20:27:23.636704 [0] Epoch: 007, Train: 0.4122, Val: 0.4159, Test: 0.4215
20:27:23.908934 [0] Epoch 00008 | Loss 2.5811
20:27:23.914535 [0] Epoch: 008, Train: 0.4968, Val: 0.4999, Test: 0.5063
20:27:24.184388 [0] Epoch 00009 | Loss 2.4334
20:27:24.189909 [0] Epoch: 009, Train: 0.5324, Val: 0.5318, Test: 0.5379
20:27:24.460297 [0] Epoch 00010 | Loss 2.2772
20:27:24.465728 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:27:24.735088 [0] Epoch 00011 | Loss 2.1108
20:27:24.741789 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:27:25.012771 [0] Epoch 00012 | Loss 1.9380
20:27:25.019522 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:27:25.289037 [0] Epoch 00013 | Loss 1.7631
20:27:25.294382 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:27:25.563691 [0] Epoch 00014 | Loss 1.6014
20:27:25.568999 [0] Epoch: 014, Train: 0.6305, Val: 0.6296, Test: 0.6292
20:27:25.838007 [0] Epoch 00015 | Loss 1.4665
20:27:25.843316 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:27:26.113379 [0] Epoch 00016 | Loss 1.3549
20:27:26.118678 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6841
20:27:26.388789 [0] Epoch 00017 | Loss 1.2613
20:27:26.394195 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:27:26.663919 [0] Epoch 00018 | Loss 1.1713
20:27:26.669240 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:27:26.938554 [0] Epoch 00019 | Loss 1.0767
20:27:26.944068 [0] Epoch: 019, Train: 0.7521, Val: 0.7491, Test: 0.7448
20:27:27.214702 [0] Epoch 00020 | Loss 0.9920
20:27:27.220123 [0] Epoch: 020, Train: 0.7804, Val: 0.7726, Test: 0.7677
20:27:27.489883 [0] Epoch 00021 | Loss 0.9222
20:27:27.495201 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7842
20:27:27.764759 [0] Epoch 00022 | Loss 0.8643
20:27:27.770461 [0] Epoch: 022, Train: 0.8195, Val: 0.8089, Test: 0.8046
20:27:28.040162 [0] Epoch 00023 | Loss 0.8168
20:27:28.045747 [0] Epoch: 023, Train: 0.8334, Val: 0.8219, Test: 0.8177
20:27:28.315496 [0] Epoch 00024 | Loss 0.7759
20:27:28.320807 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:27:28.591133 [0] Epoch 00025 | Loss 0.7380
20:27:28.596483 [0] Epoch: 025, Train: 0.8491, Val: 0.8363, Test: 0.8331
20:27:28.866647 [0] Epoch 00026 | Loss 0.7005
20:27:28.872656 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:27:29.144276 [0] Epoch 00027 | Loss 0.6622
20:27:29.150594 [0] Epoch: 027, Train: 0.8800, Val: 0.8747, Test: 0.8733
20:27:29.420666 [0] Epoch 00028 | Loss 0.6219
20:27:29.426080 [0] Epoch: 028, Train: 0.9001, Val: 0.9019, Test: 0.9000
20:27:29.697097 [0] Epoch 00029 | Loss 0.5795
20:27:29.703910 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:27:29.974395 [0] Epoch 00030 | Loss 0.5362
20:27:29.981022 [0] Epoch: 030, Train: 0.9091, Val: 0.9126, Test: 0.9107
20:27:30.251273 [0] Epoch 00031 | Loss 0.4958
20:27:30.257804 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:27:30.528859 [0] Epoch 00032 | Loss 0.4624
20:27:30.534190 [0] Epoch: 032, Train: 0.9163, Val: 0.9202, Test: 0.9185
20:27:30.803925 [0] Epoch 00033 | Loss 0.4368
20:27:30.809194 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:27:31.079519 [0] Epoch 00034 | Loss 0.4162
20:27:31.084824 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:27:31.353193 [0] Epoch 00035 | Loss 0.3991
20:27:31.358507 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:27:31.627561 [0] Epoch 00036 | Loss 0.3851
20:27:31.632854 [0] Epoch: 036, Train: 0.9274, Val: 0.9320, Test: 0.9291
20:27:31.901275 [0] Epoch 00037 | Loss 0.3738
20:27:31.906626 [0] Epoch: 037, Train: 0.9283, Val: 0.9322, Test: 0.9306
20:27:32.175473 [0] Epoch 00038 | Loss 0.3643
20:27:32.180740 [0] Epoch: 038, Train: 0.9291, Val: 0.9328, Test: 0.9308
20:27:32.449357 [0] Epoch 00039 | Loss 0.3556
20:27:32.455638 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9317
20:27:32.725468 [0] Epoch 00040 | Loss 0.3470
20:27:32.732225 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9328
20:27:33.000512 [0] Epoch 00041 | Loss 0.3389
20:27:33.008143 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:27:33.278993 [0] Epoch 00042 | Loss 0.3321
20:27:33.284581 [0] Epoch: 042, Train: 0.9339, Val: 0.9360, Test: 0.9352
20:27:33.553950 [0] Epoch 00043 | Loss 0.3271
20:27:33.559858 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:27:33.830393 [0] Epoch 00044 | Loss 0.3232
20:27:33.835920 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:27:34.105564 [0] Epoch 00045 | Loss 0.3190
20:27:34.112280 [0] Epoch: 045, Train: 0.9357, Val: 0.9371, Test: 0.9368
20:27:34.382431 [0] Epoch 00046 | Loss 0.3144
20:27:34.389075 [0] Epoch: 046, Train: 0.9364, Val: 0.9376, Test: 0.9374
20:27:34.658303 [0] Epoch 00047 | Loss 0.3102
20:27:34.663966 [0] Epoch: 047, Train: 0.9366, Val: 0.9380, Test: 0.9376
20:27:34.933945 [0] Epoch 00048 | Loss 0.3063
20:27:34.940107 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:27:35.209648 [0] Epoch 00049 | Loss 0.3023
20:27:35.216298 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:27:35.484881 [0] Epoch 00050 | Loss 0.2985
20:27:35.490662 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:27:35.760330 [0] Epoch 00051 | Loss 0.2950
20:27:35.766267 [0] Epoch: 051, Train: 0.9382, Val: 0.9382, Test: 0.9382
20:27:36.035442 [0] Epoch 00052 | Loss 0.2919
20:27:36.041039 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:27:36.309642 [0] Epoch 00053 | Loss 0.2892
20:27:36.315474 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9384
20:27:36.584885 [0] Epoch 00054 | Loss 0.2861
20:27:36.590680 [0] Epoch: 054, Train: 0.9394, Val: 0.9387, Test: 0.9387
20:27:36.859578 [0] Epoch 00055 | Loss 0.2832
20:27:36.865340 [0] Epoch: 055, Train: 0.9398, Val: 0.9392, Test: 0.9390
20:27:37.135300 [0] Epoch 00056 | Loss 0.2807
20:27:37.140992 [0] Epoch: 056, Train: 0.9402, Val: 0.9396, Test: 0.9394
20:27:37.409462 [0] Epoch 00057 | Loss 0.2782
20:27:37.415215 [0] Epoch: 057, Train: 0.9406, Val: 0.9398, Test: 0.9396
20:27:37.683744 [0] Epoch 00058 | Loss 0.2756
20:27:37.689673 [0] Epoch: 058, Train: 0.9410, Val: 0.9403, Test: 0.9401
20:27:37.957671 [0] Epoch 00059 | Loss 0.2729
20:27:37.964814 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:27:38.234159 [0] Epoch 00060 | Loss 0.2705
20:27:38.239759 [0] Epoch: 060, Train: 0.9421, Val: 0.9406, Test: 0.9404
20:27:38.507761 [0] Epoch 00061 | Loss 0.2683
20:27:38.513419 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9403
20:27:38.782259 [0] Epoch 00062 | Loss 0.2662
20:27:38.788416 [0] Epoch: 062, Train: 0.9427, Val: 0.9409, Test: 0.9404
20:27:39.059441 [0] Epoch 00063 | Loss 0.2641
20:27:39.066203 [0] Epoch: 063, Train: 0.9431, Val: 0.9413, Test: 0.9408
20:27:39.335261 [0] Epoch 00064 | Loss 0.2621
20:27:39.342033 [0] Epoch: 064, Train: 0.9433, Val: 0.9412, Test: 0.9409
20:27:39.610856 [0] Epoch 00065 | Loss 0.2601
20:27:39.617431 [0] Epoch: 065, Train: 0.9435, Val: 0.9417, Test: 0.9412
20:27:39.886702 [0] Epoch 00066 | Loss 0.2582
20:27:39.892432 [0] Epoch: 066, Train: 0.9439, Val: 0.9416, Test: 0.9414
20:27:40.162735 [0] Epoch 00067 | Loss 0.2563
20:27:40.169176 [0] Epoch: 067, Train: 0.9442, Val: 0.9419, Test: 0.9414
20:27:40.438506 [0] Epoch 00068 | Loss 0.2545
20:27:40.444036 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:27:40.713127 [0] Epoch 00069 | Loss 0.2529
20:27:40.718914 [0] Epoch: 069, Train: 0.9448, Val: 0.9424, Test: 0.9417
20:27:40.987683 [0] Epoch 00070 | Loss 0.2513
20:27:40.992901 [0] Epoch: 070, Train: 0.9450, Val: 0.9425, Test: 0.9420
20:27:41.261974 [0] Epoch 00071 | Loss 0.2497
20:27:41.268285 [0] Epoch: 071, Train: 0.9452, Val: 0.9424, Test: 0.9421
20:27:41.536976 [0] Epoch 00072 | Loss 0.2483
20:27:41.543216 [0] Epoch: 072, Train: 0.9454, Val: 0.9423, Test: 0.9422
20:27:41.811774 [0] Epoch 00073 | Loss 0.2468
20:27:41.818432 [0] Epoch: 073, Train: 0.9458, Val: 0.9429, Test: 0.9425
20:27:42.088354 [0] Epoch 00074 | Loss 0.2454
20:27:42.094977 [0] Epoch: 074, Train: 0.9460, Val: 0.9431, Test: 0.9426
20:27:42.364023 [0] Epoch 00075 | Loss 0.2440
20:27:42.369751 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:27:42.639392 [0] Epoch 00076 | Loss 0.2426
20:27:42.645048 [0] Epoch: 076, Train: 0.9465, Val: 0.9430, Test: 0.9424
20:27:42.915443 [0] Epoch 00077 | Loss 0.2412
20:27:42.921219 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:27:43.190484 [0] Epoch 00078 | Loss 0.2399
20:27:43.195830 [0] Epoch: 078, Train: 0.9468, Val: 0.9431, Test: 0.9425
20:27:43.464507 [0] Epoch 00079 | Loss 0.2386
20:27:43.470227 [0] Epoch: 079, Train: 0.9470, Val: 0.9429, Test: 0.9426
20:27:43.739611 [0] Epoch 00080 | Loss 0.2374
20:27:43.745073 [0] Epoch: 080, Train: 0.9472, Val: 0.9428, Test: 0.9427
20:27:44.014106 [0] Epoch 00081 | Loss 0.2362
20:27:44.019754 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9427
20:27:44.288627 [0] Epoch 00082 | Loss 0.2350
20:27:44.293901 [0] Epoch: 082, Train: 0.9476, Val: 0.9427, Test: 0.9428
20:27:44.563116 [0] Epoch 00083 | Loss 0.2339
20:27:44.569710 [0] Epoch: 083, Train: 0.9478, Val: 0.9429, Test: 0.9430
20:27:44.838678 [0] Epoch 00084 | Loss 0.2328
20:27:44.845255 [0] Epoch: 084, Train: 0.9479, Val: 0.9431, Test: 0.9431
20:27:45.113992 [0] Epoch 00085 | Loss 0.2317
20:27:45.119445 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9434
20:27:45.387918 [0] Epoch 00086 | Loss 0.2307
20:27:45.393727 [0] Epoch: 086, Train: 0.9482, Val: 0.9431, Test: 0.9435
20:27:45.662627 [0] Epoch 00087 | Loss 0.2297
20:27:45.668428 [0] Epoch: 087, Train: 0.9483, Val: 0.9430, Test: 0.9435
20:27:45.939520 [0] Epoch 00088 | Loss 0.2287
20:27:45.944797 [0] Epoch: 088, Train: 0.9487, Val: 0.9432, Test: 0.9436
20:27:46.212713 [0] Epoch 00089 | Loss 0.2277
20:27:46.218725 [0] Epoch: 089, Train: 0.9490, Val: 0.9435, Test: 0.9436
20:27:46.487591 [0] Epoch 00090 | Loss 0.2267
20:27:46.492846 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9437
20:27:46.760555 [0] Epoch 00091 | Loss 0.2258
20:27:46.766400 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9440
20:27:47.036566 [0] Epoch 00092 | Loss 0.2248
20:27:47.043176 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9440
20:27:47.311756 [0] Epoch 00093 | Loss 0.2239
20:27:47.317581 [0] Epoch: 093, Train: 0.9497, Val: 0.9440, Test: 0.9441
20:27:47.586439 [0] Epoch 00094 | Loss 0.2229
20:27:47.591707 [0] Epoch: 094, Train: 0.9499, Val: 0.9442, Test: 0.9440
20:27:47.860039 [0] Epoch 00095 | Loss 0.2221
20:27:47.865324 [0] Epoch: 095, Train: 0.9500, Val: 0.9444, Test: 0.9442
20:27:48.134739 [0] Epoch 00096 | Loss 0.2212
20:27:48.140113 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9443
20:27:48.408259 [0] Epoch 00097 | Loss 0.2203
20:27:48.413553 [0] Epoch: 097, Train: 0.9502, Val: 0.9445, Test: 0.9446
20:27:48.681683 [0] Epoch 00098 | Loss 0.2195
20:27:48.687037 [0] Epoch: 098, Train: 0.9504, Val: 0.9446, Test: 0.9447
20:27:48.955819 [0] Epoch 00099 | Loss 0.2186
20:27:48.962239 [0] Epoch: 099, Train: 0.9506, Val: 0.9447, Test: 0.9449
20:27:49.231433 [0] Epoch 00100 | Loss 0.2177
20:27:49.237293 [0] Epoch: 100, Train: 0.9508, Val: 0.9450, Test: 0.9448
20:27:49.505460 [0] Epoch 00101 | Loss 0.2169
20:27:49.510793 [0] Epoch: 101, Train: 0.9510, Val: 0.9451, Test: 0.9449
20:27:49.779479 [0] Epoch 00102 | Loss 0.2161
20:27:49.784781 [0] Epoch: 102, Train: 0.9512, Val: 0.9452, Test: 0.9450
20:27:50.053535 [0] Epoch 00103 | Loss 0.2153
20:27:50.059056 [0] Epoch: 103, Train: 0.9513, Val: 0.9451, Test: 0.9450
20:27:50.327888 [0] Epoch 00104 | Loss 0.2145
20:27:50.333857 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9450
20:27:50.602106 [0] Epoch 00105 | Loss 0.2137
20:27:50.608009 [0] Epoch: 105, Train: 0.9516, Val: 0.9454, Test: 0.9451
20:27:50.878454 [0] Epoch 00106 | Loss 0.2129
20:27:50.883897 [0] Epoch: 106, Train: 0.9517, Val: 0.9455, Test: 0.9452
20:27:51.153236 [0] Epoch 00107 | Loss 0.2122
20:27:51.158652 [0] Epoch: 107, Train: 0.9519, Val: 0.9455, Test: 0.9453
20:27:51.427751 [0] Epoch 00108 | Loss 0.2115
20:27:51.433541 [0] Epoch: 108, Train: 0.9521, Val: 0.9455, Test: 0.9453
20:27:51.702802 [0] Epoch 00109 | Loss 0.2108
20:27:51.709454 [0] Epoch: 109, Train: 0.9520, Val: 0.9454, Test: 0.9454
20:27:51.978659 [0] Epoch 00110 | Loss 0.2101
20:27:51.985339 [0] Epoch: 110, Train: 0.9523, Val: 0.9458, Test: 0.9454
20:27:52.254054 [0] Epoch 00111 | Loss 0.2094
20:27:52.259453 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:27:52.528709 [0] Epoch 00112 | Loss 0.2087
20:27:52.533964 [0] Epoch: 112, Train: 0.9525, Val: 0.9455, Test: 0.9454
20:27:52.801777 [0] Epoch 00113 | Loss 0.2080
20:27:52.807265 [0] Epoch: 113, Train: 0.9526, Val: 0.9455, Test: 0.9454
20:27:53.076757 [0] Epoch 00114 | Loss 0.2073
20:27:53.083491 [0] Epoch: 114, Train: 0.9527, Val: 0.9455, Test: 0.9454
20:27:53.352644 [0] Epoch 00115 | Loss 0.2066
20:27:53.359331 [0] Epoch: 115, Train: 0.9528, Val: 0.9456, Test: 0.9455
20:27:53.628050 [0] Epoch 00116 | Loss 0.2059
20:27:53.633445 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9455
20:27:53.901873 [0] Epoch 00117 | Loss 0.2053
20:27:53.907222 [0] Epoch: 117, Train: 0.9531, Val: 0.9458, Test: 0.9456
20:27:54.176410 [0] Epoch 00118 | Loss 0.2046
20:27:54.181870 [0] Epoch: 118, Train: 0.9533, Val: 0.9459, Test: 0.9457
20:27:54.450017 [0] Epoch 00119 | Loss 0.2040
20:27:54.455597 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:27:54.724336 [0] Epoch 00120 | Loss 0.2034
20:27:54.731171 [0] Epoch: 120, Train: 0.9534, Val: 0.9460, Test: 0.9459
20:27:54.999984 [0] Epoch 00121 | Loss 0.2027
20:27:55.005306 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9460
20:27:55.273883 [0] Epoch 00122 | Loss 0.2021
20:27:55.279213 [0] Epoch: 122, Train: 0.9536, Val: 0.9461, Test: 0.9460
20:27:55.546778 [0] Epoch 00123 | Loss 0.2015
20:27:55.552127 [0] Epoch: 123, Train: 0.9537, Val: 0.9462, Test: 0.9459
20:27:55.820222 [0] Epoch 00124 | Loss 0.2009
20:27:55.825532 [0] Epoch: 124, Train: 0.9538, Val: 0.9462, Test: 0.9459
20:27:56.094920 [0] Epoch 00125 | Loss 0.2003
20:27:56.100243 [0] Epoch: 125, Train: 0.9539, Val: 0.9462, Test: 0.9459
20:27:56.368154 [0] Epoch 00126 | Loss 0.1997
20:27:56.373496 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9459
20:27:56.643310 [0] Epoch 00127 | Loss 0.1992
20:27:56.648655 [0] Epoch: 127, Train: 0.9541, Val: 0.9468, Test: 0.9459
20:27:56.917432 [0] Epoch 00128 | Loss 0.1986
20:27:56.922753 [0] Epoch: 128, Train: 0.9543, Val: 0.9467, Test: 0.9459
20:27:57.193116 [0] Epoch 00129 | Loss 0.1980
20:27:57.199779 [0] Epoch: 129, Train: 0.9544, Val: 0.9467, Test: 0.9459
20:27:57.468700 [0] Epoch 00130 | Loss 0.1974
20:27:57.474006 [0] Epoch: 130, Train: 0.9545, Val: 0.9466, Test: 0.9459
20:27:57.742344 [0] Epoch 00131 | Loss 0.1969
20:27:57.747659 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9458
20:27:58.017012 [0] Epoch 00132 | Loss 0.1963
20:27:58.022483 [0] Epoch: 132, Train: 0.9547, Val: 0.9467, Test: 0.9458
20:27:58.291258 [0] Epoch 00133 | Loss 0.1958
20:27:58.297399 [0] Epoch: 133, Train: 0.9548, Val: 0.9468, Test: 0.9458
20:27:58.568078 [0] Epoch 00134 | Loss 0.1953
20:27:58.574318 [0] Epoch: 134, Train: 0.9549, Val: 0.9468, Test: 0.9460
20:27:58.844830 [0] Epoch 00135 | Loss 0.1947
20:27:58.850321 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9460
20:27:59.120115 [0] Epoch 00136 | Loss 0.1942
20:27:59.126005 [0] Epoch: 136, Train: 0.9551, Val: 0.9469, Test: 0.9460
20:27:59.395266 [0] Epoch 00137 | Loss 0.1937
20:27:59.400908 [0] Epoch: 137, Train: 0.9552, Val: 0.9469, Test: 0.9461
20:27:59.670128 [0] Epoch 00138 | Loss 0.1932
20:27:59.675694 [0] Epoch: 138, Train: 0.9552, Val: 0.9470, Test: 0.9461
20:27:59.944742 [0] Epoch 00139 | Loss 0.1927
20:27:59.950035 [0] Epoch: 139, Train: 0.9553, Val: 0.9471, Test: 0.9462
20:28:00.219995 [0] Epoch 00140 | Loss 0.1922
20:28:00.225642 [0] Epoch: 140, Train: 0.9554, Val: 0.9472, Test: 0.9463
20:28:00.495491 [0] Epoch 00141 | Loss 0.1917
20:28:00.500832 [0] Epoch: 141, Train: 0.9555, Val: 0.9473, Test: 0.9464
20:28:00.769390 [0] Epoch 00142 | Loss 0.1913
20:28:00.774686 [0] Epoch: 142, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:28:01.044222 [0] Epoch 00143 | Loss 0.1908
20:28:01.049562 [0] Epoch: 143, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:28:01.319180 [0] Epoch 00144 | Loss 0.1903
20:28:01.324737 [0] Epoch: 144, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:28:01.598052 [0] Epoch 00145 | Loss 0.1899
20:28:01.603976 [0] Epoch: 145, Train: 0.9557, Val: 0.9473, Test: 0.9464
20:28:01.880522 [0] Epoch 00146 | Loss 0.1894
20:28:01.886478 [0] Epoch: 146, Train: 0.9558, Val: 0.9472, Test: 0.9464
20:28:02.162321 [0] Epoch 00147 | Loss 0.1889
20:28:02.168140 [0] Epoch: 147, Train: 0.9559, Val: 0.9473, Test: 0.9464
20:28:02.443764 [0] Epoch 00148 | Loss 0.1885
20:28:02.450001 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:28:02.726093 [0] Epoch 00149 | Loss 0.1881
20:28:02.731680 [0] Epoch: 149, Train: 0.9561, Val: 0.9472, Test: 0.9463
20:28:03.002098 [0] Epoch 00150 | Loss 0.1876
20:28:03.008769 [0] Epoch: 150, Train: 0.9561, Val: 0.9471, Test: 0.9464
20:28:03.278134 [0] Epoch 00151 | Loss 0.1872
20:28:03.283534 [0] Epoch: 151, Train: 0.9562, Val: 0.9471, Test: 0.9464
20:28:03.552357 [0] Epoch 00152 | Loss 0.1867
20:28:03.557631 [0] Epoch: 152, Train: 0.9563, Val: 0.9472, Test: 0.9464
20:28:03.827271 [0] Epoch 00153 | Loss 0.1863
20:28:03.833974 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9464
20:28:04.103725 [0] Epoch 00154 | Loss 0.1859
20:28:04.109149 [0] Epoch: 154, Train: 0.9565, Val: 0.9472, Test: 0.9463
20:28:04.379466 [0] Epoch 00155 | Loss 0.1855
20:28:04.384932 [0] Epoch: 155, Train: 0.9566, Val: 0.9472, Test: 0.9464
20:28:04.655519 [0] Epoch 00156 | Loss 0.1850
20:28:04.661644 [0] Epoch: 156, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:28:04.931540 [0] Epoch 00157 | Loss 0.1846
20:28:04.937152 [0] Epoch: 157, Train: 0.9567, Val: 0.9472, Test: 0.9463
20:28:05.207270 [0] Epoch 00158 | Loss 0.1842
20:28:05.212725 [0] Epoch: 158, Train: 0.9568, Val: 0.9471, Test: 0.9464
20:28:05.482658 [0] Epoch 00159 | Loss 0.1838
20:28:05.488086 [0] Epoch: 159, Train: 0.9569, Val: 0.9471, Test: 0.9463
20:28:05.758714 [0] Epoch 00160 | Loss 0.1834
20:28:05.764364 [0] Epoch: 160, Train: 0.9569, Val: 0.9473, Test: 0.9464
20:28:06.033983 [0] Epoch 00161 | Loss 0.1830
20:28:06.039859 [0] Epoch: 161, Train: 0.9570, Val: 0.9473, Test: 0.9464
20:28:06.310661 [0] Epoch 00162 | Loss 0.1826
20:28:06.316087 [0] Epoch: 162, Train: 0.9571, Val: 0.9472, Test: 0.9465
20:28:06.585452 [0] Epoch 00163 | Loss 0.1822
20:28:06.590988 [0] Epoch: 163, Train: 0.9572, Val: 0.9470, Test: 0.9465
20:28:06.860357 [0] Epoch 00164 | Loss 0.1818
20:28:06.866328 [0] Epoch: 164, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:28:07.136742 [0] Epoch 00165 | Loss 0.1814
20:28:07.143541 [0] Epoch: 165, Train: 0.9574, Val: 0.9470, Test: 0.9465
20:28:07.413131 [0] Epoch 00166 | Loss 0.1810
20:28:07.418610 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:28:07.688107 [0] Epoch 00167 | Loss 0.1806
20:28:07.694748 [0] Epoch: 167, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:28:07.964841 [0] Epoch 00168 | Loss 0.1802
20:28:07.970878 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:28:08.240249 [0] Epoch 00169 | Loss 0.1798
20:28:08.245655 [0] Epoch: 169, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:28:08.515620 [0] Epoch 00170 | Loss 0.1795
20:28:08.521512 [0] Epoch: 170, Train: 0.9578, Val: 0.9471, Test: 0.9466
20:28:08.792199 [0] Epoch 00171 | Loss 0.1791
20:28:08.798446 [0] Epoch: 171, Train: 0.9579, Val: 0.9472, Test: 0.9467
20:28:09.068471 [0] Epoch 00172 | Loss 0.1787
20:28:09.075355 [0] Epoch: 172, Train: 0.9580, Val: 0.9473, Test: 0.9467
20:28:09.345115 [0] Epoch 00173 | Loss 0.1783
20:28:09.350651 [0] Epoch: 173, Train: 0.9581, Val: 0.9473, Test: 0.9467
20:28:09.619740 [0] Epoch 00174 | Loss 0.1780
20:28:09.625426 [0] Epoch: 174, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:28:09.894708 [0] Epoch 00175 | Loss 0.1776
20:28:09.900081 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:28:10.170091 [0] Epoch 00176 | Loss 0.1772
20:28:10.175956 [0] Epoch: 176, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:28:10.445296 [0] Epoch 00177 | Loss 0.1769
20:28:10.450602 [0] Epoch: 177, Train: 0.9583, Val: 0.9474, Test: 0.9468
20:28:10.720589 [0] Epoch 00178 | Loss 0.1765
20:28:10.725898 [0] Epoch: 178, Train: 0.9584, Val: 0.9475, Test: 0.9467
20:28:10.994766 [0] Epoch 00179 | Loss 0.1762
20:28:11.000855 [0] Epoch: 179, Train: 0.9584, Val: 0.9475, Test: 0.9467
20:28:11.271039 [0] Epoch 00180 | Loss 0.1758
20:28:11.276335 [0] Epoch: 180, Train: 0.9585, Val: 0.9475, Test: 0.9468
20:28:11.544803 [0] Epoch 00181 | Loss 0.1754
20:28:11.550762 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:28:11.820157 [0] Epoch 00182 | Loss 0.1751
20:28:11.825650 [0] Epoch: 182, Train: 0.9587, Val: 0.9476, Test: 0.9469
20:28:12.094489 [0] Epoch 00183 | Loss 0.1747
20:28:12.099898 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9469
20:28:12.369962 [0] Epoch 00184 | Loss 0.1744
20:28:12.375326 [0] Epoch: 184, Train: 0.9589, Val: 0.9475, Test: 0.9470
20:28:12.643786 [0] Epoch 00185 | Loss 0.1740
20:28:12.650393 [0] Epoch: 185, Train: 0.9588, Val: 0.9474, Test: 0.9470
20:28:12.920587 [0] Epoch 00186 | Loss 0.1737
20:28:12.926294 [0] Epoch: 186, Train: 0.9590, Val: 0.9474, Test: 0.9470
20:28:13.195968 [0] Epoch 00187 | Loss 0.1734
20:28:13.201644 [0] Epoch: 187, Train: 0.9590, Val: 0.9476, Test: 0.9469
20:28:13.471114 [0] Epoch 00188 | Loss 0.1731
20:28:13.476677 [0] Epoch: 188, Train: 0.9590, Val: 0.9473, Test: 0.9468
20:28:13.746082 [0] Epoch 00189 | Loss 0.1730
20:28:13.751619 [0] Epoch: 189, Train: 0.9590, Val: 0.9479, Test: 0.9469
20:28:14.021912 [0] Epoch 00190 | Loss 0.1730
20:28:14.028672 [0] Epoch: 190, Train: 0.9590, Val: 0.9470, Test: 0.9464
20:28:14.298434 [0] Epoch 00191 | Loss 0.1726
20:28:14.304455 [0] Epoch: 191, Train: 0.9591, Val: 0.9480, Test: 0.9468
20:28:14.573829 [0] Epoch 00192 | Loss 0.1718
20:28:14.579561 [0] Epoch: 192, Train: 0.9595, Val: 0.9474, Test: 0.9470
20:28:14.849161 [0] Epoch 00193 | Loss 0.1714
20:28:14.854986 [0] Epoch: 193, Train: 0.9595, Val: 0.9475, Test: 0.9470
20:28:15.125530 [0] Epoch 00194 | Loss 0.1714
20:28:15.131447 [0] Epoch: 194, Train: 0.9595, Val: 0.9479, Test: 0.9470
20:28:15.401132 [0] Epoch 00195 | Loss 0.1711
20:28:15.407064 [0] Epoch: 195, Train: 0.9596, Val: 0.9473, Test: 0.9468
20:28:15.676467 [0] Epoch 00196 | Loss 0.1704
20:28:15.681979 [0] Epoch: 196, Train: 0.9596, Val: 0.9475, Test: 0.9469
20:28:15.952392 [0] Epoch 00197 | Loss 0.1703
20:28:15.958228 [0] Epoch: 197, Train: 0.9597, Val: 0.9479, Test: 0.9470
20:28:16.228418 [0] Epoch 00198 | Loss 0.1702
20:28:16.234301 [0] Epoch: 198, Train: 0.9597, Val: 0.9474, Test: 0.9469
20:28:16.504276 [0] Epoch 00199 | Loss 0.1696
20:28:16.510042 [0] Epoch: 199, Train: 0.9598, Val: 0.9475, Test: 0.9472
20:28:16.514023 [0] 
timer summary:
  3.15s   0.24s   200 broadcast ForwardL1 0
 16.37s   0.81s  2400 broadcast
 35.40s   0.85s  2400 spmm
  2.61s   0.18s   200 broadcast ForwardL1 1
  2.79s   0.09s   200 broadcast ForwardL1 2
  1.19s   0.00s   800 mm
  1.25s   0.24s   200 broadcast ForwardL2 0
  1.13s   0.11s   200 broadcast ForwardL2 1
  1.16s   0.07s   200 broadcast ForwardL2 2
  0.32s   0.14s   200 broadcast BackwardL2 0
  0.24s   0.12s   200 broadcast BackwardL2 1
  0.21s   0.09s   200 broadcast BackwardL2 2
  0.27s   0.16s   400 all_reduce
  1.10s   0.09s   200 broadcast BackwardL1 0
  1.15s   0.11s   200 broadcast BackwardL1 1
  1.17s   0.07s   200 broadcast BackwardL1 2
 56.37s   0.12s   200 epoch
 61.58s   0.03s     1 total
20:30:06.029990 [0] proc begin: <DistEnv 0/3 nccl>
20:30:10.695520 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 77655, |E|: 39304930>
20:30:10.706012 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 494089 KiB | 496051 KiB | 500204 KiB |   6115 KiB |
|       from large pool | 492494 KiB | 494455 KiB | 498377 KiB |   5883 KiB |
|       from small pool |   1594 KiB |   1596 KiB |   1827 KiB |    232 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 493092 KiB | 494913 KiB | 498781 KiB |   5688 KiB |
|       from large pool | 491500 KiB | 493320 KiB | 496960 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1820 KiB |    228 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 522240 KiB | 522240 KiB | 522240 KiB |      0 B   |
|       from large pool | 520192 KiB | 520192 KiB | 520192 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  28151 KiB |  28151 KiB |  37225 KiB |   9074 KiB |
|       from large pool |  27697 KiB |  27697 KiB |  33580 KiB |   5883 KiB |
|       from small pool |    453 KiB |   1820 KiB |   3644 KiB |   3191 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      18    |      27    |      13    |
|       from large pool |       8    |       9    |      11    |       3    |
|       from small pool |       6    |       9    |      16    |      10    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       9    |       9    |       9    |       0    |
|       from large pool |       8    |       8    |       8    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       7    |       7    |      11    |       4    |
|       from large pool |       6    |       6    |       9    |       3    |
|       from small pool |       1    |       1    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:30:12.906715 [0] Epoch 00000 | Loss 3.8004
20:30:12.939256 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:30:13.212631 [0] Epoch 00001 | Loss 3.4369
20:30:13.218620 [0] Epoch: 001, Train: 0.1158, Val: 0.1018, Test: 0.0997
20:30:13.491215 [0] Epoch 00002 | Loss 3.2880
20:30:13.497592 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1945
20:30:13.773991 [0] Epoch 00003 | Loss 3.1591
20:30:13.780710 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:30:14.056587 [0] Epoch 00004 | Loss 3.0520
20:30:14.063267 [0] Epoch: 004, Train: 0.2965, Val: 0.2739, Test: 0.2734
20:30:14.336179 [0] Epoch 00005 | Loss 2.9471
20:30:14.342969 [0] Epoch: 005, Train: 0.3216, Val: 0.2996, Test: 0.2995
20:30:14.615068 [0] Epoch 00006 | Loss 2.8366
20:30:14.620702 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:30:14.892347 [0] Epoch 00007 | Loss 2.7157
20:30:14.897952 [0] Epoch: 007, Train: 0.4122, Val: 0.4159, Test: 0.4215
20:30:15.170179 [0] Epoch 00008 | Loss 2.5811
20:30:15.175715 [0] Epoch: 008, Train: 0.4968, Val: 0.4999, Test: 0.5063
20:30:15.446869 [0] Epoch 00009 | Loss 2.4334
20:30:15.452411 [0] Epoch: 009, Train: 0.5324, Val: 0.5318, Test: 0.5379
20:30:15.724231 [0] Epoch 00010 | Loss 2.2772
20:30:15.730843 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:30:16.002473 [0] Epoch 00011 | Loss 2.1108
20:30:16.008262 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:30:16.280273 [0] Epoch 00012 | Loss 1.9380
20:30:16.285815 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:30:16.557704 [0] Epoch 00013 | Loss 1.7631
20:30:16.564160 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:30:16.834987 [0] Epoch 00014 | Loss 1.6014
20:30:16.841653 [0] Epoch: 014, Train: 0.6305, Val: 0.6296, Test: 0.6292
20:30:17.111585 [0] Epoch 00015 | Loss 1.4665
20:30:17.118257 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:30:17.390081 [0] Epoch 00016 | Loss 1.3549
20:30:17.396845 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6841
20:30:17.667407 [0] Epoch 00017 | Loss 1.2613
20:30:17.673323 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:30:17.942691 [0] Epoch 00018 | Loss 1.1713
20:30:17.948191 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:30:18.217363 [0] Epoch 00019 | Loss 1.0767
20:30:18.222888 [0] Epoch: 019, Train: 0.7521, Val: 0.7491, Test: 0.7448
20:30:18.491845 [0] Epoch 00020 | Loss 0.9920
20:30:18.497513 [0] Epoch: 020, Train: 0.7804, Val: 0.7726, Test: 0.7677
20:30:18.766965 [0] Epoch 00021 | Loss 0.9222
20:30:18.773548 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7842
20:30:19.043495 [0] Epoch 00022 | Loss 0.8643
20:30:19.049121 [0] Epoch: 022, Train: 0.8195, Val: 0.8089, Test: 0.8046
20:30:19.318078 [0] Epoch 00023 | Loss 0.8168
20:30:19.323439 [0] Epoch: 023, Train: 0.8334, Val: 0.8219, Test: 0.8177
20:30:19.592906 [0] Epoch 00024 | Loss 0.7759
20:30:19.598304 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:30:19.867569 [0] Epoch 00025 | Loss 0.7380
20:30:19.873472 [0] Epoch: 025, Train: 0.8491, Val: 0.8363, Test: 0.8331
20:30:20.144659 [0] Epoch 00026 | Loss 0.7005
20:30:20.151465 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:30:20.420121 [0] Epoch 00027 | Loss 0.6622
20:30:20.425549 [0] Epoch: 027, Train: 0.8800, Val: 0.8747, Test: 0.8733
20:30:20.695481 [0] Epoch 00028 | Loss 0.6219
20:30:20.700850 [0] Epoch: 028, Train: 0.9001, Val: 0.9019, Test: 0.9000
20:30:20.972131 [0] Epoch 00029 | Loss 0.5795
20:30:20.978979 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:30:21.249451 [0] Epoch 00030 | Loss 0.5362
20:30:21.254930 [0] Epoch: 030, Train: 0.9091, Val: 0.9126, Test: 0.9107
20:30:21.525136 [0] Epoch 00031 | Loss 0.4958
20:30:21.530531 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:30:21.800458 [0] Epoch 00032 | Loss 0.4624
20:30:21.805848 [0] Epoch: 032, Train: 0.9163, Val: 0.9202, Test: 0.9185
20:30:22.074922 [0] Epoch 00033 | Loss 0.4368
20:30:22.080547 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:30:22.351096 [0] Epoch 00034 | Loss 0.4162
20:30:22.357783 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:30:22.628633 [0] Epoch 00035 | Loss 0.3991
20:30:22.633926 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:30:22.902475 [0] Epoch 00036 | Loss 0.3851
20:30:22.907781 [0] Epoch: 036, Train: 0.9274, Val: 0.9320, Test: 0.9291
20:30:23.175439 [0] Epoch 00037 | Loss 0.3738
20:30:23.182136 [0] Epoch: 037, Train: 0.9283, Val: 0.9322, Test: 0.9305
20:30:23.451920 [0] Epoch 00038 | Loss 0.3643
20:30:23.457345 [0] Epoch: 038, Train: 0.9291, Val: 0.9328, Test: 0.9308
20:30:23.727714 [0] Epoch 00039 | Loss 0.3556
20:30:23.733191 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9317
20:30:24.002949 [0] Epoch 00040 | Loss 0.3470
20:30:24.008403 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9328
20:30:24.279844 [0] Epoch 00041 | Loss 0.3389
20:30:24.285074 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:30:24.553156 [0] Epoch 00042 | Loss 0.3321
20:30:24.558426 [0] Epoch: 042, Train: 0.9339, Val: 0.9360, Test: 0.9352
20:30:24.826560 [0] Epoch 00043 | Loss 0.3271
20:30:24.832643 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:30:25.102084 [0] Epoch 00044 | Loss 0.3232
20:30:25.107944 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:30:25.376560 [0] Epoch 00045 | Loss 0.3190
20:30:25.382188 [0] Epoch: 045, Train: 0.9357, Val: 0.9371, Test: 0.9368
20:30:25.650917 [0] Epoch 00046 | Loss 0.3144
20:30:25.656213 [0] Epoch: 046, Train: 0.9364, Val: 0.9376, Test: 0.9374
20:30:25.925362 [0] Epoch 00047 | Loss 0.3102
20:30:25.930610 [0] Epoch: 047, Train: 0.9366, Val: 0.9380, Test: 0.9376
20:30:26.201169 [0] Epoch 00048 | Loss 0.3063
20:30:26.207935 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:30:26.476383 [0] Epoch 00049 | Loss 0.3023
20:30:26.481566 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:30:26.749625 [0] Epoch 00050 | Loss 0.2985
20:30:26.754938 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:30:27.023687 [0] Epoch 00051 | Loss 0.2950
20:30:27.030280 [0] Epoch: 051, Train: 0.9383, Val: 0.9382, Test: 0.9382
20:30:27.299919 [0] Epoch 00052 | Loss 0.2919
20:30:27.305600 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:30:27.574870 [0] Epoch 00053 | Loss 0.2892
20:30:27.580496 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9384
20:30:27.848399 [0] Epoch 00054 | Loss 0.2861
20:30:27.854810 [0] Epoch: 054, Train: 0.9394, Val: 0.9387, Test: 0.9387
20:30:28.123205 [0] Epoch 00055 | Loss 0.2832
20:30:28.130009 [0] Epoch: 055, Train: 0.9398, Val: 0.9392, Test: 0.9390
20:30:28.398340 [0] Epoch 00056 | Loss 0.2807
20:30:28.403593 [0] Epoch: 056, Train: 0.9402, Val: 0.9396, Test: 0.9394
20:30:28.671845 [0] Epoch 00057 | Loss 0.2782
20:30:28.677128 [0] Epoch: 057, Train: 0.9406, Val: 0.9398, Test: 0.9396
20:30:28.945225 [0] Epoch 00058 | Loss 0.2756
20:30:28.950890 [0] Epoch: 058, Train: 0.9410, Val: 0.9403, Test: 0.9401
20:30:29.218498 [0] Epoch 00059 | Loss 0.2729
20:30:29.223775 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:30:29.492478 [0] Epoch 00060 | Loss 0.2705
20:30:29.499092 [0] Epoch: 060, Train: 0.9421, Val: 0.9405, Test: 0.9404
20:30:29.767323 [0] Epoch 00061 | Loss 0.2683
20:30:29.772891 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9403
20:30:30.042066 [0] Epoch 00062 | Loss 0.2662
20:30:30.047802 [0] Epoch: 062, Train: 0.9427, Val: 0.9409, Test: 0.9404
20:30:30.316105 [0] Epoch 00063 | Loss 0.2641
20:30:30.321763 [0] Epoch: 063, Train: 0.9431, Val: 0.9413, Test: 0.9408
20:30:30.590541 [0] Epoch 00064 | Loss 0.2621
20:30:30.595779 [0] Epoch: 064, Train: 0.9433, Val: 0.9412, Test: 0.9409
20:30:30.864219 [0] Epoch 00065 | Loss 0.2601
20:30:30.871047 [0] Epoch: 065, Train: 0.9435, Val: 0.9417, Test: 0.9412
20:30:31.139658 [0] Epoch 00066 | Loss 0.2582
20:30:31.144910 [0] Epoch: 066, Train: 0.9439, Val: 0.9416, Test: 0.9414
20:30:31.413376 [0] Epoch 00067 | Loss 0.2563
20:30:31.418607 [0] Epoch: 067, Train: 0.9442, Val: 0.9419, Test: 0.9414
20:30:31.688259 [0] Epoch 00068 | Loss 0.2545
20:30:31.695008 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:30:31.963421 [0] Epoch 00069 | Loss 0.2529
20:30:31.968669 [0] Epoch: 069, Train: 0.9448, Val: 0.9424, Test: 0.9417
20:30:32.236882 [0] Epoch 00070 | Loss 0.2513
20:30:32.242145 [0] Epoch: 070, Train: 0.9450, Val: 0.9425, Test: 0.9420
20:30:32.510982 [0] Epoch 00071 | Loss 0.2497
20:30:32.517627 [0] Epoch: 071, Train: 0.9452, Val: 0.9424, Test: 0.9421
20:30:32.786302 [0] Epoch 00072 | Loss 0.2483
20:30:32.792277 [0] Epoch: 072, Train: 0.9454, Val: 0.9423, Test: 0.9422
20:30:33.060299 [0] Epoch 00073 | Loss 0.2468
20:30:33.066340 [0] Epoch: 073, Train: 0.9458, Val: 0.9429, Test: 0.9425
20:30:33.335619 [0] Epoch 00074 | Loss 0.2454
20:30:33.342270 [0] Epoch: 074, Train: 0.9461, Val: 0.9431, Test: 0.9426
20:30:33.609912 [0] Epoch 00075 | Loss 0.2440
20:30:33.615709 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:30:33.883913 [0] Epoch 00076 | Loss 0.2426
20:30:33.892407 [0] Epoch: 076, Train: 0.9465, Val: 0.9430, Test: 0.9424
20:30:34.162010 [0] Epoch 00077 | Loss 0.2412
20:30:34.168627 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:30:34.437370 [0] Epoch 00078 | Loss 0.2399
20:30:34.443178 [0] Epoch: 078, Train: 0.9468, Val: 0.9431, Test: 0.9425
20:30:34.711273 [0] Epoch 00079 | Loss 0.2386
20:30:34.716467 [0] Epoch: 079, Train: 0.9470, Val: 0.9429, Test: 0.9427
20:30:34.985618 [0] Epoch 00080 | Loss 0.2374
20:30:34.990924 [0] Epoch: 080, Train: 0.9472, Val: 0.9428, Test: 0.9427
20:30:35.258845 [0] Epoch 00081 | Loss 0.2362
20:30:35.264053 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9427
20:30:35.532589 [0] Epoch 00082 | Loss 0.2350
20:30:35.538860 [0] Epoch: 082, Train: 0.9476, Val: 0.9426, Test: 0.9428
20:30:35.806640 [0] Epoch 00083 | Loss 0.2339
20:30:35.812619 [0] Epoch: 083, Train: 0.9478, Val: 0.9429, Test: 0.9430
20:30:36.080507 [0] Epoch 00084 | Loss 0.2328
20:30:36.085715 [0] Epoch: 084, Train: 0.9479, Val: 0.9431, Test: 0.9431
20:30:36.354196 [0] Epoch 00085 | Loss 0.2317
20:30:36.359459 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9435
20:30:36.628520 [0] Epoch 00086 | Loss 0.2307
20:30:36.635149 [0] Epoch: 086, Train: 0.9482, Val: 0.9431, Test: 0.9435
20:30:36.904692 [0] Epoch 00087 | Loss 0.2296
20:30:36.911330 [0] Epoch: 087, Train: 0.9483, Val: 0.9430, Test: 0.9435
20:30:37.182797 [0] Epoch 00088 | Loss 0.2287
20:30:37.189214 [0] Epoch: 088, Train: 0.9487, Val: 0.9432, Test: 0.9437
20:30:37.457844 [0] Epoch 00089 | Loss 0.2277
20:30:37.463132 [0] Epoch: 089, Train: 0.9490, Val: 0.9435, Test: 0.9436
20:30:37.731870 [0] Epoch 00090 | Loss 0.2267
20:30:37.737024 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9437
20:30:38.005639 [0] Epoch 00091 | Loss 0.2258
20:30:38.010981 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9440
20:30:38.279989 [0] Epoch 00092 | Loss 0.2248
20:30:38.286556 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9440
20:30:38.554177 [0] Epoch 00093 | Loss 0.2239
20:30:38.559415 [0] Epoch: 093, Train: 0.9497, Val: 0.9440, Test: 0.9441
20:30:38.827421 [0] Epoch 00094 | Loss 0.2229
20:30:38.832631 [0] Epoch: 094, Train: 0.9499, Val: 0.9442, Test: 0.9440
20:30:39.101112 [0] Epoch 00095 | Loss 0.2221
20:30:39.106405 [0] Epoch: 095, Train: 0.9500, Val: 0.9444, Test: 0.9442
20:30:39.374936 [0] Epoch 00096 | Loss 0.2212
20:30:39.381529 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9442
20:30:39.649887 [0] Epoch 00097 | Loss 0.2203
20:30:39.655103 [0] Epoch: 097, Train: 0.9502, Val: 0.9445, Test: 0.9445
20:30:39.922942 [0] Epoch 00098 | Loss 0.2195
20:30:39.928204 [0] Epoch: 098, Train: 0.9504, Val: 0.9446, Test: 0.9447
20:30:40.195611 [0] Epoch 00099 | Loss 0.2186
20:30:40.201227 [0] Epoch: 099, Train: 0.9506, Val: 0.9447, Test: 0.9449
20:30:40.469885 [0] Epoch 00100 | Loss 0.2177
20:30:40.475447 [0] Epoch: 100, Train: 0.9508, Val: 0.9450, Test: 0.9449
20:30:40.743286 [0] Epoch 00101 | Loss 0.2169
20:30:40.748491 [0] Epoch: 101, Train: 0.9510, Val: 0.9451, Test: 0.9449
20:30:41.016687 [0] Epoch 00102 | Loss 0.2161
20:30:41.023127 [0] Epoch: 102, Train: 0.9512, Val: 0.9452, Test: 0.9450
20:30:41.290752 [0] Epoch 00103 | Loss 0.2153
20:30:41.296709 [0] Epoch: 103, Train: 0.9513, Val: 0.9452, Test: 0.9450
20:30:41.564749 [0] Epoch 00104 | Loss 0.2145
20:30:41.570586 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9450
20:30:41.838942 [0] Epoch 00105 | Loss 0.2137
20:30:41.844471 [0] Epoch: 105, Train: 0.9516, Val: 0.9454, Test: 0.9451
20:30:42.112593 [0] Epoch 00106 | Loss 0.2129
20:30:42.118359 [0] Epoch: 106, Train: 0.9517, Val: 0.9455, Test: 0.9453
20:30:42.387597 [0] Epoch 00107 | Loss 0.2122
20:30:42.393759 [0] Epoch: 107, Train: 0.9518, Val: 0.9456, Test: 0.9454
20:30:42.662767 [0] Epoch 00108 | Loss 0.2115
20:30:42.668033 [0] Epoch: 108, Train: 0.9520, Val: 0.9454, Test: 0.9453
20:30:42.935669 [0] Epoch 00109 | Loss 0.2108
20:30:42.940910 [0] Epoch: 109, Train: 0.9521, Val: 0.9454, Test: 0.9454
20:30:43.209347 [0] Epoch 00110 | Loss 0.2101
20:30:43.215215 [0] Epoch: 110, Train: 0.9523, Val: 0.9458, Test: 0.9454
20:30:43.484549 [0] Epoch 00111 | Loss 0.2093
20:30:43.489850 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:30:43.760201 [0] Epoch 00112 | Loss 0.2087
20:30:43.765638 [0] Epoch: 112, Train: 0.9525, Val: 0.9455, Test: 0.9454
20:30:44.035329 [0] Epoch 00113 | Loss 0.2080
20:30:44.040883 [0] Epoch: 113, Train: 0.9526, Val: 0.9455, Test: 0.9454
20:30:44.309218 [0] Epoch 00114 | Loss 0.2073
20:30:44.315918 [0] Epoch: 114, Train: 0.9527, Val: 0.9455, Test: 0.9454
20:30:44.584122 [0] Epoch 00115 | Loss 0.2066
20:30:44.589370 [0] Epoch: 115, Train: 0.9528, Val: 0.9456, Test: 0.9455
20:30:44.858481 [0] Epoch 00116 | Loss 0.2059
20:30:44.863917 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9455
20:30:45.133149 [0] Epoch 00117 | Loss 0.2053
20:30:45.138497 [0] Epoch: 117, Train: 0.9531, Val: 0.9458, Test: 0.9456
20:30:45.407628 [0] Epoch 00118 | Loss 0.2046
20:30:45.412994 [0] Epoch: 118, Train: 0.9533, Val: 0.9459, Test: 0.9457
20:30:45.681108 [0] Epoch 00119 | Loss 0.2040
20:30:45.686397 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:30:45.955621 [0] Epoch 00120 | Loss 0.2034
20:30:45.960898 [0] Epoch: 120, Train: 0.9534, Val: 0.9460, Test: 0.9459
20:30:46.229884 [0] Epoch 00121 | Loss 0.2027
20:30:46.235915 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9460
20:30:46.504697 [0] Epoch 00122 | Loss 0.2021
20:30:46.510136 [0] Epoch: 122, Train: 0.9536, Val: 0.9461, Test: 0.9460
20:30:46.779218 [0] Epoch 00123 | Loss 0.2015
20:30:46.785635 [0] Epoch: 123, Train: 0.9537, Val: 0.9461, Test: 0.9460
20:30:47.054664 [0] Epoch 00124 | Loss 0.2009
20:30:47.060374 [0] Epoch: 124, Train: 0.9538, Val: 0.9463, Test: 0.9459
20:30:47.329515 [0] Epoch 00125 | Loss 0.2003
20:30:47.334825 [0] Epoch: 125, Train: 0.9539, Val: 0.9462, Test: 0.9459
20:30:47.603721 [0] Epoch 00126 | Loss 0.1997
20:30:47.609019 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9459
20:30:47.877433 [0] Epoch 00127 | Loss 0.1992
20:30:47.882681 [0] Epoch: 127, Train: 0.9541, Val: 0.9468, Test: 0.9459
20:30:48.151347 [0] Epoch 00128 | Loss 0.1986
20:30:48.157713 [0] Epoch: 128, Train: 0.9543, Val: 0.9467, Test: 0.9459
20:30:48.427281 [0] Epoch 00129 | Loss 0.1980
20:30:48.432615 [0] Epoch: 129, Train: 0.9544, Val: 0.9467, Test: 0.9459
20:30:48.701261 [0] Epoch 00130 | Loss 0.1974
20:30:48.706533 [0] Epoch: 130, Train: 0.9545, Val: 0.9466, Test: 0.9459
20:30:48.974840 [0] Epoch 00131 | Loss 0.1969
20:30:48.980094 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9458
20:30:49.248651 [0] Epoch 00132 | Loss 0.1963
20:30:49.254157 [0] Epoch: 132, Train: 0.9547, Val: 0.9468, Test: 0.9458
20:30:49.522692 [0] Epoch 00133 | Loss 0.1958
20:30:49.528218 [0] Epoch: 133, Train: 0.9548, Val: 0.9468, Test: 0.9458
20:30:49.796825 [0] Epoch 00134 | Loss 0.1953
20:30:49.804011 [0] Epoch: 134, Train: 0.9549, Val: 0.9469, Test: 0.9460
20:30:50.072978 [0] Epoch 00135 | Loss 0.1947
20:30:50.079784 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9460
20:30:50.350162 [0] Epoch 00136 | Loss 0.1942
20:30:50.356831 [0] Epoch: 136, Train: 0.9551, Val: 0.9469, Test: 0.9461
20:30:50.625874 [0] Epoch 00137 | Loss 0.1937
20:30:50.631644 [0] Epoch: 137, Train: 0.9552, Val: 0.9470, Test: 0.9461
20:30:50.900417 [0] Epoch 00138 | Loss 0.1932
20:30:50.906417 [0] Epoch: 138, Train: 0.9552, Val: 0.9469, Test: 0.9461
20:30:51.175744 [0] Epoch 00139 | Loss 0.1927
20:30:51.182519 [0] Epoch: 139, Train: 0.9553, Val: 0.9471, Test: 0.9461
20:30:51.451861 [0] Epoch 00140 | Loss 0.1922
20:30:51.457188 [0] Epoch: 140, Train: 0.9554, Val: 0.9472, Test: 0.9463
20:30:51.726031 [0] Epoch 00141 | Loss 0.1917
20:30:51.731405 [0] Epoch: 141, Train: 0.9555, Val: 0.9473, Test: 0.9464
20:30:52.001065 [0] Epoch 00142 | Loss 0.1913
20:30:52.006328 [0] Epoch: 142, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:30:52.275579 [0] Epoch 00143 | Loss 0.1908
20:30:52.282159 [0] Epoch: 143, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:30:52.551683 [0] Epoch 00144 | Loss 0.1903
20:30:52.556957 [0] Epoch: 144, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:30:52.825507 [0] Epoch 00145 | Loss 0.1899
20:30:52.832254 [0] Epoch: 145, Train: 0.9557, Val: 0.9473, Test: 0.9464
20:30:53.101605 [0] Epoch 00146 | Loss 0.1894
20:30:53.107219 [0] Epoch: 146, Train: 0.9558, Val: 0.9472, Test: 0.9464
20:30:53.375697 [0] Epoch 00147 | Loss 0.1889
20:30:53.381441 [0] Epoch: 147, Train: 0.9559, Val: 0.9473, Test: 0.9464
20:30:53.651190 [0] Epoch 00148 | Loss 0.1885
20:30:53.657800 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:30:53.925764 [0] Epoch 00149 | Loss 0.1881
20:30:53.931510 [0] Epoch: 149, Train: 0.9561, Val: 0.9472, Test: 0.9464
20:30:54.199650 [0] Epoch 00150 | Loss 0.1876
20:30:54.205620 [0] Epoch: 150, Train: 0.9561, Val: 0.9471, Test: 0.9464
20:30:54.474188 [0] Epoch 00151 | Loss 0.1872
20:30:54.480105 [0] Epoch: 151, Train: 0.9562, Val: 0.9471, Test: 0.9464
20:30:54.749121 [0] Epoch 00152 | Loss 0.1867
20:30:54.755032 [0] Epoch: 152, Train: 0.9563, Val: 0.9472, Test: 0.9463
20:30:55.024705 [0] Epoch 00153 | Loss 0.1863
20:30:55.030327 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9464
20:30:55.300011 [0] Epoch 00154 | Loss 0.1859
20:30:55.306815 [0] Epoch: 154, Train: 0.9565, Val: 0.9472, Test: 0.9464
20:30:55.575680 [0] Epoch 00155 | Loss 0.1855
20:30:55.582371 [0] Epoch: 155, Train: 0.9566, Val: 0.9472, Test: 0.9463
20:30:55.851446 [0] Epoch 00156 | Loss 0.1850
20:30:55.858166 [0] Epoch: 156, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:30:56.127092 [0] Epoch 00157 | Loss 0.1846
20:30:56.134208 [0] Epoch: 157, Train: 0.9567, Val: 0.9473, Test: 0.9463
20:30:56.402809 [0] Epoch 00158 | Loss 0.1842
20:30:56.408872 [0] Epoch: 158, Train: 0.9568, Val: 0.9472, Test: 0.9463
20:30:56.677137 [0] Epoch 00159 | Loss 0.1838
20:30:56.682387 [0] Epoch: 159, Train: 0.9568, Val: 0.9471, Test: 0.9463
20:30:56.951092 [0] Epoch 00160 | Loss 0.1834
20:30:56.958350 [0] Epoch: 160, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:30:57.228256 [0] Epoch 00161 | Loss 0.1830
20:30:57.234949 [0] Epoch: 161, Train: 0.9570, Val: 0.9473, Test: 0.9464
20:30:57.504617 [0] Epoch 00162 | Loss 0.1826
20:30:57.511401 [0] Epoch: 162, Train: 0.9571, Val: 0.9472, Test: 0.9465
20:30:57.779687 [0] Epoch 00163 | Loss 0.1822
20:30:57.784920 [0] Epoch: 163, Train: 0.9572, Val: 0.9471, Test: 0.9465
20:30:58.053325 [0] Epoch 00164 | Loss 0.1818
20:30:58.058945 [0] Epoch: 164, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:30:58.327546 [0] Epoch 00165 | Loss 0.1814
20:30:58.333076 [0] Epoch: 165, Train: 0.9574, Val: 0.9470, Test: 0.9465
20:30:58.601659 [0] Epoch 00166 | Loss 0.1810
20:30:58.606988 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:30:58.874777 [0] Epoch 00167 | Loss 0.1806
20:30:58.880052 [0] Epoch: 167, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:30:59.148502 [0] Epoch 00168 | Loss 0.1802
20:30:59.154167 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:30:59.422575 [0] Epoch 00169 | Loss 0.1798
20:30:59.428362 [0] Epoch: 169, Train: 0.9577, Val: 0.9469, Test: 0.9466
20:30:59.697147 [0] Epoch 00170 | Loss 0.1795
20:30:59.702450 [0] Epoch: 170, Train: 0.9578, Val: 0.9471, Test: 0.9467
20:30:59.970582 [0] Epoch 00171 | Loss 0.1791
20:30:59.976644 [0] Epoch: 171, Train: 0.9579, Val: 0.9472, Test: 0.9467
20:31:00.245708 [0] Epoch 00172 | Loss 0.1787
20:31:00.250935 [0] Epoch: 172, Train: 0.9580, Val: 0.9473, Test: 0.9467
20:31:00.519202 [0] Epoch 00173 | Loss 0.1783
20:31:00.526042 [0] Epoch: 173, Train: 0.9581, Val: 0.9473, Test: 0.9467
20:31:00.794668 [0] Epoch 00174 | Loss 0.1780
20:31:00.799890 [0] Epoch: 174, Train: 0.9582, Val: 0.9473, Test: 0.9467
20:31:01.068251 [0] Epoch 00175 | Loss 0.1776
20:31:01.073557 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:31:01.341726 [0] Epoch 00176 | Loss 0.1772
20:31:01.346983 [0] Epoch: 176, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:31:01.615302 [0] Epoch 00177 | Loss 0.1769
20:31:01.621654 [0] Epoch: 177, Train: 0.9583, Val: 0.9474, Test: 0.9468
20:31:01.890289 [0] Epoch 00178 | Loss 0.1765
20:31:01.895568 [0] Epoch: 178, Train: 0.9584, Val: 0.9476, Test: 0.9468
20:31:02.164896 [0] Epoch 00179 | Loss 0.1762
20:31:02.171137 [0] Epoch: 179, Train: 0.9584, Val: 0.9475, Test: 0.9468
20:31:02.447322 [0] Epoch 00180 | Loss 0.1758
20:31:02.453428 [0] Epoch: 180, Train: 0.9585, Val: 0.9475, Test: 0.9468
20:31:02.729721 [0] Epoch 00181 | Loss 0.1754
20:31:02.735919 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:31:03.012691 [0] Epoch 00182 | Loss 0.1751
20:31:03.018787 [0] Epoch: 182, Train: 0.9587, Val: 0.9476, Test: 0.9468
20:31:03.297592 [0] Epoch 00183 | Loss 0.1747
20:31:03.304935 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9469
20:31:03.579322 [0] Epoch 00184 | Loss 0.1744
20:31:03.585994 [0] Epoch: 184, Train: 0.9588, Val: 0.9475, Test: 0.9470
20:31:03.855674 [0] Epoch 00185 | Loss 0.1740
20:31:03.861034 [0] Epoch: 185, Train: 0.9589, Val: 0.9475, Test: 0.9471
20:31:04.130203 [0] Epoch 00186 | Loss 0.1737
20:31:04.136694 [0] Epoch: 186, Train: 0.9589, Val: 0.9474, Test: 0.9469
20:31:04.404818 [0] Epoch 00187 | Loss 0.1734
20:31:04.411422 [0] Epoch: 187, Train: 0.9590, Val: 0.9473, Test: 0.9470
20:31:04.680820 [0] Epoch 00188 | Loss 0.1731
20:31:04.687212 [0] Epoch: 188, Train: 0.9590, Val: 0.9476, Test: 0.9469
20:31:04.956608 [0] Epoch 00189 | Loss 0.1729
20:31:04.961949 [0] Epoch: 189, Train: 0.9591, Val: 0.9473, Test: 0.9468
20:31:05.230288 [0] Epoch 00190 | Loss 0.1727
20:31:05.235684 [0] Epoch: 190, Train: 0.9591, Val: 0.9478, Test: 0.9467
20:31:05.505211 [0] Epoch 00191 | Loss 0.1728
20:31:05.510839 [0] Epoch: 191, Train: 0.9590, Val: 0.9470, Test: 0.9462
20:31:05.780164 [0] Epoch 00192 | Loss 0.1722
20:31:05.785547 [0] Epoch: 192, Train: 0.9592, Val: 0.9479, Test: 0.9469
20:31:06.055166 [0] Epoch 00193 | Loss 0.1714
20:31:06.061568 [0] Epoch: 193, Train: 0.9595, Val: 0.9473, Test: 0.9469
20:31:06.330595 [0] Epoch 00194 | Loss 0.1712
20:31:06.335994 [0] Epoch: 194, Train: 0.9596, Val: 0.9475, Test: 0.9469
20:31:06.605992 [0] Epoch 00195 | Loss 0.1712
20:31:06.612733 [0] Epoch: 195, Train: 0.9595, Val: 0.9479, Test: 0.9470
20:31:06.882545 [0] Epoch 00196 | Loss 0.1706
20:31:06.887875 [0] Epoch: 196, Train: 0.9597, Val: 0.9475, Test: 0.9469
20:31:07.157548 [0] Epoch 00197 | Loss 0.1701
20:31:07.164300 [0] Epoch: 197, Train: 0.9598, Val: 0.9473, Test: 0.9470
20:31:07.434748 [0] Epoch 00198 | Loss 0.1701
20:31:07.440616 [0] Epoch: 198, Train: 0.9597, Val: 0.9477, Test: 0.9469
20:31:07.710276 [0] Epoch 00199 | Loss 0.1698
20:31:07.715588 [0] Epoch: 199, Train: 0.9598, Val: 0.9475, Test: 0.9471
20:31:07.718143 [0] 
timer summary:
  3.15s   0.29s   200 broadcast ForwardL1 0
 16.30s   0.89s  2400 broadcast
 35.39s   0.85s  2400 spmm
  2.63s   0.18s   200 broadcast ForwardL1 1
  2.77s   0.10s   200 broadcast ForwardL1 2
  1.18s   0.00s   800 mm
  1.25s   0.25s   200 broadcast ForwardL2 0
  1.13s   0.11s   200 broadcast ForwardL2 1
  1.16s   0.07s   200 broadcast ForwardL2 2
  0.28s   0.14s   200 broadcast BackwardL2 0
  0.22s   0.09s   200 broadcast BackwardL2 1
  0.22s   0.10s   200 broadcast BackwardL2 2
  0.27s   0.16s   400 all_reduce
  1.11s   0.09s   200 broadcast BackwardL1 0
  1.14s   0.10s   200 broadcast BackwardL1 1
  1.16s   0.07s   200 broadcast BackwardL1 2
 56.41s   0.17s   200 epoch
 61.71s   0.03s     1 total

19:06:41.209576 [0] proc begin: <DistEnv 0/2 nccl>
19:06:51.134668 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
19:06:51.137494 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

19:06:55.042550 [0] Epoch 00000 | Loss 3.7513
19:06:55.049230 [0] Epoch: 000, Train: 0.0154, Val: 0.0168, Test: 0.0162
19:06:55.287585 [0] Epoch 00001 | Loss 3.7068
19:06:55.529571 [0] Epoch 00002 | Loss 3.6709
19:06:55.769551 [0] Epoch 00003 | Loss 3.6364
19:06:56.008392 [0] Epoch 00004 | Loss 3.5998
19:06:56.246938 [0] Epoch 00005 | Loss 3.5612
19:06:56.484225 [0] Epoch 00006 | Loss 3.5213
19:06:56.721534 [0] Epoch 00007 | Loss 3.4816
19:06:56.958720 [0] Epoch 00008 | Loss 3.4432
19:06:57.200219 [0] Epoch 00009 | Loss 3.4044
19:06:57.441467 [0] Epoch 00010 | Loss 3.3637
19:06:57.446915 [0] Epoch: 010, Train: 0.1412, Val: 0.1203, Test: 0.1244
19:06:57.686133 [0] Epoch 00011 | Loss 3.3204
19:06:57.928289 [0] Epoch 00012 | Loss 3.2744
19:06:58.169978 [0] Epoch 00013 | Loss 3.2272
19:06:58.410280 [0] Epoch 00014 | Loss 3.1793
19:06:58.651940 [0] Epoch 00015 | Loss 3.1298
19:06:58.890892 [0] Epoch 00016 | Loss 3.0788
19:06:59.131113 [0] Epoch 00017 | Loss 3.0256
19:06:59.369694 [0] Epoch 00018 | Loss 2.9697
19:06:59.608533 [0] Epoch 00019 | Loss 2.9106
19:06:59.614051 [0] Epoch: 019, Train: 0.2529, Val: 0.2319, Test: 0.2348
19:06:59.616029 [0] 
timer summary:
  1.27s   1.27s    20 broadcast ForwardL1 0
  1.71s   1.31s   160 broadcast
  4.19s   0.07s   160 spmm
  0.29s   0.01s    20 broadcast ForwardL1 1
  1.44s   0.09s    80 mm
  0.03s   0.03s    20 broadcast ForwardL2 0
  0.07s   0.09s    20 broadcast ForwardL2 1
  0.02s   0.00s    20 broadcast BackwardL2 0
  0.02s   0.01s    20 broadcast BackwardL2 1
  0.05s   0.01s    40 all_reduce
  0.01s   0.00s    20 broadcast BackwardL1 0
  0.01s   0.00s    20 broadcast BackwardL1 1
  7.55s   1.28s    20 epoch
 18.40s   0.01s     1 total
19:17:43.499615 [0] proc begin: <DistEnv 0/2 nccl>
19:17:54.574401 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
19:17:54.576999 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

19:17:57.668439 [0] Epoch 00000 | Loss 3.7157
19:17:57.674761 [0] Epoch: 000, Train: 0.0663, Val: 0.0574, Test: 0.0565
19:17:58.204287 [0] Epoch 00001 | Loss 3.1032
19:17:58.733045 [0] Epoch 00002 | Loss 2.5269
19:17:59.260674 [0] Epoch 00003 | Loss 2.1288
19:17:59.787622 [0] Epoch 00004 | Loss 1.7590
19:18:00.312890 [0] Epoch 00005 | Loss 1.4837
19:18:00.838594 [0] Epoch 00006 | Loss 1.2439
19:18:01.363628 [0] Epoch 00007 | Loss 1.0700
19:18:01.888603 [0] Epoch 00008 | Loss 0.9443
19:18:02.416244 [0] Epoch 00009 | Loss 0.8348
19:18:02.942766 [0] Epoch 00010 | Loss 0.7816
19:18:02.948100 [0] Epoch: 010, Train: 0.8420, Val: 0.8586, Test: 0.8538
19:18:03.474094 [0] Epoch 00011 | Loss 0.7173
19:18:03.999788 [0] Epoch 00012 | Loss 0.6670
19:18:04.525135 [0] Epoch 00013 | Loss 0.6239
19:18:05.051301 [0] Epoch 00014 | Loss 0.6014
19:18:05.577075 [0] Epoch 00015 | Loss 0.5520
19:18:06.102431 [0] Epoch 00016 | Loss 0.5411
19:18:06.628309 [0] Epoch 00017 | Loss 0.5475
19:18:07.154373 [0] Epoch 00018 | Loss 0.5151
19:18:07.680680 [0] Epoch 00019 | Loss 0.4973
19:18:07.686044 [0] Epoch: 019, Train: 0.9015, Val: 0.9096, Test: 0.9090
19:18:07.688521 [0] 
timer summary:
  2.18s   0.68s   240 broadcast
  8.82s   0.09s   240 spmm
  1.29s   0.05s   120 mm
  0.08s   0.03s    60 all_reduce
 12.61s   0.69s    20 epoch
 24.19s   0.01s     1 total
19:29:17.161764 [0] proc begin: <DistEnv 0/2 nccl>
19:29:27.986060 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
19:29:27.988368 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

19:29:30.068971 [0] Epoch 00000 | Loss 3.6990
19:29:30.073798 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
19:29:30.783566 [0] Epoch 00001 | Loss 2.8555
19:29:31.606798 [0] Epoch 00002 | Loss 2.2462
19:29:32.429337 [0] Epoch 00003 | Loss 1.8442
19:29:33.270531 [0] Epoch 00004 | Loss 1.5542
19:29:34.108171 [0] Epoch 00005 | Loss 1.3270
19:29:34.939123 [0] Epoch 00006 | Loss 1.1315
19:29:35.779199 [0] Epoch 00007 | Loss 1.0060
19:29:36.591392 [0] Epoch 00008 | Loss 0.8950
19:29:36.964584 [0] Epoch 00009 | Loss 0.7887
19:29:37.337215 [0] Epoch 00010 | Loss 0.7129
19:29:37.341582 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
19:29:37.714500 [0] Epoch 00011 | Loss 0.6705
19:29:38.087830 [0] Epoch 00012 | Loss 0.6240
19:29:38.461554 [0] Epoch 00013 | Loss 0.5829
19:29:38.834290 [0] Epoch 00014 | Loss 0.5582
19:29:39.209591 [0] Epoch 00015 | Loss 0.5328
19:29:39.596657 [0] Epoch 00016 | Loss 0.5084
19:29:39.974175 [0] Epoch 00017 | Loss 0.4888
19:29:40.348922 [0] Epoch 00018 | Loss 0.4716
19:29:40.721255 [0] Epoch 00019 | Loss 0.4586
19:29:40.725582 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
19:29:40.726302 [0] 
timer summary:
  3.17s   2.10s   160 broadcast
  7.67s   2.07s   160 spmm
  1.30s   0.25s    80 mm
  0.33s   0.35s    40 all_reduce
 12.81s   0.12s    20 epoch
 23.56s   0.00s     1 total
19:31:14.883278 [0] proc begin: <DistEnv 0/2 nccl>
19:31:25.479302 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
19:31:25.481782 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

19:31:27.923281 [0] Epoch 00000 | Loss 3.6990
19:31:27.929438 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
19:31:28.304267 [0] Epoch 00001 | Loss 2.8555
19:31:28.676382 [0] Epoch 00002 | Loss 2.2462
19:31:29.047971 [0] Epoch 00003 | Loss 1.8442
19:31:29.418661 [0] Epoch 00004 | Loss 1.5542
19:31:29.789719 [0] Epoch 00005 | Loss 1.3270
19:31:30.162336 [0] Epoch 00006 | Loss 1.1315
19:31:30.535301 [0] Epoch 00007 | Loss 1.0060
19:31:30.908972 [0] Epoch 00008 | Loss 0.8950
19:31:31.282647 [0] Epoch 00009 | Loss 0.7887
19:31:31.653637 [0] Epoch 00010 | Loss 0.7129
19:31:31.658082 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
19:31:32.029840 [0] Epoch 00011 | Loss 0.6705
19:31:32.401376 [0] Epoch 00012 | Loss 0.6240
19:31:32.773176 [0] Epoch 00013 | Loss 0.5829
19:31:33.144752 [0] Epoch 00014 | Loss 0.5582
19:31:33.516412 [0] Epoch 00015 | Loss 0.5328
19:31:33.887484 [0] Epoch 00016 | Loss 0.5084
19:31:34.259398 [0] Epoch 00017 | Loss 0.4888
19:31:34.630770 [0] Epoch 00018 | Loss 0.4716
19:31:35.001608 [0] Epoch 00019 | Loss 0.4586
19:31:35.006083 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
19:31:35.008553 [0] 
timer summary:
  1.66s   0.63s   160 broadcast
  6.30s   0.06s   160 spmm
  0.88s   0.07s    80 mm
  0.06s   0.01s    40 all_reduce
  9.08s   0.60s    20 epoch
 20.12s   0.00s     1 total
16:27:55.171113 [0] proc begin: <DistEnv 0/2 nccl>
16:27:56.564451 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
16:27:56.567774 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   65536 KB |   65536 KB |   65536 KB |       0 B  |
|       from large pool |   63488 KB |   63488 KB |   63488 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       3    |       3    |       3    |       0    |
|       from large pool |       2    |       2    |       2    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:33:00.308145 [0] proc begin: <DistEnv 0/2 nccl>
16:33:01.702532 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
16:33:01.705666 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   65536 KB |   65536 KB |   65536 KB |       0 B  |
|       from large pool |   63488 KB |   63488 KB |   63488 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       3    |       3    |       3    |       0    |
|       from large pool |       2    |       2    |       2    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:33:43.128574 [0] proc begin: <DistEnv 0/2 nccl>
16:33:44.538501 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
16:33:44.541102 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   52038 KB |   54693 KB |    3979 KB |
|       from large pool |   49555 KB |   50878 KB |   53524 KB |    3969 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   65536 KB |   65536 KB |   65536 KB |       0 B  |
|       from large pool |   63488 KB |   63488 KB |   63488 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       3    |       3    |       3    |       0    |
|       from large pool |       2    |       2    |       2    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:54:35.185068 [0] proc begin: <DistEnv 0/2 nccl>
16:54:37.025456 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
16:54:37.033038 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:54:37.046833 [0] L1 tensor(183542.5938, device='cuda:0', grad_fn=<SumBackward0>) tensor(258.8653, device='cuda:0', grad_fn=<SumBackward0>)
16:55:33.320100 [0] proc begin: <DistEnv 0/2 nccl>
16:55:34.576019 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
16:55:34.576955 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:55:34.585225 [0] L1 tensor(183542.5938, device='cuda:0', grad_fn=<SumBackward0>) tensor(258.8653, device='cuda:0', grad_fn=<SumBackward0>)
09:11:38.783826 [0] proc begin: <DistEnv 0/2 nccl>
09:12:13.446017 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
09:12:13.448910 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

09:26:41.672754 [0] proc begin: <DistEnv 0/2 nccl>
09:26:42.988063 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
09:26:42.988995 [0] graph loaded |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

09:26:44.431208 [0] Epoch 00000 | Loss 1.9460
09:26:44.432499 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
09:26:44.438039 [0] Epoch 00001 | Loss 1.9093
09:26:44.442876 [0] Epoch 00002 | Loss 1.8631
09:26:44.448158 [0] Epoch 00003 | Loss 1.8043
09:26:44.453368 [0] Epoch 00004 | Loss 1.7353
09:26:44.458597 [0] Epoch 00005 | Loss 1.6568
09:26:44.463816 [0] Epoch 00006 | Loss 1.5686
09:26:44.468930 [0] Epoch 00007 | Loss 1.4710
09:26:44.474067 [0] Epoch 00008 | Loss 1.3651
09:26:44.479263 [0] Epoch 00009 | Loss 1.2527
09:26:44.484482 [0] Epoch 00010 | Loss 1.1357
09:26:44.485377 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
09:26:44.490711 [0] Epoch 00011 | Loss 1.0166
09:26:44.496174 [0] Epoch 00012 | Loss 0.8983
09:26:44.501590 [0] Epoch 00013 | Loss 0.7835
09:26:44.506803 [0] Epoch 00014 | Loss 0.6750
09:26:44.511948 [0] Epoch 00015 | Loss 0.5752
09:26:44.517131 [0] Epoch 00016 | Loss 0.4855
09:26:44.522241 [0] Epoch 00017 | Loss 0.4068
09:26:44.527401 [0] Epoch 00018 | Loss 0.3391
09:26:44.532580 [0] Epoch 00019 | Loss 0.2818
09:26:44.533483 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
09:26:44.534399 [0] 
timer summary:
  0.17s   0.05s   160 broadcast
  0.33s   0.00s   160 spmm
  0.93s   0.04s    80 mm
  0.06s   0.00s    40 all_reduce
  1.53s   0.01s    20 epoch
  2.86s   0.00s     1 total
11:17:11.874064 [0] proc begin: <DistEnv 0/2 nccl>
18:50:39.041475 [0] proc begin: <DistEnv 0/2 nccl>
18:50:40.344030 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
18:50:40.344971 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:50:41.737953 [0] Epoch 00000 | Loss 1.9460
18:50:41.740585 [0] Epoch: 000, Train: 0.1000, Val: 0.1960, Test: 0.2040
18:50:41.747406 [0] Epoch 00001 | Loss 1.9092
18:50:41.751692 [0] Epoch 00002 | Loss 1.8670
18:50:41.754969 [0] Epoch 00003 | Loss 1.8128
18:50:41.758171 [0] Epoch 00004 | Loss 1.7471
18:50:41.761642 [0] Epoch 00005 | Loss 1.6714
18:50:41.765124 [0] Epoch 00006 | Loss 1.5865
18:50:41.768870 [0] Epoch 00007 | Loss 1.4926
18:50:41.772624 [0] Epoch 00008 | Loss 1.3909
18:50:41.776426 [0] Epoch 00009 | Loss 1.2824
18:50:41.780086 [0] Epoch 00010 | Loss 1.1690
18:50:41.781100 [0] Epoch: 010, Train: 0.9786, Val: 0.7860, Test: 0.8010
18:50:41.784901 [0] Epoch 00011 | Loss 1.0530
18:50:41.788794 [0] Epoch 00012 | Loss 0.9370
18:50:41.792387 [0] Epoch 00013 | Loss 0.8237
18:50:41.796017 [0] Epoch 00014 | Loss 0.7157
18:50:41.799632 [0] Epoch 00015 | Loss 0.6153
18:50:41.802771 [0] Epoch 00016 | Loss 0.5240
18:50:41.806567 [0] Epoch 00017 | Loss 0.4428
18:50:41.810101 [0] Epoch 00018 | Loss 0.3721
18:50:41.813500 [0] Epoch 00019 | Loss 0.3114
18:50:41.814390 [0] Epoch: 019, Train: 0.9857, Val: 0.7920, Test: 0.8130
18:50:41.815168 [0] 
timer summary:
  0.86s   0.06s    80 mm
  0.18s   0.06s   160 broadcast
  0.29s   0.04s   160 spmm
  0.05s   0.00s    40 all_reduce
  1.43s   0.05s    20 epoch
  2.77s   0.00s     1 total
18:51:50.640827 [0] proc begin: <DistEnv 0/2 nccl>
18:51:51.917116 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
18:51:51.918122 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:51:53.352094 [0] Epoch 00000 | Loss 1.9460
18:51:53.354080 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
18:51:53.360503 [0] Epoch 00001 | Loss 1.9093
18:51:53.365541 [0] Epoch 00002 | Loss 1.8631
18:51:53.370478 [0] Epoch 00003 | Loss 1.8043
18:51:53.375318 [0] Epoch 00004 | Loss 1.7353
18:51:53.380142 [0] Epoch 00005 | Loss 1.6568
18:51:53.384801 [0] Epoch 00006 | Loss 1.5686
18:51:53.389507 [0] Epoch 00007 | Loss 1.4710
18:51:53.394432 [0] Epoch 00008 | Loss 1.3651
18:51:53.399373 [0] Epoch 00009 | Loss 1.2527
18:51:53.404330 [0] Epoch 00010 | Loss 1.1357
18:51:53.405245 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
18:51:53.409691 [0] Epoch 00011 | Loss 1.0166
18:51:53.414168 [0] Epoch 00012 | Loss 0.8983
18:51:53.418751 [0] Epoch 00013 | Loss 0.7835
18:51:53.424739 [0] Epoch 00014 | Loss 0.6750
18:51:53.429629 [0] Epoch 00015 | Loss 0.5752
18:51:53.434324 [0] Epoch 00016 | Loss 0.4855
18:51:53.438967 [0] Epoch 00017 | Loss 0.4068
18:51:53.443664 [0] Epoch 00018 | Loss 0.3391
18:51:53.449053 [0] Epoch 00019 | Loss 0.2818
18:51:53.450248 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
18:51:53.451564 [0] 
timer summary:
  0.26s   0.13s   160 broadcast
  0.33s   0.01s   160 spmm
  0.85s   0.13s    80 mm
  0.05s   0.00s    40 all_reduce
  1.53s   0.01s    20 epoch
  2.81s   0.00s     1 total
18:53:09.947148 [0] proc begin: <DistEnv 0/2 nccl>
18:53:11.203371 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
18:53:11.204307 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:53:12.587540 [0] Epoch 00000 | Loss 1.9460
18:53:12.589257 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
18:53:12.596345 [0] Epoch 00001 | Loss 1.9093
18:53:12.601718 [0] Epoch 00002 | Loss 1.8631
18:53:12.606579 [0] Epoch 00003 | Loss 1.8043
18:53:12.611352 [0] Epoch 00004 | Loss 1.7353
18:53:12.616243 [0] Epoch 00005 | Loss 1.6568
18:53:12.620992 [0] Epoch 00006 | Loss 1.5686
18:53:12.625841 [0] Epoch 00007 | Loss 1.4710
18:53:12.630784 [0] Epoch 00008 | Loss 1.3651
18:53:12.636023 [0] Epoch 00009 | Loss 1.2527
18:53:12.641273 [0] Epoch 00010 | Loss 1.1357
18:53:12.642134 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
18:53:12.647608 [0] Epoch 00011 | Loss 1.0166
18:53:12.652367 [0] Epoch 00012 | Loss 0.8983
18:53:12.657079 [0] Epoch 00013 | Loss 0.7835
18:53:12.661976 [0] Epoch 00014 | Loss 0.6750
18:53:12.666844 [0] Epoch 00015 | Loss 0.5752
18:53:12.673522 [0] Epoch 00016 | Loss 0.4855
18:53:12.678703 [0] Epoch 00017 | Loss 0.4068
18:53:12.683937 [0] Epoch 00018 | Loss 0.3391
18:53:12.688792 [0] Epoch 00019 | Loss 0.2818
18:53:12.689685 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
18:53:12.690448 [0] 
timer summary:
  0.14s   0.00s   160 broadcast
  0.32s   0.00s   160 spmm
  0.91s   0.00s    80 mm
  0.06s   0.00s    40 all_reduce
  1.47s   0.01s    20 epoch
  2.74s   0.00s     1 total
18:53:28.888726 [0] proc begin: <DistEnv 0/2 nccl>
18:53:41.313937 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
18:53:41.316122 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:53:43.089157 [0] Epoch 00000 | Loss 3.6990
18:53:43.094830 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
18:53:43.467663 [0] Epoch 00001 | Loss 2.8555
18:53:43.839755 [0] Epoch 00002 | Loss 2.2462
18:53:44.209791 [0] Epoch 00003 | Loss 1.8442
18:53:44.579918 [0] Epoch 00004 | Loss 1.5542
18:53:44.950264 [0] Epoch 00005 | Loss 1.3270
18:53:45.321685 [0] Epoch 00006 | Loss 1.1315
18:53:45.692161 [0] Epoch 00007 | Loss 1.0060
18:53:46.062402 [0] Epoch 00008 | Loss 0.8950
18:53:46.433874 [0] Epoch 00009 | Loss 0.7887
18:53:46.804863 [0] Epoch 00010 | Loss 0.7129
18:53:46.809205 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
18:53:47.179971 [0] Epoch 00011 | Loss 0.6705
18:53:47.550620 [0] Epoch 00012 | Loss 0.6240
18:53:47.921632 [0] Epoch 00013 | Loss 0.5829
18:53:48.292863 [0] Epoch 00014 | Loss 0.5582
18:53:48.662792 [0] Epoch 00015 | Loss 0.5328
18:53:49.033559 [0] Epoch 00016 | Loss 0.5084
18:53:49.405205 [0] Epoch 00017 | Loss 0.4888
18:53:49.778645 [0] Epoch 00018 | Loss 0.4716
18:53:50.151854 [0] Epoch 00019 | Loss 0.4586
18:53:50.156294 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
18:53:50.157426 [0] 
timer summary:
  1.84s   0.62s   160 broadcast
  6.30s   0.06s   160 spmm
  0.95s   0.16s    80 mm
  0.06s   0.02s    40 all_reduce
  9.34s   0.74s    20 epoch
 21.27s   0.00s     1 total
18:56:30.225821 [0] proc begin: <DistEnv 0/2 nccl>
18:56:31.538097 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
18:56:31.539181 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:56:33.012435 [0] Epoch 00000 | Loss 1.9460
18:56:33.015670 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
18:56:33.022591 [0] Epoch 00001 | Loss 1.9093
18:56:33.028066 [0] Epoch 00002 | Loss 1.8631
18:56:33.033959 [0] Epoch 00003 | Loss 1.8043
18:56:33.039229 [0] Epoch 00004 | Loss 1.7353
18:56:33.044498 [0] Epoch 00005 | Loss 1.6568
18:56:33.049564 [0] Epoch 00006 | Loss 1.5686
18:56:33.057947 [0] Epoch 00007 | Loss 1.4710
18:56:33.063102 [0] Epoch 00008 | Loss 1.3651
18:56:33.068144 [0] Epoch 00009 | Loss 1.2527
18:56:33.073188 [0] Epoch 00010 | Loss 1.1357
18:56:33.074163 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
18:56:33.079122 [0] Epoch 00011 | Loss 1.0166
18:56:33.084162 [0] Epoch 00012 | Loss 0.8983
18:56:33.089033 [0] Epoch 00013 | Loss 0.7835
18:56:33.093876 [0] Epoch 00014 | Loss 0.6750
18:56:33.098982 [0] Epoch 00015 | Loss 0.5752
18:56:33.103849 [0] Epoch 00016 | Loss 0.4855
18:56:33.108728 [0] Epoch 00017 | Loss 0.4068
18:56:33.113955 [0] Epoch 00018 | Loss 0.3391
18:56:33.120026 [0] Epoch 00019 | Loss 0.2818
18:56:33.121005 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
18:56:33.122133 [0] 
timer summary:
  0.18s   0.05s   160 broadcast
  0.33s   0.01s   160 spmm
  0.95s   0.05s    80 mm
  0.05s   0.00s    40 all_reduce
  1.56s   0.02s    20 epoch
  2.89s   0.00s     1 total
18:56:37.976966 [0] proc begin: <DistEnv 0/2 nccl>
18:56:39.084053 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
18:56:39.084930 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

18:56:40.635689 [0] Epoch 00000 | Loss 1.9460
18:56:40.637769 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
18:56:40.646666 [0] Epoch 00001 | Loss 1.9093
18:56:40.652482 [0] Epoch 00002 | Loss 1.8631
18:56:40.657355 [0] Epoch 00003 | Loss 1.8043
18:56:40.662283 [0] Epoch 00004 | Loss 1.7353
18:56:40.669996 [0] Epoch 00005 | Loss 1.6568
18:56:40.675019 [0] Epoch 00006 | Loss 1.5686
18:56:40.679993 [0] Epoch 00007 | Loss 1.4710
18:56:40.685344 [0] Epoch 00008 | Loss 1.3651
18:56:40.689860 [0] Epoch 00009 | Loss 1.2527
18:56:40.694471 [0] Epoch 00010 | Loss 1.1357
18:56:40.695456 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
18:56:40.700167 [0] Epoch 00011 | Loss 1.0166
18:56:40.705221 [0] Epoch 00012 | Loss 0.8983
18:56:40.710009 [0] Epoch 00013 | Loss 0.7835
18:56:40.714482 [0] Epoch 00014 | Loss 0.6750
18:56:40.718958 [0] Epoch 00015 | Loss 0.5752
18:56:40.723479 [0] Epoch 00016 | Loss 0.4855
18:56:40.729827 [0] Epoch 00017 | Loss 0.4068
18:56:40.734973 [0] Epoch 00018 | Loss 0.3391
18:56:40.740214 [0] Epoch 00019 | Loss 0.2818
18:56:40.741371 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
18:56:40.742522 [0] 
timer summary:
  0.23s   0.13s   160 broadcast
  0.32s   0.00s   160 spmm
  0.91s   0.00s    80 mm
  0.06s   0.00s    40 all_reduce
  1.56s   0.13s    20 epoch
  2.76s   0.00s     1 total
19:07:51.551405 [0] proc begin: <DistEnv 0/2 nccl>
19:22:39.089991 [0] proc begin: <DistEnv 0/2 nccl>
19:22:40.345159 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
19:22:40.346100 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:28:05.887511 [0] proc begin: <DistEnv 0/2 nccl>
21:33:08.976568 [0] proc begin: <DistEnv 0/2 nccl>
21:33:09.954085 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:33:09.954868 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:38:08.734411 [0] proc begin: <DistEnv 0/2 nccl>
21:38:10.048324 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:38:10.049374 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:40:57.911255 [0] proc begin: <DistEnv 0/2 nccl>
21:40:59.180179 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:40:59.181139 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:49:57.321344 [0] proc begin: <DistEnv 0/2 nccl>
21:49:58.632177 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:49:58.633107 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:50:35.497098 [0] proc begin: <DistEnv 0/2 nccl>
21:50:36.720597 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:50:36.721535 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:52:45.990120 [0] proc begin: <DistEnv 0/2 nccl>
21:52:47.297831 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:52:47.298783 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:53:54.564779 [0] proc begin: <DistEnv 0/2 nccl>
21:53:55.880838 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:53:55.881805 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:57:10.007175 [0] proc begin: <DistEnv 0/2 nccl>
21:57:11.200344 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
21:57:11.201081 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:57:12.557373 [0] Epoch 00000 | Loss 1.9460
21:57:12.558398 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
21:57:12.562994 [0] Epoch 00001 | Loss 1.9093
21:57:12.567338 [0] Epoch 00002 | Loss 1.8631
21:57:12.571800 [0] Epoch 00003 | Loss 1.8043
21:57:12.576566 [0] Epoch 00004 | Loss 1.7353
21:57:12.581585 [0] Epoch 00005 | Loss 1.6568
21:57:12.586438 [0] Epoch 00006 | Loss 1.5686
21:57:12.591077 [0] Epoch 00007 | Loss 1.4710
21:57:12.595748 [0] Epoch 00008 | Loss 1.3651
21:57:12.600285 [0] Epoch 00009 | Loss 1.2527
21:57:12.606721 [0] Epoch 00010 | Loss 1.1357
21:57:12.607511 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
21:57:12.613314 [0] Epoch 00011 | Loss 1.0166
21:57:12.620114 [0] Epoch 00012 | Loss 0.8983
21:57:12.624654 [0] Epoch 00013 | Loss 0.7835
21:57:12.629476 [0] Epoch 00014 | Loss 0.6750
21:57:12.634127 [0] Epoch 00015 | Loss 0.5752
21:57:12.638638 [0] Epoch 00016 | Loss 0.4855
21:57:12.643090 [0] Epoch 00017 | Loss 0.4068
21:57:12.647495 [0] Epoch 00018 | Loss 0.3391
21:57:12.652234 [0] Epoch 00019 | Loss 0.2818
21:57:12.653430 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
21:57:12.654524 [0] 
timer summary:
  0.17s   0.01s   160 broadcast
  0.32s   0.00s   160 spmm
  0.88s   0.00s    80 mm
  0.05s   0.00s    40 all_reduce
  1.45s   0.01s    20 epoch
  2.64s   0.01s     1 total
21:58:13.458532 [0] proc begin: <DistEnv 0/2 nccl>
21:58:14.673109 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
21:58:14.674013 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

21:58:16.042141 [0] Epoch 00000 | Loss 1.9460
21:58:16.043837 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
21:58:16.051079 [0] Epoch 00001 | Loss 1.9093
21:58:16.057218 [0] Epoch 00002 | Loss 1.8631
21:58:16.061831 [0] Epoch 00003 | Loss 1.8043
21:58:16.067463 [0] Epoch 00004 | Loss 1.7353
21:58:16.073715 [0] Epoch 00005 | Loss 1.6568
21:58:16.078540 [0] Epoch 00006 | Loss 1.5686
21:58:16.084035 [0] Epoch 00007 | Loss 1.4710
21:58:16.090421 [0] Epoch 00008 | Loss 1.3651
21:58:16.095282 [0] Epoch 00009 | Loss 1.2527
21:58:16.100091 [0] Epoch 00010 | Loss 1.1357
21:58:16.101189 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
21:58:16.105910 [0] Epoch 00011 | Loss 1.0166
21:58:16.110631 [0] Epoch 00012 | Loss 0.8983
21:58:16.115412 [0] Epoch 00013 | Loss 0.7835
21:58:16.120089 [0] Epoch 00014 | Loss 0.6750
21:58:16.124911 [0] Epoch 00015 | Loss 0.5752
21:58:16.129599 [0] Epoch 00016 | Loss 0.4855
21:58:16.134222 [0] Epoch 00017 | Loss 0.4068
21:58:16.138906 [0] Epoch 00018 | Loss 0.3391
21:58:16.143600 [0] Epoch 00019 | Loss 0.2818
21:58:16.144485 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
21:58:16.145432 [0] 
timer summary:
  0.18s   0.02s   160 broadcast
  0.32s   0.00s   160 spmm
  0.87s   0.01s    80 mm
  0.05s   0.00s    40 all_reduce
  1.47s   0.01s    20 epoch
  2.68s   0.00s     1 total
21:59:32.649471 [0] proc begin: <DistEnv 0/2 nccl>
21:59:33.849980 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
21:59:33.850922 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:00:50.799019 [0] proc begin: <DistEnv 0/2 nccl>
22:04:46.600054 [0] proc begin: <DistEnv 0/2 nccl>
22:06:14.849001 [0] proc begin: <DistEnv 0/2 nccl>
22:06:34.437320 [0] proc begin: <DistEnv 0/2 nccl>
22:09:10.482458 [0] proc begin: <DistEnv 0/2 nccl>
22:09:11.746468 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
22:09:11.747379 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:09:13.249613 [0] Epoch 00000 | Loss 1.9460
22:09:13.251646 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
22:09:13.258326 [0] Epoch 00001 | Loss 1.9093
22:09:13.263943 [0] Epoch 00002 | Loss 1.8631
22:09:13.269123 [0] Epoch 00003 | Loss 1.8043
22:09:13.274043 [0] Epoch 00004 | Loss 1.7353
22:09:13.279062 [0] Epoch 00005 | Loss 1.6568
22:09:13.284168 [0] Epoch 00006 | Loss 1.5686
22:09:13.289152 [0] Epoch 00007 | Loss 1.4710
22:09:13.294249 [0] Epoch 00008 | Loss 1.3651
22:09:13.299224 [0] Epoch 00009 | Loss 1.2527
22:09:13.304193 [0] Epoch 00010 | Loss 1.1357
22:09:13.305125 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
22:09:13.310022 [0] Epoch 00011 | Loss 1.0166
22:09:13.314906 [0] Epoch 00012 | Loss 0.8983
22:09:13.319809 [0] Epoch 00013 | Loss 0.7835
22:09:13.325328 [0] Epoch 00014 | Loss 0.6750
22:09:13.333050 [0] Epoch 00015 | Loss 0.5752
22:09:13.341677 [0] Epoch 00016 | Loss 0.4855
22:09:13.346982 [0] Epoch 00017 | Loss 0.4068
22:09:13.352350 [0] Epoch 00018 | Loss 0.3391
22:09:13.357827 [0] Epoch 00019 | Loss 0.2818
22:09:13.358804 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
22:09:13.359766 [0] 
timer summary:
  0.19s   0.04s   160 broadcast
  0.37s   0.04s   160 spmm
  0.94s   0.02s    80 mm
  0.05s   0.00s    40 all_reduce
  1.59s   0.02s    20 epoch
  2.87s   0.01s     1 total
22:10:00.336006 [0] proc begin: <DistEnv 0/2 nccl>
22:10:01.614411 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
22:10:01.615392 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:10:03.011858 [0] Epoch 00000 | Loss 1.9460
22:10:03.013645 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
22:10:03.021766 [0] Epoch 00001 | Loss 1.9093
22:10:03.028083 [0] Epoch 00002 | Loss 1.8631
22:10:03.033385 [0] Epoch 00003 | Loss 1.8043
22:10:03.038877 [0] Epoch 00004 | Loss 1.7353
22:10:03.044508 [0] Epoch 00005 | Loss 1.6568
22:10:03.049921 [0] Epoch 00006 | Loss 1.5686
22:10:03.055029 [0] Epoch 00007 | Loss 1.4710
22:10:03.060252 [0] Epoch 00008 | Loss 1.3651
22:10:03.065382 [0] Epoch 00009 | Loss 1.2527
22:10:03.070648 [0] Epoch 00010 | Loss 1.1357
22:10:03.071629 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
22:10:03.076830 [0] Epoch 00011 | Loss 1.0166
22:10:03.081843 [0] Epoch 00012 | Loss 0.8983
22:10:03.087300 [0] Epoch 00013 | Loss 0.7835
22:10:03.092890 [0] Epoch 00014 | Loss 0.6750
22:10:03.098374 [0] Epoch 00015 | Loss 0.5752
22:10:03.103798 [0] Epoch 00016 | Loss 0.4855
22:10:03.109227 [0] Epoch 00017 | Loss 0.4068
22:10:03.114779 [0] Epoch 00018 | Loss 0.3391
22:10:03.120027 [0] Epoch 00019 | Loss 0.2818
22:10:03.120966 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
22:10:03.121792 [0] 
timer summary:
  0.14s   0.00s   160 broadcast
  0.34s   0.00s   160 spmm
  0.91s   0.00s    80 mm
  0.06s   0.00s    40 all_reduce
  1.49s   0.01s    20 epoch
  2.78s   0.00s     1 total
22:11:50.782679 [0] proc begin: <DistEnv 0/2 nccl>
22:11:52.412236 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
22:11:52.413149 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:11:53.946109 [0] Epoch 00000 | Loss 1.9460
22:11:53.948503 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
22:11:53.956855 [0] Epoch 00001 | Loss 1.9093
22:11:53.962871 [0] Epoch 00002 | Loss 1.8631
22:11:53.968461 [0] Epoch 00003 | Loss 1.8043
22:11:53.974007 [0] Epoch 00004 | Loss 1.7353
22:11:53.979616 [0] Epoch 00005 | Loss 1.6568
22:11:53.984789 [0] Epoch 00006 | Loss 1.5686
22:11:53.989996 [0] Epoch 00007 | Loss 1.4710
22:11:53.995450 [0] Epoch 00008 | Loss 1.3651
22:11:54.000787 [0] Epoch 00009 | Loss 1.2527
22:11:54.005902 [0] Epoch 00010 | Loss 1.1357
22:11:54.006724 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
22:11:54.011805 [0] Epoch 00011 | Loss 1.0166
22:11:54.016671 [0] Epoch 00012 | Loss 0.8983
22:11:54.021407 [0] Epoch 00013 | Loss 0.7835
22:11:54.026352 [0] Epoch 00014 | Loss 0.6750
22:11:54.031352 [0] Epoch 00015 | Loss 0.5752
22:11:54.036407 [0] Epoch 00016 | Loss 0.4855
22:11:54.041723 [0] Epoch 00017 | Loss 0.4068
22:11:54.047294 [0] Epoch 00018 | Loss 0.3391
22:11:54.052590 [0] Epoch 00019 | Loss 0.2818
22:11:54.053460 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
22:11:54.054241 [0] 
timer summary:
  0.18s   0.05s   160 broadcast
  0.43s   0.00s   160 spmm
  0.93s   0.04s    80 mm
  0.05s   0.00s    40 all_reduce
  1.62s   0.02s    20 epoch
  3.27s   0.00s     1 total
22:14:50.278376 [0] proc begin: <DistEnv 0/2 nccl>
22:14:51.547908 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:14:51.548817 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:20:57.022922 [0] proc begin: <DistEnv 0/2 nccl>
22:20:58.302065 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:20:58.303013 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:23:30.311428 [0] proc begin: <DistEnv 0/2 nccl>
22:23:31.580073 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:23:31.580987 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:24:47.248075 [0] proc begin: <DistEnv 0/2 nccl>
22:24:48.533971 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:24:48.534940 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:26:08.746837 [0] proc begin: <DistEnv 0/2 nccl>
22:26:10.038239 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:26:10.039365 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:26:53.166171 [0] proc begin: <DistEnv 0/2 nccl>
22:26:54.460863 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:26:54.461799 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |   15304 KB |   15326 KB |   15374 KB |   71680 B  |
|       from large pool |   15158 KB |   15158 KB |   15158 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   18432 KB |   18432 KB |   18432 KB |       0 B  |
|       from large pool |   16384 KB |   16384 KB |   16384 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3128 KB |    3243 KB |    3340 KB |  217600 B  |
|       from large pool |    1225 KB |    1225 KB |    1225 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:54:26.344816 [0] proc begin: <DistEnv 0/2 nccl>
22:54:27.653771 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:54:27.654578 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:55:28.162656 [0] proc begin: <DistEnv 0/2 nccl>
22:55:29.451286 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:55:29.452227 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:55:49.453395 [0] proc begin: <DistEnv 0/2 nccl>
22:55:50.747051 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:55:50.748016 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

22:59:15.257324 [0] proc begin: <DistEnv 0/2 nccl>
22:59:16.241965 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
22:59:16.242763 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:00:43.001791 [0] proc begin: <DistEnv 0/2 nccl>
23:00:44.264975 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:00:44.265937 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:04:03.504482 [0] proc begin: <DistEnv 0/2 nccl>
23:04:04.795304 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:04:04.796250 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:05:11.980768 [0] proc begin: <DistEnv 0/2 nccl>
23:05:13.271627 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:05:13.272573 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:07:22.101647 [0] proc begin: <DistEnv 0/2 nccl>
23:07:23.066005 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:07:23.066822 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:11:11.789745 [0] proc begin: <DistEnv 0/2 nccl>
23:11:12.797604 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:11:12.798486 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:13:38.689301 [0] proc begin: <DistEnv 0/2 nccl>
23:13:39.693516 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:13:39.694276 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:14:19.803142 [0] proc begin: <DistEnv 0/2 nccl>
23:14:20.807918 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:14:20.808702 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:16:24.271293 [0] proc begin: <DistEnv 0/2 nccl>
23:16:25.572802 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:16:25.573590 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:19:51.269874 [0] proc begin: <DistEnv 0/2 nccl>
23:19:52.542378 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:19:52.543311 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:21:15.756899 [0] proc begin: <DistEnv 0/2 nccl>
23:21:17.024043 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:21:17.024996 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:24:17.297304 [0] proc begin: <DistEnv 0/2 nccl>
23:24:18.286444 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:24:18.287206 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:25:51.752483 [0] proc begin: <DistEnv 0/2 nccl>
23:25:52.999725 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:25:53.000675 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

23:30:10.836739 [0] proc begin: <DistEnv 0/2 nccl>
23:30:12.126123 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
23:30:12.126990 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

09:30:12.680160 [0] proc begin: <DistEnv 0/2 nccl>
09:30:14.122850 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
09:30:14.123807 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

09:36:08.334125 [0] proc begin: <DistEnv 0/2 nccl>
09:36:09.762173 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
09:36:09.763288 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

09:54:57.075802 [0] proc begin: <DistEnv 0/2 nccl>
09:54:58.699583 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
09:54:58.700531 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:01:49.397464 [0] proc begin: <DistEnv 0/2 nccl>
10:01:50.592555 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:01:50.593500 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:07:24.991930 [0] proc begin: <DistEnv 0/2 nccl>
10:07:26.253583 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:07:26.254524 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:15:35.937832 [0] proc begin: <DistEnv 0/2 nccl>
10:15:37.695667 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:15:37.703281 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:16:52.506662 [0] proc begin: <DistEnv 0/2 nccl>
10:16:53.909117 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:16:53.910056 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:17:57.192481 [0] proc begin: <DistEnv 0/2 nccl>
10:17:58.802851 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:17:58.803634 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:18:31.730393 [0] proc begin: <DistEnv 0/2 nccl>
10:18:33.163544 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:18:33.164491 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:26:14.328323 [0] proc begin: <DistEnv 0/2 nccl>
10:26:15.393728 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 2708, |E|: 13264>
10:26:15.394423 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7725 KB |    7747 KB |    7795 KB |   71680 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |     145 KB |     167 KB |     215 KB |   71680 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14803 KB |   14918 KB |   15015 KB |  217600 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1902 KB |    2045 KB |    2115 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      10    |      17    |       9    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       7    |       9    |      16    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:32:04.636458 [0] proc begin: <DistEnv 0/2 nccl>
10:32:06.074729 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169343, |E|: 1335586>
10:32:06.077718 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102909 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1166 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102909 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1166 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9612 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     890 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:32:26.501355 [0] proc begin: <DistEnv 0/2 nccl>
10:32:27.939355 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169343, |E|: 1335586>
10:32:27.941802 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102909 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1166 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102909 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1166 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9612 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     890 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:54:11.169170 [0] proc begin: <DistEnv 0/2 nccl>
10:54:12.612624 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
10:54:12.615133 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:58:45.055270 [0] proc begin: <DistEnv 0/2 nccl>
10:58:46.555276 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
10:58:46.557952 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:00:35.256222 [0] proc begin: <DistEnv 0/2 nccl>
11:00:36.726334 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:00:36.728823 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:01:31.742745 [0] proc begin: <DistEnv 0/2 nccl>
11:01:33.235066 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:01:33.237601 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:04:57.952525 [0] proc begin: <DistEnv 0/2 nccl>
11:04:59.378345 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:04:59.381309 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:06:15.733473 [0] proc begin: <DistEnv 0/2 nccl>
11:06:17.173348 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:06:17.176353 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:07:07.199319 [0] proc begin: <DistEnv 0/2 nccl>
11:07:08.618670 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:07:08.620864 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:07:36.817904 [0] proc begin: <DistEnv 0/2 nccl>
11:07:38.331388 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:07:38.334301 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:07:41.216195 [0] Epoch 00000 | Loss 3.6925
11:07:41.222439 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
11:07:41.350218 [0] Epoch 00001 | Loss 3.5845
11:07:41.458516 [0] Epoch 00002 | Loss 3.8658
11:07:41.564685 [0] Epoch 00003 | Loss 4.6374
11:07:41.670987 [0] Epoch 00004 | Loss 5.8564
11:07:41.777271 [0] Epoch 00005 | Loss 7.4233
11:07:41.883488 [0] Epoch 00006 | Loss 9.2427
11:07:41.989733 [0] Epoch 00007 | Loss 11.2466
11:07:42.095986 [0] Epoch 00008 | Loss 13.4136
11:07:42.202249 [0] Epoch 00009 | Loss 15.7737
11:07:42.308447 [0] Epoch 00010 | Loss 18.3630
11:07:42.314912 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
11:07:42.443635 [0] Epoch 00011 | Loss 21.1870
11:07:42.549543 [0] Epoch 00012 | Loss 24.2306
11:07:42.656211 [0] Epoch 00013 | Loss 27.4851
11:07:42.762387 [0] Epoch 00014 | Loss 30.9766
11:07:42.868172 [0] Epoch 00015 | Loss 34.7489
11:07:42.974439 [0] Epoch 00016 | Loss 38.8200
11:07:43.080644 [0] Epoch 00017 | Loss 43.1675
11:07:43.186928 [0] Epoch 00018 | Loss 47.7810
11:07:43.293066 [0] Epoch 00019 | Loss 52.7074
11:07:43.299646 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
11:07:43.326647 [0] 
timer summary:
  1.36s   0.68s    80 mm
  0.70s   0.40s    80 broadcast
  0.57s   0.30s    80 spmm
  0.18s   0.12s    40 all_reduce
  4.69s   0.36s    20 epoch
  6.50s   0.02s     1 total
11:08:40.290471 [0] proc begin: <DistEnv 0/2 nccl>
11:08:41.628804 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:08:41.631792 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:08:44.194569 [0] Epoch 00000 | Loss 3.6796
11:08:44.200733 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
11:08:44.346921 [0] Epoch 00001 | Loss 3.4888
11:08:44.470826 [0] Epoch 00002 | Loss 3.4475
11:08:44.594771 [0] Epoch 00003 | Loss 3.5963
11:08:44.718731 [0] Epoch 00004 | Loss 3.9376
11:08:44.842580 [0] Epoch 00005 | Loss 4.4440
11:08:44.966464 [0] Epoch 00006 | Loss 5.0673
11:08:45.090871 [0] Epoch 00007 | Loss 5.7588
11:08:45.214343 [0] Epoch 00008 | Loss 6.5295
11:08:45.338171 [0] Epoch 00009 | Loss 7.3825
11:08:45.462051 [0] Epoch 00010 | Loss 8.2471
11:08:45.468266 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
11:08:45.615620 [0] Epoch 00011 | Loss 9.0631
11:08:45.738912 [0] Epoch 00012 | Loss 9.8321
11:08:45.862759 [0] Epoch 00013 | Loss 10.5323
11:08:45.986631 [0] Epoch 00014 | Loss 11.1359
11:08:46.110511 [0] Epoch 00015 | Loss 11.6644
11:08:46.234412 [0] Epoch 00016 | Loss 12.0868
11:08:46.358262 [0] Epoch 00017 | Loss 12.4616
11:08:46.482138 [0] Epoch 00018 | Loss 12.8053
11:08:46.606327 [0] Epoch 00019 | Loss 13.0934
11:08:46.613116 [0] Epoch: 019, Train: 0.2584, Val: 0.2931, Test: 0.2624
11:08:46.639548 [0] 
timer summary:
  2.21s   1.67s   160 broadcast
  0.63s   0.38s   160 spmm
  1.28s   0.70s    80 mm
  0.23s   0.12s    40 all_reduce
  4.81s   0.22s    20 epoch
  6.33s   0.01s     1 total
11:10:29.078097 [0] proc begin: <DistEnv 0/2 nccl>
11:10:30.490534 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:10:30.493468 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:10:33.528515 [0] Epoch 00000 | Loss 3.6796
11:10:33.536816 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
11:10:33.676469 [0] Epoch 00001 | Loss 3.4888
11:10:33.793488 [0] Epoch 00002 | Loss 3.4475
11:10:33.910531 [0] Epoch 00003 | Loss 3.5963
11:10:34.027544 [0] Epoch 00004 | Loss 3.9376
11:10:34.144518 [0] Epoch 00005 | Loss 4.4440
11:10:34.261552 [0] Epoch 00006 | Loss 5.0673
11:10:34.378576 [0] Epoch 00007 | Loss 5.7588
11:10:34.495562 [0] Epoch 00008 | Loss 6.5295
11:10:34.612664 [0] Epoch 00009 | Loss 7.3825
11:10:34.729728 [0] Epoch 00010 | Loss 8.2472
11:10:34.735814 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
11:10:34.875861 [0] Epoch 00011 | Loss 9.0631
11:10:34.992833 [0] Epoch 00012 | Loss 9.8321
11:10:35.110056 [0] Epoch 00013 | Loss 10.5323
11:10:35.227156 [0] Epoch 00014 | Loss 11.1359
11:10:35.344253 [0] Epoch 00015 | Loss 11.6644
11:10:35.461420 [0] Epoch 00016 | Loss 12.0868
11:10:35.579212 [0] Epoch 00017 | Loss 12.4616
11:10:35.695918 [0] Epoch 00018 | Loss 12.8053
11:10:35.813676 [0] Epoch 00019 | Loss 13.0934
11:10:35.820020 [0] Epoch: 019, Train: 0.2584, Val: 0.2931, Test: 0.2624
11:10:35.846579 [0] 
timer summary:
  2.40s   1.92s   160 broadcast
  0.65s   0.40s   160 spmm
  1.38s   0.90s    80 mm
  0.23s   0.12s    40 all_reduce
  5.05s   0.35s    20 epoch
  6.75s   0.01s     1 total
11:10:52.856773 [0] proc begin: <DistEnv 0/2 nccl>
11:10:53.944408 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:10:53.946925 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:10:56.986668 [0] Epoch 00000 | Loss 3.6796
11:10:56.992776 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
11:10:57.132590 [0] Epoch 00001 | Loss 3.4888
11:10:57.249231 [0] Epoch 00002 | Loss 3.4475
11:10:57.366072 [0] Epoch 00003 | Loss 3.5963
11:10:57.482996 [0] Epoch 00004 | Loss 3.9376
11:10:57.599775 [0] Epoch 00005 | Loss 4.4440
11:10:57.716818 [0] Epoch 00006 | Loss 5.0673
11:10:57.833926 [0] Epoch 00007 | Loss 5.7588
11:10:57.950966 [0] Epoch 00008 | Loss 6.5295
11:10:58.067539 [0] Epoch 00009 | Loss 7.3825
11:10:58.184382 [0] Epoch 00010 | Loss 8.2472
11:10:58.190936 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
11:10:58.330585 [0] Epoch 00011 | Loss 9.0631
11:10:58.447920 [0] Epoch 00012 | Loss 9.8321
11:10:58.564861 [0] Epoch 00013 | Loss 10.5323
11:10:58.681672 [0] Epoch 00014 | Loss 11.1359
11:10:58.798557 [0] Epoch 00015 | Loss 11.6644
11:10:58.916427 [0] Epoch 00016 | Loss 12.0868
11:10:59.032997 [0] Epoch 00017 | Loss 12.4616
11:10:59.150464 [0] Epoch 00018 | Loss 12.8053
11:10:59.266702 [0] Epoch 00019 | Loss 13.0934
11:10:59.272929 [0] Epoch: 019, Train: 0.2584, Val: 0.2931, Test: 0.2624
11:10:59.300274 [0] 
timer summary:
  2.44s   2.02s   160 broadcast
  0.62s   0.47s   160 spmm
  1.24s   0.74s    80 mm
  0.23s   0.12s    40 all_reduce
  4.93s   0.53s    20 epoch
  6.43s   0.01s     1 total
11:11:26.732624 [0] proc begin: <DistEnv 0/2 nccl>
11:11:28.184958 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
11:11:28.187858 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:11:30.949490 [0] Epoch 00000 | Loss 3.6925
11:11:30.955645 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
11:11:31.077562 [0] Epoch 00001 | Loss 3.5845
11:11:31.176781 [0] Epoch 00002 | Loss 3.8658
11:11:31.276680 [0] Epoch 00003 | Loss 4.6374
11:11:31.375286 [0] Epoch 00004 | Loss 5.8564
11:11:31.474554 [0] Epoch 00005 | Loss 7.4233
11:11:31.573806 [0] Epoch 00006 | Loss 9.2427
11:11:31.673084 [0] Epoch 00007 | Loss 11.2466
11:11:31.772355 [0] Epoch 00008 | Loss 13.4136
11:11:31.871578 [0] Epoch 00009 | Loss 15.7737
11:11:31.970854 [0] Epoch 00010 | Loss 18.3630
11:11:31.977056 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
11:11:32.099129 [0] Epoch 00011 | Loss 21.1870
11:11:32.198412 [0] Epoch 00012 | Loss 24.2306
11:11:32.297654 [0] Epoch 00013 | Loss 27.4851
11:11:32.397046 [0] Epoch 00014 | Loss 30.9766
11:11:32.496317 [0] Epoch 00015 | Loss 34.7489
11:11:32.595620 [0] Epoch 00016 | Loss 38.8200
11:11:32.694873 [0] Epoch 00017 | Loss 43.1675
11:11:32.794094 [0] Epoch 00018 | Loss 47.7810
11:11:32.893424 [0] Epoch 00019 | Loss 52.7073
11:11:32.899582 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
11:11:32.926949 [0] 
timer summary:
  1.33s   0.64s    80 mm
  0.64s   0.31s    80 broadcast
  0.47s   0.31s    80 spmm
  0.18s   0.13s    40 all_reduce
  4.42s   0.38s    20 epoch
  6.18s   0.01s     1 total
11:12:13.053895 [0] proc begin: <DistEnv 0/2 nccl>
11:12:14.463972 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:12:14.466962 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:12:17.494960 [0] Epoch 00000 | Loss 3.6797
11:12:17.500866 [0] Epoch: 000, Train: 0.0259, Val: 0.0271, Test: 0.0269
11:12:17.617320 [0] Epoch 00001 | Loss 3.4861
11:12:17.711405 [0] Epoch 00002 | Loss 3.4453
11:12:17.805675 [0] Epoch 00003 | Loss 3.5961
11:12:17.899828 [0] Epoch 00004 | Loss 3.9358
11:12:17.994220 [0] Epoch 00005 | Loss 4.4300
11:12:18.088180 [0] Epoch 00006 | Loss 5.0457
11:12:18.182700 [0] Epoch 00007 | Loss 5.7493
11:12:18.276965 [0] Epoch 00008 | Loss 6.5105
11:12:18.370630 [0] Epoch 00009 | Loss 7.3267
11:12:18.465053 [0] Epoch 00010 | Loss 8.1667
11:12:18.471501 [0] Epoch: 010, Train: 0.2481, Val: 0.2887, Test: 0.2587
11:12:18.588157 [0] Epoch 00011 | Loss 8.9586
11:12:18.682386 [0] Epoch 00012 | Loss 9.6813
11:12:18.776522 [0] Epoch 00013 | Loss 10.2843
11:12:18.870774 [0] Epoch 00014 | Loss 10.7786
11:12:18.965010 [0] Epoch 00015 | Loss 11.1752
11:12:19.059225 [0] Epoch 00016 | Loss 11.5051
11:12:19.153431 [0] Epoch 00017 | Loss 11.7761
11:12:19.247849 [0] Epoch 00018 | Loss 11.9818
11:12:19.341566 [0] Epoch 00019 | Loss 12.1189
11:12:19.347699 [0] Epoch: 019, Train: 0.2638, Val: 0.2952, Test: 0.2645
11:12:19.375352 [0] 
timer summary:
  1.45s   0.72s    80 mm
  1.88s   1.88s   160 broadcast
  0.61s   0.48s   160 spmm
  0.23s   0.12s    40 all_reduce
  4.61s   0.36s    20 epoch
  6.30s   0.01s     1 total
14:54:26.500159 [0] proc begin: <DistEnv 0/2 nccl>
14:54:28.131189 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
14:54:28.133979 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:54:31.437296 [0] Epoch 00000 | Loss 3.6925
14:54:31.443401 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
14:54:31.565135 [0] Epoch 00001 | Loss 3.5845
14:54:31.664442 [0] Epoch 00002 | Loss 3.8658
14:54:31.763731 [0] Epoch 00003 | Loss 4.6374
14:54:31.863092 [0] Epoch 00004 | Loss 5.8564
14:54:31.968917 [0] Epoch 00005 | Loss 7.4233
14:54:32.068326 [0] Epoch 00006 | Loss 9.2427
14:54:32.167656 [0] Epoch 00007 | Loss 11.2466
14:54:32.269804 [0] Epoch 00008 | Loss 13.4136
14:54:32.369137 [0] Epoch 00009 | Loss 15.7737
14:54:32.468781 [0] Epoch 00010 | Loss 18.3630
14:54:32.475107 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
14:54:32.598761 [0] Epoch 00011 | Loss 21.1870
14:54:32.697921 [0] Epoch 00012 | Loss 24.2306
14:54:32.797320 [0] Epoch 00013 | Loss 27.4851
14:54:32.896578 [0] Epoch 00014 | Loss 30.9766
14:54:32.995940 [0] Epoch 00015 | Loss 34.7489
14:54:33.095264 [0] Epoch 00016 | Loss 38.8200
14:54:33.196008 [0] Epoch 00017 | Loss 43.1675
14:54:33.295160 [0] Epoch 00018 | Loss 47.7810
14:54:33.394610 [0] Epoch 00019 | Loss 52.7074
14:54:33.494014 [0] Epoch 00020 | Loss 57.9163
14:54:33.499830 [0] Epoch: 020, Train: 0.1219, Val: 0.1366, Test: 0.1319
14:54:33.622337 [0] Epoch 00021 | Loss 63.4050
14:54:33.721328 [0] Epoch 00022 | Loss 69.2416
14:54:33.822946 [0] Epoch 00023 | Loss 75.4387
14:54:33.921713 [0] Epoch 00024 | Loss 82.0022
14:54:34.021007 [0] Epoch 00025 | Loss 88.9442
14:54:34.120332 [0] Epoch 00026 | Loss 96.2252
14:54:34.219636 [0] Epoch 00027 | Loss 103.8738
14:54:34.318964 [0] Epoch 00028 | Loss 111.9224
14:54:34.418222 [0] Epoch 00029 | Loss 120.3934
14:54:34.517517 [0] Epoch 00030 | Loss 129.2964
14:54:34.523887 [0] Epoch: 030, Train: 0.1243, Val: 0.1394, Test: 0.1338
14:54:34.646574 [0] Epoch 00031 | Loss 138.6120
14:54:34.745877 [0] Epoch 00032 | Loss 148.3563
14:54:34.845436 [0] Epoch 00033 | Loss 158.5576
14:54:34.943868 [0] Epoch 00034 | Loss 169.2257
14:54:35.043189 [0] Epoch 00035 | Loss 180.3734
14:54:35.142533 [0] Epoch 00036 | Loss 192.0086
14:54:35.241845 [0] Epoch 00037 | Loss 204.1017
14:54:35.341228 [0] Epoch 00038 | Loss 216.7072
14:54:35.440751 [0] Epoch 00039 | Loss 229.8490
14:54:35.540116 [0] Epoch 00040 | Loss 243.4846
14:54:35.546678 [0] Epoch: 040, Train: 0.1236, Val: 0.1374, Test: 0.1326
14:54:35.668028 [0] Epoch 00041 | Loss 257.6526
14:54:35.767329 [0] Epoch 00042 | Loss 272.1324
14:54:35.867088 [0] Epoch 00043 | Loss 286.7610
14:54:35.965995 [0] Epoch 00044 | Loss 301.3252
14:54:36.065237 [0] Epoch 00045 | Loss 316.0774
14:54:36.164508 [0] Epoch 00046 | Loss 332.3400
14:54:36.263842 [0] Epoch 00047 | Loss 346.0570
14:54:36.363375 [0] Epoch 00048 | Loss 362.3319
14:54:36.462962 [0] Epoch 00049 | Loss 369.4483
14:54:36.562084 [0] Epoch 00050 | Loss 383.3892
14:54:36.568080 [0] Epoch: 050, Train: 0.0581, Val: 0.0934, Test: 0.1015
14:54:36.690257 [0] Epoch 00051 | Loss 393.3403
14:54:36.789518 [0] Epoch 00052 | Loss 404.9128
14:54:36.888718 [0] Epoch 00053 | Loss 412.0730
14:54:36.988005 [0] Epoch 00054 | Loss 425.3214
14:54:37.087324 [0] Epoch 00055 | Loss 440.2024
14:54:37.187198 [0] Epoch 00056 | Loss 452.9634
14:54:37.286449 [0] Epoch 00057 | Loss 469.8881
14:54:37.385759 [0] Epoch 00058 | Loss 483.6540
14:54:37.484505 [0] Epoch 00059 | Loss 502.4246
14:54:37.583798 [0] Epoch 00060 | Loss 517.5221
14:54:37.590160 [0] Epoch: 060, Train: 0.1028, Val: 0.1054, Test: 0.0929
14:54:37.712910 [0] Epoch 00061 | Loss 535.0397
14:54:37.812226 [0] Epoch 00062 | Loss 551.8356
14:54:37.911532 [0] Epoch 00063 | Loss 568.8011
14:54:38.010831 [0] Epoch 00064 | Loss 589.1144
14:54:38.109836 [0] Epoch 00065 | Loss 607.9763
14:54:38.209415 [0] Epoch 00066 | Loss 628.7541
14:54:38.308592 [0] Epoch 00067 | Loss 650.0428
14:54:38.407431 [0] Epoch 00068 | Loss 672.0709
14:54:38.507263 [0] Epoch 00069 | Loss 691.8867
14:54:38.606620 [0] Epoch 00070 | Loss 713.3689
14:54:38.613124 [0] Epoch: 070, Train: 0.0717, Val: 0.0875, Test: 0.1133
14:54:38.734445 [0] Epoch 00071 | Loss 733.7036
14:54:38.833775 [0] Epoch 00072 | Loss 756.6423
14:54:38.933093 [0] Epoch 00073 | Loss 776.9924
14:54:39.032391 [0] Epoch 00074 | Loss 799.1866
14:54:39.131960 [0] Epoch 00075 | Loss 820.9030
14:54:39.231137 [0] Epoch 00076 | Loss 844.9335
14:54:39.330242 [0] Epoch 00077 | Loss 870.4799
14:54:39.429985 [0] Epoch 00078 | Loss 894.8705
14:54:39.529506 [0] Epoch 00079 | Loss 920.2534
14:54:39.628617 [0] Epoch 00080 | Loss 940.6273
14:54:39.635100 [0] Epoch: 080, Train: 0.1197, Val: 0.1210, Test: 0.1119
14:54:39.756627 [0] Epoch 00081 | Loss 965.1429
14:54:39.856396 [0] Epoch 00082 | Loss 986.0749
14:54:39.955221 [0] Epoch 00083 | Loss 1010.4869
14:54:40.054543 [0] Epoch 00084 | Loss 1031.9092
14:54:40.153878 [0] Epoch 00085 | Loss 1055.2992
14:54:40.253200 [0] Epoch 00086 | Loss 1078.6519
14:54:40.352402 [0] Epoch 00087 | Loss 1103.0303
14:54:40.451797 [0] Epoch 00088 | Loss 1126.7841
14:54:40.551106 [0] Epoch 00089 | Loss 1151.9041
14:54:40.650901 [0] Epoch 00090 | Loss 1179.8071
14:54:40.657512 [0] Epoch: 090, Train: 0.0816, Val: 0.0955, Test: 0.0998
14:54:40.778840 [0] Epoch 00091 | Loss 1205.8350
14:54:40.878555 [0] Epoch 00092 | Loss 1232.1790
14:54:40.977453 [0] Epoch 00093 | Loss 1261.3892
14:54:41.076740 [0] Epoch 00094 | Loss 1288.3491
14:54:41.176060 [0] Epoch 00095 | Loss 1315.0803
14:54:41.275405 [0] Epoch 00096 | Loss 1344.6637
14:54:41.375161 [0] Epoch 00097 | Loss 1372.9843
14:54:41.474062 [0] Epoch 00098 | Loss 1402.2976
14:54:41.573255 [0] Epoch 00099 | Loss 1434.8770
14:54:41.579517 [0] Epoch: 099, Train: 0.0951, Val: 0.0504, Test: 0.0388
14:54:41.606967 [0] 
timer summary:
  2.06s   1.26s   400 mm
  3.18s   1.55s   400 broadcast
  1.02s   0.81s   400 spmm
  0.90s   0.63s   200 all_reduce
 12.95s   0.60s   100 epoch
 15.09s   0.02s     1 total
14:59:36.603444 [0] proc begin: <DistEnv 0/2 nccl>
14:59:37.922051 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
14:59:37.924571 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:59:40.651310 [0] Epoch 00000 | Loss 3.6797
14:59:40.657637 [0] Epoch: 000, Train: 0.0259, Val: 0.0271, Test: 0.0269
14:59:40.773619 [0] Epoch 00001 | Loss 3.4861
14:59:40.867195 [0] Epoch 00002 | Loss 3.4453
14:59:40.961292 [0] Epoch 00003 | Loss 3.5961
14:59:41.055447 [0] Epoch 00004 | Loss 3.9358
14:59:41.149838 [0] Epoch 00005 | Loss 4.4300
14:59:41.243625 [0] Epoch 00006 | Loss 5.0457
14:59:41.337733 [0] Epoch 00007 | Loss 5.7493
14:59:41.431836 [0] Epoch 00008 | Loss 6.5105
14:59:41.525937 [0] Epoch 00009 | Loss 7.3267
14:59:41.620065 [0] Epoch 00010 | Loss 8.1667
14:59:41.626289 [0] Epoch: 010, Train: 0.2481, Val: 0.2887, Test: 0.2587
14:59:41.743242 [0] Epoch 00011 | Loss 8.9586
14:59:41.837368 [0] Epoch 00012 | Loss 9.6813
14:59:41.931488 [0] Epoch 00013 | Loss 10.2843
14:59:42.025571 [0] Epoch 00014 | Loss 10.7786
14:59:42.119725 [0] Epoch 00015 | Loss 11.1752
14:59:42.213823 [0] Epoch 00016 | Loss 11.5051
14:59:42.307913 [0] Epoch 00017 | Loss 11.7761
14:59:42.402042 [0] Epoch 00018 | Loss 11.9818
14:59:42.496397 [0] Epoch 00019 | Loss 12.1189
14:59:42.590237 [0] Epoch 00020 | Loss 12.2051
14:59:42.596447 [0] Epoch: 020, Train: 0.2688, Val: 0.2972, Test: 0.2668
14:59:42.713385 [0] Epoch 00021 | Loss 12.2800
14:59:42.807538 [0] Epoch 00022 | Loss 12.3657
14:59:42.901598 [0] Epoch 00023 | Loss 12.4701
14:59:42.995700 [0] Epoch 00024 | Loss 12.5707
14:59:43.089810 [0] Epoch 00025 | Loss 12.6611
14:59:43.184065 [0] Epoch 00026 | Loss 12.7488
14:59:43.278216 [0] Epoch 00027 | Loss 12.8454
14:59:43.372067 [0] Epoch 00028 | Loss 12.9253
14:59:43.466250 [0] Epoch 00029 | Loss 12.9531
14:59:43.560280 [0] Epoch 00030 | Loss 12.9294
14:59:43.566416 [0] Epoch: 030, Train: 0.2803, Val: 0.3073, Test: 0.2787
14:59:43.683755 [0] Epoch 00031 | Loss 12.8752
14:59:43.777765 [0] Epoch 00032 | Loss 12.8040
14:59:43.871666 [0] Epoch 00033 | Loss 12.7192
14:59:43.965807 [0] Epoch 00034 | Loss 12.6211
14:59:44.059886 [0] Epoch 00035 | Loss 12.5131
14:59:44.153990 [0] Epoch 00036 | Loss 12.4064
14:59:44.248113 [0] Epoch 00037 | Loss 12.3232
14:59:44.342765 [0] Epoch 00038 | Loss 12.2785
14:59:44.436356 [0] Epoch 00039 | Loss 12.2690
14:59:44.531039 [0] Epoch 00040 | Loss 12.2840
14:59:44.537656 [0] Epoch: 040, Train: 0.3106, Val: 0.3274, Test: 0.3023
14:59:44.654225 [0] Epoch 00041 | Loss 12.3163
14:59:44.747842 [0] Epoch 00042 | Loss 12.3592
14:59:44.841952 [0] Epoch 00043 | Loss 12.4029
14:59:44.936064 [0] Epoch 00044 | Loss 12.4411
14:59:45.030181 [0] Epoch 00045 | Loss 12.4744
14:59:45.124295 [0] Epoch 00046 | Loss 12.5052
14:59:45.219064 [0] Epoch 00047 | Loss 12.5301
14:59:45.313135 [0] Epoch 00048 | Loss 12.5429
14:59:45.406604 [0] Epoch 00049 | Loss 12.5422
14:59:45.500728 [0] Epoch 00050 | Loss 12.5328
14:59:45.506964 [0] Epoch: 050, Train: 0.3485, Val: 0.3594, Test: 0.3366
14:59:45.624392 [0] Epoch 00051 | Loss 12.5252
14:59:45.718035 [0] Epoch 00052 | Loss 12.5321
14:59:45.812163 [0] Epoch 00053 | Loss 12.5625
14:59:45.906262 [0] Epoch 00054 | Loss 12.6159
14:59:46.000951 [0] Epoch 00055 | Loss 12.6847
14:59:46.094491 [0] Epoch 00056 | Loss 12.7594
14:59:46.188617 [0] Epoch 00057 | Loss 12.8283
14:59:46.282642 [0] Epoch 00058 | Loss 12.8820
14:59:46.377375 [0] Epoch 00059 | Loss 12.9205
14:59:46.470937 [0] Epoch 00060 | Loss 12.9548
14:59:46.477101 [0] Epoch: 060, Train: 0.3787, Val: 0.3910, Test: 0.3746
14:59:46.594134 [0] Epoch 00061 | Loss 12.9985
14:59:46.688257 [0] Epoch 00062 | Loss 13.0597
14:59:46.782351 [0] Epoch 00063 | Loss 13.1405
14:59:46.876474 [0] Epoch 00064 | Loss 13.2389
14:59:46.970580 [0] Epoch 00065 | Loss 13.3481
14:59:47.064678 [0] Epoch 00066 | Loss 13.4596
14:59:47.158814 [0] Epoch 00067 | Loss 13.5683
14:59:47.252904 [0] Epoch 00068 | Loss 13.6742
14:59:47.347341 [0] Epoch 00069 | Loss 13.7784
14:59:47.441698 [0] Epoch 00070 | Loss 13.8804
14:59:47.448195 [0] Epoch: 070, Train: 0.4008, Val: 0.4165, Test: 0.4078
14:59:47.564304 [0] Epoch 00071 | Loss 13.9802
14:59:47.658436 [0] Epoch 00072 | Loss 14.0801
14:59:47.752539 [0] Epoch 00073 | Loss 14.1831
14:59:47.846665 [0] Epoch 00074 | Loss 14.2912
14:59:47.940762 [0] Epoch 00075 | Loss 14.4052
14:59:48.034894 [0] Epoch 00076 | Loss 14.5249
14:59:48.129014 [0] Epoch 00077 | Loss 14.6481
14:59:48.223107 [0] Epoch 00078 | Loss 14.7712
14:59:48.317711 [0] Epoch 00079 | Loss 14.8914
14:59:48.412014 [0] Epoch 00080 | Loss 15.0081
14:59:48.418454 [0] Epoch: 080, Train: 0.4172, Val: 0.4411, Test: 0.4381
14:59:48.534537 [0] Epoch 00081 | Loss 15.1229
14:59:48.628634 [0] Epoch 00082 | Loss 15.2376
14:59:48.722770 [0] Epoch 00083 | Loss 15.3542
14:59:48.816856 [0] Epoch 00084 | Loss 15.4753
14:59:48.910965 [0] Epoch 00085 | Loss 15.6008
14:59:49.005243 [0] Epoch 00086 | Loss 15.7287
14:59:49.099157 [0] Epoch 00087 | Loss 15.8580
14:59:49.193263 [0] Epoch 00088 | Loss 15.9895
14:59:49.287335 [0] Epoch 00089 | Loss 16.1242
14:59:49.381504 [0] Epoch 00090 | Loss 16.2618
14:59:49.387705 [0] Epoch: 090, Train: 0.4339, Val: 0.4647, Test: 0.4666
14:59:49.504709 [0] Epoch 00091 | Loss 16.4015
14:59:49.598813 [0] Epoch 00092 | Loss 16.5420
14:59:49.692884 [0] Epoch 00093 | Loss 16.6815
14:59:49.787002 [0] Epoch 00094 | Loss 16.8188
14:59:49.881155 [0] Epoch 00095 | Loss 16.9547
14:59:49.975286 [0] Epoch 00096 | Loss 17.0922
14:59:50.069883 [0] Epoch 00097 | Loss 17.2342
14:59:50.163504 [0] Epoch 00098 | Loss 17.3811
14:59:50.257654 [0] Epoch 00099 | Loss 17.5324
14:59:50.263825 [0] Epoch: 099, Train: 0.4469, Val: 0.4829, Test: 0.4875
14:59:50.291162 [0] 
timer summary:
  1.82s   1.12s   400 mm
  5.70s   4.71s   800 broadcast
  1.38s   1.41s   800 spmm
  0.95s   0.62s   200 all_reduce
 11.93s   0.48s   100 epoch
 13.67s   0.01s     1 total
15:00:36.763767 [0] proc begin: <DistEnv 0/2 nccl>
15:00:38.084850 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
15:00:38.087670 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:00:40.955417 [0] Epoch 00000 | Loss 3.6796
15:00:40.961601 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
15:00:41.101017 [0] Epoch 00001 | Loss 3.4888
15:00:41.217964 [0] Epoch 00002 | Loss 3.4475
15:00:41.335005 [0] Epoch 00003 | Loss 3.5963
15:00:41.451926 [0] Epoch 00004 | Loss 3.9376
15:00:41.568853 [0] Epoch 00005 | Loss 4.4440
15:00:41.685726 [0] Epoch 00006 | Loss 5.0673
15:00:41.802721 [0] Epoch 00007 | Loss 5.7588
15:00:41.919672 [0] Epoch 00008 | Loss 6.5295
15:00:42.036595 [0] Epoch 00009 | Loss 7.3825
15:00:42.153576 [0] Epoch 00010 | Loss 8.2472
15:00:42.159744 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
15:00:42.300201 [0] Epoch 00011 | Loss 9.0631
15:00:42.417190 [0] Epoch 00012 | Loss 9.8321
15:00:42.533570 [0] Epoch 00013 | Loss 10.5323
15:00:42.650530 [0] Epoch 00014 | Loss 11.1359
15:00:42.767495 [0] Epoch 00015 | Loss 11.6644
15:00:42.884989 [0] Epoch 00016 | Loss 12.0868
15:00:43.001423 [0] Epoch 00017 | Loss 12.4616
15:00:43.118326 [0] Epoch 00018 | Loss 12.8053
15:00:43.235267 [0] Epoch 00019 | Loss 13.0934
15:00:43.352367 [0] Epoch 00020 | Loss 13.3051
15:00:43.358390 [0] Epoch: 020, Train: 0.2543, Val: 0.2914, Test: 0.2606
15:00:43.498215 [0] Epoch 00021 | Loss 13.4066
15:00:43.615158 [0] Epoch 00022 | Loss 13.4400
15:00:43.732019 [0] Epoch 00023 | Loss 13.4397
15:00:43.848971 [0] Epoch 00024 | Loss 13.4337
15:00:43.965865 [0] Epoch 00025 | Loss 13.4379
15:00:44.082920 [0] Epoch 00026 | Loss 13.4386
15:00:44.199803 [0] Epoch 00027 | Loss 13.4326
15:00:44.316873 [0] Epoch 00028 | Loss 13.4227
15:00:44.434194 [0] Epoch 00029 | Loss 13.4161
15:00:44.550720 [0] Epoch 00030 | Loss 13.4079
15:00:44.556867 [0] Epoch: 030, Train: 0.2720, Val: 0.3023, Test: 0.2726
15:00:44.696806 [0] Epoch 00031 | Loss 13.3808
15:00:44.813768 [0] Epoch 00032 | Loss 13.3160
15:00:44.930709 [0] Epoch 00033 | Loss 13.2179
15:00:45.047585 [0] Epoch 00034 | Loss 13.1002
15:00:45.164506 [0] Epoch 00035 | Loss 12.9706
15:00:45.281360 [0] Epoch 00036 | Loss 12.8357
15:00:45.398287 [0] Epoch 00037 | Loss 12.7045
15:00:45.515270 [0] Epoch 00038 | Loss 12.5852
15:00:45.632165 [0] Epoch 00039 | Loss 12.4782
15:00:45.748981 [0] Epoch 00040 | Loss 12.3834
15:00:45.755114 [0] Epoch: 040, Train: 0.3040, Val: 0.3259, Test: 0.2979
15:00:45.894918 [0] Epoch 00041 | Loss 12.3071
15:00:46.011830 [0] Epoch 00042 | Loss 12.2597
15:00:46.128963 [0] Epoch 00043 | Loss 12.2459
15:00:46.245897 [0] Epoch 00044 | Loss 12.2594
15:00:46.363001 [0] Epoch 00045 | Loss 12.2907
15:00:46.479659 [0] Epoch 00046 | Loss 12.3321
15:00:46.596527 [0] Epoch 00047 | Loss 12.3804
15:00:46.713308 [0] Epoch 00048 | Loss 12.4345
15:00:46.830099 [0] Epoch 00049 | Loss 12.4946
15:00:46.946971 [0] Epoch 00050 | Loss 12.5585
15:00:46.953097 [0] Epoch: 050, Train: 0.3422, Val: 0.3567, Test: 0.3332
15:00:47.092907 [0] Epoch 00051 | Loss 12.6186
15:00:47.209711 [0] Epoch 00052 | Loss 12.6674
15:00:47.326824 [0] Epoch 00053 | Loss 12.7039
15:00:47.443363 [0] Epoch 00054 | Loss 12.7351
15:00:47.560189 [0] Epoch 00055 | Loss 12.7693
15:00:47.676959 [0] Epoch 00056 | Loss 12.8113
15:00:47.793858 [0] Epoch 00057 | Loss 12.8635
15:00:47.910808 [0] Epoch 00058 | Loss 12.9288
15:00:48.027644 [0] Epoch 00059 | Loss 13.0058
15:00:48.144454 [0] Epoch 00060 | Loss 13.0864
15:00:48.150602 [0] Epoch: 060, Train: 0.3686, Val: 0.3824, Test: 0.3651
15:00:48.290397 [0] Epoch 00061 | Loss 13.1626
15:00:48.407400 [0] Epoch 00062 | Loss 13.2326
15:00:48.524014 [0] Epoch 00063 | Loss 13.2989
15:00:48.640809 [0] Epoch 00064 | Loss 13.3658
15:00:48.757668 [0] Epoch 00065 | Loss 13.4389
15:00:48.874431 [0] Epoch 00066 | Loss 13.5225
15:00:48.991339 [0] Epoch 00067 | Loss 13.6154
15:00:49.108271 [0] Epoch 00068 | Loss 13.7106
15:00:49.225189 [0] Epoch 00069 | Loss 13.8025
15:00:49.342363 [0] Epoch 00070 | Loss 13.8912
15:00:49.348599 [0] Epoch: 070, Train: 0.3902, Val: 0.4062, Test: 0.3959
15:00:49.487941 [0] Epoch 00071 | Loss 13.9787
15:00:49.604754 [0] Epoch 00072 | Loss 14.0672
15:00:49.721557 [0] Epoch 00073 | Loss 14.1603
15:00:49.838367 [0] Epoch 00074 | Loss 14.2621
15:00:49.955255 [0] Epoch 00075 | Loss 14.3729
15:00:50.072093 [0] Epoch 00076 | Loss 14.4886
15:00:50.188900 [0] Epoch 00077 | Loss 14.6046
15:00:50.305878 [0] Epoch 00078 | Loss 14.7190
15:00:50.422598 [0] Epoch 00079 | Loss 14.8303
15:00:50.539387 [0] Epoch 00080 | Loss 14.9385
15:00:50.545524 [0] Epoch: 080, Train: 0.4066, Val: 0.4309, Test: 0.4261
15:00:50.685320 [0] Epoch 00081 | Loss 15.0472
15:00:50.802272 [0] Epoch 00082 | Loss 15.1594
15:00:50.919124 [0] Epoch 00083 | Loss 15.2742
15:00:51.036023 [0] Epoch 00084 | Loss 15.3886
15:00:51.152756 [0] Epoch 00085 | Loss 15.5009
15:00:51.269578 [0] Epoch 00086 | Loss 15.6101
15:00:51.386401 [0] Epoch 00087 | Loss 15.7157
15:00:51.503446 [0] Epoch 00088 | Loss 15.8186
15:00:51.620122 [0] Epoch 00089 | Loss 15.9229
15:00:51.737015 [0] Epoch 00090 | Loss 16.0319
15:00:51.743175 [0] Epoch: 090, Train: 0.4229, Val: 0.4536, Test: 0.4555
15:00:51.882946 [0] Epoch 00091 | Loss 16.1466
15:00:51.999772 [0] Epoch 00092 | Loss 16.2668
15:00:52.116651 [0] Epoch 00093 | Loss 16.3911
15:00:52.233475 [0] Epoch 00094 | Loss 16.5156
15:00:52.350638 [0] Epoch 00095 | Loss 16.6360
15:00:52.467455 [0] Epoch 00096 | Loss 16.7505
15:00:52.584087 [0] Epoch 00097 | Loss 16.8603
15:00:52.700920 [0] Epoch 00098 | Loss 16.9678
15:00:52.817826 [0] Epoch 00099 | Loss 17.0758
15:00:52.824010 [0] Epoch: 099, Train: 0.4367, Val: 0.4736, Test: 0.4790
15:00:52.851408 [0] 
timer summary:
  7.94s   4.46s   800 broadcast
  1.63s   1.45s   800 spmm
  1.85s   1.12s   400 mm
  0.95s   0.62s   200 all_reduce
 14.31s   0.51s   100 epoch
 16.07s   0.01s     1 total
15:07:41.435736 [0] proc begin: <DistEnv 0/2 nccl>
15:07:42.754092 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
15:07:42.757002 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:07:45.642709 [0] Epoch 00000 | Loss 3.6796
15:07:45.648583 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
15:07:45.789445 [0] Epoch 00001 | Loss 3.4888
15:07:45.907555 [0] Epoch 00002 | Loss 3.4475
15:07:46.025768 [0] Epoch 00003 | Loss 3.5963
15:07:46.143932 [0] Epoch 00004 | Loss 3.9376
15:07:46.262051 [0] Epoch 00005 | Loss 4.4440
15:07:46.380221 [0] Epoch 00006 | Loss 5.0673
15:07:46.498411 [0] Epoch 00007 | Loss 5.7588
15:07:46.616625 [0] Epoch 00008 | Loss 6.5295
15:07:46.734742 [0] Epoch 00009 | Loss 7.3825
15:07:46.852855 [0] Epoch 00010 | Loss 8.2471
15:07:46.859020 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
15:07:47.000149 [0] Epoch 00011 | Loss 9.0631
15:07:47.118366 [0] Epoch 00012 | Loss 9.8321
15:07:47.236781 [0] Epoch 00013 | Loss 10.5323
15:07:47.354697 [0] Epoch 00014 | Loss 11.1359
15:07:47.472879 [0] Epoch 00015 | Loss 11.6644
15:07:47.591001 [0] Epoch 00016 | Loss 12.0868
15:07:47.709150 [0] Epoch 00017 | Loss 12.4616
15:07:47.827371 [0] Epoch 00018 | Loss 12.8053
15:07:47.946004 [0] Epoch 00019 | Loss 13.0934
15:07:48.063516 [0] Epoch 00020 | Loss 13.3051
15:07:48.069655 [0] Epoch: 020, Train: 0.2543, Val: 0.2914, Test: 0.2606
15:07:48.211064 [0] Epoch 00021 | Loss 13.4066
15:07:48.329057 [0] Epoch 00022 | Loss 13.4400
15:07:48.447146 [0] Epoch 00023 | Loss 13.4397
15:07:48.565495 [0] Epoch 00024 | Loss 13.4337
15:07:48.683601 [0] Epoch 00025 | Loss 13.4379
15:07:48.801616 [0] Epoch 00026 | Loss 13.4386
15:07:48.920443 [0] Epoch 00027 | Loss 13.4326
15:07:49.037899 [0] Epoch 00028 | Loss 13.4227
15:07:49.156591 [0] Epoch 00029 | Loss 13.4161
15:07:49.274275 [0] Epoch 00030 | Loss 13.4079
15:07:49.280412 [0] Epoch: 030, Train: 0.2720, Val: 0.3023, Test: 0.2726
15:07:49.421503 [0] Epoch 00031 | Loss 13.3808
15:07:49.539648 [0] Epoch 00032 | Loss 13.3160
15:07:49.657806 [0] Epoch 00033 | Loss 13.2179
15:07:49.776605 [0] Epoch 00034 | Loss 13.1002
15:07:49.894114 [0] Epoch 00035 | Loss 12.9706
15:07:50.012261 [0] Epoch 00036 | Loss 12.8357
15:07:50.130389 [0] Epoch 00037 | Loss 12.7045
15:07:50.248943 [0] Epoch 00038 | Loss 12.5852
15:07:50.366728 [0] Epoch 00039 | Loss 12.4782
15:07:50.484846 [0] Epoch 00040 | Loss 12.3834
15:07:50.490989 [0] Epoch: 040, Train: 0.3040, Val: 0.3259, Test: 0.2979
15:07:50.632143 [0] Epoch 00041 | Loss 12.3071
15:07:50.750723 [0] Epoch 00042 | Loss 12.2597
15:07:50.868992 [0] Epoch 00043 | Loss 12.2459
15:07:50.987077 [0] Epoch 00044 | Loss 12.2594
15:07:51.105233 [0] Epoch 00045 | Loss 12.2907
15:07:51.223339 [0] Epoch 00046 | Loss 12.3321
15:07:51.341464 [0] Epoch 00047 | Loss 12.3804
15:07:51.459693 [0] Epoch 00048 | Loss 12.4345
15:07:51.577748 [0] Epoch 00049 | Loss 12.4946
15:07:51.695880 [0] Epoch 00050 | Loss 12.5585
15:07:51.702273 [0] Epoch: 050, Train: 0.3422, Val: 0.3567, Test: 0.3332
15:07:51.842520 [0] Epoch 00051 | Loss 12.6186
15:07:51.960515 [0] Epoch 00052 | Loss 12.6674
15:07:52.078684 [0] Epoch 00053 | Loss 12.7039
15:07:52.197496 [0] Epoch 00054 | Loss 12.7351
15:07:52.315136 [0] Epoch 00055 | Loss 12.7693
15:07:52.433337 [0] Epoch 00056 | Loss 12.8113
15:07:52.551710 [0] Epoch 00057 | Loss 12.8635
15:07:52.669812 [0] Epoch 00058 | Loss 12.9288
15:07:52.787787 [0] Epoch 00059 | Loss 13.0058
15:07:52.905918 [0] Epoch 00060 | Loss 13.0864
15:07:52.912139 [0] Epoch: 060, Train: 0.3686, Val: 0.3824, Test: 0.3651
15:07:53.053526 [0] Epoch 00061 | Loss 13.1626
15:07:53.171461 [0] Epoch 00062 | Loss 13.2326
15:07:53.289500 [0] Epoch 00063 | Loss 13.2989
15:07:53.407583 [0] Epoch 00064 | Loss 13.3658
15:07:53.525749 [0] Epoch 00065 | Loss 13.4389
15:07:53.643912 [0] Epoch 00066 | Loss 13.5226
15:07:53.762048 [0] Epoch 00067 | Loss 13.6154
15:07:53.880241 [0] Epoch 00068 | Loss 13.7106
15:07:53.998390 [0] Epoch 00069 | Loss 13.8025
15:07:54.116668 [0] Epoch 00070 | Loss 13.8912
15:07:54.122790 [0] Epoch: 070, Train: 0.3902, Val: 0.4062, Test: 0.3959
15:07:54.264159 [0] Epoch 00071 | Loss 13.9787
15:07:54.382068 [0] Epoch 00072 | Loss 14.0672
15:07:54.500151 [0] Epoch 00073 | Loss 14.1603
15:07:54.618422 [0] Epoch 00074 | Loss 14.2621
15:07:54.736575 [0] Epoch 00075 | Loss 14.3729
15:07:54.854737 [0] Epoch 00076 | Loss 14.4886
15:07:54.972910 [0] Epoch 00077 | Loss 14.6046
15:07:55.091087 [0] Epoch 00078 | Loss 14.7190
15:07:55.209509 [0] Epoch 00079 | Loss 14.8303
15:07:55.327543 [0] Epoch 00080 | Loss 14.9385
15:07:55.333702 [0] Epoch: 080, Train: 0.4066, Val: 0.4309, Test: 0.4261
15:07:55.475039 [0] Epoch 00081 | Loss 15.0472
15:07:55.592825 [0] Epoch 00082 | Loss 15.1594
15:07:55.710957 [0] Epoch 00083 | Loss 15.2742
15:07:55.829124 [0] Epoch 00084 | Loss 15.3886
15:07:55.947254 [0] Epoch 00085 | Loss 15.5009
15:07:56.065448 [0] Epoch 00086 | Loss 15.6101
15:07:56.183579 [0] Epoch 00087 | Loss 15.7157
15:07:56.301667 [0] Epoch 00088 | Loss 15.8186
15:07:56.420533 [0] Epoch 00089 | Loss 15.9229
15:07:56.538209 [0] Epoch 00090 | Loss 16.0319
15:07:56.544058 [0] Epoch: 090, Train: 0.4229, Val: 0.4536, Test: 0.4555
15:07:56.685285 [0] Epoch 00091 | Loss 16.1466
15:07:56.803477 [0] Epoch 00092 | Loss 16.2668
15:07:56.921731 [0] Epoch 00093 | Loss 16.3911
15:07:57.039632 [0] Epoch 00094 | Loss 16.5156
15:07:57.158091 [0] Epoch 00095 | Loss 16.6360
15:07:57.276006 [0] Epoch 00096 | Loss 16.7505
15:07:57.394152 [0] Epoch 00097 | Loss 16.8603
15:07:57.512586 [0] Epoch 00098 | Loss 16.9678
15:07:57.630462 [0] Epoch 00099 | Loss 17.0758
15:07:57.636615 [0] Epoch: 099, Train: 0.4367, Val: 0.4736, Test: 0.4790
15:07:57.664024 [0] 
timer summary:
  8.06s   4.45s   800 broadcast
  1.62s   1.44s   800 spmm
  1.88s   1.14s   400 mm
  0.94s   0.60s   200 all_reduce
 14.46s   0.50s   100 epoch
 16.21s   0.01s     1 total
15:08:31.327382 [0] proc begin: <DistEnv 0/2 nccl>
15:08:42.933075 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:08:42.936154 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:08:46.674269 [0] Epoch 00000 | Loss 3.6990
15:08:46.684521 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
15:08:47.533061 [0] Epoch 00001 | Loss 2.8555
15:08:48.363366 [0] Epoch 00002 | Loss 2.2462
15:08:49.195282 [0] Epoch 00003 | Loss 1.8442
15:08:50.028755 [0] Epoch 00004 | Loss 1.5542
15:08:50.860416 [0] Epoch 00005 | Loss 1.3270
15:08:51.692619 [0] Epoch 00006 | Loss 1.1315
15:08:52.525235 [0] Epoch 00007 | Loss 1.0060
15:08:53.358203 [0] Epoch 00008 | Loss 0.8950
15:08:54.190191 [0] Epoch 00009 | Loss 0.7887
15:08:55.022515 [0] Epoch 00010 | Loss 0.7129
15:08:55.032360 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
15:08:55.888070 [0] Epoch 00011 | Loss 0.6705
15:08:56.721281 [0] Epoch 00012 | Loss 0.6240
15:08:57.554049 [0] Epoch 00013 | Loss 0.5829
15:08:58.387540 [0] Epoch 00014 | Loss 0.5582
15:08:59.219639 [0] Epoch 00015 | Loss 0.5328
15:09:00.052603 [0] Epoch 00016 | Loss 0.5084
15:09:00.885603 [0] Epoch 00017 | Loss 0.4888
15:09:01.718296 [0] Epoch 00018 | Loss 0.4716
15:09:02.551216 [0] Epoch 00019 | Loss 0.4586
15:09:02.561264 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
15:09:02.588514 [0] 
timer summary:
  6.50s   5.97s   160 broadcast
 10.03s   5.12s   160 spmm
  1.57s   0.73s    80 mm
  0.68s   0.75s    40 all_reduce
 19.27s   0.46s    20 epoch
 31.25s   0.02s     1 total
15:10:36.027017 [0] proc begin: <DistEnv 0/2 nccl>
15:10:37.012249 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
15:10:37.012912 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:10:40.088698 [0] Epoch 00000 | Loss 1.9460
15:10:40.093049 [0] Epoch: 000, Train: 0.1143, Val: 0.2060, Test: 0.2000
15:10:40.190099 [0] Epoch 00001 | Loss 1.9093
15:10:40.264627 [0] Epoch 00002 | Loss 1.8631
15:10:40.339015 [0] Epoch 00003 | Loss 1.8043
15:10:40.413401 [0] Epoch 00004 | Loss 1.7353
15:10:40.487857 [0] Epoch 00005 | Loss 1.6568
15:10:40.562937 [0] Epoch 00006 | Loss 1.5686
15:10:40.636967 [0] Epoch 00007 | Loss 1.4710
15:10:40.711764 [0] Epoch 00008 | Loss 1.3651
15:10:40.786263 [0] Epoch 00009 | Loss 1.2527
15:10:40.860601 [0] Epoch 00010 | Loss 1.1357
15:10:40.865342 [0] Epoch: 010, Train: 0.9786, Val: 0.7900, Test: 0.8070
15:10:40.962333 [0] Epoch 00011 | Loss 1.0166
15:10:41.036858 [0] Epoch 00012 | Loss 0.8983
15:10:41.111499 [0] Epoch 00013 | Loss 0.7835
15:10:41.185540 [0] Epoch 00014 | Loss 0.6750
15:10:41.259922 [0] Epoch 00015 | Loss 0.5752
15:10:41.334335 [0] Epoch 00016 | Loss 0.4855
15:10:41.408792 [0] Epoch 00017 | Loss 0.4068
15:10:41.483306 [0] Epoch 00018 | Loss 0.3391
15:10:41.558351 [0] Epoch 00019 | Loss 0.2818
15:10:41.563237 [0] Epoch: 019, Train: 0.9857, Val: 0.7860, Test: 0.8100
15:10:41.589496 [0] 
timer summary:
  1.85s   1.93s   160 broadcast
  0.58s   0.48s   160 spmm
  1.21s   0.73s    80 mm
  0.23s   0.12s    40 all_reduce
  4.14s   0.56s    20 epoch
  5.54s   0.01s     1 total
15:14:37.942132 [0] proc begin: <DistEnv 0/2 nccl>
15:14:49.803337 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:14:49.806081 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:14:53.203073 [0] Epoch 00000 | Loss 3.9379
15:14:53.212185 [0] Epoch: 000, Train: 0.0153, Val: 0.0172, Test: 0.0171
15:14:54.075618 [0] Epoch 00001 | Loss 3.4473
15:14:54.919928 [0] Epoch 00002 | Loss 3.3080
15:14:55.764964 [0] Epoch 00003 | Loss 3.1781
15:14:56.609451 [0] Epoch 00004 | Loss 3.0637
15:14:57.449590 [0] Epoch 00005 | Loss 2.9619
15:14:58.281894 [0] Epoch 00006 | Loss 2.8683
15:14:59.123005 [0] Epoch 00007 | Loss 2.7739
15:14:59.963286 [0] Epoch 00008 | Loss 2.6707
15:15:00.803713 [0] Epoch 00009 | Loss 2.5570
15:15:01.638911 [0] Epoch 00010 | Loss 2.4289
15:15:01.649027 [0] Epoch: 010, Train: 0.4937, Val: 0.4934, Test: 0.4972
15:15:02.509028 [0] Epoch 00011 | Loss 2.2857
15:15:03.209277 [0] Epoch 00012 | Loss 2.1229
15:15:03.596593 [0] Epoch 00013 | Loss 1.9521
15:15:03.982777 [0] Epoch 00014 | Loss 1.7881
15:15:04.368073 [0] Epoch 00015 | Loss 1.6427
15:15:04.759238 [0] Epoch 00016 | Loss 1.5174
15:15:05.145954 [0] Epoch 00017 | Loss 1.4129
15:15:05.686598 [0] Epoch 00018 | Loss 1.3120
15:15:06.067402 [0] Epoch 00019 | Loss 1.2129
15:15:06.073556 [0] Epoch: 019, Train: 0.7188, Val: 0.7150, Test: 0.7112
15:15:06.075842 [0] 
timer summary:
  0.95s   0.32s    20 broadcast ForwardL1 0
  5.03s   3.45s   160 broadcast
  9.01s   3.17s   160 spmm
  1.19s   1.05s    20 broadcast ForwardL1 1
  1.64s   0.77s    80 mm
  1.33s   1.52s    20 broadcast ForwardL2 0
  0.46s   0.38s    20 broadcast ForwardL2 1
  0.34s   0.40s    20 broadcast BackwardL2 0
  0.10s   0.07s    20 broadcast BackwardL2 1
  0.42s   0.40s    40 all_reduce
  0.23s   0.01s    20 broadcast BackwardL1 0
  0.43s   0.35s    20 broadcast BackwardL1 1
 16.46s   0.32s    20 epoch
 28.13s   0.00s     1 total
15:15:22.113845 [0] proc begin: <DistEnv 0/2 nccl>
15:15:33.063896 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:15:33.066371 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:15:35.292266 [0] Epoch 00000 | Loss 3.9379
15:15:35.298067 [0] Epoch: 000, Train: 0.0153, Val: 0.0172, Test: 0.0171
15:15:35.694132 [0] Epoch 00001 | Loss 3.4473
15:15:36.086943 [0] Epoch 00002 | Loss 3.3080
15:15:36.474616 [0] Epoch 00003 | Loss 3.1781
15:15:36.865371 [0] Epoch 00004 | Loss 3.0637
15:15:37.252484 [0] Epoch 00005 | Loss 2.9619
15:15:37.635890 [0] Epoch 00006 | Loss 2.8683
15:15:38.019940 [0] Epoch 00007 | Loss 2.7739
15:15:38.404807 [0] Epoch 00008 | Loss 2.6707
15:15:38.789880 [0] Epoch 00009 | Loss 2.5570
15:15:39.176480 [0] Epoch 00010 | Loss 2.4289
15:15:39.182323 [0] Epoch: 010, Train: 0.4937, Val: 0.4934, Test: 0.4972
15:15:39.569541 [0] Epoch 00011 | Loss 2.2857
15:15:39.959057 [0] Epoch 00012 | Loss 2.1229
15:15:40.346835 [0] Epoch 00013 | Loss 1.9521
15:15:40.734085 [0] Epoch 00014 | Loss 1.7881
15:15:41.120985 [0] Epoch 00015 | Loss 1.6427
15:15:41.504499 [0] Epoch 00016 | Loss 1.5174
15:15:41.889341 [0] Epoch 00017 | Loss 1.4129
15:15:42.276705 [0] Epoch 00018 | Loss 1.3120
15:15:42.662285 [0] Epoch 00019 | Loss 1.2129
15:15:42.667947 [0] Epoch: 019, Train: 0.7188, Val: 0.7150, Test: 0.7112
15:15:42.671415 [0] 
timer summary:
  0.63s   0.29s    20 broadcast ForwardL1 0
  1.58s   0.41s   160 broadcast
  6.52s   0.04s   160 spmm
  0.31s   0.03s    20 broadcast ForwardL1 1
  0.99s   0.14s    80 mm
  0.24s   0.10s    20 broadcast ForwardL2 0
  0.12s   0.00s    20 broadcast ForwardL2 1
  0.02s   0.01s    20 broadcast BackwardL2 0
  0.02s   0.01s    20 broadcast BackwardL2 1
  0.06s   0.00s    40 all_reduce
  0.13s   0.01s    20 broadcast BackwardL1 0
  0.12s   0.00s    20 broadcast BackwardL1 1
  9.36s   0.31s    20 epoch
 20.55s   0.00s     1 total
15:15:59.023429 [0] proc begin: <DistEnv 0/2 nccl>
15:16:10.206069 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:16:10.208938 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:16:12.072067 [0] Epoch 00000 | Loss 3.6990
15:16:12.078618 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
15:16:12.457207 [0] Epoch 00001 | Loss 2.8555
15:16:12.835100 [0] Epoch 00002 | Loss 2.2462
15:16:13.212869 [0] Epoch 00003 | Loss 1.8442
15:16:13.591313 [0] Epoch 00004 | Loss 1.5542
15:16:13.969876 [0] Epoch 00005 | Loss 1.3270
15:16:14.348656 [0] Epoch 00006 | Loss 1.1315
15:16:14.727038 [0] Epoch 00007 | Loss 1.0060
15:16:15.105516 [0] Epoch 00008 | Loss 0.8950
15:16:15.483822 [0] Epoch 00009 | Loss 0.7887
15:16:15.860918 [0] Epoch 00010 | Loss 0.7129
15:16:15.866600 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
15:16:16.240914 [0] Epoch 00011 | Loss 0.6705
15:16:16.616560 [0] Epoch 00012 | Loss 0.6240
15:16:16.993418 [0] Epoch 00013 | Loss 0.5829
15:16:17.370936 [0] Epoch 00014 | Loss 0.5582
15:16:17.747923 [0] Epoch 00015 | Loss 0.5328
15:16:18.124675 [0] Epoch 00016 | Loss 0.5084
15:16:18.502473 [0] Epoch 00017 | Loss 0.4888
15:16:18.880082 [0] Epoch 00018 | Loss 0.4716
15:16:19.256574 [0] Epoch 00019 | Loss 0.4586
15:16:19.262292 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
15:16:19.264138 [0] 
timer summary:
  1.97s   0.77s   160 broadcast
  6.32s   0.08s   160 spmm
  1.06s   0.11s    80 mm
  0.06s   0.01s    40 all_reduce
  9.61s   0.82s    20 epoch
 20.24s   0.00s     1 total
15:17:29.066409 [0] proc begin: <DistEnv 0/2 nccl>
15:17:39.039105 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:17:39.041781 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:17:41.286455 [0] Epoch 00000 | Loss 3.6990
15:17:41.291543 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
15:17:41.665362 [0] Epoch 00001 | Loss 2.8555
15:17:42.037946 [0] Epoch 00002 | Loss 2.2462
15:17:42.409661 [0] Epoch 00003 | Loss 1.8442
15:17:42.781156 [0] Epoch 00004 | Loss 1.5542
15:17:43.152933 [0] Epoch 00005 | Loss 1.3270
15:17:43.523796 [0] Epoch 00006 | Loss 1.1315
15:17:43.894793 [0] Epoch 00007 | Loss 1.0060
15:17:44.266261 [0] Epoch 00008 | Loss 0.8950
15:17:44.639562 [0] Epoch 00009 | Loss 0.7887
15:17:45.010506 [0] Epoch 00010 | Loss 0.7129
15:17:45.014865 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
15:17:45.385619 [0] Epoch 00011 | Loss 0.6705
15:17:45.757174 [0] Epoch 00012 | Loss 0.6240
15:17:46.128252 [0] Epoch 00013 | Loss 0.5829
15:17:46.499484 [0] Epoch 00014 | Loss 0.5582
15:17:46.870773 [0] Epoch 00015 | Loss 0.5328
15:17:47.242755 [0] Epoch 00016 | Loss 0.5084
15:17:47.613974 [0] Epoch 00017 | Loss 0.4888
15:17:47.985546 [0] Epoch 00018 | Loss 0.4716
15:17:48.357612 [0] Epoch 00019 | Loss 0.4586
15:17:48.363174 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
15:17:48.366017 [0] 
timer summary:
  1.54s   0.47s   160 broadcast
  6.30s   0.06s   160 spmm
  0.89s   0.05s    80 mm
  0.06s   0.02s    40 all_reduce
  8.98s   0.46s    20 epoch
 19.29s   0.00s     1 total
15:19:23.587397 [0] proc begin: <DistEnv 0/2 nccl>
15:19:35.010050 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:19:35.012773 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:19:37.207773 [0] Epoch 00000 | Loss 3.7175
15:19:37.213872 [0] Epoch: 000, Train: 0.0233, Val: 0.0159, Test: 0.0164
15:19:37.278582 [0] Epoch 00001 | Loss 2.8340
15:19:37.343000 [0] Epoch 00002 | Loss 2.4177
15:19:37.408451 [0] Epoch 00003 | Loss 2.0779
15:19:37.473885 [0] Epoch 00004 | Loss 1.8086
15:19:37.539632 [0] Epoch 00005 | Loss 1.5902
15:19:37.605020 [0] Epoch 00006 | Loss 1.4156
15:19:37.670113 [0] Epoch 00007 | Loss 1.2602
15:19:37.735986 [0] Epoch 00008 | Loss 1.1329
15:19:37.801911 [0] Epoch 00009 | Loss 1.0079
15:19:37.867118 [0] Epoch 00010 | Loss 0.9141
15:19:37.871632 [0] Epoch: 010, Train: 0.8282, Val: 0.8445, Test: 0.8394
15:19:37.936578 [0] Epoch 00011 | Loss 0.8423
15:19:38.002419 [0] Epoch 00012 | Loss 0.7948
15:19:38.067596 [0] Epoch 00013 | Loss 0.7511
15:19:38.133426 [0] Epoch 00014 | Loss 0.6858
15:19:38.199557 [0] Epoch 00015 | Loss 0.6427
15:19:38.265545 [0] Epoch 00016 | Loss 0.6211
15:19:38.331669 [0] Epoch 00017 | Loss 0.6046
15:19:38.397600 [0] Epoch 00018 | Loss 0.5773
15:19:38.463345 [0] Epoch 00019 | Loss 0.5491
15:19:38.468968 [0] Epoch: 019, Train: 0.8974, Val: 0.9097, Test: 0.9067
15:19:38.471138 [0] 
timer summary:
  1.01s   0.10s    80 mm
  0.74s   0.65s   160 broadcast
  1.11s   0.03s   160 spmm
  0.06s   0.00s    40 all_reduce
  3.07s   0.52s    20 epoch
 14.88s   0.01s     1 total
15:23:23.600144 [0] proc begin: <DistEnv 0/2 nccl>
15:23:25.119944 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
15:23:25.123189 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:23:26.489781 [0] Epoch 00000 | Loss 3.6925
15:23:26.493587 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
15:23:26.507735 [0] Epoch 00001 | Loss 3.5845
15:23:26.520623 [0] Epoch 00002 | Loss 3.8658
15:23:26.531678 [0] Epoch 00003 | Loss 4.6374
15:23:26.542896 [0] Epoch 00004 | Loss 5.8564
15:23:26.554042 [0] Epoch 00005 | Loss 7.4233
15:23:26.565277 [0] Epoch 00006 | Loss 9.2427
15:23:26.576403 [0] Epoch 00007 | Loss 11.2466
15:23:26.587502 [0] Epoch 00008 | Loss 13.4136
15:23:26.598798 [0] Epoch 00009 | Loss 15.7737
15:23:26.610517 [0] Epoch 00010 | Loss 18.3630
15:23:26.613011 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
15:23:26.624701 [0] Epoch 00011 | Loss 21.1870
15:23:26.635803 [0] Epoch 00012 | Loss 24.2306
15:23:26.647086 [0] Epoch 00013 | Loss 27.4851
15:23:26.658666 [0] Epoch 00014 | Loss 30.9766
15:23:26.669634 [0] Epoch 00015 | Loss 34.7489
15:23:26.680843 [0] Epoch 00016 | Loss 38.8200
15:23:26.692010 [0] Epoch 00017 | Loss 43.1675
15:23:26.702946 [0] Epoch 00018 | Loss 47.7810
15:23:26.713778 [0] Epoch 00019 | Loss 52.7073
15:23:26.716126 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
15:23:26.717117 [0] 
timer summary:
  0.84s   0.12s    80 mm
  0.07s   0.00s    80 broadcast
  0.35s   0.02s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.58s   0.00s    20 epoch
  3.11s   0.01s     1 total
16:43:19.949506 [0] proc begin: <DistEnv 0/2 nccl>
16:43:21.184281 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:43:21.187435 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:43:22.545277 [0] Epoch 00000 | Loss 3.6925
16:43:22.549773 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:43:22.563623 [0] Epoch 00001 | Loss 3.5845
16:43:22.575797 [0] Epoch 00002 | Loss 3.8658
16:43:22.587334 [0] Epoch 00003 | Loss 4.6374
16:43:22.598754 [0] Epoch 00004 | Loss 5.8564
16:43:22.609881 [0] Epoch 00005 | Loss 7.4233
16:43:22.620919 [0] Epoch 00006 | Loss 9.2427
16:43:22.632113 [0] Epoch 00007 | Loss 11.2466
16:43:22.643397 [0] Epoch 00008 | Loss 13.4136
16:43:22.654930 [0] Epoch 00009 | Loss 15.7737
16:43:22.666026 [0] Epoch 00010 | Loss 18.3630
16:43:22.668423 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:43:22.679504 [0] Epoch 00011 | Loss 21.1870
16:43:22.690524 [0] Epoch 00012 | Loss 24.2306
16:43:22.702345 [0] Epoch 00013 | Loss 27.4851
16:43:22.713299 [0] Epoch 00014 | Loss 30.9766
16:43:22.724526 [0] Epoch 00015 | Loss 34.7489
16:43:22.735631 [0] Epoch 00016 | Loss 38.8200
16:43:22.747045 [0] Epoch 00017 | Loss 43.1675
16:43:22.758162 [0] Epoch 00018 | Loss 47.7810
16:43:22.769425 [0] Epoch 00019 | Loss 52.7073
16:43:22.772013 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:43:22.773261 [0] 
timer summary:
  0.82s   0.13s    80 mm
  0.07s   0.00s    80 broadcast
  0.35s   0.01s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.46s   0.16s    20 epoch
  2.82s   0.00s     1 total
16:47:55.322141 [0] proc begin: <DistEnv 0/2 nccl>
16:47:56.825549 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:47:56.828778 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:47:58.190957 [0] Epoch 00000 | Loss 3.6925
16:47:58.195260 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:47:58.209964 [0] Epoch 00001 | Loss 3.5845
16:47:58.221801 [0] Epoch 00002 | Loss 3.8658
16:47:58.233316 [0] Epoch 00003 | Loss 4.6374
16:47:58.244819 [0] Epoch 00004 | Loss 5.8564
16:47:58.255980 [0] Epoch 00005 | Loss 7.4233
16:47:58.267104 [0] Epoch 00006 | Loss 9.2427
16:47:58.278415 [0] Epoch 00007 | Loss 11.2466
16:47:58.290317 [0] Epoch 00008 | Loss 13.4136
16:47:58.301581 [0] Epoch 00009 | Loss 15.7737
16:47:58.313961 [0] Epoch 00010 | Loss 18.3630
16:47:58.316701 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:47:58.329148 [0] Epoch 00011 | Loss 21.1870
16:47:58.340832 [0] Epoch 00012 | Loss 24.2306
16:47:58.353365 [0] Epoch 00013 | Loss 27.4851
16:47:58.366228 [0] Epoch 00014 | Loss 30.9766
16:47:58.382490 [0] Epoch 00015 | Loss 34.7489
16:47:58.400314 [0] Epoch 00016 | Loss 38.8200
16:47:58.414933 [0] Epoch 00017 | Loss 43.1675
16:47:58.426478 [0] Epoch 00018 | Loss 47.7810
16:47:58.437957 [0] Epoch 00019 | Loss 52.7073
16:47:58.440363 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:47:58.441429 [0] 
timer summary:
  0.88s   0.06s    80 mm
  0.07s   0.00s    80 broadcast
  0.36s   0.00s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.60s   0.01s    20 epoch
  3.11s   0.00s     1 total
16:52:47.588853 [0] proc begin: <DistEnv 0/2 nccl>
16:52:49.093121 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:52:49.096194 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:52:50.343971 [0] Epoch 00000 | Loss 3.6925
16:52:50.347489 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:52:50.360888 [0] Epoch 00001 | Loss 3.5845
16:52:50.371969 [0] Epoch 00002 | Loss 3.8658
16:52:50.383461 [0] Epoch 00003 | Loss 4.6374
16:52:50.395193 [0] Epoch 00004 | Loss 5.8564
16:52:50.408329 [0] Epoch 00005 | Loss 7.4233
16:52:50.419483 [0] Epoch 00006 | Loss 9.2427
16:52:50.431064 [0] Epoch 00007 | Loss 11.2466
16:52:50.442230 [0] Epoch 00008 | Loss 13.4136
16:52:50.453458 [0] Epoch 00009 | Loss 15.7737
16:52:50.464626 [0] Epoch 00010 | Loss 18.3630
16:52:50.466991 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:52:50.478271 [0] Epoch 00011 | Loss 21.1870
16:52:50.489161 [0] Epoch 00012 | Loss 24.2306
16:52:50.503579 [0] Epoch 00013 | Loss 27.4851
16:52:50.516377 [0] Epoch 00014 | Loss 30.9766
16:52:50.527937 [0] Epoch 00015 | Loss 34.7489
16:52:50.539343 [0] Epoch 00016 | Loss 38.8200
16:52:50.550405 [0] Epoch 00017 | Loss 43.1675
16:52:50.561422 [0] Epoch 00018 | Loss 47.7810
16:52:50.573034 [0] Epoch 00019 | Loss 52.7073
16:52:50.575499 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:52:50.576532 [0] 
timer summary:
  0.87s   0.06s    80 mm
  0.07s   0.00s    80 broadcast
  0.29s   0.03s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.47s   0.01s    20 epoch
  2.99s   0.00s     1 total
16:54:12.573414 [0] proc begin: <DistEnv 0/2 nccl>
16:54:14.150118 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:54:14.153324 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:54:15.479126 [0] Epoch 00000 | Loss 3.6925
16:54:15.482845 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:54:15.497405 [0] Epoch 00001 | Loss 3.5845
16:54:15.509234 [0] Epoch 00002 | Loss 3.8658
16:54:15.520840 [0] Epoch 00003 | Loss 4.6374
16:54:15.532163 [0] Epoch 00004 | Loss 5.8564
16:54:15.543660 [0] Epoch 00005 | Loss 7.4233
16:54:15.555074 [0] Epoch 00006 | Loss 9.2427
16:54:15.566570 [0] Epoch 00007 | Loss 11.2466
16:54:15.577914 [0] Epoch 00008 | Loss 13.4136
16:54:15.589431 [0] Epoch 00009 | Loss 15.7737
16:54:15.601027 [0] Epoch 00010 | Loss 18.3630
16:54:15.603598 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:54:15.614983 [0] Epoch 00011 | Loss 21.1870
16:54:15.626124 [0] Epoch 00012 | Loss 24.2306
16:54:15.638950 [0] Epoch 00013 | Loss 27.4851
16:54:15.651103 [0] Epoch 00014 | Loss 30.9766
16:54:15.667828 [0] Epoch 00015 | Loss 34.7489
16:54:15.681569 [0] Epoch 00016 | Loss 38.8200
16:54:15.693315 [0] Epoch 00017 | Loss 43.1675
16:54:15.704520 [0] Epoch 00018 | Loss 47.7810
16:54:15.715653 [0] Epoch 00019 | Loss 52.7073
16:54:15.718144 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:54:15.719228 [0] 
timer summary:
  0.81s   0.14s    80 mm
  0.06s   0.00s    80 broadcast
  0.33s   0.00s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.58s   0.04s    20 epoch
  3.14s   0.01s     1 total
16:54:38.253555 [0] proc begin: <DistEnv 0/2 nccl>
16:54:39.758390 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:54:39.761640 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:54:41.111016 [0] Epoch 00000 | Loss 3.6925
16:54:41.114534 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:54:41.127711 [0] Epoch 00001 | Loss 3.5845
16:54:41.139799 [0] Epoch 00002 | Loss 3.8658
16:54:41.151588 [0] Epoch 00003 | Loss 4.6374
16:54:41.162611 [0] Epoch 00004 | Loss 5.8564
16:54:41.173521 [0] Epoch 00005 | Loss 7.4233
16:54:41.184794 [0] Epoch 00006 | Loss 9.2427
16:54:41.195851 [0] Epoch 00007 | Loss 11.2466
16:54:41.206929 [0] Epoch 00008 | Loss 13.4136
16:54:41.217916 [0] Epoch 00009 | Loss 15.7737
16:54:41.229200 [0] Epoch 00010 | Loss 18.3630
16:54:41.231843 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:54:41.242399 [0] Epoch 00011 | Loss 21.1870
16:54:41.253120 [0] Epoch 00012 | Loss 24.2306
16:54:41.266105 [0] Epoch 00013 | Loss 27.4851
16:54:41.277361 [0] Epoch 00014 | Loss 30.9766
16:54:41.288052 [0] Epoch 00015 | Loss 34.7489
16:54:41.298893 [0] Epoch 00016 | Loss 38.8200
16:54:41.309144 [0] Epoch 00017 | Loss 43.1675
16:54:41.320644 [0] Epoch 00018 | Loss 47.7810
16:54:41.330826 [0] Epoch 00019 | Loss 52.7073
16:54:41.333144 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:54:41.334066 [0] 
timer summary:
  0.87s   0.08s    80 mm
  0.06s   0.00s    80 broadcast
  0.30s   0.05s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.55s   0.02s    20 epoch
  3.08s   0.01s     1 total
16:54:47.196363 [0] proc begin: <DistEnv 0/2 nccl>
16:54:48.731642 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:54:48.734330 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:54:50.103724 [0] Epoch 00000 | Loss 3.6925
16:54:50.107917 [0] Epoch: 000, Train: 0.0168, Val: 0.0178, Test: 0.0170
16:54:50.123933 [0] Epoch 00001 | Loss 3.5845
16:54:50.139161 [0] Epoch 00002 | Loss 3.8658
16:54:50.153286 [0] Epoch 00003 | Loss 4.6374
16:54:50.164928 [0] Epoch 00004 | Loss 5.8564
16:54:50.176687 [0] Epoch 00005 | Loss 7.4233
16:54:50.188245 [0] Epoch 00006 | Loss 9.2427
16:54:50.199862 [0] Epoch 00007 | Loss 11.2466
16:54:50.211556 [0] Epoch 00008 | Loss 13.4136
16:54:50.223413 [0] Epoch 00009 | Loss 15.7737
16:54:50.235602 [0] Epoch 00010 | Loss 18.3630
16:54:50.238065 [0] Epoch: 010, Train: 0.1281, Val: 0.1342, Test: 0.1290
16:54:50.252826 [0] Epoch 00011 | Loss 21.1870
16:54:50.265384 [0] Epoch 00012 | Loss 24.2306
16:54:50.279249 [0] Epoch 00013 | Loss 27.4851
16:54:50.291945 [0] Epoch 00014 | Loss 30.9766
16:54:50.303886 [0] Epoch 00015 | Loss 34.7489
16:54:50.315216 [0] Epoch 00016 | Loss 38.8200
16:54:50.327610 [0] Epoch 00017 | Loss 43.1675
16:54:50.340055 [0] Epoch 00018 | Loss 47.7810
16:54:50.352599 [0] Epoch 00019 | Loss 52.7074
16:54:50.355228 [0] Epoch: 019, Train: 0.1227, Val: 0.1369, Test: 0.1318
16:54:50.356501 [0] 
timer summary:
  0.89s   0.06s    80 mm
  0.07s   0.00s    80 broadcast
  0.34s   0.01s    80 spmm
  0.00s   0.00s    40 all_reduce
  1.61s   0.00s    20 epoch
  3.16s   0.00s     1 total
17:08:43.155742 [0] proc begin: <DistEnv 0/2 nccl>
17:08:44.865007 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
17:08:44.867901 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:41:28.397198 [0] proc begin: <DistEnv 0/2 nccl>
10:41:30.246304 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
10:41:30.250454 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:42:09.359018 [0] proc begin: <DistEnv 0/2 nccl>
10:42:11.044140 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
10:42:11.045191 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:42:13.843452 [0] Epoch 00000 | Loss 1.9460
10:42:13.846190 [0] Epoch: 000, Train: 0.1000, Val: 0.1960, Test: 0.2040
10:42:13.850567 [0] Epoch 00001 | Loss 1.9092
10:42:13.854784 [0] Epoch 00002 | Loss 1.8670
10:42:13.858940 [0] Epoch 00003 | Loss 1.8128
10:42:13.862878 [0] Epoch 00004 | Loss 1.7471
10:42:13.867006 [0] Epoch 00005 | Loss 1.6714
10:42:13.871422 [0] Epoch 00006 | Loss 1.5865
10:42:13.875600 [0] Epoch 00007 | Loss 1.4926
10:42:13.879576 [0] Epoch 00008 | Loss 1.3909
10:42:13.883507 [0] Epoch 00009 | Loss 1.2824
10:42:13.887267 [0] Epoch 00010 | Loss 1.1690
10:42:13.888276 [0] Epoch: 010, Train: 0.9786, Val: 0.7860, Test: 0.8010
10:42:13.892391 [0] Epoch 00011 | Loss 1.0530
10:42:13.896317 [0] Epoch 00012 | Loss 0.9370
10:42:13.900090 [0] Epoch 00013 | Loss 0.8237
10:42:13.903891 [0] Epoch 00014 | Loss 0.7157
10:42:13.907697 [0] Epoch 00015 | Loss 0.6153
10:42:13.911326 [0] Epoch 00016 | Loss 0.5240
10:42:13.915075 [0] Epoch 00017 | Loss 0.4428
10:42:13.919016 [0] Epoch 00018 | Loss 0.3721
10:42:13.923023 [0] Epoch 00019 | Loss 0.3114
10:42:13.923992 [0] Epoch: 019, Train: 0.9857, Val: 0.7920, Test: 0.8130
10:42:13.925226 [0] 
timer summary:
  1.84s   0.06s    80 mm
  0.20s   0.04s   160 broadcast
  0.70s   0.01s   160 spmm
  0.05s   0.00s    40 all_reduce
  2.86s   0.01s    20 epoch
  4.56s   0.01s     1 total
10:48:19.099580 [0] proc begin: <DistEnv 0/2 nccl>
10:48:20.547319 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
10:48:20.549785 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:48:22.154909 [0] Epoch 00000 | Loss 3.6797
10:48:22.158458 [0] Epoch: 000, Train: 0.0259, Val: 0.0271, Test: 0.0269
10:48:22.176722 [0] Epoch 00001 | Loss 3.4861
10:48:22.193949 [0] Epoch 00002 | Loss 3.4453
10:48:22.217191 [0] Epoch 00003 | Loss 3.5961
10:48:22.234930 [0] Epoch 00004 | Loss 3.9358
10:48:22.252658 [0] Epoch 00005 | Loss 4.4300
10:48:22.270917 [0] Epoch 00006 | Loss 5.0457
10:48:22.289141 [0] Epoch 00007 | Loss 5.7493
10:48:22.305408 [0] Epoch 00008 | Loss 6.5105
10:48:22.323915 [0] Epoch 00009 | Loss 7.3267
10:48:22.346151 [0] Epoch 00010 | Loss 8.1667
10:48:22.349955 [0] Epoch: 010, Train: 0.2481, Val: 0.2887, Test: 0.2587
10:48:22.367077 [0] Epoch 00011 | Loss 8.9586
10:48:22.384588 [0] Epoch 00012 | Loss 9.6813
10:48:22.400364 [0] Epoch 00013 | Loss 10.2843
10:48:22.417992 [0] Epoch 00014 | Loss 10.7786
10:48:22.435453 [0] Epoch 00015 | Loss 11.1752
10:48:22.451745 [0] Epoch 00016 | Loss 11.5051
10:48:22.468250 [0] Epoch 00017 | Loss 11.7761
10:48:22.485366 [0] Epoch 00018 | Loss 11.9818
10:48:22.502973 [0] Epoch 00019 | Loss 12.1189
10:48:22.506793 [0] Epoch: 019, Train: 0.2638, Val: 0.2952, Test: 0.2645
10:48:22.509782 [0] 
timer summary:
  1.00s   0.03s    80 mm
  0.34s   0.11s   160 broadcast
  0.35s   0.02s   160 spmm
  0.06s   0.00s    40 all_reduce
  1.87s   0.11s    20 epoch
  3.41s   0.00s     1 total
10:48:56.570015 [0] proc begin: <DistEnv 0/2 nccl>
10:48:58.436539 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
10:48:58.440968 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:49:00.141977 [0] Epoch 00000 | Loss 3.6796
10:49:00.146280 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
10:49:00.180468 [0] Epoch 00001 | Loss 3.4888
10:49:00.213813 [0] Epoch 00002 | Loss 3.4475
10:49:00.247505 [0] Epoch 00003 | Loss 3.5963
10:49:00.280310 [0] Epoch 00004 | Loss 3.9376
10:49:00.313632 [0] Epoch 00005 | Loss 4.4440
10:49:00.347142 [0] Epoch 00006 | Loss 5.0673
10:49:00.380065 [0] Epoch 00007 | Loss 5.7588
10:49:00.414000 [0] Epoch 00008 | Loss 6.5295
10:49:00.448052 [0] Epoch 00009 | Loss 7.3825
10:49:00.480609 [0] Epoch 00010 | Loss 8.2472
10:49:00.483813 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
10:49:00.516452 [0] Epoch 00011 | Loss 9.0631
10:49:00.549307 [0] Epoch 00012 | Loss 9.8321
10:49:00.583304 [0] Epoch 00013 | Loss 10.5323
10:49:00.617319 [0] Epoch 00014 | Loss 11.1359
10:49:00.651129 [0] Epoch 00015 | Loss 11.6644
10:49:00.684106 [0] Epoch 00016 | Loss 12.0868
10:49:00.716898 [0] Epoch 00017 | Loss 12.4616
10:49:00.749912 [0] Epoch 00018 | Loss 12.8053
10:49:00.783993 [0] Epoch 00019 | Loss 13.0934
10:49:00.787463 [0] Epoch: 019, Train: 0.2584, Val: 0.2931, Test: 0.2624
10:49:00.790730 [0] 
timer summary:
  0.58s   0.02s   160 broadcast
  0.41s   0.01s   160 spmm
  1.16s   0.00s    80 mm
  0.05s   0.00s    40 all_reduce
  2.32s   0.01s    20 epoch
  4.21s   0.00s     1 total
11:20:11.955743 [0] proc begin: <DistEnv 0/2 nccl>
11:20:22.874895 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
11:20:22.877189 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:20:24.452151 [0] Epoch 00000 | Loss 3.6990
11:20:24.458527 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
11:20:24.831833 [0] Epoch 00001 | Loss 2.8555
11:20:25.203621 [0] Epoch 00002 | Loss 2.2462
11:20:25.574726 [0] Epoch 00003 | Loss 1.8442
11:20:25.946433 [0] Epoch 00004 | Loss 1.5542
11:20:26.317187 [0] Epoch 00005 | Loss 1.3270
11:20:26.687945 [0] Epoch 00006 | Loss 1.1315
11:20:27.061893 [0] Epoch 00007 | Loss 1.0060
11:20:27.433654 [0] Epoch 00008 | Loss 0.8950
11:20:27.805195 [0] Epoch 00009 | Loss 0.7887
11:20:28.176388 [0] Epoch 00010 | Loss 0.7129
11:20:28.181501 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
11:20:28.552182 [0] Epoch 00011 | Loss 0.6705
11:20:28.923573 [0] Epoch 00012 | Loss 0.6240
11:20:29.294205 [0] Epoch 00013 | Loss 0.5829
11:20:29.665200 [0] Epoch 00014 | Loss 0.5582
11:20:30.036918 [0] Epoch 00015 | Loss 0.5328
11:20:30.409478 [0] Epoch 00016 | Loss 0.5084
11:20:30.781348 [0] Epoch 00017 | Loss 0.4888
11:20:31.154024 [0] Epoch 00018 | Loss 0.4716
11:20:31.526035 [0] Epoch 00019 | Loss 0.4586
11:20:31.530603 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
11:20:31.531996 [0] 
timer summary:
  1.39s   0.29s   160 broadcast
  6.28s   0.07s   160 spmm
  0.86s   0.02s    80 mm
  0.06s   0.01s    40 all_reduce
  8.78s   0.21s    20 epoch
 19.57s   0.01s     1 total
11:23:31.973506 [0] proc begin: <DistEnv 0/2 nccl>
11:23:42.693632 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
11:23:42.696450 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:23:44.253232 [0] Epoch 00000 | Loss 3.7175
11:23:44.259042 [0] Epoch: 000, Train: 0.0233, Val: 0.0159, Test: 0.0164
11:23:44.322396 [0] Epoch 00001 | Loss 2.8340
11:23:44.384851 [0] Epoch 00002 | Loss 2.4177
11:23:44.449288 [0] Epoch 00003 | Loss 2.0779
11:23:44.512925 [0] Epoch 00004 | Loss 1.8086
11:23:44.576952 [0] Epoch 00005 | Loss 1.5902
11:23:44.641540 [0] Epoch 00006 | Loss 1.4156
11:23:44.705843 [0] Epoch 00007 | Loss 1.2602
11:23:44.770040 [0] Epoch 00008 | Loss 1.1329
11:23:44.834389 [0] Epoch 00009 | Loss 1.0079
11:23:44.897809 [0] Epoch 00010 | Loss 0.9141
11:23:44.902426 [0] Epoch: 010, Train: 0.8282, Val: 0.8445, Test: 0.8394
11:23:44.965573 [0] Epoch 00011 | Loss 0.8423
11:23:45.029335 [0] Epoch 00012 | Loss 0.7948
11:23:45.093203 [0] Epoch 00013 | Loss 0.7511
11:23:45.156777 [0] Epoch 00014 | Loss 0.6858
11:23:45.220636 [0] Epoch 00015 | Loss 0.6427
11:23:45.284524 [0] Epoch 00016 | Loss 0.6211
11:23:45.348293 [0] Epoch 00017 | Loss 0.6046
11:23:45.411704 [0] Epoch 00018 | Loss 0.5773
11:23:45.476409 [0] Epoch 00019 | Loss 0.5491
11:23:45.480928 [0] Epoch: 019, Train: 0.8974, Val: 0.9097, Test: 0.9067
11:23:45.482203 [0] 
timer summary:
  0.92s   0.09s    80 mm
  0.39s   0.17s   160 broadcast
  1.07s   0.02s   160 spmm
  0.05s   0.01s    40 all_reduce
  2.57s   0.28s    20 epoch
 13.50s   0.00s     1 total
11:26:22.605541 [0] proc begin: <DistEnv 0/2 nccl>
11:26:32.504090 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
11:26:32.506366 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:26:34.333047 [0] Epoch 00000 | Loss 3.6990
11:26:34.340428 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
11:26:34.755188 [0] Epoch 00001 | Loss 2.8555
11:26:35.180370 [0] Epoch 00002 | Loss 2.2462
11:26:35.615336 [0] Epoch 00003 | Loss 1.8442
11:26:36.053866 [0] Epoch 00004 | Loss 1.5542
11:26:36.492893 [0] Epoch 00005 | Loss 1.3270
11:26:36.932630 [0] Epoch 00006 | Loss 1.1315
11:26:37.370809 [0] Epoch 00007 | Loss 1.0060
11:26:37.811258 [0] Epoch 00008 | Loss 0.8950
11:26:38.247159 [0] Epoch 00009 | Loss 0.7887
11:26:38.684516 [0] Epoch 00010 | Loss 0.7129
11:26:38.689501 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
11:26:39.120113 [0] Epoch 00011 | Loss 0.6705
11:26:39.558777 [0] Epoch 00012 | Loss 0.6240
11:26:39.996771 [0] Epoch 00013 | Loss 0.5829
11:26:40.432981 [0] Epoch 00014 | Loss 0.5582
11:26:40.869928 [0] Epoch 00015 | Loss 0.5328
11:26:41.306716 [0] Epoch 00016 | Loss 0.5084
11:26:41.742583 [0] Epoch 00017 | Loss 0.4888
11:26:42.179796 [0] Epoch 00018 | Loss 0.4716
11:26:42.616452 [0] Epoch 00019 | Loss 0.4586
11:26:42.622024 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
11:26:42.625670 [0] 
timer summary:
  2.19s   0.92s   160 broadcast
  6.84s   0.65s   160 spmm
  1.04s   0.06s    80 mm
  0.12s   0.10s    40 all_reduce
 10.40s   0.43s    20 epoch
 20.01s   0.01s     1 total
11:27:20.321661 [0] proc begin: <DistEnv 0/2 nccl>
11:27:32.475621 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
11:27:32.479817 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:27:34.612156 [0] Epoch 00000 | Loss 3.6990
11:27:34.617478 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
11:27:34.994102 [0] Epoch 00001 | Loss 2.8555
11:27:35.365932 [0] Epoch 00002 | Loss 2.2462
11:27:35.737629 [0] Epoch 00003 | Loss 1.8442
11:27:36.109205 [0] Epoch 00004 | Loss 1.5542
11:27:36.480108 [0] Epoch 00005 | Loss 1.3270
11:27:36.851728 [0] Epoch 00006 | Loss 1.1315
11:27:37.223110 [0] Epoch 00007 | Loss 1.0060
11:27:37.593852 [0] Epoch 00008 | Loss 0.8950
11:27:37.964674 [0] Epoch 00009 | Loss 0.7887
11:27:38.335938 [0] Epoch 00010 | Loss 0.7129
11:27:38.340299 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
11:27:38.711297 [0] Epoch 00011 | Loss 0.6705
11:27:39.083719 [0] Epoch 00012 | Loss 0.6240
11:27:39.455419 [0] Epoch 00013 | Loss 0.5829
11:27:39.826509 [0] Epoch 00014 | Loss 0.5582
11:27:40.197145 [0] Epoch 00015 | Loss 0.5328
11:27:40.567856 [0] Epoch 00016 | Loss 0.5084
11:27:40.939010 [0] Epoch 00017 | Loss 0.4888
11:27:41.309834 [0] Epoch 00018 | Loss 0.4716
11:27:41.680525 [0] Epoch 00019 | Loss 0.4586
11:27:41.685589 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
11:27:41.688023 [0] 
timer summary:
  1.39s   0.21s   160 broadcast
  6.35s   0.13s   160 spmm
  1.04s   0.09s    80 mm
  0.06s   0.02s    40 all_reduce
  9.02s   0.23s    20 epoch
 21.36s   0.00s     1 total
11:27:48.053770 [0] proc begin: <DistEnv 0/2 nccl>
11:27:57.710463 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
11:27:57.712667 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:27:59.282400 [0] Epoch 00000 | Loss 3.6990
11:27:59.287166 [0] Epoch: 000, Train: 0.0163, Val: 0.0146, Test: 0.0152
11:27:59.659885 [0] Epoch 00001 | Loss 2.8555
11:28:00.032354 [0] Epoch 00002 | Loss 2.2462
11:28:00.403525 [0] Epoch 00003 | Loss 1.8442
11:28:00.775334 [0] Epoch 00004 | Loss 1.5542
11:28:01.146456 [0] Epoch 00005 | Loss 1.3270
11:28:01.517394 [0] Epoch 00006 | Loss 1.1315
11:28:01.888922 [0] Epoch 00007 | Loss 1.0060
11:28:02.262877 [0] Epoch 00008 | Loss 0.8950
11:28:02.637211 [0] Epoch 00009 | Loss 0.7887
11:28:03.011432 [0] Epoch 00010 | Loss 0.7129
11:28:03.016740 [0] Epoch: 010, Train: 0.8793, Val: 0.8920, Test: 0.8904
11:28:03.390815 [0] Epoch 00011 | Loss 0.6705
11:28:03.763836 [0] Epoch 00012 | Loss 0.6240
11:28:04.137817 [0] Epoch 00013 | Loss 0.5829
11:28:04.510820 [0] Epoch 00014 | Loss 0.5582
11:28:04.883535 [0] Epoch 00015 | Loss 0.5328
11:28:05.256010 [0] Epoch 00016 | Loss 0.5084
11:28:05.628310 [0] Epoch 00017 | Loss 0.4888
11:28:06.000647 [0] Epoch 00018 | Loss 0.4716
11:28:06.373556 [0] Epoch 00019 | Loss 0.4586
11:28:06.378098 [0] Epoch: 019, Train: 0.9108, Val: 0.9201, Test: 0.9192
11:28:06.379618 [0] 
timer summary:
  1.46s   0.31s   160 broadcast
  6.29s   0.06s   160 spmm
  0.84s   0.02s    80 mm
  0.07s   0.02s    40 all_reduce
  8.86s   0.29s    20 epoch
 18.32s   0.00s     1 total
11:29:39.344212 [0] proc begin: <DistEnv 0/2 nccl>
11:29:41.149720 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:29:41.153629 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:29:42.798124 [0] Epoch 00000 | Loss 3.6796
11:29:42.803121 [0] Epoch: 000, Train: 0.0259, Val: 0.0272, Test: 0.0270
11:29:42.836280 [0] Epoch 00001 | Loss 3.4888
11:29:42.871884 [0] Epoch 00002 | Loss 3.4475
11:29:42.905008 [0] Epoch 00003 | Loss 3.5963
11:29:42.939241 [0] Epoch 00004 | Loss 3.9376
11:29:42.973125 [0] Epoch 00005 | Loss 4.4440
11:29:43.005273 [0] Epoch 00006 | Loss 5.0673
11:29:43.039199 [0] Epoch 00007 | Loss 5.7588
11:29:43.072556 [0] Epoch 00008 | Loss 6.5295
11:29:43.106393 [0] Epoch 00009 | Loss 7.3825
11:29:43.139571 [0] Epoch 00010 | Loss 8.2472
11:29:43.142973 [0] Epoch: 010, Train: 0.2225, Val: 0.2744, Test: 0.2461
11:29:43.176479 [0] Epoch 00011 | Loss 9.0631
11:29:43.210554 [0] Epoch 00012 | Loss 9.8321
11:29:43.243961 [0] Epoch 00013 | Loss 10.5323
11:29:43.277260 [0] Epoch 00014 | Loss 11.1359
11:29:43.309895 [0] Epoch 00015 | Loss 11.6644
11:29:43.342371 [0] Epoch 00016 | Loss 12.0868
11:29:43.376032 [0] Epoch 00017 | Loss 12.4616
11:29:43.409038 [0] Epoch 00018 | Loss 12.8053
11:29:43.441381 [0] Epoch 00019 | Loss 13.0934
11:29:43.444497 [0] Epoch: 019, Train: 0.2584, Val: 0.2931, Test: 0.2624
11:29:43.447385 [0] 
timer summary:
  0.61s   0.00s   160 broadcast
  0.38s   0.01s   160 spmm
  1.12s   0.02s    80 mm
  0.05s   0.00s    40 all_reduce
  2.28s   0.00s    20 epoch
  4.10s   0.01s     1 total
11:31:33.896811 [0] proc begin: <DistEnv 0/2 nccl>
11:31:35.722619 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
11:31:35.726140 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:31:37.206551 [0] Epoch 00000 | Loss 3.6797
11:31:37.210703 [0] Epoch: 000, Train: 0.0259, Val: 0.0271, Test: 0.0269
11:31:37.228123 [0] Epoch 00001 | Loss 3.4861
11:31:37.247710 [0] Epoch 00002 | Loss 3.4453
11:31:37.261922 [0] Epoch 00003 | Loss 3.5961
11:31:37.275339 [0] Epoch 00004 | Loss 3.9358
11:31:37.288734 [0] Epoch 00005 | Loss 4.4300
11:31:37.302469 [0] Epoch 00006 | Loss 5.0457
11:31:37.315396 [0] Epoch 00007 | Loss 5.7493
11:31:37.328655 [0] Epoch 00008 | Loss 6.5105
11:31:37.341757 [0] Epoch 00009 | Loss 7.3267
11:31:37.354939 [0] Epoch 00010 | Loss 8.1667
11:31:37.357671 [0] Epoch: 010, Train: 0.2481, Val: 0.2887, Test: 0.2587
11:31:37.376920 [0] Epoch 00011 | Loss 8.9586
11:31:37.390447 [0] Epoch 00012 | Loss 9.6813
11:31:37.403543 [0] Epoch 00013 | Loss 10.2843
11:31:37.416851 [0] Epoch 00014 | Loss 10.7786
11:31:37.429819 [0] Epoch 00015 | Loss 11.1752
11:31:37.442953 [0] Epoch 00016 | Loss 11.5051
11:31:37.456376 [0] Epoch 00017 | Loss 11.7761
11:31:37.469274 [0] Epoch 00018 | Loss 11.9818
11:31:37.482224 [0] Epoch 00019 | Loss 12.1189
11:31:37.484609 [0] Epoch: 019, Train: 0.2638, Val: 0.2952, Test: 0.2645
11:31:37.486308 [0] 
timer summary:
  0.94s   0.08s    80 mm
  0.37s   0.03s   160 broadcast
  0.30s   0.06s   160 spmm
  0.06s   0.00s    40 all_reduce
  1.76s   0.02s    20 epoch
  3.59s   0.00s     1 total
20:45:19.515000 [0] proc begin: <DistEnv 0/2 nccl>
20:45:21.764383 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
20:45:21.766952 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:45:23.180004 [0] Epoch 00000 | Loss 3.6797
20:45:23.186845 [0] Epoch: 000, Train: 0.0259, Val: 0.0271, Test: 0.0269
20:45:23.202164 [0] Epoch 00001 | Loss 3.4861
20:45:23.215557 [0] Epoch 00002 | Loss 3.4453
20:45:23.228990 [0] Epoch 00003 | Loss 3.5961
20:45:23.243742 [0] Epoch 00004 | Loss 3.9358
20:45:23.257008 [0] Epoch 00005 | Loss 4.4300
20:45:23.270348 [0] Epoch 00006 | Loss 5.0457
20:45:23.284132 [0] Epoch 00007 | Loss 5.7493
20:45:23.297354 [0] Epoch 00008 | Loss 6.5105
20:45:23.311039 [0] Epoch 00009 | Loss 7.3267
20:45:23.324618 [0] Epoch 00010 | Loss 8.1667
20:45:23.328466 [0] Epoch: 010, Train: 0.2481, Val: 0.2887, Test: 0.2587
20:45:23.346235 [0] Epoch 00011 | Loss 8.9586
20:45:23.359698 [0] Epoch 00012 | Loss 9.6813
20:45:23.372531 [0] Epoch 00013 | Loss 10.2843
20:45:23.385022 [0] Epoch 00014 | Loss 10.7786
20:45:23.397591 [0] Epoch 00015 | Loss 11.1752
20:45:23.410408 [0] Epoch 00016 | Loss 11.5051
20:45:23.423241 [0] Epoch 00017 | Loss 11.7761
20:45:23.435195 [0] Epoch 00018 | Loss 11.9818
20:45:23.447801 [0] Epoch 00019 | Loss 12.1189
20:45:23.450655 [0] Epoch: 019, Train: 0.2638, Val: 0.2952, Test: 0.2645
20:45:23.452010 [0] 
timer summary:
  0.97s   0.01s    80 mm
  0.19s   0.02s    80 broadcast
  0.34s   0.02s    80 spmm
  0.01s   0.00s    40 all_reduce
  1.63s   0.05s    20 epoch
  3.93s   0.00s     1 total
20:57:30.604471 [0] proc begin: <DistEnv 0/2 nccl>
10:26:07.251045 [0] proc begin: <DistEnv 0/2 nccl>
10:26:42.445676 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
10:26:42.448154 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1198 MB |    1198 MB |    1198 MB |       0 B  |
|       from large pool |    1196 MB |    1196 MB |    1196 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  105652 KB |  304551 KB |  381081 KB |  275428 KB |
|       from large pool |  105652 KB |  304551 KB |  366735 KB |  261083 KB |
|       from small pool |       0 KB |    2047 KB |   14345 KB |   14345 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |      10    |       7    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       7    |       7    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:26:43.875812 [0] Epoch 00000 | Loss 3.8899
10:26:43.919072 [0] Epoch: 000, Train: 0.0081, Val: 0.0090, Test: 0.0171
10:26:44.163432 [0] Epoch 00001 | Loss 3.1236
10:26:44.402397 [0] Epoch 00002 | Loss 2.5894
10:26:44.642470 [0] Epoch 00003 | Loss 2.2164
10:26:44.886708 [0] Epoch 00004 | Loss 1.9567
10:26:45.126298 [0] Epoch 00005 | Loss 1.7751
10:26:45.366940 [0] Epoch 00006 | Loss 1.6339
10:26:45.614006 [0] Epoch 00007 | Loss 1.5056
10:26:45.854101 [0] Epoch 00008 | Loss 1.3862
10:26:46.105826 [0] Epoch 00009 | Loss 1.2838
10:26:46.348364 [0] Epoch 00010 | Loss 1.2017
10:26:46.392699 [0] Epoch: 010, Train: 0.7842, Val: 0.7806, Test: 0.6068
10:26:46.638258 [0] Epoch 00011 | Loss 1.1343
10:26:46.879492 [0] Epoch 00012 | Loss 1.0749
10:26:47.120738 [0] Epoch 00013 | Loss 1.0213
10:26:47.360967 [0] Epoch 00014 | Loss 0.9751
10:26:47.601846 [0] Epoch 00015 | Loss 0.9361
10:26:47.841921 [0] Epoch 00016 | Loss 0.9001
10:26:48.081178 [0] Epoch 00017 | Loss 0.8643
10:26:48.324261 [0] Epoch 00018 | Loss 0.8308
10:26:48.565345 [0] Epoch 00019 | Loss 0.8024
10:26:48.609644 [0] Epoch: 019, Train: 0.8381, Val: 0.8326, Test: 0.6673
10:26:48.610537 [0] 
timer summary:
  1.15s   0.01s    80 mm
  2.75s   1.16s   160 broadcast
  2.12s   0.40s   160 spmm
  0.09s   0.04s    40 all_reduce
  6.54s   0.73s    20 epoch
 41.36s   0.00s     1 total
10:27:03.717333 [0] proc begin: <DistEnv 0/2 nccl>
10:27:18.256519 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
10:27:18.259829 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1198 MB |    1198 MB |    1198 MB |       0 B  |
|       from large pool |    1196 MB |    1196 MB |    1196 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  105652 KB |  304551 KB |  381081 KB |  275428 KB |
|       from large pool |  105652 KB |  304551 KB |  366735 KB |  261083 KB |
|       from small pool |       0 KB |    2047 KB |   14345 KB |   14345 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |      10    |       7    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       7    |       7    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:27:20.346943 [0] Epoch 00000 | Loss 3.8787
10:27:20.391036 [0] Epoch: 000, Train: 0.0159, Val: 0.0176, Test: 0.0211
10:27:21.073792 [0] Epoch 00001 | Loss 3.2950
10:27:21.757454 [0] Epoch 00002 | Loss 2.8133
10:27:22.440950 [0] Epoch 00003 | Loss 2.4100
10:27:23.124089 [0] Epoch 00004 | Loss 2.0741
10:27:23.807427 [0] Epoch 00005 | Loss 1.8040
10:27:24.492588 [0] Epoch 00006 | Loss 1.5942
10:27:25.175845 [0] Epoch 00007 | Loss 1.4324
10:27:25.860980 [0] Epoch 00008 | Loss 1.3035
10:27:26.543529 [0] Epoch 00009 | Loss 1.1970
10:27:27.225676 [0] Epoch 00010 | Loss 1.1081
10:27:27.269665 [0] Epoch: 010, Train: 0.7900, Val: 0.7845, Test: 0.6037
10:27:27.952665 [0] Epoch 00011 | Loss 1.0349
10:27:28.635162 [0] Epoch 00012 | Loss 0.9748
10:27:29.319038 [0] Epoch 00013 | Loss 0.9247
10:27:30.001195 [0] Epoch 00014 | Loss 0.8819
10:27:30.688321 [0] Epoch 00015 | Loss 0.8447
10:27:31.370393 [0] Epoch 00016 | Loss 0.8128
10:27:32.051656 [0] Epoch 00017 | Loss 0.7857
10:27:32.733002 [0] Epoch 00018 | Loss 0.7621
10:27:33.414728 [0] Epoch 00019 | Loss 0.7405
10:27:33.458013 [0] Epoch: 019, Train: 0.8469, Val: 0.8436, Test: 0.6769
10:27:33.459037 [0] 
timer summary:
  9.22s   4.36s   160 broadcast
  5.70s   1.45s   160 spmm
  1.40s   0.03s    80 mm
  0.20s   0.21s    40 all_reduce
 17.22s   3.05s    20 epoch
 29.74s   0.00s     1 total
10:44:40.040371 [0] proc begin: <DistEnv 0/2 nccl>
10:44:52.474553 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
10:44:52.477209 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1198 MB |    1198 MB |    1198 MB |       0 B  |
|       from large pool |    1196 MB |    1196 MB |    1196 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  105652 KB |  304551 KB |  381081 KB |  275428 KB |
|       from large pool |  105652 KB |  304551 KB |  366735 KB |  261083 KB |
|       from small pool |       0 KB |    2047 KB |   14345 KB |   14345 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |      10    |       7    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       7    |       7    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:44:54.490225 [0] Epoch 00000 | Loss 3.8787
10:44:54.533501 [0] Epoch: 000, Train: 0.0159, Val: 0.0176, Test: 0.0211
10:44:55.217575 [0] Epoch 00001 | Loss 3.2950
10:44:55.900974 [0] Epoch 00002 | Loss 2.8133
10:44:56.592808 [0] Epoch 00003 | Loss 2.4100
10:44:57.277382 [0] Epoch 00004 | Loss 2.0741
10:44:57.962229 [0] Epoch 00005 | Loss 1.8040
10:44:58.645969 [0] Epoch 00006 | Loss 1.5942
10:44:59.330278 [0] Epoch 00007 | Loss 1.4324
10:45:00.015221 [0] Epoch 00008 | Loss 1.3035
10:45:00.699710 [0] Epoch 00009 | Loss 1.1970
10:45:01.394300 [0] Epoch 00010 | Loss 1.1081
10:45:01.438361 [0] Epoch: 010, Train: 0.7900, Val: 0.7845, Test: 0.6037
10:45:02.134826 [0] Epoch 00011 | Loss 1.0349
10:45:02.828639 [0] Epoch 00012 | Loss 0.9748
10:45:03.518232 [0] Epoch 00013 | Loss 0.9247
10:45:04.210223 [0] Epoch 00014 | Loss 0.8819
10:45:04.896816 [0] Epoch 00015 | Loss 0.8447
10:45:05.583303 [0] Epoch 00016 | Loss 0.8128
10:45:06.269797 [0] Epoch 00017 | Loss 0.7857
10:45:06.956122 [0] Epoch 00018 | Loss 0.7621
10:45:07.642513 [0] Epoch 00019 | Loss 0.7405
10:45:07.687007 [0] Epoch: 019, Train: 0.8469, Val: 0.8436, Test: 0.6769
10:45:07.687956 [0] 
timer summary:
  8.91s   3.57s   160 broadcast
  5.70s   1.49s   160 spmm
  1.27s   0.18s    80 mm
  0.20s   0.22s    40 all_reduce
 16.77s   2.40s    20 epoch
 27.64s   0.00s     1 total
10:38:10.397789 [0] proc begin: <DistEnv 0/2 nccl>
10:38:33.570087 [0] proc begin: <DistEnv 0/2 nccl>
10:38:53.042255 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
10:38:53.045568 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:44:08.877633 [0] proc begin: <DistEnv 0/2 nccl>
10:44:25.360597 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
10:44:25.363322 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

10:53:55.284317 [0] proc begin: <DistEnv 0/2 nccl>
10:54:12.908528 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
10:54:12.912927 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:00:57.194499 [0] proc begin: <DistEnv 0/2 nccl>
11:01:16.406879 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
11:01:16.409507 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:05:45.308535 [0] proc begin: <DistEnv 0/2 nccl>
11:06:01.552857 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
11:06:01.555503 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

11:12:26.021592 [0] proc begin: <DistEnv 0/2 nccl>
11:22:08.804645 [0] proc begin: <DistEnv 0/2 nccl>
11:22:27.516723 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
11:22:27.520319 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:32:17.930100 [0] proc begin: <DistEnv 0/2 nccl>
14:32:20.347465 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
14:32:20.350976 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:32:21.770943 [0] Epoch 00000 | Loss 3.6865
14:32:21.774812 [0] Epoch: 000, Train: 0.0155, Val: 0.0135, Test: 0.0156
14:32:21.798647 [0] Epoch 00001 | Loss 3.6118
14:32:21.818988 [0] Epoch 00002 | Loss 3.5422
14:32:21.841936 [0] Epoch 00003 | Loss 3.4880
14:32:21.864354 [0] Epoch 00004 | Loss 3.4675
14:32:21.887215 [0] Epoch 00005 | Loss 3.4927
14:32:21.907890 [0] Epoch 00006 | Loss 3.5693
14:32:21.927538 [0] Epoch 00007 | Loss 3.6983
14:32:21.947782 [0] Epoch 00008 | Loss 3.8782
14:32:21.968053 [0] Epoch 00009 | Loss 4.1047
14:32:21.987550 [0] Epoch 00010 | Loss 4.3707
14:32:21.989931 [0] Epoch: 010, Train: 0.1795, Val: 0.0769, Test: 0.0589
14:32:22.009984 [0] Epoch 00011 | Loss 4.6688
14:32:22.031963 [0] Epoch 00012 | Loss 4.9900
14:32:22.056418 [0] Epoch 00013 | Loss 5.3240
14:32:22.077967 [0] Epoch 00014 | Loss 5.6590
14:32:22.100199 [0] Epoch 00015 | Loss 5.9955
14:32:22.124516 [0] Epoch 00016 | Loss 6.3520
14:32:22.145616 [0] Epoch 00017 | Loss 6.7485
14:32:22.171288 [0] Epoch 00018 | Loss 7.1712
14:32:22.195104 [0] Epoch 00019 | Loss 7.5910
14:32:22.197444 [0] Epoch: 019, Train: 0.1274, Val: 0.2343, Test: 0.2184
14:32:22.198460 [0] 
timer summary:
  0.42s   0.01s   160 broadcast
  0.44s   0.01s   160 spmm
  0.88s   0.06s    80 mm
  0.05s   0.00s    40 all_reduce
  1.88s   0.06s    20 epoch
  4.26s   0.00s     1 total
14:35:43.302167 [0] proc begin: <DistEnv 0/2 nccl>
14:35:45.066250 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
14:35:45.069249 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:35:47.082632 [0] Epoch 00000 | Loss 3.6865
14:35:47.085888 [0] Epoch: 000, Train: 0.0155, Val: 0.0135, Test: 0.0156
14:35:47.108186 [0] Epoch 00001 | Loss 3.6118
14:35:47.129832 [0] Epoch 00002 | Loss 3.5422
14:35:47.153379 [0] Epoch 00003 | Loss 3.4880
14:35:47.175937 [0] Epoch 00004 | Loss 3.4675
14:35:47.198537 [0] Epoch 00005 | Loss 3.4927
14:35:47.229378 [0] Epoch 00006 | Loss 3.5693
14:35:47.258904 [0] Epoch 00007 | Loss 3.6983
14:35:47.284916 [0] Epoch 00008 | Loss 3.8782
14:35:47.308997 [0] Epoch 00009 | Loss 4.1047
14:35:47.337920 [0] Epoch 00010 | Loss 4.3707
14:35:47.341192 [0] Epoch: 010, Train: 0.1795, Val: 0.0769, Test: 0.0589
14:35:47.365812 [0] Epoch 00011 | Loss 4.6688
14:35:47.388750 [0] Epoch 00012 | Loss 4.9900
14:35:47.417573 [0] Epoch 00013 | Loss 5.3240
14:35:47.438400 [0] Epoch 00014 | Loss 5.6590
14:35:47.463421 [0] Epoch 00015 | Loss 5.9955
14:35:47.684500 [0] Epoch 00016 | Loss 6.3520
14:35:47.712976 [0] Epoch 00017 | Loss 6.7485
14:35:47.734658 [0] Epoch 00018 | Loss 7.1712
14:35:47.757463 [0] Epoch 00019 | Loss 7.5910
14:35:47.779018 [0] Epoch 00020 | Loss 7.9879
14:35:47.781622 [0] Epoch: 020, Train: 0.1417, Val: 0.2399, Test: 0.2215
14:35:47.802841 [0] Epoch 00021 | Loss 8.3577
14:35:47.827009 [0] Epoch 00022 | Loss 8.7119
14:35:47.849032 [0] Epoch 00023 | Loss 9.0540
14:35:47.874175 [0] Epoch 00024 | Loss 9.3687
14:35:47.902548 [0] Epoch 00025 | Loss 9.6616
14:35:47.925680 [0] Epoch 00026 | Loss 9.9441
14:35:47.949455 [0] Epoch 00027 | Loss 10.2074
14:35:47.973328 [0] Epoch 00028 | Loss 10.4495
14:35:47.996899 [0] Epoch 00029 | Loss 10.6797
14:35:48.020996 [0] Epoch 00030 | Loss 10.9040
14:35:48.024076 [0] Epoch: 030, Train: 0.2586, Val: 0.2917, Test: 0.2611
14:35:48.047951 [0] Epoch 00031 | Loss 11.1141
14:35:48.068734 [0] Epoch 00032 | Loss 11.3042
14:35:48.090647 [0] Epoch 00033 | Loss 11.4776
14:35:48.113241 [0] Epoch 00034 | Loss 11.6292
14:35:48.138326 [0] Epoch 00035 | Loss 11.7507
14:35:48.164745 [0] Epoch 00036 | Loss 11.8481
14:35:48.188460 [0] Epoch 00037 | Loss 11.9337
14:35:48.214255 [0] Epoch 00038 | Loss 12.0069
14:35:48.236437 [0] Epoch 00039 | Loss 12.0673
14:35:48.462516 [0] Epoch 00040 | Loss 12.1172
14:35:48.465449 [0] Epoch: 040, Train: 0.2536, Val: 0.2892, Test: 0.2588
14:35:48.487433 [0] Epoch 00041 | Loss 12.1544
14:35:48.510339 [0] Epoch 00042 | Loss 12.1781
14:35:48.531226 [0] Epoch 00043 | Loss 12.1923
14:35:48.555784 [0] Epoch 00044 | Loss 12.2008
14:35:48.576650 [0] Epoch 00045 | Loss 12.2030
14:35:48.600355 [0] Epoch 00046 | Loss 12.2003
14:35:48.624839 [0] Epoch 00047 | Loss 12.1934
14:35:48.648280 [0] Epoch 00048 | Loss 12.1795
14:35:48.673112 [0] Epoch 00049 | Loss 12.1561
14:35:48.695672 [0] Epoch 00050 | Loss 12.1227
14:35:48.698253 [0] Epoch: 050, Train: 0.2655, Val: 0.2967, Test: 0.2663
14:35:48.720482 [0] Epoch 00051 | Loss 12.0796
14:35:48.744066 [0] Epoch 00052 | Loss 12.0287
14:35:48.771746 [0] Epoch 00053 | Loss 11.9754
14:35:48.792973 [0] Epoch 00054 | Loss 11.9251
14:35:48.815096 [0] Epoch 00055 | Loss 11.8796
14:35:48.837328 [0] Epoch 00056 | Loss 11.8378
14:35:48.857879 [0] Epoch 00057 | Loss 11.7975
14:35:48.883561 [0] Epoch 00058 | Loss 11.7557
14:35:48.906798 [0] Epoch 00059 | Loss 11.7111
14:35:48.932820 [0] Epoch 00060 | Loss 11.6668
14:35:48.935627 [0] Epoch: 060, Train: 0.2781, Val: 0.3077, Test: 0.2780
14:35:48.958595 [0] Epoch 00061 | Loss 11.6266
14:35:48.982198 [0] Epoch 00062 | Loss 11.5915
14:35:49.195181 [0] Epoch 00063 | Loss 11.5612
14:35:49.220571 [0] Epoch 00064 | Loss 11.5344
14:35:49.242141 [0] Epoch 00065 | Loss 11.5106
14:35:49.264702 [0] Epoch 00066 | Loss 11.4911
14:35:49.286918 [0] Epoch 00067 | Loss 11.4787
14:35:49.309458 [0] Epoch 00068 | Loss 11.4746
14:35:49.333280 [0] Epoch 00069 | Loss 11.4779
14:35:49.357469 [0] Epoch 00070 | Loss 11.4867
14:35:49.360465 [0] Epoch: 070, Train: 0.3025, Val: 0.3246, Test: 0.2977
14:35:49.386153 [0] Epoch 00071 | Loss 11.4983
14:35:49.408489 [0] Epoch 00072 | Loss 11.5111
14:35:49.431322 [0] Epoch 00073 | Loss 11.5249
14:35:49.452959 [0] Epoch 00074 | Loss 11.5405
14:35:49.474939 [0] Epoch 00075 | Loss 11.5585
14:35:49.496291 [0] Epoch 00076 | Loss 11.5790
14:35:49.532625 [0] Epoch 00077 | Loss 11.6020
14:35:49.554581 [0] Epoch 00078 | Loss 11.6272
14:35:49.576627 [0] Epoch 00079 | Loss 11.6548
14:35:49.600929 [0] Epoch 00080 | Loss 11.6847
14:35:49.603925 [0] Epoch: 080, Train: 0.3310, Val: 0.3471, Test: 0.3205
14:35:49.625714 [0] Epoch 00081 | Loss 11.7165
14:35:49.648083 [0] Epoch 00082 | Loss 11.7487
14:35:49.673407 [0] Epoch 00083 | Loss 11.7805
14:35:49.697030 [0] Epoch 00084 | Loss 11.8113
14:35:49.723780 [0] Epoch 00085 | Loss 11.8417
14:35:49.950524 [0] Epoch 00086 | Loss 11.8726
14:35:49.974781 [0] Epoch 00087 | Loss 11.9049
14:35:49.997762 [0] Epoch 00088 | Loss 11.9389
14:35:50.019973 [0] Epoch 00089 | Loss 11.9741
14:35:50.040729 [0] Epoch 00090 | Loss 12.0097
14:35:50.044006 [0] Epoch: 090, Train: 0.3496, Val: 0.3641, Test: 0.3412
14:35:50.068901 [0] Epoch 00091 | Loss 12.0453
14:35:50.094484 [0] Epoch 00092 | Loss 12.0810
14:35:50.116020 [0] Epoch 00093 | Loss 12.1175
14:35:50.138919 [0] Epoch 00094 | Loss 12.1556
14:35:50.160689 [0] Epoch 00095 | Loss 12.1954
14:35:50.186543 [0] Epoch 00096 | Loss 12.2365
14:35:50.211411 [0] Epoch 00097 | Loss 12.2781
14:35:50.232798 [0] Epoch 00098 | Loss 12.3199
14:35:50.257551 [0] Epoch 00099 | Loss 12.3621
14:35:50.278134 [0] Epoch 00100 | Loss 12.4049
14:35:50.280979 [0] Epoch: 100, Train: 0.3643, Val: 0.3789, Test: 0.3594
14:35:50.305139 [0] Epoch 00101 | Loss 12.4483
14:35:50.332729 [0] Epoch 00102 | Loss 12.4923
14:35:50.354217 [0] Epoch 00103 | Loss 12.5368
14:35:50.378874 [0] Epoch 00104 | Loss 12.5824
14:35:50.401451 [0] Epoch 00105 | Loss 12.6293
14:35:50.424440 [0] Epoch 00106 | Loss 12.6775
14:35:50.446320 [0] Epoch 00107 | Loss 12.7268
14:35:50.466166 [0] Epoch 00108 | Loss 12.7769
14:35:50.490661 [0] Epoch 00109 | Loss 12.8277
14:35:50.704174 [0] Epoch 00110 | Loss 12.8791
14:35:50.706867 [0] Epoch: 110, Train: 0.3773, Val: 0.3919, Test: 0.3771
14:35:50.727687 [0] Epoch 00111 | Loss 12.9309
14:35:50.753559 [0] Epoch 00112 | Loss 12.9831
14:35:50.777339 [0] Epoch 00113 | Loss 13.0358
14:35:50.799958 [0] Epoch 00114 | Loss 13.0894
14:35:50.820156 [0] Epoch 00115 | Loss 13.1439
14:35:50.840729 [0] Epoch 00116 | Loss 13.1993
14:35:50.865575 [0] Epoch 00117 | Loss 13.2552
14:35:50.890017 [0] Epoch 00118 | Loss 13.3116
14:35:50.912996 [0] Epoch 00119 | Loss 13.3689
14:35:50.934821 [0] Epoch 00120 | Loss 13.4271
14:35:50.938099 [0] Epoch: 120, Train: 0.3890, Val: 0.4058, Test: 0.3939
14:35:50.958713 [0] Epoch 00121 | Loss 13.4862
14:35:50.980754 [0] Epoch 00122 | Loss 13.5461
14:35:51.007132 [0] Epoch 00123 | Loss 13.6067
14:35:51.030362 [0] Epoch 00124 | Loss 13.6679
14:35:51.055345 [0] Epoch 00125 | Loss 13.7295
14:35:51.078568 [0] Epoch 00126 | Loss 13.7913
14:35:51.100395 [0] Epoch 00127 | Loss 13.8529
14:35:51.121332 [0] Epoch 00128 | Loss 13.9145
14:35:51.142302 [0] Epoch 00129 | Loss 13.9763
14:35:51.166187 [0] Epoch 00130 | Loss 14.0386
14:35:51.169231 [0] Epoch: 130, Train: 0.3995, Val: 0.4198, Test: 0.4111
14:35:51.193402 [0] Epoch 00131 | Loss 14.1016
14:35:51.222460 [0] Epoch 00132 | Loss 14.1651
14:35:51.245961 [0] Epoch 00133 | Loss 14.2292
14:35:51.465371 [0] Epoch 00134 | Loss 14.2934
14:35:51.488506 [0] Epoch 00135 | Loss 14.3578
14:35:51.512376 [0] Epoch 00136 | Loss 14.4221
14:35:51.533479 [0] Epoch 00137 | Loss 14.4862
14:35:51.556216 [0] Epoch 00138 | Loss 14.5498
14:35:51.578865 [0] Epoch 00139 | Loss 14.6127
14:35:51.601007 [0] Epoch 00140 | Loss 14.6750
14:35:51.603490 [0] Epoch: 140, Train: 0.4099, Val: 0.4322, Test: 0.4273
14:35:51.623332 [0] Epoch 00141 | Loss 14.7369
14:35:51.644147 [0] Epoch 00142 | Loss 14.7987
14:35:51.668773 [0] Epoch 00143 | Loss 14.8607
14:35:51.693410 [0] Epoch 00144 | Loss 14.9231
14:35:51.717875 [0] Epoch 00145 | Loss 14.9858
14:35:51.738970 [0] Epoch 00146 | Loss 15.0489
14:35:51.766087 [0] Epoch 00147 | Loss 15.1121
14:35:51.789057 [0] Epoch 00148 | Loss 15.1751
14:35:51.810636 [0] Epoch 00149 | Loss 15.2380
14:35:51.831767 [0] Epoch 00150 | Loss 15.3008
14:35:51.835048 [0] Epoch: 150, Train: 0.4182, Val: 0.4450, Test: 0.4422
14:35:51.858519 [0] Epoch 00151 | Loss 15.3636
14:35:51.891431 [0] Epoch 00152 | Loss 15.4267
14:35:51.913395 [0] Epoch 00153 | Loss 15.4901
14:35:51.937460 [0] Epoch 00154 | Loss 15.5537
14:35:51.961175 [0] Epoch 00155 | Loss 15.6172
14:35:51.983776 [0] Epoch 00156 | Loss 15.6806
14:35:52.204964 [0] Epoch 00157 | Loss 15.7441
14:35:52.228461 [0] Epoch 00158 | Loss 15.8077
14:35:52.250172 [0] Epoch 00159 | Loss 15.8715
14:35:52.273775 [0] Epoch 00160 | Loss 15.9352
14:35:52.276427 [0] Epoch: 160, Train: 0.4256, Val: 0.4561, Test: 0.4568
14:35:52.297116 [0] Epoch 00161 | Loss 15.9991
14:35:52.322128 [0] Epoch 00162 | Loss 16.0634
14:35:52.343020 [0] Epoch 00163 | Loss 16.1283
14:35:52.365922 [0] Epoch 00164 | Loss 16.1938
14:35:52.385896 [0] Epoch 00165 | Loss 16.2598
14:35:52.406282 [0] Epoch 00166 | Loss 16.3264
14:35:52.429010 [0] Epoch 00167 | Loss 16.3936
14:35:52.454807 [0] Epoch 00168 | Loss 16.4612
14:35:52.477156 [0] Epoch 00169 | Loss 16.5294
14:35:52.500522 [0] Epoch 00170 | Loss 16.5980
14:35:52.503002 [0] Epoch: 170, Train: 0.4319, Val: 0.4662, Test: 0.4690
14:35:52.523812 [0] Epoch 00171 | Loss 16.6669
14:35:52.547707 [0] Epoch 00172 | Loss 16.7360
14:35:52.570922 [0] Epoch 00173 | Loss 16.8053
14:35:52.593682 [0] Epoch 00174 | Loss 16.8749
14:35:52.615022 [0] Epoch 00175 | Loss 16.9447
14:35:52.639225 [0] Epoch 00176 | Loss 17.0148
14:35:52.661479 [0] Epoch 00177 | Loss 17.0853
14:35:52.684917 [0] Epoch 00178 | Loss 17.1561
14:35:52.709918 [0] Epoch 00179 | Loss 17.2272
14:35:52.732401 [0] Epoch 00180 | Loss 17.2983
14:35:52.735381 [0] Epoch: 180, Train: 0.4395, Val: 0.4774, Test: 0.4812
14:35:52.957209 [0] Epoch 00181 | Loss 17.3693
14:35:52.984736 [0] Epoch 00182 | Loss 17.4400
14:35:53.006928 [0] Epoch 00183 | Loss 17.5104
14:35:53.031217 [0] Epoch 00184 | Loss 17.5806
14:35:53.052575 [0] Epoch 00185 | Loss 17.6507
14:35:53.075308 [0] Epoch 00186 | Loss 17.7208
14:35:53.099648 [0] Epoch 00187 | Loss 17.7912
14:35:53.123015 [0] Epoch 00188 | Loss 17.8618
14:35:53.145103 [0] Epoch 00189 | Loss 17.9326
14:35:53.169481 [0] Epoch 00190 | Loss 18.0035
14:35:53.172026 [0] Epoch: 190, Train: 0.4459, Val: 0.4865, Test: 0.4918
14:35:53.194447 [0] Epoch 00191 | Loss 18.0743
14:35:53.228065 [0] Epoch 00192 | Loss 18.1449
14:35:53.252028 [0] Epoch 00193 | Loss 18.2153
14:35:53.274595 [0] Epoch 00194 | Loss 18.2855
14:35:53.296911 [0] Epoch 00195 | Loss 18.3555
14:35:53.318085 [0] Epoch 00196 | Loss 18.4256
14:35:53.341840 [0] Epoch 00197 | Loss 18.4956
14:35:53.362580 [0] Epoch 00198 | Loss 18.5656
14:35:53.385364 [0] Epoch 00199 | Loss 18.6356
14:35:53.388443 [0] Epoch: 199, Train: 0.4510, Val: 0.4936, Test: 0.4993
14:35:53.390578 [0] 
timer summary:
  2.22s   0.02s  1600 broadcast
  3.53s   0.02s  1600 spmm
  1.46s   0.02s   800 mm
  0.12s   0.04s   400 all_reduce
  8.26s   0.01s   200 epoch
 10.08s   0.00s     1 total
14:37:15.165003 [0] proc begin: <DistEnv 0/2 nccl>
14:37:50.296556 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
14:37:50.300916 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:37:52.598147 [0] Epoch 00000 | Loss 3.7317
14:37:52.603504 [0] Epoch: 000, Train: 0.0201, Val: 0.0164, Test: 0.0156
14:37:52.860806 [0] Epoch 00001 | Loss 3.3378
14:37:53.319912 [0] Epoch 00002 | Loss 2.9697
14:37:53.575111 [0] Epoch 00003 | Loss 2.6359
14:37:54.031198 [0] Epoch 00004 | Loss 2.3539
14:37:54.285364 [0] Epoch 00005 | Loss 2.1190
14:37:54.762867 [0] Epoch 00006 | Loss 1.9186
14:37:55.017692 [0] Epoch 00007 | Loss 1.7448
14:37:55.269667 [0] Epoch 00008 | Loss 1.5957
14:37:55.689187 [0] Epoch 00009 | Loss 1.4682
14:37:55.944189 [0] Epoch 00010 | Loss 1.3530
14:37:55.949031 [0] Epoch: 010, Train: 0.7733, Val: 0.7937, Test: 0.7883
14:37:56.392712 [0] Epoch 00011 | Loss 1.2476
14:37:56.651471 [0] Epoch 00012 | Loss 1.1571
14:37:57.125553 [0] Epoch 00013 | Loss 1.0799
14:37:57.380022 [0] Epoch 00014 | Loss 1.0103
14:37:57.633236 [0] Epoch 00015 | Loss 0.9465
14:37:58.058598 [0] Epoch 00016 | Loss 0.8870
14:37:58.314622 [0] Epoch 00017 | Loss 0.8341
14:37:58.745334 [0] Epoch 00018 | Loss 0.7893
14:37:59.002527 [0] Epoch 00019 | Loss 0.7518
14:37:59.007395 [0] Epoch: 019, Train: 0.8713, Val: 0.8878, Test: 0.8833
14:37:59.010209 [0] 
timer summary:
  1.36s   0.77s   160 broadcast
  6.24s   0.06s   160 spmm
  1.20s   0.23s    80 mm
  0.06s   0.01s    40 all_reduce
  9.03s   0.49s    20 epoch
 43.84s   0.01s     1 total
14:46:12.351876 [0] proc begin: <DistEnv 0/2 nccl>
14:46:22.358248 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
14:46:22.360511 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:46:25.122114 [0] Epoch 00000 | Loss 3.7347
14:46:25.128030 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
14:46:25.195724 [0] Epoch 00001 | Loss 3.3026
14:46:25.272064 [0] Epoch 00002 | Loss 2.9690
14:46:25.335958 [0] Epoch 00003 | Loss 2.7159
14:46:25.402370 [0] Epoch 00004 | Loss 2.5007
14:46:25.466721 [0] Epoch 00005 | Loss 2.3153
14:46:25.539360 [0] Epoch 00006 | Loss 2.1407
14:46:25.603354 [0] Epoch 00007 | Loss 1.9787
14:46:25.882391 [0] Epoch 00008 | Loss 1.8415
14:46:25.947512 [0] Epoch 00009 | Loss 1.7203
14:46:26.013780 [0] Epoch 00010 | Loss 1.6011
14:46:26.019107 [0] Epoch: 010, Train: 0.7707, Val: 0.7886, Test: 0.7842
14:46:26.082261 [0] Epoch 00011 | Loss 1.4863
14:46:26.146953 [0] Epoch 00012 | Loss 1.3836
14:46:26.211267 [0] Epoch 00013 | Loss 1.2946
14:46:26.277625 [0] Epoch 00014 | Loss 1.2154
14:46:26.350980 [0] Epoch 00015 | Loss 1.1400
14:46:26.623325 [0] Epoch 00016 | Loss 1.0692
14:46:26.690039 [0] Epoch 00017 | Loss 1.0104
14:46:26.759376 [0] Epoch 00018 | Loss 0.9649
14:46:26.823653 [0] Epoch 00019 | Loss 0.9228
14:46:26.829062 [0] Epoch: 019, Train: 0.8397, Val: 0.8551, Test: 0.8523
14:46:26.831903 [0] 
timer summary:
  1.07s   0.19s    80 mm
  0.87s   0.86s   160 broadcast
  1.68s   0.04s   160 spmm
  0.26s   0.00s    40 all_reduce
  4.01s   0.63s    20 epoch
 14.48s   0.00s     1 total
14:46:39.994827 [0] proc begin: <DistEnv 0/2 nccl>
14:47:30.066820 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
14:47:30.070981 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:47:31.714537 [0] Epoch 00000 | Loss 3.7347
14:47:31.720338 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
14:47:32.027802 [0] Epoch 00001 | Loss 3.3026
14:47:32.124469 [0] Epoch 00002 | Loss 2.9690
14:47:32.221682 [0] Epoch 00003 | Loss 2.7159
14:47:32.323615 [0] Epoch 00004 | Loss 2.5007
14:47:32.422772 [0] Epoch 00005 | Loss 2.3153
14:47:32.520198 [0] Epoch 00006 | Loss 2.1407
14:47:32.818739 [0] Epoch 00007 | Loss 1.9787
14:47:32.919264 [0] Epoch 00008 | Loss 1.8415
14:47:33.017179 [0] Epoch 00009 | Loss 1.7203
14:47:33.116947 [0] Epoch 00010 | Loss 1.6011
14:47:33.122363 [0] Epoch: 010, Train: 0.7707, Val: 0.7886, Test: 0.7842
14:47:33.220265 [0] Epoch 00011 | Loss 1.4863
14:47:33.319999 [0] Epoch 00012 | Loss 1.3836
14:47:33.623091 [0] Epoch 00013 | Loss 1.2946
14:47:33.721313 [0] Epoch 00014 | Loss 1.2154
14:47:33.820862 [0] Epoch 00015 | Loss 1.1400
14:47:33.920299 [0] Epoch 00016 | Loss 1.0692
14:47:34.019253 [0] Epoch 00017 | Loss 1.0104
14:47:34.118202 [0] Epoch 00018 | Loss 0.9649
14:47:34.410295 [0] Epoch 00019 | Loss 0.9228
14:47:34.415917 [0] Epoch: 019, Train: 0.8397, Val: 0.8551, Test: 0.8523
14:47:34.418848 [0] 
timer summary:
  0.98s   0.01s    80 mm
  0.47s   0.01s    80 broadcast
  2.76s   0.04s    80 spmm
  0.00s   0.00s    40 all_reduce
  4.36s   0.05s    20 epoch
 54.42s   0.00s     1 total
14:51:05.275267 [0] proc begin: <DistEnv 0/2 nccl>
14:53:28.577702 [0] proc begin: <DistEnv 0/2 nccl>
14:53:40.128445 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
14:53:40.130925 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:53:42.403375 [0] Epoch 00000 | Loss 3.7984
14:53:42.409381 [0] Epoch: 000, Train: 0.0173, Val: 0.0190, Test: 0.0208
14:53:42.853875 [0] Epoch 00001 | Loss 3.6293
14:53:43.125445 [0] Epoch 00002 | Loss 3.4914
14:53:43.604175 [0] Epoch 00003 | Loss 3.3851
14:53:43.863521 [0] Epoch 00004 | Loss 3.3072
14:53:44.118824 [0] Epoch 00005 | Loss 3.2470
14:53:44.595796 [0] Epoch 00006 | Loss 3.1955
14:53:44.848013 [0] Epoch 00007 | Loss 3.1458
14:53:45.287542 [0] Epoch 00008 | Loss 3.0897
14:53:45.542661 [0] Epoch 00009 | Loss 3.0193
14:53:45.964765 [0] Epoch 00010 | Loss 2.9321
14:53:45.970278 [0] Epoch: 010, Train: 0.2425, Val: 0.2279, Test: 0.2247
14:53:46.222662 [0] Epoch 00011 | Loss 2.8304
14:53:46.682174 [0] Epoch 00012 | Loss 2.7196
14:53:46.936062 [0] Epoch 00013 | Loss 2.6027
14:53:47.188374 [0] Epoch 00014 | Loss 2.4825
14:53:47.602869 [0] Epoch 00015 | Loss 2.3635
14:53:47.855311 [0] Epoch 00016 | Loss 2.2509
14:53:48.306555 [0] Epoch 00017 | Loss 2.1470
14:53:48.567387 [0] Epoch 00018 | Loss 2.0497
14:53:49.044437 [0] Epoch 00019 | Loss 1.9566
14:53:49.049916 [0] Epoch: 019, Train: 0.5494, Val: 0.5523, Test: 0.5538
14:53:49.052615 [0] 
timer summary:
  1.12s   1.04s    20 broadcast ForwardL1 0
  1.77s   0.78s   160 broadcast
  6.31s   0.16s   160 spmm
  0.31s   0.05s    20 broadcast ForwardL1 1
  1.32s   0.08s    80 mm
  0.10s   0.05s    20 broadcast ForwardL2 0
  0.03s   0.01s    20 broadcast ForwardL2 1
  0.02s   0.01s    20 broadcast BackwardL2 0
  0.02s   0.01s    20 broadcast BackwardL2 1
  0.04s   0.01s    40 all_reduce
  0.03s   0.01s    20 broadcast BackwardL1 0
  0.14s   0.16s    20 broadcast BackwardL1 1
  9.62s   1.02s    20 epoch
 20.47s   0.00s     1 total
14:56:28.185003 [0] proc begin: <DistEnv 0/2 nccl>
14:56:51.366688 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
14:56:51.370881 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:56:53.177060 [0] Epoch 00000 | Loss 3.7360
14:56:53.183111 [0] Epoch: 000, Train: 0.0527, Val: 0.0519, Test: 0.0498
14:56:53.413008 [0] Epoch 00001 | Loss 3.6160
14:56:53.834503 [0] Epoch 00002 | Loss 3.5098
14:56:54.067216 [0] Epoch 00003 | Loss 3.4067
14:56:54.500273 [0] Epoch 00004 | Loss 3.2655
14:56:54.728073 [0] Epoch 00005 | Loss 3.1280
14:56:54.955651 [0] Epoch 00006 | Loss 2.9928
14:56:55.390934 [0] Epoch 00007 | Loss 2.8642
14:56:55.620978 [0] Epoch 00008 | Loss 2.7546
14:56:56.093239 [0] Epoch 00009 | Loss 2.6024
14:56:56.325798 [0] Epoch 00010 | Loss 2.4641
14:56:56.331508 [0] Epoch: 010, Train: 0.5053, Val: 0.5445, Test: 0.5438
14:56:56.557210 [0] Epoch 00011 | Loss 2.3109
14:56:56.992011 [0] Epoch 00012 | Loss 2.1617
14:56:57.221110 [0] Epoch 00013 | Loss 1.9957
14:56:57.660246 [0] Epoch 00014 | Loss 1.8369
14:56:57.894722 [0] Epoch 00015 | Loss 1.7317
14:56:58.341783 [0] Epoch 00016 | Loss 1.6134
14:56:58.569015 [0] Epoch 00017 | Loss 1.5360
14:56:58.798187 [0] Epoch 00018 | Loss 1.5342
14:56:59.227048 [0] Epoch 00019 | Loss 1.4174
14:56:59.232748 [0] Epoch: 019, Train: 0.6509, Val: 0.6805, Test: 0.6777
14:56:59.235762 [0] 
timer summary:
  1.19s   0.25s   200 mm
  2.59s   3.26s    80 broadcast
  6.35s   0.04s   200 spmm
  0.01s   0.00s   100 all_reduce
 10.35s   3.54s    20 epoch
 31.05s   0.00s     1 total
14:57:16.395049 [0] proc begin: <DistEnv 0/2 nccl>
14:57:27.761795 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
14:57:27.764933 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:57:29.666578 [0] Epoch 00000 | Loss 3.7355
14:57:29.672425 [0] Epoch: 000, Train: 0.0516, Val: 0.0506, Test: 0.0490
14:57:29.957646 [0] Epoch 00001 | Loss 3.5986
14:57:30.023570 [0] Epoch 00002 | Loss 3.4577
14:57:30.094693 [0] Epoch 00003 | Loss 3.3313
14:57:30.162016 [0] Epoch 00004 | Loss 3.1508
14:57:30.230690 [0] Epoch 00005 | Loss 2.9737
14:57:30.307554 [0] Epoch 00006 | Loss 2.7925
14:57:30.375570 [0] Epoch 00007 | Loss 2.6291
14:57:30.440312 [0] Epoch 00008 | Loss 2.4538
14:57:30.715747 [0] Epoch 00009 | Loss 2.2825
14:57:30.781869 [0] Epoch 00010 | Loss 2.1283
14:57:30.787391 [0] Epoch: 010, Train: 0.5482, Val: 0.5866, Test: 0.5817
14:57:30.857372 [0] Epoch 00011 | Loss 1.9696
14:57:30.924357 [0] Epoch 00012 | Loss 1.8065
14:57:31.005470 [0] Epoch 00013 | Loss 1.6587
14:57:31.071934 [0] Epoch 00014 | Loss 1.5370
14:57:31.139706 [0] Epoch 00015 | Loss 1.4150
14:57:31.236924 [0] Epoch 00016 | Loss 1.3111
14:57:31.521135 [0] Epoch 00017 | Loss 1.2181
14:57:31.587549 [0] Epoch 00018 | Loss 1.1800
14:57:31.653812 [0] Epoch 00019 | Loss 1.1406
14:57:31.658664 [0] Epoch: 019, Train: 0.7353, Val: 0.7558, Test: 0.7559
14:57:31.659813 [0] 
timer summary:
  1.05s   0.15s   200 mm
  1.00s   0.70s   160 broadcast
  1.96s   0.05s   160 spmm
  0.06s   0.00s   100 all_reduce
  4.23s   0.50s    20 epoch
 15.26s   0.01s     1 total
14:58:29.454494 [0] proc begin: <DistEnv 0/2 nccl>
14:58:39.759672 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
14:58:39.762148 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:58:43.044439 [0] Epoch 00000 | Loss 3.7360
14:58:43.050163 [0] Epoch: 000, Train: 0.0527, Val: 0.0519, Test: 0.0498
14:58:43.201522 [0] Epoch 00001 | Loss 3.6160
14:58:43.562720 [0] Epoch 00002 | Loss 3.5098
14:58:43.713628 [0] Epoch 00003 | Loss 3.4067
14:58:43.862168 [0] Epoch 00004 | Loss 3.2655
14:58:44.214889 [0] Epoch 00005 | Loss 3.1280
14:58:44.368548 [0] Epoch 00006 | Loss 2.9928
14:58:44.519141 [0] Epoch 00007 | Loss 2.8643
14:58:44.683785 [0] Epoch 00008 | Loss 2.7546
14:58:45.077565 [0] Epoch 00009 | Loss 2.6024
14:58:45.230208 [0] Epoch 00010 | Loss 2.4641
14:58:45.235802 [0] Epoch: 010, Train: 0.5053, Val: 0.5444, Test: 0.5438
14:58:45.397045 [0] Epoch 00011 | Loss 2.3110
14:58:45.782965 [0] Epoch 00012 | Loss 2.1619
14:58:45.933238 [0] Epoch 00013 | Loss 1.9958
14:58:46.083207 [0] Epoch 00014 | Loss 1.8369
14:58:46.239498 [0] Epoch 00015 | Loss 1.7317
14:58:46.638302 [0] Epoch 00016 | Loss 1.6136
14:58:46.790932 [0] Epoch 00017 | Loss 1.5364
14:58:46.943863 [0] Epoch 00018 | Loss 1.5336
14:58:47.096174 [0] Epoch 00019 | Loss 1.4164
14:58:47.101713 [0] Epoch: 019, Train: 0.6501, Val: 0.6791, Test: 0.6771
14:58:47.104053 [0] 
timer summary:
  1.09s   0.06s   200 mm
  1.27s   1.03s   400 broadcast
  4.01s   0.00s   400 spmm
  0.07s   0.01s   100 all_reduce
  6.64s   0.96s    20 epoch
 17.65s   0.00s     1 total
15:17:52.025760 [0] proc begin: <DistEnv 0/2 nccl>
15:18:03.538560 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:18:03.543721 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:18:05.838776 [0] Epoch 00000 | Loss 3.7360
15:18:05.844876 [0] Epoch: 000, Train: 0.0527, Val: 0.0519, Test: 0.0498
15:18:05.847320 [0] 
timer summary:
  1.13s   0.34s    10 mm
  0.50s   0.48s    20 broadcast
  0.68s   0.03s    20 spmm
  0.05s   0.00s     5 all_reduce
  2.37s   0.10s     1 epoch
 13.82s   0.00s     1 total
15:18:17.413849 [0] proc begin: <DistEnv 0/2 nccl>
15:18:35.971913 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:18:36.063081 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:18:40.281027 [0] Epoch 00000 | Loss 3.7360
15:18:40.286802 [0] Epoch: 000, Train: 0.0527, Val: 0.0519, Test: 0.0498
15:18:40.288268 [0] 
timer summary:
  0.93s   0.02s    10 mm
  1.35s   1.77s     4 broadcast
  0.66s   0.01s    10 spmm
  0.00s   0.00s     5 all_reduce
  2.96s   1.78s     1 epoch
 22.87s   0.00s     1 total
15:19:26.488422 [0] proc begin: <DistEnv 0/2 nccl>
15:19:44.642527 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:19:44.645131 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:19:49.668820 [0] Epoch 00000 | Loss 3.7347
15:19:49.674643 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:19:49.676005 [0] 
timer summary:
  0.91s   0.03s     4 mm
  1.85s   2.48s     4 broadcast
  0.53s   0.01s     4 spmm
  0.00s   0.00s     2 all_reduce
  3.30s   2.43s     1 epoch
 23.19s   0.00s     1 total
15:50:42.398885 [0] proc begin: <DistEnv 0/2 nccl>
15:51:03.592042 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:51:03.595763 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:51:05.270408 [0] Epoch 00000 | Loss 3.7347
15:51:05.276627 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:51:05.279948 [0] 
timer summary:
  0.91s   0.01s     4 mm
  2.03s   2.29s     4 broadcast
  0.37s   0.05s     4 spmm
  0.00s   0.00s     2 all_reduce
  3.32s   2.33s     1 epoch
 22.88s   0.00s     1 total
15:54:15.012899 [0] proc begin: <DistEnv 0/2 nccl>
15:54:37.227175 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:54:37.230995 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:54:39.126181 [0] Epoch 00000 | Loss 3.7347
15:54:39.131931 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:54:39.135169 [0] 
timer summary:
  0.99s   0.18s     4 mm
  2.41s   2.79s     4 broadcast
  0.48s   0.21s     4 spmm
  0.00s   0.00s     2 all_reduce
  3.88s   2.82s     1 epoch
 24.12s   0.00s     1 total
15:54:47.706548 [0] proc begin: <DistEnv 0/2 nccl>
15:55:06.986647 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:55:06.993388 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:55:09.225637 [0] Epoch 00000 | Loss 3.7347
15:55:09.230818 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:55:09.233024 [0] 
timer summary:
  1.27s   0.29s     4 mm
  0.16s   0.01s     4 broadcast
  0.60s   0.01s     4 spmm
  0.00s   0.00s     2 all_reduce
  2.04s   0.27s     1 epoch
 21.52s   0.00s     1 total
15:55:36.536447 [0] proc begin: <DistEnv 0/2 nccl>
15:56:01.889773 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:56:01.893716 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:56:05.023035 [0] Epoch 00000 | Loss 3.7315
15:56:05.028571 [0] Epoch: 000, Train: 0.0070, Val: 0.0066, Test: 0.0061
15:56:05.029858 [0] 
timer summary:
  1.28s   0.20s     6 mm
  0.58s   0.67s     4 broadcast
  0.64s   0.00s     6 spmm
  0.00s   0.00s     3 all_reduce
  2.52s   0.87s     1 epoch
 28.49s   0.00s     1 total
15:56:48.294172 [0] proc begin: <DistEnv 0/2 nccl>
15:57:08.458902 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:57:08.495143 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:57:11.120893 [0] Epoch 00000 | Loss 3.7347
15:57:11.125427 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:57:11.126587 [0] 
timer summary:
  0.97s   0.04s     4 mm
  0.59s   0.68s     4 broadcast
  0.54s   0.01s     4 spmm
  0.00s   0.00s     2 all_reduce
  2.10s   0.73s     1 epoch
 22.83s   0.00s     1 total
15:57:23.032646 [0] proc begin: <DistEnv 0/2 nccl>
15:57:43.799295 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:57:43.803263 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:57:45.433467 [0] Epoch 00000 | Loss 3.7347
15:57:45.439615 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:57:45.441183 [0] 
timer summary:
  1.00s   0.20s     4 mm
  1.02s   1.25s     4 broadcast
  0.33s   0.01s     4 spmm
  0.00s   0.00s     2 all_reduce
  2.36s   1.04s     1 epoch
 22.40s   0.01s     1 total
15:58:04.929287 [0] proc begin: <DistEnv 0/2 nccl>
15:58:23.169483 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
15:58:23.172255 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:58:28.589704 [0] Epoch 00000 | Loss 3.7347
15:58:28.594438 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
15:58:28.595471 [0] 
timer summary:
  1.08s   0.25s     4 mm
  2.14s   2.89s     4 broadcast
  0.36s   0.06s     4 spmm
  0.00s   0.00s     2 all_reduce
  3.59s   2.58s     1 epoch
 23.67s   0.00s     1 total
16:01:41.514988 [0] proc begin: <DistEnv 0/2 nccl>
16:02:00.849951 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:02:00.852935 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:02:02.699865 [0] Epoch 00000 | Loss 3.7347
16:02:02.704909 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
16:02:02.706488 [0] 
timer summary:
  1.06s   0.03s     4 mm
  0.45s   0.43s     4 broadcast
  0.62s   0.01s     4 spmm
  0.00s   0.00s     2 all_reduce
  2.14s   0.42s     1 epoch
 21.19s   0.00s     1 total
16:02:10.545704 [0] proc begin: <DistEnv 0/2 nccl>
16:02:31.365406 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:02:31.369176 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:03:22.724766 [0] proc begin: <DistEnv 0/2 nccl>
16:03:41.745536 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:03:41.805969 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:03:43.405448 [0] Epoch 00000 | Loss 3.7315
16:03:43.409918 [0] Epoch: 000, Train: 0.0070, Val: 0.0066, Test: 0.0061
16:03:43.412103 [0] 
timer summary:
  0.89s   0.00s     6 mm
  0.88s   1.05s     4 broadcast
  0.57s   0.00s     6 spmm
  0.00s   0.00s     3 all_reduce
  2.35s   1.06s     1 epoch
 20.68s   0.01s     1 total
16:04:55.660878 [0] proc begin: <DistEnv 0/2 nccl>
16:05:16.025608 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:05:16.028143 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:05:18.105529 [0] Epoch 00000 | Loss 3.7315
16:05:18.110033 [0] Epoch: 000, Train: 0.0070, Val: 0.0066, Test: 0.0061
16:05:18.110795 [0] 
timer summary:
  0.92s   0.01s     6 mm
  0.34s   0.34s     4 broadcast
  0.60s   0.03s     6 spmm
  0.00s   0.00s     3 all_reduce
  1.86s   0.30s     1 epoch
 22.45s   0.00s     1 total
16:06:01.303764 [0] proc begin: <DistEnv 0/2 nccl>
16:06:23.733459 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:06:23.736002 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:06:25.351876 [0] Epoch 00000 | Loss 3.7315
16:06:25.357774 [0] Epoch: 000, Train: 0.0070, Val: 0.0066, Test: 0.0061
16:06:25.359848 [0] 
timer summary:
  1.00s   0.14s     6 mm
  1.97s   2.61s     4 broadcast
  0.37s   0.00s     6 spmm
  0.00s   0.00s     3 all_reduce
  3.36s   2.47s     1 epoch
 24.05s   0.00s     1 total
16:09:09.710799 [0] proc begin: <DistEnv 0/2 nccl>
16:09:27.403706 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:09:27.406270 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:13:03.171458 [0] proc begin: <DistEnv 0/2 nccl>
16:13:05.824506 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:13:05.827687 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:13:07.539026 [0] Epoch 00000 | Loss 3.6876
16:13:07.543136 [0] Epoch: 000, Train: 0.0079, Val: 0.0082, Test: 0.0081
16:13:07.566762 [0] Epoch 00001 | Loss 3.6468
16:13:07.590798 [0] Epoch 00002 | Loss 3.6098
16:13:07.617272 [0] Epoch 00003 | Loss 3.7976
16:13:07.643597 [0] Epoch 00004 | Loss 4.6338
16:13:07.666336 [0] Epoch 00005 | Loss 6.6306
16:13:07.685185 [0] Epoch 00006 | Loss 10.6961
16:13:07.911527 [0] Epoch 00007 | Loss 18.2651
16:13:07.936397 [0] Epoch 00008 | Loss 30.8639
16:13:07.960359 [0] Epoch 00009 | Loss 47.3017
16:13:07.982069 [0] Epoch 00010 | Loss 68.6254
16:13:07.984735 [0] Epoch: 010, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:13:08.005807 [0] Epoch 00011 | Loss 103.4954
16:13:08.028926 [0] Epoch 00012 | Loss 151.9264
16:13:08.057990 [0] Epoch 00013 | Loss 203.8317
16:13:08.082242 [0] Epoch 00014 | Loss 281.9518
16:13:08.105140 [0] Epoch 00015 | Loss 381.7664
16:13:08.130139 [0] Epoch 00016 | Loss 464.9884
16:13:08.159799 [0] Epoch 00017 | Loss 569.4692
16:13:08.182431 [0] Epoch 00018 | Loss 708.2255
16:13:08.209450 [0] Epoch 00019 | Loss 822.0643
16:13:08.233709 [0] Epoch 00020 | Loss 928.1768
16:13:08.236379 [0] Epoch: 020, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:13:08.258600 [0] Epoch 00021 | Loss 1098.0826
16:13:08.281597 [0] Epoch 00022 | Loss 1193.9364
16:13:08.303248 [0] Epoch 00023 | Loss 1401.9871
16:13:08.323722 [0] Epoch 00024 | Loss 1479.5698
16:13:08.345649 [0] Epoch 00025 | Loss 1624.1598
16:13:08.369674 [0] Epoch 00026 | Loss 1677.3430
16:13:08.392443 [0] Epoch 00027 | Loss 1605.1571
16:13:08.414780 [0] Epoch 00028 | Loss 1563.5723
16:13:08.438587 [0] Epoch 00029 | Loss 1588.6306
16:13:08.459246 [0] Epoch 00030 | Loss 1410.2314
16:13:08.462476 [0] Epoch: 030, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:13:08.681135 [0] Epoch 00031 | Loss 1533.7614
16:13:08.703991 [0] Epoch 00032 | Loss 1651.1610
16:13:08.728394 [0] Epoch 00033 | Loss 1678.7227
16:13:08.749242 [0] Epoch 00034 | Loss 1572.8566
16:13:08.771626 [0] Epoch 00035 | Loss 1679.0953
16:13:08.810368 [0] Epoch 00036 | Loss 1724.7063
16:13:08.833654 [0] Epoch 00037 | Loss 1719.7377
16:13:08.857944 [0] Epoch 00038 | Loss 1780.3912
16:13:08.881746 [0] Epoch 00039 | Loss 1697.5410
16:13:08.905846 [0] Epoch 00040 | Loss 1807.1539
16:13:08.908995 [0] Epoch: 040, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:13:08.929894 [0] Epoch 00041 | Loss 1784.9496
16:13:08.951528 [0] Epoch 00042 | Loss 1852.8252
16:13:08.974362 [0] Epoch 00043 | Loss 1791.0435
16:13:08.997654 [0] Epoch 00044 | Loss 1785.8201
16:13:09.022201 [0] Epoch 00045 | Loss 1839.4818
16:13:09.048870 [0] Epoch 00046 | Loss 1856.1698
16:13:09.071554 [0] Epoch 00047 | Loss 1815.7208
16:13:09.094017 [0] Epoch 00048 | Loss 1714.9137
16:13:09.115914 [0] Epoch 00049 | Loss 1859.9032
16:13:09.139253 [0] Epoch 00050 | Loss 2007.2986
16:13:09.142163 [0] Epoch: 050, Train: 0.1781, Val: 0.0762, Test: 0.0585
16:13:09.171374 [0] Epoch 00051 | Loss 2289.4180
16:13:09.195570 [0] Epoch 00052 | Loss 2704.4253
16:13:09.220077 [0] Epoch 00053 | Loss 3042.3164
16:13:09.440908 [0] Epoch 00054 | Loss 3060.9224
16:13:09.462339 [0] Epoch 00055 | Loss 2903.3169
16:13:09.486890 [0] Epoch 00056 | Loss 3276.4468
16:13:09.517924 [0] Epoch 00057 | Loss 3491.8167
16:13:09.541758 [0] Epoch 00058 | Loss 3935.2024
16:13:09.564010 [0] Epoch 00059 | Loss 4475.7373
16:13:09.586201 [0] Epoch 00060 | Loss 4565.4414
16:13:09.588881 [0] Epoch: 060, Train: 0.1126, Val: 0.2301, Test: 0.2160
16:13:09.612172 [0] Epoch 00061 | Loss 4659.8633
16:13:09.633616 [0] Epoch 00062 | Loss 4628.1431
16:13:09.655165 [0] Epoch 00063 | Loss 5175.9951
16:13:09.679165 [0] Epoch 00064 | Loss 6021.7188
16:13:09.703744 [0] Epoch 00065 | Loss 6450.9546
16:13:09.723507 [0] Epoch 00066 | Loss 6746.1587
16:13:09.744678 [0] Epoch 00067 | Loss 6875.6030
16:13:09.764054 [0] Epoch 00068 | Loss 8258.2080
16:13:09.786127 [0] Epoch 00069 | Loss 8037.0552
16:13:09.809911 [0] Epoch 00070 | Loss 9003.7959
16:13:09.813354 [0] Epoch: 070, Train: 0.1139, Val: 0.2307, Test: 0.2162
16:13:09.836095 [0] Epoch 00071 | Loss 9434.2031
16:13:09.861879 [0] Epoch 00072 | Loss 9192.7393
16:13:09.885787 [0] Epoch 00073 | Loss 10415.6172
16:13:09.910283 [0] Epoch 00074 | Loss 10514.8848
16:13:09.932123 [0] Epoch 00075 | Loss 12676.8896
16:13:09.954240 [0] Epoch 00076 | Loss 14323.8125
16:13:10.179610 [0] Epoch 00077 | Loss 14934.4678
16:13:10.204953 [0] Epoch 00078 | Loss 14510.3994
16:13:10.228568 [0] Epoch 00079 | Loss 13785.1250
16:13:10.248092 [0] Epoch 00080 | Loss 13656.1846
16:13:10.250588 [0] Epoch: 080, Train: 0.1240, Val: 0.2318, Test: 0.2173
16:13:10.270491 [0] Epoch 00081 | Loss 16518.4102
16:13:10.293536 [0] Epoch 00082 | Loss 19894.9453
16:13:10.314585 [0] Epoch 00083 | Loss 19487.5391
16:13:10.337784 [0] Epoch 00084 | Loss 22751.1582
16:13:10.361530 [0] Epoch 00085 | Loss 23889.7461
16:13:10.384191 [0] Epoch 00086 | Loss 22110.2812
16:13:10.406943 [0] Epoch 00087 | Loss 19644.1680
16:13:10.427984 [0] Epoch 00088 | Loss 20848.9180
16:13:10.452716 [0] Epoch 00089 | Loss 25920.8125
16:13:10.476798 [0] Epoch 00090 | Loss 30584.8125
16:13:10.479495 [0] Epoch: 090, Train: 0.1173, Val: 0.2311, Test: 0.2164
16:13:10.508731 [0] Epoch 00091 | Loss 33293.3672
16:13:10.531912 [0] Epoch 00092 | Loss 31608.6211
16:13:10.552674 [0] Epoch 00093 | Loss 28306.8555
16:13:10.574076 [0] Epoch 00094 | Loss 29632.1992
16:13:10.596232 [0] Epoch 00095 | Loss 33985.9141
16:13:10.622435 [0] Epoch 00096 | Loss 40119.4258
16:13:10.646758 [0] Epoch 00097 | Loss 43263.2188
16:13:10.670046 [0] Epoch 00098 | Loss 43877.6641
16:13:10.694035 [0] Epoch 00099 | Loss 42235.9141
16:13:10.717478 [0] Epoch 00100 | Loss 40146.7734
16:13:10.720113 [0] Epoch: 100, Train: 0.1148, Val: 0.2317, Test: 0.2173
16:13:10.936822 [0] Epoch 00101 | Loss 40508.2734
16:13:10.963815 [0] Epoch 00102 | Loss 45484.3398
16:13:10.986658 [0] Epoch 00103 | Loss 49417.7188
16:13:11.011702 [0] Epoch 00104 | Loss 55986.7109
16:13:11.037583 [0] Epoch 00105 | Loss 63369.9727
16:13:11.058264 [0] Epoch 00106 | Loss 63874.4844
16:13:11.082083 [0] Epoch 00107 | Loss 62477.4336
16:13:11.104182 [0] Epoch 00108 | Loss 58385.7109
16:13:11.128023 [0] Epoch 00109 | Loss 60622.4375
16:13:11.147424 [0] Epoch 00110 | Loss 67591.4844
16:13:11.149944 [0] Epoch: 110, Train: 0.1680, Val: 0.0756, Test: 0.0588
16:13:11.174891 [0] Epoch 00111 | Loss 64880.3516
16:13:11.197898 [0] Epoch 00112 | Loss 72470.3359
16:13:11.220047 [0] Epoch 00113 | Loss 75866.1250
16:13:11.242672 [0] Epoch 00114 | Loss 77672.6406
16:13:11.265602 [0] Epoch 00115 | Loss 78290.5156
16:13:11.286921 [0] Epoch 00116 | Loss 84653.5391
16:13:11.309778 [0] Epoch 00117 | Loss 88729.4453
16:13:11.334048 [0] Epoch 00118 | Loss 91014.5234
16:13:11.358150 [0] Epoch 00119 | Loss 90787.3516
16:13:11.383765 [0] Epoch 00120 | Loss 86524.4062
16:13:11.386704 [0] Epoch: 120, Train: 0.1154, Val: 0.2319, Test: 0.2177
16:13:11.408947 [0] Epoch 00121 | Loss 105175.2031
16:13:11.432955 [0] Epoch 00122 | Loss 116651.4609
16:13:11.456176 [0] Epoch 00123 | Loss 101557.6250
16:13:11.685386 [0] Epoch 00124 | Loss 98070.4609
16:13:11.710706 [0] Epoch 00125 | Loss 122112.3203
16:13:11.733004 [0] Epoch 00126 | Loss 130739.0078
16:13:11.755064 [0] Epoch 00127 | Loss 122148.7344
16:13:11.777896 [0] Epoch 00128 | Loss 121921.5078
16:13:11.800162 [0] Epoch 00129 | Loss 100910.2109
16:13:11.821982 [0] Epoch 00130 | Loss 95189.2422
16:13:11.825413 [0] Epoch: 130, Train: 0.1233, Val: 0.2351, Test: 0.2205
16:13:11.847793 [0] Epoch 00131 | Loss 96695.6641
16:13:11.870102 [0] Epoch 00132 | Loss 106683.1953
16:13:11.890607 [0] Epoch 00133 | Loss 113292.8359
16:13:11.912713 [0] Epoch 00134 | Loss 128658.1172
16:13:11.934686 [0] Epoch 00135 | Loss 142785.3750
16:13:11.957871 [0] Epoch 00136 | Loss 144399.3594
16:13:11.979934 [0] Epoch 00137 | Loss 146068.9219
16:13:12.003181 [0] Epoch 00138 | Loss 146811.5000
16:13:12.025592 [0] Epoch 00139 | Loss 169917.2812
16:13:12.053108 [0] Epoch 00140 | Loss 152985.6875
16:13:12.056595 [0] Epoch: 140, Train: 0.1764, Val: 0.0788, Test: 0.0608
16:13:12.081094 [0] Epoch 00141 | Loss 170803.0625
16:13:12.103803 [0] Epoch 00142 | Loss 181192.7344
16:13:12.125599 [0] Epoch 00143 | Loss 178912.3438
16:13:12.147137 [0] Epoch 00144 | Loss 169678.5156
16:13:12.174724 [0] Epoch 00145 | Loss 167734.6875
16:13:12.198575 [0] Epoch 00146 | Loss 174141.0781
16:13:12.219353 [0] Epoch 00147 | Loss 177100.2500
16:13:12.434019 [0] Epoch 00148 | Loss 190716.5000
16:13:12.455980 [0] Epoch 00149 | Loss 213072.3906
16:13:12.474661 [0] Epoch 00150 | Loss 222614.2656
16:13:12.477114 [0] Epoch: 150, Train: 0.1153, Val: 0.2312, Test: 0.2166
16:13:12.495957 [0] Epoch 00151 | Loss 225122.5156
16:13:12.521822 [0] Epoch 00152 | Loss 235684.2344
16:13:12.546164 [0] Epoch 00153 | Loss 212713.9688
16:13:12.567792 [0] Epoch 00154 | Loss 223009.9531
16:13:12.594735 [0] Epoch 00155 | Loss 227498.4688
16:13:12.623960 [0] Epoch 00156 | Loss 219798.7188
16:13:12.648093 [0] Epoch 00157 | Loss 207467.4062
16:13:12.673448 [0] Epoch 00158 | Loss 217000.1875
16:13:12.697637 [0] Epoch 00159 | Loss 200868.5312
16:13:12.725613 [0] Epoch 00160 | Loss 221472.2500
16:13:12.728627 [0] Epoch: 160, Train: 0.0891, Val: 0.1509, Test: 0.2217
16:13:12.751719 [0] Epoch 00161 | Loss 259549.0156
16:13:12.773751 [0] Epoch 00162 | Loss 282817.4375
16:13:12.796617 [0] Epoch 00163 | Loss 326949.2188
16:13:12.818843 [0] Epoch 00164 | Loss 335685.1250
16:13:12.839594 [0] Epoch 00165 | Loss 323663.9688
16:13:12.859165 [0] Epoch 00166 | Loss 288682.9375
16:13:12.880860 [0] Epoch 00167 | Loss 297097.1562
16:13:12.904166 [0] Epoch 00168 | Loss 298875.1875
16:13:12.927754 [0] Epoch 00169 | Loss 316691.4062
16:13:12.950719 [0] Epoch 00170 | Loss 322152.4688
16:13:12.953591 [0] Epoch: 170, Train: 0.1354, Val: 0.2376, Test: 0.2223
16:13:12.975507 [0] Epoch 00171 | Loss 373880.0000
16:13:13.190813 [0] Epoch 00172 | Loss 414713.5938
16:13:13.213793 [0] Epoch 00173 | Loss 458895.0312
16:13:13.237562 [0] Epoch 00174 | Loss 485477.1250
16:13:13.261538 [0] Epoch 00175 | Loss 545791.0000
16:13:13.284609 [0] Epoch 00176 | Loss 539328.7500
16:13:13.313081 [0] Epoch 00177 | Loss 519458.4688
16:13:13.337557 [0] Epoch 00178 | Loss 493843.1562
16:13:13.360198 [0] Epoch 00179 | Loss 457194.6562
16:13:13.381616 [0] Epoch 00180 | Loss 431182.6562
16:13:13.384192 [0] Epoch: 180, Train: 0.1222, Val: 0.2323, Test: 0.2179
16:13:13.407858 [0] Epoch 00181 | Loss 405077.2812
16:13:13.429650 [0] Epoch 00182 | Loss 457515.3125
16:13:13.450984 [0] Epoch 00183 | Loss 473230.8125
16:13:13.474258 [0] Epoch 00184 | Loss 571976.4375
16:13:13.497622 [0] Epoch 00185 | Loss 604324.5000
16:13:13.518872 [0] Epoch 00186 | Loss 675738.3750
16:13:13.536395 [0] Epoch 00187 | Loss 693637.6875
16:13:13.561342 [0] Epoch 00188 | Loss 744284.2500
16:13:13.585406 [0] Epoch 00189 | Loss 718308.4375
16:13:13.607921 [0] Epoch 00190 | Loss 712510.1250
16:13:13.611075 [0] Epoch: 190, Train: 0.0337, Val: 0.0400, Test: 0.0446
16:13:13.632898 [0] Epoch 00191 | Loss 702560.0000
16:13:13.654334 [0] Epoch 00192 | Loss 622647.6875
16:13:13.676838 [0] Epoch 00193 | Loss 703968.3125
16:13:13.703144 [0] Epoch 00194 | Loss 785985.7500
16:13:13.729685 [0] Epoch 00195 | Loss 884818.0625
16:13:13.955248 [0] Epoch 00196 | Loss 947771.5000
16:13:13.981714 [0] Epoch 00197 | Loss 982889.5000
16:13:14.004701 [0] Epoch 00198 | Loss 1017474.5625
16:13:14.025053 [0] Epoch 00199 | Loss 967406.5625
16:13:14.027585 [0] Epoch: 199, Train: 0.0501, Val: 0.0315, Test: 0.0272
16:13:14.029607 [0] 
timer summary:
  1.38s   0.00s  2000 mm
  1.08s   0.01s   800 broadcast
  4.27s   0.00s  2000 spmm
  0.10s   0.00s  1000 all_reduce
  8.12s   0.02s   200 epoch
 10.86s   0.00s     1 total
16:13:36.912612 [0] proc begin: <DistEnv 0/2 nccl>
16:13:38.711927 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
16:13:38.715005 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:13:40.742118 [0] Epoch 00000 | Loss 3.6876
16:13:40.746703 [0] Epoch: 000, Train: 0.0079, Val: 0.0082, Test: 0.0081
16:13:40.784399 [0] Epoch 00001 | Loss 3.6468
16:13:40.828317 [0] Epoch 00002 | Loss 3.6098
16:13:40.868992 [0] Epoch 00003 | Loss 3.7976
16:13:40.917629 [0] Epoch 00004 | Loss 4.6338
16:13:40.961034 [0] Epoch 00005 | Loss 6.6306
16:13:41.001213 [0] Epoch 00006 | Loss 10.6961
16:13:41.039583 [0] Epoch 00007 | Loss 18.2651
16:13:41.082520 [0] Epoch 00008 | Loss 30.8639
16:13:41.122359 [0] Epoch 00009 | Loss 47.3017
16:13:41.161728 [0] Epoch 00010 | Loss 68.6254
16:13:41.165193 [0] Epoch: 010, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:13:41.209172 [0] Epoch 00011 | Loss 103.4955
16:13:41.453484 [0] Epoch 00012 | Loss 151.9264
16:13:41.498446 [0] Epoch 00013 | Loss 203.8317
16:13:41.545370 [0] Epoch 00014 | Loss 281.9518
16:13:41.583735 [0] Epoch 00015 | Loss 381.7664
16:13:41.632853 [0] Epoch 00016 | Loss 464.9885
16:13:41.678814 [0] Epoch 00017 | Loss 569.4691
16:13:41.717861 [0] Epoch 00018 | Loss 708.2251
16:13:41.756674 [0] Epoch 00019 | Loss 822.0643
16:13:41.796681 [0] Epoch 00020 | Loss 928.1761
16:13:41.800030 [0] Epoch: 020, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:13:41.836896 [0] Epoch 00021 | Loss 1098.0825
16:13:41.874399 [0] Epoch 00022 | Loss 1193.9344
16:13:41.915098 [0] Epoch 00023 | Loss 1401.9884
16:13:41.952816 [0] Epoch 00024 | Loss 1479.5675
16:13:41.994111 [0] Epoch 00025 | Loss 1624.1659
16:13:42.236476 [0] Epoch 00026 | Loss 1677.3428
16:13:42.277406 [0] Epoch 00027 | Loss 1605.1572
16:13:42.322698 [0] Epoch 00028 | Loss 1563.5684
16:13:42.360381 [0] Epoch 00029 | Loss 1588.6290
16:13:42.400375 [0] Epoch 00030 | Loss 1410.2268
16:13:42.403560 [0] Epoch: 030, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:13:42.438591 [0] Epoch 00031 | Loss 1533.7753
16:13:42.475302 [0] Epoch 00032 | Loss 1651.1621
16:13:42.516816 [0] Epoch 00033 | Loss 1678.7233
16:13:42.559194 [0] Epoch 00034 | Loss 1572.8569
16:13:42.599662 [0] Epoch 00035 | Loss 1679.1001
16:13:42.662573 [0] Epoch 00036 | Loss 1724.6984
16:13:42.709160 [0] Epoch 00037 | Loss 1719.7233
16:13:42.752420 [0] Epoch 00038 | Loss 1780.3507
16:13:42.982989 [0] Epoch 00039 | Loss 1697.5389
16:13:43.025041 [0] Epoch 00040 | Loss 1807.1451
16:13:43.028262 [0] Epoch: 040, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:13:43.067327 [0] Epoch 00041 | Loss 1784.9365
16:13:43.110223 [0] Epoch 00042 | Loss 1852.8108
16:13:43.150161 [0] Epoch 00043 | Loss 1791.0443
16:13:43.191956 [0] Epoch 00044 | Loss 1785.8042
16:13:43.245506 [0] Epoch 00045 | Loss 1839.5667
16:13:43.286441 [0] Epoch 00046 | Loss 1856.3333
16:13:43.328605 [0] Epoch 00047 | Loss 1815.9431
16:13:43.370570 [0] Epoch 00048 | Loss 1715.1024
16:13:43.416454 [0] Epoch 00049 | Loss 1860.0414
16:13:43.460115 [0] Epoch 00050 | Loss 2007.3246
16:13:43.463629 [0] Epoch: 050, Train: 0.1781, Val: 0.0762, Test: 0.0586
16:13:43.502072 [0] Epoch 00051 | Loss 2289.2522
16:13:43.748080 [0] Epoch 00052 | Loss 2704.1379
16:13:43.787613 [0] Epoch 00053 | Loss 3042.1204
16:13:43.830969 [0] Epoch 00054 | Loss 3060.8872
16:13:43.875151 [0] Epoch 00055 | Loss 2903.6707
16:13:43.917133 [0] Epoch 00056 | Loss 3276.4324
16:13:43.958778 [0] Epoch 00057 | Loss 3492.6338
16:13:43.996161 [0] Epoch 00058 | Loss 3933.8105
16:13:44.033933 [0] Epoch 00059 | Loss 4474.5620
16:13:44.075049 [0] Epoch 00060 | Loss 4563.3159
16:13:44.078149 [0] Epoch: 060, Train: 0.1125, Val: 0.2301, Test: 0.2160
16:13:44.119844 [0] Epoch 00061 | Loss 4659.2866
16:13:44.159145 [0] Epoch 00062 | Loss 4627.6465
16:13:44.198471 [0] Epoch 00063 | Loss 5189.1055
16:13:44.238998 [0] Epoch 00064 | Loss 6025.6323
16:13:44.276386 [0] Epoch 00065 | Loss 6452.4316
16:13:44.510569 [0] Epoch 00066 | Loss 6724.5449
16:13:44.554049 [0] Epoch 00067 | Loss 6878.8315
16:13:44.595568 [0] Epoch 00068 | Loss 8241.1768
16:13:44.638755 [0] Epoch 00069 | Loss 8015.9419
16:13:44.676154 [0] Epoch 00070 | Loss 9030.1445
16:13:44.679580 [0] Epoch: 070, Train: 0.1148, Val: 0.2309, Test: 0.2163
16:13:44.716434 [0] Epoch 00071 | Loss 9441.7510
16:13:44.761787 [0] Epoch 00072 | Loss 9157.9434
16:13:44.799284 [0] Epoch 00073 | Loss 10480.5723
16:13:44.840384 [0] Epoch 00074 | Loss 10520.7783
16:13:44.878574 [0] Epoch 00075 | Loss 12556.3096
16:13:44.918038 [0] Epoch 00076 | Loss 14427.9570
16:13:44.954573 [0] Epoch 00077 | Loss 14981.3008
16:13:44.992950 [0] Epoch 00078 | Loss 14591.4766
16:13:45.037442 [0] Epoch 00079 | Loss 13852.7695
16:13:45.270955 [0] Epoch 00080 | Loss 13677.4492
16:13:45.274472 [0] Epoch: 080, Train: 0.1243, Val: 0.2320, Test: 0.2175
16:13:45.314043 [0] Epoch 00081 | Loss 16101.4971
16:13:45.353024 [0] Epoch 00082 | Loss 19410.8887
16:13:45.394793 [0] Epoch 00083 | Loss 18432.8301
16:13:45.434685 [0] Epoch 00084 | Loss 22136.9395
16:13:45.473691 [0] Epoch 00085 | Loss 23482.9473
16:13:45.516397 [0] Epoch 00086 | Loss 21970.0762
16:13:45.562336 [0] Epoch 00087 | Loss 19671.0293
16:13:45.605672 [0] Epoch 00088 | Loss 22105.0684
16:13:45.647593 [0] Epoch 00089 | Loss 27783.3125
16:13:45.686609 [0] Epoch 00090 | Loss 26584.3164
16:13:45.690089 [0] Epoch: 090, Train: 0.0851, Val: 0.1503, Test: 0.2212
16:13:45.730045 [0] Epoch 00091 | Loss 31600.1289
16:13:45.767930 [0] Epoch 00092 | Loss 33886.4219
16:13:46.008002 [0] Epoch 00093 | Loss 31838.0039
16:13:46.045447 [0] Epoch 00094 | Loss 27915.5859
16:13:46.085995 [0] Epoch 00095 | Loss 31308.8574
16:13:46.124251 [0] Epoch 00096 | Loss 34349.4492
16:13:46.164081 [0] Epoch 00097 | Loss 33252.2656
16:13:46.204265 [0] Epoch 00098 | Loss 38220.4258
16:13:46.247729 [0] Epoch 00099 | Loss 42624.1328
16:13:46.288140 [0] Epoch 00100 | Loss 41815.7656
16:13:46.291905 [0] Epoch: 100, Train: 0.1246, Val: 0.2338, Test: 0.2180
16:13:46.326730 [0] Epoch 00101 | Loss 39842.5898
16:13:46.364527 [0] Epoch 00102 | Loss 47074.8008
16:13:46.404273 [0] Epoch 00103 | Loss 44867.4883
16:13:46.445331 [0] Epoch 00104 | Loss 49413.8047
16:13:46.484810 [0] Epoch 00105 | Loss 51719.4922
16:13:46.526276 [0] Epoch 00106 | Loss 51006.9492
16:13:46.774301 [0] Epoch 00107 | Loss 46768.1094
16:13:46.814176 [0] Epoch 00108 | Loss 47180.9922
16:13:46.851205 [0] Epoch 00109 | Loss 56724.8438
16:13:46.890509 [0] Epoch 00110 | Loss 56813.0312
16:13:46.893328 [0] Epoch: 110, Train: 0.0634, Val: 0.1004, Test: 0.0983
16:13:46.929520 [0] Epoch 00111 | Loss 65025.8867
16:13:46.969205 [0] Epoch 00112 | Loss 67375.4141
16:13:47.013906 [0] Epoch 00113 | Loss 61977.9258
16:13:47.059849 [0] Epoch 00114 | Loss 59529.3086
16:13:47.101541 [0] Epoch 00115 | Loss 55192.1719
16:13:47.139262 [0] Epoch 00116 | Loss 58689.4023
16:13:47.180153 [0] Epoch 00117 | Loss 71924.8828
16:13:47.221676 [0] Epoch 00118 | Loss 70048.7500
16:13:47.258167 [0] Epoch 00119 | Loss 79782.8984
16:13:47.296576 [0] Epoch 00120 | Loss 82124.3203
16:13:47.299800 [0] Epoch: 120, Train: 0.1285, Val: 0.2354, Test: 0.2195
16:13:47.525895 [0] Epoch 00121 | Loss 83412.4219
16:13:47.565186 [0] Epoch 00122 | Loss 84289.7109
16:13:47.605195 [0] Epoch 00123 | Loss 85961.5625
16:13:47.644572 [0] Epoch 00124 | Loss 86896.3984
16:13:47.685523 [0] Epoch 00125 | Loss 87026.7188
16:13:47.721708 [0] Epoch 00126 | Loss 87236.1562
16:13:47.768216 [0] Epoch 00127 | Loss 88820.0547
16:13:47.808503 [0] Epoch 00128 | Loss 88812.0469
16:13:47.851783 [0] Epoch 00129 | Loss 105833.5078
16:13:47.894943 [0] Epoch 00130 | Loss 108901.3125
16:13:47.898223 [0] Epoch: 130, Train: 0.1762, Val: 0.0806, Test: 0.0620
16:13:47.937394 [0] Epoch 00131 | Loss 133868.2969
16:13:47.975223 [0] Epoch 00132 | Loss 146216.8281
16:13:48.016738 [0] Epoch 00133 | Loss 153060.1875
16:13:48.266886 [0] Epoch 00134 | Loss 148726.8281
16:13:48.310160 [0] Epoch 00135 | Loss 142476.4375
16:13:48.351418 [0] Epoch 00136 | Loss 139271.1875
16:13:48.394995 [0] Epoch 00137 | Loss 144726.3281
16:13:48.439730 [0] Epoch 00138 | Loss 165396.1719
16:13:48.480033 [0] Epoch 00139 | Loss 196187.4219
16:13:48.520625 [0] Epoch 00140 | Loss 226876.3594
16:13:48.524127 [0] Epoch: 140, Train: 0.0734, Val: 0.1046, Test: 0.1018
16:13:48.566794 [0] Epoch 00141 | Loss 256697.3438
16:13:48.605688 [0] Epoch 00142 | Loss 263334.9688
16:13:48.647697 [0] Epoch 00143 | Loss 246400.6719
16:13:48.686225 [0] Epoch 00144 | Loss 284383.0938
16:13:48.722381 [0] Epoch 00145 | Loss 274138.9375
16:13:48.762452 [0] Epoch 00146 | Loss 268158.0938
16:13:48.799725 [0] Epoch 00147 | Loss 256896.5312
16:13:49.033970 [0] Epoch 00148 | Loss 280643.4375
16:13:49.074416 [0] Epoch 00149 | Loss 292486.3750
16:13:49.111361 [0] Epoch 00150 | Loss 299492.9062
16:13:49.114807 [0] Epoch: 150, Train: 0.0241, Val: 0.0205, Test: 0.0182
16:13:49.149785 [0] Epoch 00151 | Loss 306711.4688
16:13:49.192645 [0] Epoch 00152 | Loss 348744.3750
16:13:49.231819 [0] Epoch 00153 | Loss 348862.9375
16:13:49.270338 [0] Epoch 00154 | Loss 392849.5625
16:13:49.311278 [0] Epoch 00155 | Loss 432301.0000
16:13:49.352875 [0] Epoch 00156 | Loss 463711.7188
16:13:49.390410 [0] Epoch 00157 | Loss 464635.6562
16:13:49.428508 [0] Epoch 00158 | Loss 462182.9062
16:13:49.467915 [0] Epoch 00159 | Loss 447491.2188
16:13:49.507335 [0] Epoch 00160 | Loss 412386.3750
16:13:49.510314 [0] Epoch: 160, Train: 0.1480, Val: 0.2449, Test: 0.2296
16:13:49.554696 [0] Epoch 00161 | Loss 376989.3125
16:13:49.791716 [0] Epoch 00162 | Loss 363930.3125
16:13:49.832540 [0] Epoch 00163 | Loss 376067.9375
16:13:49.871226 [0] Epoch 00164 | Loss 410851.3750
16:13:49.910026 [0] Epoch 00165 | Loss 513296.5000
16:13:49.950057 [0] Epoch 00166 | Loss 528127.8750
16:13:49.990215 [0] Epoch 00167 | Loss 588877.4375
16:13:50.036531 [0] Epoch 00168 | Loss 595578.6250
16:13:50.076067 [0] Epoch 00169 | Loss 620460.8750
16:13:50.118514 [0] Epoch 00170 | Loss 596729.0625
16:13:50.121973 [0] Epoch: 170, Train: 0.1875, Val: 0.0830, Test: 0.0633
16:13:50.156682 [0] Epoch 00171 | Loss 548514.9375
16:13:50.200051 [0] Epoch 00172 | Loss 600379.6875
16:13:50.239046 [0] Epoch 00173 | Loss 636825.6250
16:13:50.282424 [0] Epoch 00174 | Loss 652932.7500
16:13:50.521253 [0] Epoch 00175 | Loss 666094.0000
16:13:50.561760 [0] Epoch 00176 | Loss 670425.9375
16:13:50.607624 [0] Epoch 00177 | Loss 771337.0625
16:13:50.645302 [0] Epoch 00178 | Loss 767277.2500
16:13:50.683652 [0] Epoch 00179 | Loss 777719.0625
16:13:50.720732 [0] Epoch 00180 | Loss 895423.7500
16:13:50.724311 [0] Epoch: 180, Train: 0.1897, Val: 0.0830, Test: 0.0628
16:13:50.759702 [0] Epoch 00181 | Loss 1065655.0000
16:13:50.796968 [0] Epoch 00182 | Loss 1192660.3750
16:13:50.834625 [0] Epoch 00183 | Loss 1198730.1250
16:13:50.874636 [0] Epoch 00184 | Loss 1099996.0000
16:13:50.912027 [0] Epoch 00185 | Loss 985577.4375
16:13:50.955386 [0] Epoch 00186 | Loss 917926.1250
16:13:50.995927 [0] Epoch 00187 | Loss 894525.7500
16:13:51.033887 [0] Epoch 00188 | Loss 910017.7500
16:13:51.272900 [0] Epoch 00189 | Loss 942130.6250
16:13:51.311753 [0] Epoch 00190 | Loss 998419.6250
16:13:51.315230 [0] Epoch: 190, Train: 0.1037, Val: 0.1575, Test: 0.2275
16:13:51.351645 [0] Epoch 00191 | Loss 1030946.1875
16:13:51.394658 [0] Epoch 00192 | Loss 1112988.2500
16:13:51.430873 [0] Epoch 00193 | Loss 1259819.5000
16:13:51.467946 [0] Epoch 00194 | Loss 1363385.7500
16:13:51.505265 [0] Epoch 00195 | Loss 1391774.7500
16:13:51.549693 [0] Epoch 00196 | Loss 1557766.0000
16:13:51.588497 [0] Epoch 00197 | Loss 1556538.2500
16:13:51.625222 [0] Epoch 00198 | Loss 1501759.0000
16:13:51.664185 [0] Epoch 00199 | Loss 1432305.8750
16:13:51.667470 [0] Epoch: 199, Train: 0.0312, Val: 0.0429, Test: 0.0492
16:13:51.669117 [0] 
timer summary:
  1.61s   0.01s  2000 mm
  3.28s   0.11s  4000 broadcast
  6.29s   0.11s  4000 spmm
  0.15s   0.02s  1000 all_reduce
 12.88s   0.00s   200 epoch
 14.76s   0.00s     1 total
16:14:53.877631 [0] proc begin: <DistEnv 0/2 nccl>
16:14:55.700866 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
16:14:55.703818 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:14:57.725368 [0] Epoch 00000 | Loss 3.6854
16:14:57.729891 [0] Epoch: 000, Train: 0.0151, Val: 0.0139, Test: 0.0146
16:14:57.748445 [0] Epoch 00001 | Loss 3.6109
16:14:57.765239 [0] Epoch 00002 | Loss 3.5397
16:14:57.784577 [0] Epoch 00003 | Loss 3.4854
16:14:57.801850 [0] Epoch 00004 | Loss 3.4674
16:14:57.819675 [0] Epoch 00005 | Loss 3.4969
16:14:57.842748 [0] Epoch 00006 | Loss 3.5782
16:14:57.860838 [0] Epoch 00007 | Loss 3.7134
16:14:57.878056 [0] Epoch 00008 | Loss 3.9016
16:14:57.897958 [0] Epoch 00009 | Loss 4.1381
16:14:57.916342 [0] Epoch 00010 | Loss 4.4164
16:14:57.919118 [0] Epoch: 010, Train: 0.1812, Val: 0.0802, Test: 0.0619
16:14:57.937168 [0] Epoch 00011 | Loss 4.7280
16:14:57.954901 [0] Epoch 00012 | Loss 5.0625
16:14:57.974314 [0] Epoch 00013 | Loss 5.4080
16:14:57.992837 [0] Epoch 00014 | Loss 5.7537
16:14:58.014100 [0] Epoch 00015 | Loss 6.0979
16:14:58.033126 [0] Epoch 00016 | Loss 6.4555
16:14:58.050781 [0] Epoch 00017 | Loss 6.8460
16:14:58.069592 [0] Epoch 00018 | Loss 7.2595
16:14:58.088590 [0] Epoch 00019 | Loss 7.6605
16:14:58.106506 [0] Epoch 00020 | Loss 8.0287
16:14:58.109276 [0] Epoch: 020, Train: 0.2320, Val: 0.2777, Test: 0.2488
16:14:58.131730 [0] Epoch 00021 | Loss 8.3742
16:14:58.154107 [0] Epoch 00022 | Loss 8.7160
16:14:58.171231 [0] Epoch 00023 | Loss 9.0344
16:14:58.191884 [0] Epoch 00024 | Loss 9.3062
16:14:58.210052 [0] Epoch 00025 | Loss 9.5503
16:14:58.229661 [0] Epoch 00026 | Loss 9.7905
16:14:58.249155 [0] Epoch 00027 | Loss 10.0173
16:14:58.476903 [0] Epoch 00028 | Loss 10.2166
16:14:58.500388 [0] Epoch 00029 | Loss 10.3997
16:14:58.515792 [0] Epoch 00030 | Loss 10.5718
16:14:58.518307 [0] Epoch: 030, Train: 0.2746, Val: 0.2990, Test: 0.2679
16:14:58.535330 [0] Epoch 00031 | Loss 10.7209
16:14:58.552778 [0] Epoch 00032 | Loss 10.8486
16:14:58.572008 [0] Epoch 00033 | Loss 10.9671
16:14:58.592028 [0] Epoch 00034 | Loss 11.0758
16:14:58.611611 [0] Epoch 00035 | Loss 11.1673
16:14:58.629483 [0] Epoch 00036 | Loss 11.2481
16:14:58.647702 [0] Epoch 00037 | Loss 11.3271
16:14:58.665466 [0] Epoch 00038 | Loss 11.4018
16:14:58.685607 [0] Epoch 00039 | Loss 11.4714
16:14:58.705934 [0] Epoch 00040 | Loss 11.5403
16:14:58.708645 [0] Epoch: 040, Train: 0.2655, Val: 0.2951, Test: 0.2645
16:14:58.726450 [0] Epoch 00041 | Loss 11.6034
16:14:58.742823 [0] Epoch 00042 | Loss 11.6561
16:14:58.764347 [0] Epoch 00043 | Loss 11.7032
16:14:58.785170 [0] Epoch 00044 | Loss 11.7465
16:14:58.802369 [0] Epoch 00045 | Loss 11.7827
16:14:58.820908 [0] Epoch 00046 | Loss 11.8103
16:14:58.839999 [0] Epoch 00047 | Loss 11.8276
16:14:58.857803 [0] Epoch 00048 | Loss 11.8320
16:14:58.876673 [0] Epoch 00049 | Loss 11.8246
16:14:58.895196 [0] Epoch 00050 | Loss 11.8084
16:14:58.898086 [0] Epoch: 050, Train: 0.2738, Val: 0.3007, Test: 0.2713
16:14:58.917523 [0] Epoch 00051 | Loss 11.7866
16:14:58.933781 [0] Epoch 00052 | Loss 11.7612
16:14:58.950717 [0] Epoch 00053 | Loss 11.7344
16:14:58.970141 [0] Epoch 00054 | Loss 11.7090
16:14:58.989849 [0] Epoch 00055 | Loss 11.6858
16:14:59.008892 [0] Epoch 00056 | Loss 11.6633
16:14:59.220691 [0] Epoch 00057 | Loss 11.6413
16:14:59.242026 [0] Epoch 00058 | Loss 11.6211
16:14:59.260238 [0] Epoch 00059 | Loss 11.6056
16:14:59.278637 [0] Epoch 00060 | Loss 11.5974
16:14:59.281657 [0] Epoch: 060, Train: 0.2893, Val: 0.3136, Test: 0.2867
16:14:59.300269 [0] Epoch 00061 | Loss 11.5965
16:14:59.316858 [0] Epoch 00062 | Loss 11.6006
16:14:59.338790 [0] Epoch 00063 | Loss 11.6062
16:14:59.354584 [0] Epoch 00064 | Loss 11.6105
16:14:59.370562 [0] Epoch 00065 | Loss 11.6135
16:14:59.386610 [0] Epoch 00066 | Loss 11.6166
16:14:59.403128 [0] Epoch 00067 | Loss 11.6207
16:14:59.420332 [0] Epoch 00068 | Loss 11.6258
16:14:59.438030 [0] Epoch 00069 | Loss 11.6311
16:14:59.455684 [0] Epoch 00070 | Loss 11.6363
16:14:59.457997 [0] Epoch: 070, Train: 0.3177, Val: 0.3313, Test: 0.3055
16:14:59.477048 [0] Epoch 00071 | Loss 11.6417
16:14:59.495008 [0] Epoch 00072 | Loss 11.6473
16:14:59.513862 [0] Epoch 00073 | Loss 11.6527
16:14:59.535363 [0] Epoch 00074 | Loss 11.6573
16:14:59.552791 [0] Epoch 00075 | Loss 11.6620
16:14:59.569498 [0] Epoch 00076 | Loss 11.6686
16:14:59.590271 [0] Epoch 00077 | Loss 11.6790
16:14:59.606996 [0] Epoch 00078 | Loss 11.6938
16:14:59.623880 [0] Epoch 00079 | Loss 11.7125
16:14:59.639195 [0] Epoch 00080 | Loss 11.7333
16:14:59.641519 [0] Epoch: 080, Train: 0.3452, Val: 0.3561, Test: 0.3312
16:14:59.656845 [0] Epoch 00081 | Loss 11.7541
16:14:59.671655 [0] Epoch 00082 | Loss 11.7739
16:14:59.689084 [0] Epoch 00083 | Loss 11.7928
16:14:59.712502 [0] Epoch 00084 | Loss 11.8120
16:14:59.729913 [0] Epoch 00085 | Loss 11.8327
16:14:59.748602 [0] Epoch 00086 | Loss 11.8563
16:14:59.968833 [0] Epoch 00087 | Loss 11.8828
16:14:59.987037 [0] Epoch 00088 | Loss 11.9119
16:15:00.002640 [0] Epoch 00089 | Loss 11.9429
16:15:00.021669 [0] Epoch 00090 | Loss 11.9756
16:15:00.025146 [0] Epoch: 090, Train: 0.3641, Val: 0.3767, Test: 0.3528
16:15:00.044056 [0] Epoch 00091 | Loss 12.0104
16:15:00.060719 [0] Epoch 00092 | Loss 12.0476
16:15:00.076145 [0] Epoch 00093 | Loss 12.0875
16:15:00.091656 [0] Epoch 00094 | Loss 12.1298
16:15:00.109387 [0] Epoch 00095 | Loss 12.1737
16:15:00.128457 [0] Epoch 00096 | Loss 12.2189
16:15:00.146097 [0] Epoch 00097 | Loss 12.2649
16:15:00.164438 [0] Epoch 00098 | Loss 12.3118
16:15:00.180719 [0] Epoch 00099 | Loss 12.3596
16:15:00.202834 [0] Epoch 00100 | Loss 12.4086
16:15:00.205608 [0] Epoch: 100, Train: 0.3815, Val: 0.3941, Test: 0.3746
16:15:00.225252 [0] Epoch 00101 | Loss 12.4589
16:15:00.245495 [0] Epoch 00102 | Loss 12.5105
16:15:00.263670 [0] Epoch 00103 | Loss 12.5633
16:15:00.281469 [0] Epoch 00104 | Loss 12.6165
16:15:00.300827 [0] Epoch 00105 | Loss 12.6698
16:15:00.320511 [0] Epoch 00106 | Loss 12.7229
16:15:00.338555 [0] Epoch 00107 | Loss 12.7762
16:15:00.356109 [0] Epoch 00108 | Loss 12.8306
16:15:00.373099 [0] Epoch 00109 | Loss 12.8867
16:15:00.390420 [0] Epoch 00110 | Loss 12.9438
16:15:00.392957 [0] Epoch: 110, Train: 0.3970, Val: 0.4105, Test: 0.3952
16:15:00.411899 [0] Epoch 00111 | Loss 13.0006
16:15:00.428135 [0] Epoch 00112 | Loss 13.0570
16:15:00.446808 [0] Epoch 00113 | Loss 13.1132
16:15:00.465448 [0] Epoch 00114 | Loss 13.1697
16:15:00.483099 [0] Epoch 00115 | Loss 13.2269
16:15:00.501592 [0] Epoch 00116 | Loss 13.2850
16:15:00.520896 [0] Epoch 00117 | Loss 13.3439
16:15:00.741170 [0] Epoch 00118 | Loss 13.4034
16:15:00.758253 [0] Epoch 00119 | Loss 13.4635
16:15:00.775494 [0] Epoch 00120 | Loss 13.5239
16:15:00.777812 [0] Epoch: 120, Train: 0.4090, Val: 0.4261, Test: 0.4139
16:15:00.796159 [0] Epoch 00121 | Loss 13.5847
16:15:00.814531 [0] Epoch 00122 | Loss 13.6460
16:15:00.832456 [0] Epoch 00123 | Loss 13.7080
16:15:00.853173 [0] Epoch 00124 | Loss 13.7708
16:15:00.870498 [0] Epoch 00125 | Loss 13.8342
16:15:00.887567 [0] Epoch 00126 | Loss 13.8982
16:15:00.902903 [0] Epoch 00127 | Loss 13.9629
16:15:00.919240 [0] Epoch 00128 | Loss 14.0283
16:15:00.939786 [0] Epoch 00129 | Loss 14.0947
16:15:00.956193 [0] Epoch 00130 | Loss 14.1621
16:15:00.958791 [0] Epoch: 130, Train: 0.4208, Val: 0.4409, Test: 0.4331
16:15:00.978279 [0] Epoch 00131 | Loss 14.2302
16:15:00.994691 [0] Epoch 00132 | Loss 14.2988
16:15:01.010842 [0] Epoch 00133 | Loss 14.3676
16:15:01.026502 [0] Epoch 00134 | Loss 14.4367
16:15:01.040960 [0] Epoch 00135 | Loss 14.5065
16:15:01.058077 [0] Epoch 00136 | Loss 14.5769
16:15:01.076963 [0] Epoch 00137 | Loss 14.6479
16:15:01.092459 [0] Epoch 00138 | Loss 14.7192
16:15:01.108211 [0] Epoch 00139 | Loss 14.7907
16:15:01.125521 [0] Epoch 00140 | Loss 14.8623
16:15:01.127947 [0] Epoch: 140, Train: 0.4304, Val: 0.4558, Test: 0.4503
16:15:01.144623 [0] Epoch 00141 | Loss 14.9343
16:15:01.160833 [0] Epoch 00142 | Loss 15.0068
16:15:01.178728 [0] Epoch 00143 | Loss 15.0799
16:15:01.198683 [0] Epoch 00144 | Loss 15.1536
16:15:01.217886 [0] Epoch 00145 | Loss 15.2275
16:15:01.238925 [0] Epoch 00146 | Loss 15.3018
16:15:01.257731 [0] Epoch 00147 | Loss 15.3764
16:15:01.275481 [0] Epoch 00148 | Loss 15.4516
16:15:01.490355 [0] Epoch 00149 | Loss 15.5272
16:15:01.511785 [0] Epoch 00150 | Loss 15.6033
16:15:01.514725 [0] Epoch: 150, Train: 0.4392, Val: 0.4690, Test: 0.4672
16:15:01.532697 [0] Epoch 00151 | Loss 15.6798
16:15:01.548762 [0] Epoch 00152 | Loss 15.7565
16:15:01.564238 [0] Epoch 00153 | Loss 15.8335
16:15:01.580273 [0] Epoch 00154 | Loss 15.9106
16:15:01.597527 [0] Epoch 00155 | Loss 15.9881
16:15:01.614405 [0] Epoch 00156 | Loss 16.0661
16:15:01.634265 [0] Epoch 00157 | Loss 16.1449
16:15:01.654986 [0] Epoch 00158 | Loss 16.2242
16:15:01.671267 [0] Epoch 00159 | Loss 16.3039
16:15:01.689887 [0] Epoch 00160 | Loss 16.3835
16:15:01.693285 [0] Epoch: 160, Train: 0.4477, Val: 0.4818, Test: 0.4813
16:15:01.710954 [0] Epoch 00161 | Loss 16.4632
16:15:01.726410 [0] Epoch 00162 | Loss 16.5431
16:15:01.747228 [0] Epoch 00163 | Loss 16.6237
16:15:01.766929 [0] Epoch 00164 | Loss 16.7052
16:15:01.785515 [0] Epoch 00165 | Loss 16.7878
16:15:01.805382 [0] Epoch 00166 | Loss 16.8715
16:15:01.822795 [0] Epoch 00167 | Loss 16.9559
16:15:01.839877 [0] Epoch 00168 | Loss 17.0408
16:15:01.864144 [0] Epoch 00169 | Loss 17.1260
16:15:01.883416 [0] Epoch 00170 | Loss 17.2116
16:15:01.886150 [0] Epoch: 170, Train: 0.4546, Val: 0.4911, Test: 0.4940
16:15:01.904509 [0] Epoch 00171 | Loss 17.2976
16:15:01.921730 [0] Epoch 00172 | Loss 17.3840
16:15:01.938784 [0] Epoch 00173 | Loss 17.4709
16:15:01.957052 [0] Epoch 00174 | Loss 17.5583
16:15:01.980523 [0] Epoch 00175 | Loss 17.6457
16:15:02.000406 [0] Epoch 00176 | Loss 17.7333
16:15:02.017659 [0] Epoch 00177 | Loss 17.8215
16:15:02.227078 [0] Epoch 00178 | Loss 17.9106
16:15:02.249159 [0] Epoch 00179 | Loss 18.0003
16:15:02.267418 [0] Epoch 00180 | Loss 18.0901
16:15:02.270546 [0] Epoch: 180, Train: 0.4613, Val: 0.5001, Test: 0.5058
16:15:02.289891 [0] Epoch 00181 | Loss 18.1795
16:15:02.307948 [0] Epoch 00182 | Loss 18.2684
16:15:02.327151 [0] Epoch 00183 | Loss 18.3571
16:15:02.347381 [0] Epoch 00184 | Loss 18.4462
16:15:02.366293 [0] Epoch 00185 | Loss 18.5365
16:15:02.389005 [0] Epoch 00186 | Loss 18.6284
16:15:02.407561 [0] Epoch 00187 | Loss 18.7215
16:15:02.428623 [0] Epoch 00188 | Loss 18.8154
16:15:02.448110 [0] Epoch 00189 | Loss 18.9093
16:15:02.466806 [0] Epoch 00190 | Loss 19.0025
16:15:02.469467 [0] Epoch: 190, Train: 0.4681, Val: 0.5097, Test: 0.5155
16:15:02.488067 [0] Epoch 00191 | Loss 19.0948
16:15:02.506166 [0] Epoch 00192 | Loss 19.1866
16:15:02.524100 [0] Epoch 00193 | Loss 19.2784
16:15:02.540845 [0] Epoch 00194 | Loss 19.3711
16:15:02.560623 [0] Epoch 00195 | Loss 19.4646
16:15:02.577240 [0] Epoch 00196 | Loss 19.5582
16:15:02.597549 [0] Epoch 00197 | Loss 19.6514
16:15:02.616276 [0] Epoch 00198 | Loss 19.7448
16:15:02.634078 [0] Epoch 00199 | Loss 19.8391
16:15:02.636798 [0] Epoch: 199, Train: 0.4739, Val: 0.5160, Test: 0.5237
16:15:02.638126 [0] 
timer summary:
  1.43s   0.01s   800 mm
  1.34s   0.05s  1600 broadcast
  2.93s   0.03s  1600 spmm
  0.30s   0.01s   400 all_reduce
  6.88s   0.01s   200 epoch
  8.75s   0.01s     1 total
16:15:52.548577 [0] proc begin: <DistEnv 0/2 nccl>
16:15:54.515123 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:15:54.517753 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:15:56.354391 [0] Epoch 00000 | Loss 3.6854
16:15:56.357770 [0] Epoch: 000, Train: 0.0151, Val: 0.0139, Test: 0.0146
16:15:56.373144 [0] Epoch 00001 | Loss 3.6109
16:15:56.584256 [0] Epoch 00002 | Loss 3.5397
16:15:56.599761 [0] Epoch 00003 | Loss 3.4854
16:15:56.611518 [0] Epoch 00004 | Loss 3.4674
16:15:56.627042 [0] Epoch 00005 | Loss 3.4969
16:15:56.638939 [0] Epoch 00006 | Loss 3.5782
16:15:56.650654 [0] Epoch 00007 | Loss 3.7134
16:15:56.662386 [0] Epoch 00008 | Loss 3.9016
16:15:56.673603 [0] Epoch 00009 | Loss 4.1381
16:15:56.685215 [0] Epoch 00010 | Loss 4.4164
16:15:56.687584 [0] Epoch: 010, Train: 0.1812, Val: 0.0802, Test: 0.0619
16:15:56.701720 [0] Epoch 00011 | Loss 4.7280
16:15:56.713474 [0] Epoch 00012 | Loss 5.0625
16:15:56.724818 [0] Epoch 00013 | Loss 5.4080
16:15:56.738893 [0] Epoch 00014 | Loss 5.7537
16:15:56.752242 [0] Epoch 00015 | Loss 6.0979
16:15:56.763189 [0] Epoch 00016 | Loss 6.4555
16:15:56.774723 [0] Epoch 00017 | Loss 6.8460
16:15:56.786166 [0] Epoch 00018 | Loss 7.2595
16:15:56.797402 [0] Epoch 00019 | Loss 7.6605
16:15:56.808656 [0] Epoch 00020 | Loss 8.0287
16:15:56.811007 [0] Epoch: 020, Train: 0.2320, Val: 0.2777, Test: 0.2488
16:15:56.826720 [0] Epoch 00021 | Loss 8.3742
16:15:56.838308 [0] Epoch 00022 | Loss 8.7160
16:15:56.849904 [0] Epoch 00023 | Loss 9.0344
16:15:56.861190 [0] Epoch 00024 | Loss 9.3062
16:15:56.872155 [0] Epoch 00025 | Loss 9.5503
16:15:56.883203 [0] Epoch 00026 | Loss 9.7905
16:15:56.894858 [0] Epoch 00027 | Loss 10.0173
16:15:56.906441 [0] Epoch 00028 | Loss 10.2166
16:15:56.917342 [0] Epoch 00029 | Loss 10.3997
16:15:56.928102 [0] Epoch 00030 | Loss 10.5718
16:15:56.930577 [0] Epoch: 030, Train: 0.2746, Val: 0.2990, Test: 0.2679
16:15:56.941864 [0] Epoch 00031 | Loss 10.7209
16:15:56.953217 [0] Epoch 00032 | Loss 10.8486
16:15:56.964125 [0] Epoch 00033 | Loss 10.9671
16:15:56.975468 [0] Epoch 00034 | Loss 11.0758
16:15:56.988207 [0] Epoch 00035 | Loss 11.1673
16:15:56.999984 [0] Epoch 00036 | Loss 11.2481
16:15:57.011498 [0] Epoch 00037 | Loss 11.3271
16:15:57.022328 [0] Epoch 00038 | Loss 11.4018
16:15:57.033309 [0] Epoch 00039 | Loss 11.4714
16:15:57.044249 [0] Epoch 00040 | Loss 11.5403
16:15:57.046756 [0] Epoch: 040, Train: 0.2655, Val: 0.2951, Test: 0.2645
16:15:57.058636 [0] Epoch 00041 | Loss 11.6034
16:15:57.069550 [0] Epoch 00042 | Loss 11.6561
16:15:57.080776 [0] Epoch 00043 | Loss 11.7032
16:15:57.092456 [0] Epoch 00044 | Loss 11.7465
16:15:57.103015 [0] Epoch 00045 | Loss 11.7827
16:15:57.117472 [0] Epoch 00046 | Loss 11.8103
16:15:57.324888 [0] Epoch 00047 | Loss 11.8276
16:15:57.339552 [0] Epoch 00048 | Loss 11.8320
16:15:57.350312 [0] Epoch 00049 | Loss 11.8246
16:15:57.361480 [0] Epoch 00050 | Loss 11.8084
16:15:57.363831 [0] Epoch: 050, Train: 0.2738, Val: 0.3007, Test: 0.2713
16:15:57.374823 [0] Epoch 00051 | Loss 11.7866
16:15:57.385706 [0] Epoch 00052 | Loss 11.7612
16:15:57.397096 [0] Epoch 00053 | Loss 11.7344
16:15:57.408111 [0] Epoch 00054 | Loss 11.7090
16:15:57.418901 [0] Epoch 00055 | Loss 11.6858
16:15:57.430568 [0] Epoch 00056 | Loss 11.6633
16:15:57.442404 [0] Epoch 00057 | Loss 11.6413
16:15:57.453231 [0] Epoch 00058 | Loss 11.6211
16:15:57.464517 [0] Epoch 00059 | Loss 11.6056
16:15:57.475223 [0] Epoch 00060 | Loss 11.5974
16:15:57.477591 [0] Epoch: 060, Train: 0.2893, Val: 0.3136, Test: 0.2867
16:15:57.489185 [0] Epoch 00061 | Loss 11.5965
16:15:57.499931 [0] Epoch 00062 | Loss 11.6006
16:15:57.517177 [0] Epoch 00063 | Loss 11.6062
16:15:57.529774 [0] Epoch 00064 | Loss 11.6105
16:15:57.540540 [0] Epoch 00065 | Loss 11.6135
16:15:57.553114 [0] Epoch 00066 | Loss 11.6166
16:15:57.563886 [0] Epoch 00067 | Loss 11.6207
16:15:57.574638 [0] Epoch 00068 | Loss 11.6258
16:15:57.585879 [0] Epoch 00069 | Loss 11.6311
16:15:57.596766 [0] Epoch 00070 | Loss 11.6363
16:15:57.599116 [0] Epoch: 070, Train: 0.3177, Val: 0.3313, Test: 0.3055
16:15:57.610668 [0] Epoch 00071 | Loss 11.6417
16:15:57.624115 [0] Epoch 00072 | Loss 11.6473
16:15:57.635084 [0] Epoch 00073 | Loss 11.6527
16:15:57.646637 [0] Epoch 00074 | Loss 11.6573
16:15:57.658065 [0] Epoch 00075 | Loss 11.6620
16:15:57.668904 [0] Epoch 00076 | Loss 11.6686
16:15:57.679676 [0] Epoch 00077 | Loss 11.6790
16:15:57.690603 [0] Epoch 00078 | Loss 11.6938
16:15:57.701851 [0] Epoch 00079 | Loss 11.7125
16:15:57.712663 [0] Epoch 00080 | Loss 11.7333
16:15:57.715012 [0] Epoch: 080, Train: 0.3452, Val: 0.3561, Test: 0.3312
16:15:57.727718 [0] Epoch 00081 | Loss 11.7541
16:15:57.739504 [0] Epoch 00082 | Loss 11.7739
16:15:57.750697 [0] Epoch 00083 | Loss 11.7928
16:15:57.762124 [0] Epoch 00084 | Loss 11.8120
16:15:57.773253 [0] Epoch 00085 | Loss 11.8327
16:15:57.784351 [0] Epoch 00086 | Loss 11.8563
16:15:57.795526 [0] Epoch 00087 | Loss 11.8828
16:15:57.807151 [0] Epoch 00088 | Loss 11.9119
16:15:57.817946 [0] Epoch 00089 | Loss 11.9429
16:15:57.829361 [0] Epoch 00090 | Loss 11.9756
16:15:57.831700 [0] Epoch: 090, Train: 0.3641, Val: 0.3767, Test: 0.3528
16:15:57.843311 [0] Epoch 00091 | Loss 12.0104
16:15:57.854724 [0] Epoch 00092 | Loss 12.0476
16:15:57.867528 [0] Epoch 00093 | Loss 12.0875
16:15:58.076301 [0] Epoch 00094 | Loss 12.1298
16:15:58.088283 [0] Epoch 00095 | Loss 12.1737
16:15:58.100104 [0] Epoch 00096 | Loss 12.2189
16:15:58.112011 [0] Epoch 00097 | Loss 12.2649
16:15:58.123959 [0] Epoch 00098 | Loss 12.3118
16:15:58.136931 [0] Epoch 00099 | Loss 12.3596
16:15:58.148123 [0] Epoch 00100 | Loss 12.4086
16:15:58.150493 [0] Epoch: 100, Train: 0.3815, Val: 0.3941, Test: 0.3746
16:15:58.167769 [0] Epoch 00101 | Loss 12.4589
16:15:58.181953 [0] Epoch 00102 | Loss 12.5105
16:15:58.194034 [0] Epoch 00103 | Loss 12.5633
16:15:58.209692 [0] Epoch 00104 | Loss 12.6165
16:15:58.220667 [0] Epoch 00105 | Loss 12.6698
16:15:58.233450 [0] Epoch 00106 | Loss 12.7229
16:15:58.245542 [0] Epoch 00107 | Loss 12.7762
16:15:58.257936 [0] Epoch 00108 | Loss 12.8306
16:15:58.270584 [0] Epoch 00109 | Loss 12.8867
16:15:58.283232 [0] Epoch 00110 | Loss 12.9438
16:15:58.285718 [0] Epoch: 110, Train: 0.3970, Val: 0.4105, Test: 0.3952
16:15:58.299397 [0] Epoch 00111 | Loss 13.0006
16:15:58.310784 [0] Epoch 00112 | Loss 13.0570
16:15:58.321811 [0] Epoch 00113 | Loss 13.1132
16:15:58.333451 [0] Epoch 00114 | Loss 13.1697
16:15:58.346569 [0] Epoch 00115 | Loss 13.2269
16:15:58.360978 [0] Epoch 00116 | Loss 13.2850
16:15:58.373515 [0] Epoch 00117 | Loss 13.3439
16:15:58.386973 [0] Epoch 00118 | Loss 13.4034
16:15:58.399168 [0] Epoch 00119 | Loss 13.4635
16:15:58.412621 [0] Epoch 00120 | Loss 13.5239
16:15:58.415664 [0] Epoch: 120, Train: 0.4090, Val: 0.4261, Test: 0.4139
16:15:58.429028 [0] Epoch 00121 | Loss 13.5847
16:15:58.440545 [0] Epoch 00122 | Loss 13.6460
16:15:58.451638 [0] Epoch 00123 | Loss 13.7080
16:15:58.462505 [0] Epoch 00124 | Loss 13.7708
16:15:58.475892 [0] Epoch 00125 | Loss 13.8342
16:15:58.487397 [0] Epoch 00126 | Loss 13.8982
16:15:58.498289 [0] Epoch 00127 | Loss 13.9629
16:15:58.509684 [0] Epoch 00128 | Loss 14.0283
16:15:58.520906 [0] Epoch 00129 | Loss 14.0947
16:15:58.532320 [0] Epoch 00130 | Loss 14.1621
16:15:58.534758 [0] Epoch: 130, Train: 0.4208, Val: 0.4409, Test: 0.4331
16:15:58.545983 [0] Epoch 00131 | Loss 14.2302
16:15:58.557976 [0] Epoch 00132 | Loss 14.2988
16:15:58.572932 [0] Epoch 00133 | Loss 14.3676
16:15:58.585163 [0] Epoch 00134 | Loss 14.4367
16:15:58.596211 [0] Epoch 00135 | Loss 14.5065
16:15:58.609070 [0] Epoch 00136 | Loss 14.5769
16:15:58.817315 [0] Epoch 00137 | Loss 14.6479
16:15:58.834227 [0] Epoch 00138 | Loss 14.7192
16:15:58.847581 [0] Epoch 00139 | Loss 14.7907
16:15:58.859899 [0] Epoch 00140 | Loss 14.8623
16:15:58.862546 [0] Epoch: 140, Train: 0.4304, Val: 0.4558, Test: 0.4503
16:15:58.877515 [0] Epoch 00141 | Loss 14.9343
16:15:58.891302 [0] Epoch 00142 | Loss 15.0068
16:15:58.904870 [0] Epoch 00143 | Loss 15.0799
16:15:58.915962 [0] Epoch 00144 | Loss 15.1536
16:15:58.931129 [0] Epoch 00145 | Loss 15.2275
16:15:58.946956 [0] Epoch 00146 | Loss 15.3018
16:15:58.958953 [0] Epoch 00147 | Loss 15.3764
16:15:58.971073 [0] Epoch 00148 | Loss 15.4516
16:15:58.982025 [0] Epoch 00149 | Loss 15.5272
16:15:58.993690 [0] Epoch 00150 | Loss 15.6033
16:15:58.996014 [0] Epoch: 150, Train: 0.4392, Val: 0.4690, Test: 0.4672
16:15:59.008388 [0] Epoch 00151 | Loss 15.6798
16:15:59.019740 [0] Epoch 00152 | Loss 15.7565
16:15:59.030591 [0] Epoch 00153 | Loss 15.8335
16:15:59.042442 [0] Epoch 00154 | Loss 15.9106
16:15:59.055401 [0] Epoch 00155 | Loss 15.9881
16:15:59.066770 [0] Epoch 00156 | Loss 16.0661
16:15:59.078884 [0] Epoch 00157 | Loss 16.1449
16:15:59.090745 [0] Epoch 00158 | Loss 16.2242
16:15:59.101474 [0] Epoch 00159 | Loss 16.3039
16:15:59.113169 [0] Epoch 00160 | Loss 16.3835
16:15:59.115777 [0] Epoch: 160, Train: 0.4477, Val: 0.4818, Test: 0.4813
16:15:59.128435 [0] Epoch 00161 | Loss 16.4632
16:15:59.140518 [0] Epoch 00162 | Loss 16.5431
16:15:59.152305 [0] Epoch 00163 | Loss 16.6237
16:15:59.163497 [0] Epoch 00164 | Loss 16.7052
16:15:59.178277 [0] Epoch 00165 | Loss 16.7878
16:15:59.197401 [0] Epoch 00166 | Loss 16.8715
16:15:59.211055 [0] Epoch 00167 | Loss 16.9559
16:15:59.223394 [0] Epoch 00168 | Loss 17.0408
16:15:59.234696 [0] Epoch 00169 | Loss 17.1260
16:15:59.245995 [0] Epoch 00170 | Loss 17.2116
16:15:59.248564 [0] Epoch: 170, Train: 0.4546, Val: 0.4911, Test: 0.4940
16:15:59.261074 [0] Epoch 00171 | Loss 17.2976
16:15:59.272667 [0] Epoch 00172 | Loss 17.3840
16:15:59.290845 [0] Epoch 00173 | Loss 17.4709
16:15:59.306093 [0] Epoch 00174 | Loss 17.5583
16:15:59.320401 [0] Epoch 00175 | Loss 17.6457
16:15:59.334900 [0] Epoch 00176 | Loss 17.7333
16:15:59.347691 [0] Epoch 00177 | Loss 17.8215
16:15:59.358725 [0] Epoch 00178 | Loss 17.9106
16:15:59.372024 [0] Epoch 00179 | Loss 18.0003
16:15:59.578143 [0] Epoch 00180 | Loss 18.0901
16:15:59.580701 [0] Epoch: 180, Train: 0.4613, Val: 0.5001, Test: 0.5058
16:15:59.595222 [0] Epoch 00181 | Loss 18.1795
16:15:59.607985 [0] Epoch 00182 | Loss 18.2684
16:15:59.622427 [0] Epoch 00183 | Loss 18.3571
16:15:59.641970 [0] Epoch 00184 | Loss 18.4462
16:15:59.654673 [0] Epoch 00185 | Loss 18.5365
16:15:59.666954 [0] Epoch 00186 | Loss 18.6284
16:15:59.679227 [0] Epoch 00187 | Loss 18.7215
16:15:59.690996 [0] Epoch 00188 | Loss 18.8154
16:15:59.702654 [0] Epoch 00189 | Loss 18.9093
16:15:59.714760 [0] Epoch 00190 | Loss 19.0025
16:15:59.717179 [0] Epoch: 190, Train: 0.4681, Val: 0.5097, Test: 0.5155
16:15:59.730194 [0] Epoch 00191 | Loss 19.0948
16:15:59.745474 [0] Epoch 00192 | Loss 19.1866
16:15:59.758584 [0] Epoch 00193 | Loss 19.2784
16:15:59.771623 [0] Epoch 00194 | Loss 19.3711
16:15:59.782588 [0] Epoch 00195 | Loss 19.4646
16:15:59.794855 [0] Epoch 00196 | Loss 19.5582
16:15:59.807535 [0] Epoch 00197 | Loss 19.6514
16:15:59.819421 [0] Epoch 00198 | Loss 19.7448
16:15:59.832859 [0] Epoch 00199 | Loss 19.8391
16:15:59.835234 [0] Epoch: 199, Train: 0.4739, Val: 0.5160, Test: 0.5237
16:15:59.836325 [0] 
timer summary:
  1.52s   0.01s   800 mm
  0.75s   0.00s   800 broadcast
  2.13s   0.01s   800 spmm
  0.04s   0.00s   400 all_reduce
  5.25s   0.02s   200 epoch
  7.28s   0.00s     1 total
16:16:16.620010 [0] proc begin: <DistEnv 0/2 nccl>
16:16:18.510553 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 169344, |E|: 1335586>
16:16:18.513676 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| Active memory         |   55924 KB |   87835 KB |  102910 KB |   46985 KB |
|       from large pool |   54766 KB |   87339 KB |  101743 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1167 KB |       8 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    9611 KB |   21039 KB |   25017 KB |   15405 KB |
|       from large pool |    8722 KB |   19157 KB |   23126 KB |   14404 KB |
|       from small pool |     889 KB |    1882 KB |    1891 KB |    1001 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      27    |      19    |
|       from large pool |       4    |       5    |       8    |       4    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:16:20.196156 [0] Epoch 00000 | Loss 3.6876
16:16:20.199702 [0] Epoch: 000, Train: 0.0079, Val: 0.0082, Test: 0.0081
16:16:20.222172 [0] Epoch 00001 | Loss 3.6468
16:16:20.452756 [0] Epoch 00002 | Loss 3.6098
16:16:20.476606 [0] Epoch 00003 | Loss 3.7976
16:16:20.498787 [0] Epoch 00004 | Loss 4.6338
16:16:20.523955 [0] Epoch 00005 | Loss 6.6306
16:16:20.544961 [0] Epoch 00006 | Loss 10.6961
16:16:20.568818 [0] Epoch 00007 | Loss 18.2651
16:16:20.589387 [0] Epoch 00008 | Loss 30.8639
16:16:20.612359 [0] Epoch 00009 | Loss 47.3017
16:16:20.635341 [0] Epoch 00010 | Loss 68.6254
16:16:20.638190 [0] Epoch: 010, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:16:20.659281 [0] Epoch 00011 | Loss 103.4955
16:16:20.679161 [0] Epoch 00012 | Loss 151.9263
16:16:20.698587 [0] Epoch 00013 | Loss 203.8317
16:16:20.723083 [0] Epoch 00014 | Loss 281.9518
16:16:20.745675 [0] Epoch 00015 | Loss 381.7664
16:16:20.771768 [0] Epoch 00016 | Loss 464.9885
16:16:20.795476 [0] Epoch 00017 | Loss 569.4691
16:16:20.823228 [0] Epoch 00018 | Loss 708.2252
16:16:20.849946 [0] Epoch 00019 | Loss 822.0643
16:16:20.875297 [0] Epoch 00020 | Loss 928.1760
16:16:20.879013 [0] Epoch: 020, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:16:20.902545 [0] Epoch 00021 | Loss 1098.0823
16:16:20.926404 [0] Epoch 00022 | Loss 1193.9346
16:16:20.946923 [0] Epoch 00023 | Loss 1401.9884
16:16:20.977512 [0] Epoch 00024 | Loss 1479.5679
16:16:21.005519 [0] Epoch 00025 | Loss 1624.1648
16:16:21.228892 [0] Epoch 00026 | Loss 1677.3427
16:16:21.254132 [0] Epoch 00027 | Loss 1605.1571
16:16:21.279584 [0] Epoch 00028 | Loss 1563.5687
16:16:21.302148 [0] Epoch 00029 | Loss 1588.6289
16:16:21.323994 [0] Epoch 00030 | Loss 1410.2273
16:16:21.326458 [0] Epoch: 030, Train: 0.1791, Val: 0.0763, Test: 0.0586
16:16:21.349016 [0] Epoch 00031 | Loss 1533.7720
16:16:21.369764 [0] Epoch 00032 | Loss 1651.1616
16:16:21.394384 [0] Epoch 00033 | Loss 1678.7230
16:16:21.415403 [0] Epoch 00034 | Loss 1572.8569
16:16:21.435043 [0] Epoch 00035 | Loss 1679.0994
16:16:21.457156 [0] Epoch 00036 | Loss 1724.6996
16:16:21.479977 [0] Epoch 00037 | Loss 1719.7246
16:16:21.501362 [0] Epoch 00038 | Loss 1780.3594
16:16:21.524108 [0] Epoch 00039 | Loss 1697.5393
16:16:21.547990 [0] Epoch 00040 | Loss 1807.1467
16:16:21.550385 [0] Epoch: 040, Train: 0.1099, Val: 0.2297, Test: 0.2156
16:16:21.572354 [0] Epoch 00041 | Loss 1784.9395
16:16:21.598247 [0] Epoch 00042 | Loss 1852.8131
16:16:21.620812 [0] Epoch 00043 | Loss 1791.0452
16:16:21.648339 [0] Epoch 00044 | Loss 1785.8062
16:16:21.671391 [0] Epoch 00045 | Loss 1839.5483
16:16:21.691369 [0] Epoch 00046 | Loss 1856.3223
16:16:21.714001 [0] Epoch 00047 | Loss 1815.9293
16:16:21.735752 [0] Epoch 00048 | Loss 1715.0898
16:16:21.760725 [0] Epoch 00049 | Loss 1860.0487
16:16:21.983106 [0] Epoch 00050 | Loss 2007.3367
16:16:21.986683 [0] Epoch: 050, Train: 0.1781, Val: 0.0762, Test: 0.0586
16:16:22.009465 [0] Epoch 00051 | Loss 2289.2822
16:16:22.030724 [0] Epoch 00052 | Loss 2704.1467
16:16:22.054452 [0] Epoch 00053 | Loss 3042.1204
16:16:22.075380 [0] Epoch 00054 | Loss 3060.8740
16:16:22.097745 [0] Epoch 00055 | Loss 2903.6506
16:16:22.119401 [0] Epoch 00056 | Loss 3276.4077
16:16:22.143312 [0] Epoch 00057 | Loss 3492.6260
16:16:22.166144 [0] Epoch 00058 | Loss 3933.7170
16:16:22.193701 [0] Epoch 00059 | Loss 4474.5444
16:16:22.217609 [0] Epoch 00060 | Loss 4563.2764
16:16:22.220222 [0] Epoch: 060, Train: 0.1125, Val: 0.2301, Test: 0.2160
16:16:22.242553 [0] Epoch 00061 | Loss 4659.4912
16:16:22.266502 [0] Epoch 00062 | Loss 4627.5640
16:16:22.289339 [0] Epoch 00063 | Loss 5189.8384
16:16:22.315395 [0] Epoch 00064 | Loss 6025.6582
16:16:22.336466 [0] Epoch 00065 | Loss 6452.4873
16:16:22.359105 [0] Epoch 00066 | Loss 6723.1934
16:16:22.379629 [0] Epoch 00067 | Loss 6879.4653
16:16:22.402078 [0] Epoch 00068 | Loss 8241.5039
16:16:22.431188 [0] Epoch 00069 | Loss 8013.5322
16:16:22.452711 [0] Epoch 00070 | Loss 9030.8223
16:16:22.455767 [0] Epoch: 070, Train: 0.1148, Val: 0.2309, Test: 0.2163
16:16:22.476586 [0] Epoch 00071 | Loss 9442.0449
16:16:22.500092 [0] Epoch 00072 | Loss 9157.1455
16:16:22.722633 [0] Epoch 00073 | Loss 10486.7754
16:16:22.745281 [0] Epoch 00074 | Loss 10521.3184
16:16:22.768566 [0] Epoch 00075 | Loss 12547.1602
16:16:22.794926 [0] Epoch 00076 | Loss 14437.0225
16:16:22.821841 [0] Epoch 00077 | Loss 14983.9775
16:16:22.847507 [0] Epoch 00078 | Loss 14596.6025
16:16:22.871253 [0] Epoch 00079 | Loss 13854.4512
16:16:22.892976 [0] Epoch 00080 | Loss 13670.4932
16:16:22.895712 [0] Epoch: 080, Train: 0.1244, Val: 0.2320, Test: 0.2174
16:16:22.914680 [0] Epoch 00081 | Loss 16050.0078
16:16:22.936794 [0] Epoch 00082 | Loss 19409.9375
16:16:22.956933 [0] Epoch 00083 | Loss 18445.5957
16:16:22.976963 [0] Epoch 00084 | Loss 22186.4141
16:16:22.999635 [0] Epoch 00085 | Loss 23477.7891
16:16:23.022514 [0] Epoch 00086 | Loss 21927.5781
16:16:23.044060 [0] Epoch 00087 | Loss 19641.8457
16:16:23.065298 [0] Epoch 00088 | Loss 22166.2402
16:16:23.087233 [0] Epoch 00089 | Loss 27933.9316
16:16:23.112526 [0] Epoch 00090 | Loss 26780.4883
16:16:23.115097 [0] Epoch: 090, Train: 0.0879, Val: 0.1518, Test: 0.2219
16:16:23.134745 [0] Epoch 00091 | Loss 31981.6152
16:16:23.157697 [0] Epoch 00092 | Loss 34208.9141
16:16:23.182616 [0] Epoch 00093 | Loss 32034.1914
16:16:23.207354 [0] Epoch 00094 | Loss 28527.6641
16:16:23.233543 [0] Epoch 00095 | Loss 29967.5156
16:16:23.255194 [0] Epoch 00096 | Loss 31967.3633
16:16:23.278030 [0] Epoch 00097 | Loss 38504.0742
16:16:23.495853 [0] Epoch 00098 | Loss 41150.9180
16:16:23.519409 [0] Epoch 00099 | Loss 39171.1172
16:16:23.541818 [0] Epoch 00100 | Loss 38187.4219
16:16:23.544449 [0] Epoch: 100, Train: 0.0535, Val: 0.0332, Test: 0.0273
16:16:23.565075 [0] Epoch 00101 | Loss 40511.8555
16:16:23.588040 [0] Epoch 00102 | Loss 46358.0312
16:16:23.608940 [0] Epoch 00103 | Loss 55803.1367
16:16:23.630395 [0] Epoch 00104 | Loss 57584.1523
16:16:23.653722 [0] Epoch 00105 | Loss 52743.6719
16:16:23.675831 [0] Epoch 00106 | Loss 45301.6055
16:16:23.702290 [0] Epoch 00107 | Loss 49877.6680
16:16:23.726783 [0] Epoch 00108 | Loss 53084.8555
16:16:23.755042 [0] Epoch 00109 | Loss 50416.2539
16:16:23.779366 [0] Epoch 00110 | Loss 57360.3164
16:16:23.782607 [0] Epoch: 110, Train: 0.1788, Val: 0.0786, Test: 0.0588
16:16:23.804816 [0] Epoch 00111 | Loss 61876.6719
16:16:23.826853 [0] Epoch 00112 | Loss 70646.0781
16:16:23.845558 [0] Epoch 00113 | Loss 71482.6172
16:16:23.865493 [0] Epoch 00114 | Loss 66183.6953
16:16:23.886995 [0] Epoch 00115 | Loss 58928.8789
16:16:23.906418 [0] Epoch 00116 | Loss 59606.5586
16:16:23.926038 [0] Epoch 00117 | Loss 66737.9375
16:16:23.945333 [0] Epoch 00118 | Loss 67975.8047
16:16:23.965840 [0] Epoch 00119 | Loss 78995.2656
16:16:23.985793 [0] Epoch 00120 | Loss 86836.2266
16:16:23.988554 [0] Epoch: 120, Train: 0.0891, Val: 0.1509, Test: 0.2206
16:16:24.008205 [0] Epoch 00121 | Loss 95882.0938
16:16:24.037917 [0] Epoch 00122 | Loss 101133.1328
16:16:24.245281 [0] Epoch 00123 | Loss 97519.8594
16:16:24.269404 [0] Epoch 00124 | Loss 87163.2031
16:16:24.290999 [0] Epoch 00125 | Loss 84639.7422
16:16:24.312163 [0] Epoch 00126 | Loss 86973.1016
16:16:24.333353 [0] Epoch 00127 | Loss 85443.4922
16:16:24.354892 [0] Epoch 00128 | Loss 95435.2266
16:16:24.382852 [0] Epoch 00129 | Loss 112189.5703
16:16:24.407871 [0] Epoch 00130 | Loss 117037.0703
16:16:24.410378 [0] Epoch: 130, Train: 0.1289, Val: 0.2353, Test: 0.2194
16:16:24.429581 [0] Epoch 00131 | Loss 123413.7969
16:16:24.451132 [0] Epoch 00132 | Loss 124781.7188
16:16:24.469217 [0] Epoch 00133 | Loss 125624.4062
16:16:24.488826 [0] Epoch 00134 | Loss 141469.2500
16:16:24.509848 [0] Epoch 00135 | Loss 146522.0156
16:16:24.529967 [0] Epoch 00136 | Loss 158674.3906
16:16:24.550248 [0] Epoch 00137 | Loss 145914.0156
16:16:24.571955 [0] Epoch 00138 | Loss 155680.0625
16:16:24.593926 [0] Epoch 00139 | Loss 161868.3281
16:16:24.621141 [0] Epoch 00140 | Loss 169549.5938
16:16:24.624711 [0] Epoch: 140, Train: 0.1220, Val: 0.2338, Test: 0.2188
16:16:24.651459 [0] Epoch 00141 | Loss 197612.3125
16:16:24.674842 [0] Epoch 00142 | Loss 192372.0469
16:16:24.695262 [0] Epoch 00143 | Loss 218208.4531
16:16:24.718260 [0] Epoch 00144 | Loss 229883.5312
16:16:24.745052 [0] Epoch 00145 | Loss 260270.9062
16:16:24.766094 [0] Epoch 00146 | Loss 253732.4531
16:16:24.986104 [0] Epoch 00147 | Loss 233283.8438
16:16:25.013823 [0] Epoch 00148 | Loss 236600.9531
16:16:25.040489 [0] Epoch 00149 | Loss 246731.0156
16:16:25.065663 [0] Epoch 00150 | Loss 269271.9688
16:16:25.069150 [0] Epoch: 150, Train: 0.1696, Val: 0.0772, Test: 0.0582
16:16:25.092042 [0] Epoch 00151 | Loss 279229.5938
16:16:25.115372 [0] Epoch 00152 | Loss 295485.1875
16:16:25.135618 [0] Epoch 00153 | Loss 288625.5938
16:16:25.157333 [0] Epoch 00154 | Loss 322694.3438
16:16:25.181970 [0] Epoch 00155 | Loss 346411.5625
16:16:25.208074 [0] Epoch 00156 | Loss 327276.0312
16:16:25.231290 [0] Epoch 00157 | Loss 276125.0312
16:16:25.250744 [0] Epoch 00158 | Loss 326119.3750
16:16:25.274515 [0] Epoch 00159 | Loss 365284.8750
16:16:25.298043 [0] Epoch 00160 | Loss 383523.5625
16:16:25.300658 [0] Epoch: 160, Train: 0.1263, Val: 0.2379, Test: 0.2234
16:16:25.327955 [0] Epoch 00161 | Loss 381690.8438
16:16:25.350846 [0] Epoch 00162 | Loss 373270.5625
16:16:25.370828 [0] Epoch 00163 | Loss 431545.2812
16:16:25.390677 [0] Epoch 00164 | Loss 491690.9375
16:16:25.411267 [0] Epoch 00165 | Loss 482689.4688
16:16:25.433306 [0] Epoch 00166 | Loss 489937.5625
16:16:25.457272 [0] Epoch 00167 | Loss 496889.8438
16:16:25.478843 [0] Epoch 00168 | Loss 519162.3125
16:16:25.505946 [0] Epoch 00169 | Loss 476686.1250
16:16:25.529579 [0] Epoch 00170 | Loss 490950.8438
16:16:25.532939 [0] Epoch: 170, Train: 0.1244, Val: 0.2352, Test: 0.2210
16:16:25.741164 [0] Epoch 00171 | Loss 523354.9062
16:16:25.765510 [0] Epoch 00172 | Loss 557711.2500
16:16:25.786811 [0] Epoch 00173 | Loss 605970.1250
16:16:25.809700 [0] Epoch 00174 | Loss 634469.5625
16:16:25.830112 [0] Epoch 00175 | Loss 640350.3125
16:16:25.855890 [0] Epoch 00176 | Loss 676484.0000
16:16:25.878364 [0] Epoch 00177 | Loss 671000.7500
16:16:25.898813 [0] Epoch 00178 | Loss 685985.1250
16:16:25.918494 [0] Epoch 00179 | Loss 671920.0000
16:16:25.940952 [0] Epoch 00180 | Loss 741408.6875
16:16:25.943957 [0] Epoch: 180, Train: 0.1042, Val: 0.1578, Test: 0.2282
16:16:25.966189 [0] Epoch 00181 | Loss 769740.5000
16:16:25.989639 [0] Epoch 00182 | Loss 780188.7500
16:16:26.011872 [0] Epoch 00183 | Loss 844213.3125
16:16:26.038246 [0] Epoch 00184 | Loss 900562.5000
16:16:26.063120 [0] Epoch 00185 | Loss 952883.0625
16:16:26.085117 [0] Epoch 00186 | Loss 939996.3750
16:16:26.108979 [0] Epoch 00187 | Loss 918179.5000
16:16:26.130442 [0] Epoch 00188 | Loss 957840.6250
16:16:26.150570 [0] Epoch 00189 | Loss 1105507.2500
16:16:26.173630 [0] Epoch 00190 | Loss 1099041.8750
16:16:26.177128 [0] Epoch: 190, Train: 0.1848, Val: 0.0839, Test: 0.0638
16:16:26.198299 [0] Epoch 00191 | Loss 1164541.6250
16:16:26.218403 [0] Epoch 00192 | Loss 1212071.8750
16:16:26.240835 [0] Epoch 00193 | Loss 1346772.2500
16:16:26.265275 [0] Epoch 00194 | Loss 1438753.1250
16:16:26.487293 [0] Epoch 00195 | Loss 1461355.5000
16:16:26.510352 [0] Epoch 00196 | Loss 1375486.2500
16:16:26.530807 [0] Epoch 00197 | Loss 1410164.5000
16:16:26.551790 [0] Epoch 00198 | Loss 1346447.5000
16:16:26.576344 [0] Epoch 00199 | Loss 1528418.5000
16:16:26.579473 [0] Epoch: 199, Train: 0.1176, Val: 0.2334, Test: 0.2191
16:16:26.581491 [0] 
timer summary:
  1.56s   0.00s  2000 mm
  0.89s   0.01s   800 broadcast
  4.18s   0.02s  2000 spmm
  0.10s   0.00s  1000 all_reduce
  7.99s   0.01s   200 epoch
  9.96s   0.00s     1 total
16:18:29.142507 [0] proc begin: <DistEnv 0/2 nccl>
16:18:48.285911 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:18:48.288580 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:18:50.672913 [0] Epoch 00000 | Loss 3.7347
16:18:50.678710 [0] Epoch: 000, Train: 0.0188, Val: 0.0167, Test: 0.0176
16:18:50.987547 [0] Epoch 00001 | Loss 3.3026
16:18:51.086518 [0] Epoch 00002 | Loss 2.9690
16:18:51.185691 [0] Epoch 00003 | Loss 2.7159
16:18:51.286317 [0] Epoch 00004 | Loss 2.5007
16:18:51.386035 [0] Epoch 00005 | Loss 2.3153
16:18:51.678803 [0] Epoch 00006 | Loss 2.1407
16:18:51.778179 [0] Epoch 00007 | Loss 1.9787
16:18:51.878689 [0] Epoch 00008 | Loss 1.8415
16:18:51.977165 [0] Epoch 00009 | Loss 1.7203
16:18:52.077098 [0] Epoch 00010 | Loss 1.6011
16:18:52.082249 [0] Epoch: 010, Train: 0.7707, Val: 0.7886, Test: 0.7842
16:18:52.189132 [0] Epoch 00011 | Loss 1.4863
16:18:52.492020 [0] Epoch 00012 | Loss 1.3836
16:18:52.593894 [0] Epoch 00013 | Loss 1.2946
16:18:52.692453 [0] Epoch 00014 | Loss 1.2154
16:18:52.791361 [0] Epoch 00015 | Loss 1.1400
16:18:52.889425 [0] Epoch 00016 | Loss 1.0692
16:18:53.199941 [0] Epoch 00017 | Loss 1.0104
16:18:53.299540 [0] Epoch 00018 | Loss 0.9649
16:18:53.398568 [0] Epoch 00019 | Loss 0.9228
16:18:53.500272 [0] Epoch 00020 | Loss 0.8819
16:18:53.505858 [0] Epoch: 020, Train: 0.8503, Val: 0.8642, Test: 0.8621
16:18:53.604491 [0] Epoch 00021 | Loss 0.8422
16:18:53.703206 [0] Epoch 00022 | Loss 0.8038
16:18:54.019436 [0] Epoch 00023 | Loss 0.7690
16:18:54.119583 [0] Epoch 00024 | Loss 0.7428
16:18:54.218558 [0] Epoch 00025 | Loss 0.7201
16:18:54.322569 [0] Epoch 00026 | Loss 0.6968
16:18:54.421093 [0] Epoch 00027 | Loss 0.6761
16:18:54.523262 [0] Epoch 00028 | Loss 0.6561
16:18:54.823629 [0] Epoch 00029 | Loss 0.6368
16:18:54.922969 [0] Epoch 00030 | Loss 0.6194
16:18:54.928511 [0] Epoch: 030, Train: 0.8890, Val: 0.9018, Test: 0.9003
16:18:55.026567 [0] Epoch 00031 | Loss 0.6048
16:18:55.125308 [0] Epoch 00032 | Loss 0.5920
16:18:55.224601 [0] Epoch 00033 | Loss 0.5797
16:18:55.535205 [0] Epoch 00034 | Loss 0.5678
16:18:55.632628 [0] Epoch 00035 | Loss 0.5560
16:18:55.735665 [0] Epoch 00036 | Loss 0.5450
16:18:55.834571 [0] Epoch 00037 | Loss 0.5356
16:18:55.933574 [0] Epoch 00038 | Loss 0.5264
16:18:56.033673 [0] Epoch 00039 | Loss 0.5178
16:18:56.336512 [0] Epoch 00040 | Loss 0.5103
16:18:56.341901 [0] Epoch: 040, Train: 0.9070, Val: 0.9178, Test: 0.9153
16:18:56.439900 [0] Epoch 00041 | Loss 0.5029
16:18:56.539734 [0] Epoch 00042 | Loss 0.4960
16:18:56.640426 [0] Epoch 00043 | Loss 0.4897
16:18:56.738163 [0] Epoch 00044 | Loss 0.4833
16:18:56.835654 [0] Epoch 00045 | Loss 0.4768
16:18:57.144618 [0] Epoch 00046 | Loss 0.4710
16:18:57.242789 [0] Epoch 00047 | Loss 0.4656
16:18:57.343005 [0] Epoch 00048 | Loss 0.4609
16:18:57.439997 [0] Epoch 00049 | Loss 0.4565
16:18:57.539405 [0] Epoch 00050 | Loss 0.4518
16:18:57.544352 [0] Epoch: 050, Train: 0.9179, Val: 0.9269, Test: 0.9247
16:18:57.644881 [0] Epoch 00051 | Loss 0.4476
16:18:57.940896 [0] Epoch 00052 | Loss 0.4436
16:18:58.042703 [0] Epoch 00053 | Loss 0.4395
16:18:58.142814 [0] Epoch 00054 | Loss 0.4355
16:18:58.242416 [0] Epoch 00055 | Loss 0.4319
16:18:58.343275 [0] Epoch 00056 | Loss 0.4284
16:18:58.648468 [0] Epoch 00057 | Loss 0.4251
16:18:58.746625 [0] Epoch 00058 | Loss 0.4220
16:18:58.846409 [0] Epoch 00059 | Loss 0.4189
16:18:58.945922 [0] Epoch 00060 | Loss 0.4160
16:18:58.951487 [0] Epoch: 060, Train: 0.9232, Val: 0.9300, Test: 0.9289
16:18:59.049088 [0] Epoch 00061 | Loss 0.4132
16:18:59.148609 [0] Epoch 00062 | Loss 0.4104
16:18:59.448386 [0] Epoch 00063 | Loss 0.4077
16:18:59.548497 [0] Epoch 00064 | Loss 0.4051
16:18:59.646665 [0] Epoch 00065 | Loss 0.4027
16:18:59.746971 [0] Epoch 00066 | Loss 0.4003
16:18:59.845464 [0] Epoch 00067 | Loss 0.3979
16:18:59.943742 [0] Epoch 00068 | Loss 0.3957
16:19:00.241366 [0] Epoch 00069 | Loss 0.3935
16:19:00.341238 [0] Epoch 00070 | Loss 0.3914
16:19:00.346486 [0] Epoch: 070, Train: 0.9264, Val: 0.9331, Test: 0.9316
16:19:00.446821 [0] Epoch 00071 | Loss 0.3893
16:19:00.547939 [0] Epoch 00072 | Loss 0.3873
16:19:00.648173 [0] Epoch 00073 | Loss 0.3854
16:19:00.747410 [0] Epoch 00074 | Loss 0.3834
16:19:01.054695 [0] Epoch 00075 | Loss 0.3816
16:19:01.152494 [0] Epoch 00076 | Loss 0.3798
16:19:01.250918 [0] Epoch 00077 | Loss 0.3780
16:19:01.350099 [0] Epoch 00078 | Loss 0.3762
16:19:01.450842 [0] Epoch 00079 | Loss 0.3745
16:19:01.756263 [0] Epoch 00080 | Loss 0.3729
16:19:01.761573 [0] Epoch: 080, Train: 0.9294, Val: 0.9348, Test: 0.9342
16:19:01.859479 [0] Epoch 00081 | Loss 0.3713
16:19:01.963613 [0] Epoch 00082 | Loss 0.3697
16:19:02.063213 [0] Epoch 00083 | Loss 0.3682
16:19:02.165277 [0] Epoch 00084 | Loss 0.3666
16:19:02.265986 [0] Epoch 00085 | Loss 0.3652
16:19:02.574072 [0] Epoch 00086 | Loss 0.3637
16:19:02.676042 [0] Epoch 00087 | Loss 0.3622
16:19:02.776165 [0] Epoch 00088 | Loss 0.3608
16:19:02.876338 [0] Epoch 00089 | Loss 0.3594
16:19:02.986510 [0] Epoch 00090 | Loss 0.3581
16:19:02.991263 [0] Epoch: 090, Train: 0.9311, Val: 0.9363, Test: 0.9356
16:19:03.309687 [0] Epoch 00091 | Loss 0.3568
16:19:03.409037 [0] Epoch 00092 | Loss 0.3555
16:19:03.510731 [0] Epoch 00093 | Loss 0.3542
16:19:03.610700 [0] Epoch 00094 | Loss 0.3529
16:19:03.709771 [0] Epoch 00095 | Loss 0.3517
16:19:03.809579 [0] Epoch 00096 | Loss 0.3505
16:19:04.124346 [0] Epoch 00097 | Loss 0.3493
16:19:04.224938 [0] Epoch 00098 | Loss 0.3481
16:19:04.326602 [0] Epoch 00099 | Loss 0.3470
16:19:04.331215 [0] Epoch: 099, Train: 0.9325, Val: 0.9374, Test: 0.9367
16:19:04.332163 [0] 
timer summary:
  1.44s   0.04s   400 mm
  0.96s   0.42s   400 broadcast
 12.53s   0.06s   400 spmm
  0.02s   0.00s   200 all_reduce
 15.61s   0.53s   100 epoch
 35.18s   0.01s     1 total
16:19:22.764271 [0] proc begin: <DistEnv 0/2 nccl>
16:19:41.194816 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 232966, |E|: 114848857>
16:19:41.345555 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1147 MB |    1149 MB |    1153 MB |    5808 KB |
|       from large pool |    1146 MB |    1147 MB |    1151 MB |    5794 KB |
|       from small pool |       1 MB |       1 MB |       1 MB |      13 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1170 MB |    1170 MB |    1170 MB |       0 B  |
|       from large pool |    1168 MB |    1168 MB |    1168 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22976 KB |   22976 KB |   30150 KB |    7174 KB |
|       from large pool |   22522 KB |   22522 KB |   28317 KB |    5794 KB |
|       from small pool |     453 KB |    1820 KB |    1833 KB |    1380 KB |
|---------------------------------------------------------------------------|
| Allocations           |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| Active allocs         |       8    |      12    |      26    |      18    |
|       from large pool |       4    |       5    |       7    |       3    |
|       from small pool |       4    |       7    |      19    |      15    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       5    |       5    |       5    |       0    |
|       from large pool |       4    |       4    |       4    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       7    |       3    |
|       from large pool |       3    |       3    |       6    |       3    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

16:19:45.607037 [0] Epoch 00000 | Loss 3.7360
16:19:45.612995 [0] Epoch: 000, Train: 0.0527, Val: 0.0519, Test: 0.0498
16:19:46.046359 [0] Epoch 00001 | Loss 3.6160
16:19:46.273129 [0] Epoch 00002 | Loss 3.5098
16:19:46.717076 [0] Epoch 00003 | Loss 3.4067
16:19:46.947883 [0] Epoch 00004 | Loss 3.2655
16:19:47.176535 [0] Epoch 00005 | Loss 3.1280
16:19:47.605312 [0] Epoch 00006 | Loss 2.9928
16:19:47.833731 [0] Epoch 00007 | Loss 2.8642
16:19:48.313789 [0] Epoch 00008 | Loss 2.7546
16:19:48.541261 [0] Epoch 00009 | Loss 2.6024
16:19:48.778885 [0] Epoch 00010 | Loss 2.4641
16:19:48.784494 [0] Epoch: 010, Train: 0.5053, Val: 0.5445, Test: 0.5438
16:19:49.210491 [0] Epoch 00011 | Loss 2.3109
16:19:49.438472 [0] Epoch 00012 | Loss 2.1617
16:19:49.869257 [0] Epoch 00013 | Loss 1.9957
16:19:50.096322 [0] Epoch 00014 | Loss 1.8368
16:19:50.323966 [0] Epoch 00015 | Loss 1.7317
16:19:50.747585 [0] Epoch 00016 | Loss 1.6135
16:19:50.978940 [0] Epoch 00017 | Loss 1.5361
16:19:51.403715 [0] Epoch 00018 | Loss 1.5342
16:19:51.632135 [0] Epoch 00019 | Loss 1.4174
16:19:51.861571 [0] Epoch 00020 | Loss 1.3932
16:19:51.867134 [0] Epoch: 020, Train: 0.6922, Val: 0.7128, Test: 0.7108
16:19:52.292817 [0] Epoch 00021 | Loss 1.4021
16:19:52.520259 [0] Epoch 00022 | Loss 1.3043
16:19:52.953979 [0] Epoch 00023 | Loss 1.2643
16:19:53.181331 [0] Epoch 00024 | Loss 1.2123
16:19:53.410074 [0] Epoch 00025 | Loss 1.1967
16:19:53.838479 [0] Epoch 00026 | Loss 1.1435
16:19:54.067881 [0] Epoch 00027 | Loss 1.0578
16:19:54.502160 [0] Epoch 00028 | Loss 1.0582
16:19:54.728331 [0] Epoch 00029 | Loss 1.0496
16:19:54.958102 [0] Epoch 00030 | Loss 0.9932
16:19:54.962648 [0] Epoch: 030, Train: 0.7668, Val: 0.7844, Test: 0.7834
16:19:55.386734 [0] Epoch 00031 | Loss 0.9901
16:19:55.615933 [0] Epoch 00032 | Loss 0.9554
16:19:56.049798 [0] Epoch 00033 | Loss 0.9418
16:19:56.276707 [0] Epoch 00034 | Loss 0.9256
16:19:56.507301 [0] Epoch 00035 | Loss 0.8999
16:19:56.949829 [0] Epoch 00036 | Loss 0.8825
16:19:57.179768 [0] Epoch 00037 | Loss 0.8483
16:19:57.618087 [0] Epoch 00038 | Loss 0.8625
16:19:57.848933 [0] Epoch 00039 | Loss 0.8325
16:19:58.078510 [0] Epoch 00040 | Loss 0.8018
16:19:58.084107 [0] Epoch: 040, Train: 0.8246, Val: 0.8385, Test: 0.8375
16:19:58.526869 [0] Epoch 00041 | Loss 0.8190
16:19:58.755288 [0] Epoch 00042 | Loss 0.7996
16:19:59.190078 [0] Epoch 00043 | Loss 0.7930
16:19:59.419832 [0] Epoch 00044 | Loss 0.7922
16:19:59.651014 [0] Epoch 00045 | Loss 0.7964
16:20:00.072407 [0] Epoch 00046 | Loss 0.8024
16:20:00.300924 [0] Epoch 00047 | Loss 0.8268
16:20:00.745009 [0] Epoch 00048 | Loss 0.7560
16:20:00.974259 [0] Epoch 00049 | Loss 0.8243
16:20:01.203741 [0] Epoch 00050 | Loss 0.7775
16:20:01.208800 [0] Epoch: 050, Train: 0.8236, Val: 0.8341, Test: 0.8298
16:20:01.651373 [0] Epoch 00051 | Loss 0.8002
16:20:01.886759 [0] Epoch 00052 | Loss 0.8232
16:20:02.335241 [0] Epoch 00053 | Loss 0.7234
16:20:02.569687 [0] Epoch 00054 | Loss 0.7405
16:20:03.025933 [0] Epoch 00055 | Loss 0.7828
16:20:03.252388 [0] Epoch 00056 | Loss 0.7089
16:20:03.480828 [0] Epoch 00057 | Loss 0.7184
16:20:03.919391 [0] Epoch 00058 | Loss 0.7156
16:20:04.148148 [0] Epoch 00059 | Loss 0.6768
16:20:04.580346 [0] Epoch 00060 | Loss 0.7014
16:20:04.585429 [0] Epoch: 060, Train: 0.8377, Val: 0.8488, Test: 0.8436
16:20:04.812287 [0] Epoch 00061 | Loss 0.6741
16:20:05.052739 [0] Epoch 00062 | Loss 0.6745
16:20:05.488559 [0] Epoch 00063 | Loss 0.6590
16:20:05.719719 [0] Epoch 00064 | Loss 0.6567
16:20:06.160284 [0] Epoch 00065 | Loss 0.6425
16:20:06.390190 [0] Epoch 00066 | Loss 0.6437
16:20:06.623996 [0] Epoch 00067 | Loss 0.6260
16:20:07.049595 [0] Epoch 00068 | Loss 0.6233
16:20:07.279491 [0] Epoch 00069 | Loss 0.6171
16:20:07.714782 [0] Epoch 00070 | Loss 0.6081
16:20:07.720289 [0] Epoch: 070, Train: 0.8652, Val: 0.8760, Test: 0.8738
16:20:07.950353 [0] Epoch 00071 | Loss 0.6063
16:20:08.182885 [0] Epoch 00072 | Loss 0.5943
16:20:08.627259 [0] Epoch 00073 | Loss 0.5920
16:20:08.858063 [0] Epoch 00074 | Loss 0.5838
16:20:09.293982 [0] Epoch 00075 | Loss 0.5827
16:20:09.524313 [0] Epoch 00076 | Loss 0.5708
16:20:09.754916 [0] Epoch 00077 | Loss 0.5689
16:20:10.198506 [0] Epoch 00078 | Loss 0.5680
16:20:10.430452 [0] Epoch 00079 | Loss 0.5651
16:20:10.861534 [0] Epoch 00080 | Loss 0.5549
16:20:10.866518 [0] Epoch: 080, Train: 0.8807, Val: 0.8901, Test: 0.8867
16:20:11.096887 [0] Epoch 00081 | Loss 0.5593
16:20:11.329495 [0] Epoch 00082 | Loss 0.5540
16:20:11.772952 [0] Epoch 00083 | Loss 0.5542
16:20:12.002826 [0] Epoch 00084 | Loss 0.5435
16:20:12.437355 [0] Epoch 00085 | Loss 0.5382
16:20:12.672782 [0] Epoch 00086 | Loss 0.5474
16:20:12.904219 [0] Epoch 00087 | Loss 0.5412
16:20:13.349616 [0] Epoch 00088 | Loss 0.5365
16:20:13.585924 [0] Epoch 00089 | Loss 0.5352
16:20:14.019366 [0] Epoch 00090 | Loss 0.5322
16:20:14.024982 [0] Epoch: 090, Train: 0.8878, Val: 0.8966, Test: 0.8933
16:20:14.255751 [0] Epoch 00091 | Loss 0.5264
16:20:14.696184 [0] Epoch 00092 | Loss 0.5284
16:20:14.928284 [0] Epoch 00093 | Loss 0.5356
16:20:15.158854 [0] Epoch 00094 | Loss 0.5393
16:20:15.605487 [0] Epoch 00095 | Loss 0.5692
16:20:15.836983 [0] Epoch 00096 | Loss 0.6052
16:20:16.265842 [0] Epoch 00097 | Loss 0.6981
16:20:16.500945 [0] Epoch 00098 | Loss 0.8413
16:20:16.731820 [0] Epoch 00099 | Loss 0.8147
16:20:16.737354 [0] Epoch: 099, Train: 0.8192, Val: 0.8277, Test: 0.8247
16:20:16.739725 [0] 
timer summary:
  1.42s   0.13s  1000 mm
  1.85s   1.56s   400 broadcast
 29.84s   0.10s  1000 spmm
  0.04s   0.00s   500 all_reduce
 34.05s   1.81s   100 epoch
 53.97s   0.00s     1 total
15:48:48.986050 [0] proc begin: <DistEnv 0/2 gloo>
15:48:50.300476 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
15:46:45.068959 [0] proc begin: <DistEnv 0/2 nccl>
15:46:47.762935 [0] graph loaded <COO Graph: ogbn-arxiv, |V|: 169343, |E|: 1166243, masks: 90941,29799,48603><Local: 0, |V|: 84672, |E|: 668471>
15:46:47.765271 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| Active memory         |   50713 KB |   87835 KB |   97701 KB |   46987 KB |
|       from large pool |   49555 KB |   87339 KB |   96532 KB |   46977 KB |
|       from small pool |    1158 KB |    1160 KB |    1169 KB |      10 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  108544 KB |  108544 KB |  108544 KB |       0 B  |
|       from large pool |  106496 KB |  106496 KB |  106496 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14822 KB |   21039 KB |   25019 KB |   10196 KB |
|       from large pool |   13933 KB |   19157 KB |   23126 KB |    9193 KB |
|       from small pool |     889 KB |    1882 KB |    1893 KB |    1003 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |       6    |       7    |      10    |       4    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:46:54.222586 [0] Epoch 00000 | Loss 3.6894
15:46:54.225685 [0] Epoch: 000, Train: 0.0152, Val: 0.0138, Test: 0.0143
15:46:54.259517 [0] Epoch 00001 | Loss 3.6318
15:46:54.301405 [0] Epoch 00002 | Loss 3.5932
15:46:54.337966 [0] Epoch 00003 | Loss 3.5863
15:46:54.370228 [0] Epoch 00004 | Loss 3.6241
15:46:54.406176 [0] Epoch 00005 | Loss 3.7121
15:46:54.442143 [0] Epoch 00006 | Loss 3.8498
15:46:54.479268 [0] Epoch 00007 | Loss 4.0352
15:46:54.515773 [0] Epoch 00008 | Loss 4.2677
15:46:54.550624 [0] Epoch 00009 | Loss 4.5464
15:46:54.582597 [0] Epoch 00010 | Loss 4.8696
15:46:54.586010 [0] Epoch: 010, Train: 0.1801, Val: 0.0774, Test: 0.0590
15:46:54.620857 [0] Epoch 00011 | Loss 5.2357
15:46:54.657525 [0] Epoch 00012 | Loss 5.6447
15:46:54.692762 [0] Epoch 00013 | Loss 6.0970
15:46:54.724950 [0] Epoch 00014 | Loss 6.5934
15:46:54.757964 [0] Epoch 00015 | Loss 7.1340
15:46:54.790805 [0] Epoch 00016 | Loss 7.7195
15:46:54.827880 [0] Epoch 00017 | Loss 8.3503
15:46:54.861747 [0] Epoch 00018 | Loss 9.0269
15:46:54.894700 [0] Epoch 00019 | Loss 9.7498
15:46:54.927206 [0] Epoch 00020 | Loss 10.5189
15:46:54.930649 [0] Epoch: 020, Train: 0.1795, Val: 0.0767, Test: 0.0587
15:46:54.966993 [0] Epoch 00021 | Loss 11.3321
15:46:54.999601 [0] Epoch 00022 | Loss 12.1870
15:46:55.037668 [0] Epoch 00023 | Loss 13.0816
15:46:55.072394 [0] Epoch 00024 | Loss 14.0145
15:46:55.108777 [0] Epoch 00025 | Loss 14.9848
15:46:55.142398 [0] Epoch 00026 | Loss 15.9918
15:46:55.175193 [0] Epoch 00027 | Loss 17.0342
15:46:55.212814 [0] Epoch 00028 | Loss 18.1100
15:46:55.244594 [0] Epoch 00029 | Loss 19.2181
15:46:55.281103 [0] Epoch 00030 | Loss 20.3580
15:46:55.284564 [0] Epoch: 030, Train: 0.1806, Val: 0.0774, Test: 0.0589
15:46:55.318042 [0] Epoch 00031 | Loss 21.5299
15:46:55.350867 [0] Epoch 00032 | Loss 22.7341
15:46:55.391618 [0] Epoch 00033 | Loss 23.9715
15:46:55.428688 [0] Epoch 00034 | Loss 25.2434
15:46:55.462186 [0] Epoch 00035 | Loss 26.5510
15:46:55.495994 [0] Epoch 00036 | Loss 27.8956
15:46:55.529334 [0] Epoch 00037 | Loss 29.2791
15:46:55.562806 [0] Epoch 00038 | Loss 30.7021
15:46:55.599164 [0] Epoch 00039 | Loss 32.1638
15:46:55.636807 [0] Epoch 00040 | Loss 33.6600
15:46:55.639880 [0] Epoch: 040, Train: 0.2376, Val: 0.2268, Test: 0.2140
15:46:55.670291 [0] Epoch 00041 | Loss 35.1876
15:46:55.702886 [0] Epoch 00042 | Loss 36.7464
15:46:55.735561 [0] Epoch 00043 | Loss 38.3363
15:46:55.771322 [0] Epoch 00044 | Loss 39.9558
15:46:55.803542 [0] Epoch 00045 | Loss 41.6051
15:46:55.839355 [0] Epoch 00046 | Loss 43.2863
15:46:55.871571 [0] Epoch 00047 | Loss 45.0019
15:46:55.903730 [0] Epoch 00048 | Loss 46.7535
15:46:55.937146 [0] Epoch 00049 | Loss 48.5421
15:46:55.974442 [0] Epoch 00050 | Loss 50.3664
15:46:55.977907 [0] Epoch: 050, Train: 0.2609, Val: 0.2763, Test: 0.2568
15:46:56.009893 [0] Epoch 00051 | Loss 52.2236
15:46:56.047205 [0] Epoch 00052 | Loss 54.1098
15:46:56.086150 [0] Epoch 00053 | Loss 56.0209
15:46:56.118808 [0] Epoch 00054 | Loss 57.9555
15:46:56.152322 [0] Epoch 00055 | Loss 59.9177
15:46:56.187796 [0] Epoch 00056 | Loss 61.9123
15:46:56.221302 [0] Epoch 00057 | Loss 63.9412
15:46:56.254101 [0] Epoch 00058 | Loss 66.0026
15:46:56.289326 [0] Epoch 00059 | Loss 68.0930
15:46:56.324424 [0] Epoch 00060 | Loss 70.2083
15:46:56.328079 [0] Epoch: 060, Train: 0.2661, Val: 0.2853, Test: 0.2628
15:46:56.366069 [0] Epoch 00061 | Loss 72.3464
15:46:56.403586 [0] Epoch 00062 | Loss 74.5078
15:46:56.437201 [0] Epoch 00063 | Loss 76.6950
15:46:56.470726 [0] Epoch 00064 | Loss 78.9101
15:46:56.505683 [0] Epoch 00065 | Loss 81.1539
15:46:56.542506 [0] Epoch 00066 | Loss 83.4253
15:46:56.578247 [0] Epoch 00067 | Loss 85.7226
15:46:56.614101 [0] Epoch 00068 | Loss 88.0440
15:46:56.647044 [0] Epoch 00069 | Loss 90.3894
15:46:56.681794 [0] Epoch 00070 | Loss 92.7599
15:46:56.684701 [0] Epoch: 070, Train: 0.2686, Val: 0.2905, Test: 0.2656
15:46:56.718081 [0] Epoch 00071 | Loss 95.1563
15:46:56.751170 [0] Epoch 00072 | Loss 97.5781
15:46:56.783909 [0] Epoch 00073 | Loss 100.0235
15:46:56.820572 [0] Epoch 00074 | Loss 102.4895
15:46:56.852688 [0] Epoch 00075 | Loss 104.9742
15:46:56.885155 [0] Epoch 00076 | Loss 107.4768
15:46:56.919354 [0] Epoch 00077 | Loss 109.9976
15:46:56.954555 [0] Epoch 00078 | Loss 112.5369
15:46:56.988945 [0] Epoch 00079 | Loss 115.0940
15:46:57.025068 [0] Epoch 00080 | Loss 117.6677
15:46:57.028529 [0] Epoch: 080, Train: 0.2686, Val: 0.2920, Test: 0.2659
15:46:57.060756 [0] Epoch 00081 | Loss 120.2569
15:46:57.095854 [0] Epoch 00082 | Loss 122.8611
15:46:57.130794 [0] Epoch 00083 | Loss 125.4806
15:46:57.162809 [0] Epoch 00084 | Loss 128.1156
15:46:57.199164 [0] Epoch 00085 | Loss 130.7657
15:46:57.240151 [0] Epoch 00086 | Loss 133.4296
15:46:57.273714 [0] Epoch 00087 | Loss 136.1059
15:46:57.311013 [0] Epoch 00088 | Loss 138.7937
15:46:57.346997 [0] Epoch 00089 | Loss 141.4924
15:46:57.380901 [0] Epoch 00090 | Loss 144.2018
15:46:57.384353 [0] Epoch: 090, Train: 0.2681, Val: 0.2930, Test: 0.2662
15:46:57.418605 [0] Epoch 00091 | Loss 146.9219
15:46:57.455317 [0] Epoch 00092 | Loss 149.6517
15:46:57.489127 [0] Epoch 00093 | Loss 152.3905
15:46:57.525879 [0] Epoch 00094 | Loss 155.1378
15:46:57.558976 [0] Epoch 00095 | Loss 157.8933
15:46:57.594095 [0] Epoch 00096 | Loss 160.6569
15:46:57.627526 [0] Epoch 00097 | Loss 163.4284
15:46:57.663926 [0] Epoch 00098 | Loss 166.2070
15:46:57.696968 [0] Epoch 00099 | Loss 168.9922
15:46:57.730212 [0] Epoch 00100 | Loss 171.7833
15:46:57.733552 [0] Epoch: 100, Train: 0.2682, Val: 0.2942, Test: 0.2667
15:46:57.765017 [0] Epoch 00101 | Loss 174.5800
15:46:57.798301 [0] Epoch 00102 | Loss 177.3825
15:46:57.835104 [0] Epoch 00103 | Loss 180.1907
15:46:57.869106 [0] Epoch 00104 | Loss 183.0043
15:46:57.903600 [0] Epoch 00105 | Loss 185.8229
15:46:57.937736 [0] Epoch 00106 | Loss 188.6462
15:46:57.976232 [0] Epoch 00107 | Loss 191.4740
15:46:58.009997 [0] Epoch 00108 | Loss 194.3062
15:46:58.044128 [0] Epoch 00109 | Loss 197.1423
15:46:58.084433 [0] Epoch 00110 | Loss 199.9819
15:46:58.088381 [0] Epoch: 110, Train: 0.2685, Val: 0.2951, Test: 0.2669
15:46:58.120427 [0] Epoch 00111 | Loss 202.8246
15:46:58.152173 [0] Epoch 00112 | Loss 205.6701
15:46:58.189734 [0] Epoch 00113 | Loss 208.5184
15:46:58.227819 [0] Epoch 00114 | Loss 211.3695
15:46:58.263039 [0] Epoch 00115 | Loss 214.2233
15:46:58.300830 [0] Epoch 00116 | Loss 217.0798
15:46:58.333935 [0] Epoch 00117 | Loss 219.9391
15:46:58.369138 [0] Epoch 00118 | Loss 222.8023
15:46:58.403390 [0] Epoch 00119 | Loss 225.6702
15:46:58.440887 [0] Epoch 00120 | Loss 228.5394
15:46:58.443777 [0] Epoch: 120, Train: 0.2687, Val: 0.2958, Test: 0.2671
15:46:58.481663 [0] Epoch 00121 | Loss 231.4070
15:46:58.515933 [0] Epoch 00122 | Loss 234.2733
15:46:58.548383 [0] Epoch 00123 | Loss 237.1397
15:46:58.584160 [0] Epoch 00124 | Loss 240.0071
15:46:58.620239 [0] Epoch 00125 | Loss 242.8763
15:46:58.653594 [0] Epoch 00126 | Loss 245.7470
15:46:58.688163 [0] Epoch 00127 | Loss 248.6192
15:46:58.722196 [0] Epoch 00128 | Loss 251.4931
15:46:58.754419 [0] Epoch 00129 | Loss 254.3681
15:46:58.790568 [0] Epoch 00130 | Loss 257.2437
15:46:58.792953 [0] Epoch: 130, Train: 0.2691, Val: 0.2965, Test: 0.2673
15:46:58.824507 [0] Epoch 00131 | Loss 260.1191
15:46:58.860628 [0] Epoch 00132 | Loss 262.9943
15:46:58.895832 [0] Epoch 00133 | Loss 265.8694
15:46:58.932131 [0] Epoch 00134 | Loss 268.7452
15:46:58.968996 [0] Epoch 00135 | Loss 271.6215
15:46:59.002399 [0] Epoch 00136 | Loss 274.4983
15:46:59.036216 [0] Epoch 00137 | Loss 277.3748
15:46:59.075673 [0] Epoch 00138 | Loss 280.2507
15:46:59.112086 [0] Epoch 00139 | Loss 283.1261
15:46:59.145175 [0] Epoch 00140 | Loss 286.0011
15:46:59.148106 [0] Epoch: 140, Train: 0.2696, Val: 0.2971, Test: 0.2673
15:46:59.186992 [0] Epoch 00141 | Loss 288.8763
15:46:59.219554 [0] Epoch 00142 | Loss 291.7517
15:46:59.256052 [0] Epoch 00143 | Loss 294.6270
15:46:59.289980 [0] Epoch 00144 | Loss 297.5016
15:46:59.324593 [0] Epoch 00145 | Loss 300.3755
15:46:59.356710 [0] Epoch 00146 | Loss 303.2476
15:46:59.391206 [0] Epoch 00147 | Loss 306.1165
15:46:59.425339 [0] Epoch 00148 | Loss 308.9829
15:46:59.457883 [0] Epoch 00149 | Loss 311.8476
15:46:59.494464 [0] Epoch 00150 | Loss 314.7116
15:46:59.497929 [0] Epoch: 150, Train: 0.2697, Val: 0.2974, Test: 0.2676
15:46:59.531913 [0] Epoch 00151 | Loss 317.5754
15:46:59.568681 [0] Epoch 00152 | Loss 320.4392
15:46:59.602622 [0] Epoch 00153 | Loss 323.3022
15:46:59.638516 [0] Epoch 00154 | Loss 326.1640
15:46:59.672200 [0] Epoch 00155 | Loss 329.0242
15:46:59.705461 [0] Epoch 00156 | Loss 331.8830
15:46:59.743641 [0] Epoch 00157 | Loss 334.7411
15:46:59.776779 [0] Epoch 00158 | Loss 337.6024
15:46:59.812868 [0] Epoch 00159 | Loss 340.4716
15:46:59.850774 [0] Epoch 00160 | Loss 343.3420
15:46:59.853803 [0] Epoch: 160, Train: 0.2699, Val: 0.2979, Test: 0.2673
15:46:59.892351 [0] Epoch 00161 | Loss 346.2057
15:46:59.929813 [0] Epoch 00162 | Loss 349.0637
15:46:59.965641 [0] Epoch 00163 | Loss 351.9192
15:47:00.002428 [0] Epoch 00164 | Loss 354.7741
15:47:00.037172 [0] Epoch 00165 | Loss 357.6277
15:47:00.071362 [0] Epoch 00166 | Loss 360.4780
15:47:00.110792 [0] Epoch 00167 | Loss 363.3248
15:47:00.147854 [0] Epoch 00168 | Loss 366.1701
15:47:00.183659 [0] Epoch 00169 | Loss 369.0159
15:47:00.219760 [0] Epoch 00170 | Loss 371.8611
15:47:00.223235 [0] Epoch: 170, Train: 0.2703, Val: 0.2987, Test: 0.2674
15:47:00.259703 [0] Epoch 00171 | Loss 374.7033
15:47:00.296028 [0] Epoch 00172 | Loss 377.5399
15:47:00.331553 [0] Epoch 00173 | Loss 380.3710
15:47:00.367558 [0] Epoch 00174 | Loss 383.1987
15:47:00.403130 [0] Epoch 00175 | Loss 386.0229
15:47:00.439891 [0] Epoch 00176 | Loss 388.8416
15:47:00.475145 [0] Epoch 00177 | Loss 391.6552
15:47:00.514274 [0] Epoch 00178 | Loss 394.4669
15:47:00.547351 [0] Epoch 00179 | Loss 397.2775
15:47:00.582795 [0] Epoch 00180 | Loss 400.0833
15:47:00.585499 [0] Epoch: 180, Train: 0.2698, Val: 0.2992, Test: 0.2684
15:47:00.620513 [0] Epoch 00181 | Loss 402.8808
15:47:00.654932 [0] Epoch 00182 | Loss 405.6714
15:47:00.689697 [0] Epoch 00183 | Loss 408.4593
15:47:00.721738 [0] Epoch 00184 | Loss 411.2461
15:47:00.757961 [0] Epoch 00185 | Loss 414.0293
15:47:00.792709 [0] Epoch 00186 | Loss 416.8065
15:47:00.824770 [0] Epoch 00187 | Loss 419.5787
15:47:00.857828 [0] Epoch 00188 | Loss 422.3487
15:47:00.891590 [0] Epoch 00189 | Loss 425.1177
15:47:00.925164 [0] Epoch 00190 | Loss 427.8842
15:47:00.928053 [0] Epoch: 190, Train: 0.2686, Val: 0.2997, Test: 0.2687
15:47:00.967611 [0] Epoch 00191 | Loss 430.6468
15:47:01.004280 [0] Epoch 00192 | Loss 433.4039
15:47:01.037809 [0] Epoch 00193 | Loss 436.1562
15:47:01.077896 [0] Epoch 00194 | Loss 438.9045
15:47:01.113036 [0] Epoch 00195 | Loss 441.6495
15:47:01.146320 [0] Epoch 00196 | Loss 444.3908
15:47:01.179931 [0] Epoch 00197 | Loss 447.1284
15:47:01.215909 [0] Epoch 00198 | Loss 449.8623
15:47:01.251587 [0] Epoch 00199 | Loss 452.5931
15:47:01.255067 [0] Epoch: 199, Train: 0.2673, Val: 0.2996, Test: 0.2685
15:47:01.258652 [0] 
timer summary:
  4.52s   0.11s   800 mm
  3.19s   0.07s  4000 broadcast
  4.56s   0.03s  4000 spmm
  0.07s   0.01s   400 all_reduce
 13.50s   0.11s   200 epoch
 16.18s   0.00s     1 total
15:50:33.949255 [0] proc begin: <DistEnv 0/2 nccl>
15:51:09.813888 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:51:09.817357 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:51:11.186924 [0] Epoch 00000 | Loss 3.7289
15:51:11.192603 [0] Epoch: 000, Train: 0.0186, Val: 0.0164, Test: 0.0175
15:51:11.336586 [0] Epoch 00001 | Loss 3.3773
15:51:11.481586 [0] Epoch 00002 | Loss 3.1051
15:51:11.625582 [0] Epoch 00003 | Loss 2.8955
15:51:11.771490 [0] Epoch 00004 | Loss 2.7210
15:51:11.918222 [0] Epoch 00005 | Loss 2.5764
15:51:12.067028 [0] Epoch 00006 | Loss 2.4377
15:51:12.213895 [0] Epoch 00007 | Loss 2.3067
15:51:12.362936 [0] Epoch 00008 | Loss 2.1905
15:51:12.508913 [0] Epoch 00009 | Loss 2.0812
15:51:12.655434 [0] Epoch 00010 | Loss 1.9746
15:51:12.660728 [0] Epoch: 010, Train: 0.6556, Val: 0.6788, Test: 0.6720
15:51:12.806428 [0] Epoch 00011 | Loss 1.8741
15:51:12.953397 [0] Epoch 00012 | Loss 1.7778
15:51:13.098165 [0] Epoch 00013 | Loss 1.6866
15:51:13.246997 [0] Epoch 00014 | Loss 1.6035
15:51:13.390406 [0] Epoch 00015 | Loss 1.5258
15:51:13.536851 [0] Epoch 00016 | Loss 1.4552
15:51:13.681137 [0] Epoch 00017 | Loss 1.3933
15:51:13.825837 [0] Epoch 00018 | Loss 1.3371
15:51:13.972021 [0] Epoch 00019 | Loss 1.2829
15:51:14.125039 [0] Epoch 00020 | Loss 1.2336
15:51:14.130413 [0] Epoch: 020, Train: 0.7726, Val: 0.7878, Test: 0.7852
15:51:14.278958 [0] Epoch 00021 | Loss 1.1870
15:51:14.425227 [0] Epoch 00022 | Loss 1.1429
15:51:14.571279 [0] Epoch 00023 | Loss 1.1038
15:51:14.721262 [0] Epoch 00024 | Loss 1.0690
15:51:14.866170 [0] Epoch 00025 | Loss 1.0370
15:51:15.011437 [0] Epoch 00026 | Loss 1.0040
15:51:15.162933 [0] Epoch 00027 | Loss 0.9741
15:51:15.308502 [0] Epoch 00028 | Loss 0.9479
15:51:15.458029 [0] Epoch 00029 | Loss 0.9210
15:51:15.603326 [0] Epoch 00030 | Loss 0.8963
15:51:15.607561 [0] Epoch: 030, Train: 0.8471, Val: 0.8621, Test: 0.8593
15:51:15.752316 [0] Epoch 00031 | Loss 0.8734
15:51:15.898841 [0] Epoch 00032 | Loss 0.8544
15:51:16.045647 [0] Epoch 00033 | Loss 0.8370
15:51:16.189492 [0] Epoch 00034 | Loss 0.8188
15:51:16.333754 [0] Epoch 00035 | Loss 0.8005
15:51:16.478284 [0] Epoch 00036 | Loss 0.7840
15:51:16.622477 [0] Epoch 00037 | Loss 0.7687
15:51:16.767898 [0] Epoch 00038 | Loss 0.7536
15:51:16.914638 [0] Epoch 00039 | Loss 0.7404
15:51:17.059457 [0] Epoch 00040 | Loss 0.7292
15:51:17.064808 [0] Epoch: 040, Train: 0.8760, Val: 0.8880, Test: 0.8866
15:51:17.210026 [0] Epoch 00041 | Loss 0.7166
15:51:17.356592 [0] Epoch 00042 | Loss 0.7052
15:51:17.505760 [0] Epoch 00043 | Loss 0.6950
15:51:17.651500 [0] Epoch 00044 | Loss 0.6846
15:51:17.798378 [0] Epoch 00045 | Loss 0.6751
15:51:17.944446 [0] Epoch 00046 | Loss 0.6666
15:51:18.091162 [0] Epoch 00047 | Loss 0.6577
15:51:18.236040 [0] Epoch 00048 | Loss 0.6488
15:51:18.381459 [0] Epoch 00049 | Loss 0.6413
15:51:18.525226 [0] Epoch 00050 | Loss 0.6342
15:51:18.530582 [0] Epoch: 050, Train: 0.8892, Val: 0.9017, Test: 0.8997
15:51:18.675448 [0] Epoch 00051 | Loss 0.6275
15:51:18.820159 [0] Epoch 00052 | Loss 0.6209
15:51:18.964966 [0] Epoch 00053 | Loss 0.6142
15:51:19.111422 [0] Epoch 00054 | Loss 0.6082
15:51:19.261095 [0] Epoch 00055 | Loss 0.6023
15:51:19.408493 [0] Epoch 00056 | Loss 0.5967
15:51:19.555323 [0] Epoch 00057 | Loss 0.5918
15:51:19.704688 [0] Epoch 00058 | Loss 0.5867
15:51:19.851152 [0] Epoch 00059 | Loss 0.5816
15:51:19.997324 [0] Epoch 00060 | Loss 0.5771
15:51:20.001611 [0] Epoch: 060, Train: 0.8954, Val: 0.9075, Test: 0.9038
15:51:20.149663 [0] Epoch 00061 | Loss 0.5726
15:51:20.296383 [0] Epoch 00062 | Loss 0.5682
15:51:20.447188 [0] Epoch 00063 | Loss 0.5641
15:51:20.593100 [0] Epoch 00064 | Loss 0.5601
15:51:20.738178 [0] Epoch 00065 | Loss 0.5563
15:51:20.885755 [0] Epoch 00066 | Loss 0.5525
15:51:21.031069 [0] Epoch 00067 | Loss 0.5489
15:51:21.177674 [0] Epoch 00068 | Loss 0.5454
15:51:21.326141 [0] Epoch 00069 | Loss 0.5421
15:51:21.477150 [0] Epoch 00070 | Loss 0.5389
15:51:21.482495 [0] Epoch: 070, Train: 0.8986, Val: 0.9098, Test: 0.9066
15:51:21.629918 [0] Epoch 00071 | Loss 0.5356
15:51:21.778073 [0] Epoch 00072 | Loss 0.5326
15:51:21.923609 [0] Epoch 00073 | Loss 0.5296
15:51:22.069424 [0] Epoch 00074 | Loss 0.5267
15:51:22.216470 [0] Epoch 00075 | Loss 0.5239
15:51:22.366016 [0] Epoch 00076 | Loss 0.5212
15:51:22.514212 [0] Epoch 00077 | Loss 0.5186
15:51:22.662896 [0] Epoch 00078 | Loss 0.5160
15:51:22.808889 [0] Epoch 00079 | Loss 0.5135
15:51:22.956667 [0] Epoch 00080 | Loss 0.5111
15:51:22.961275 [0] Epoch: 080, Train: 0.9010, Val: 0.9117, Test: 0.9083
15:51:23.106622 [0] Epoch 00081 | Loss 0.5087
15:51:23.258038 [0] Epoch 00082 | Loss 0.5064
15:51:23.405939 [0] Epoch 00083 | Loss 0.5042
15:51:23.553485 [0] Epoch 00084 | Loss 0.5020
15:51:23.699952 [0] Epoch 00085 | Loss 0.4999
15:51:23.846497 [0] Epoch 00086 | Loss 0.4978
15:51:23.995296 [0] Epoch 00087 | Loss 0.4958
15:51:24.140993 [0] Epoch 00088 | Loss 0.4938
15:51:24.290812 [0] Epoch 00089 | Loss 0.4919
15:51:24.437227 [0] Epoch 00090 | Loss 0.4900
15:51:24.442741 [0] Epoch: 090, Train: 0.9026, Val: 0.9136, Test: 0.9107
15:51:24.590604 [0] Epoch 00091 | Loss 0.4881
15:51:24.738336 [0] Epoch 00092 | Loss 0.4863
15:51:24.886152 [0] Epoch 00093 | Loss 0.4846
15:51:25.033195 [0] Epoch 00094 | Loss 0.4828
15:51:25.181933 [0] Epoch 00095 | Loss 0.4811
15:51:25.327732 [0] Epoch 00096 | Loss 0.4795
15:51:25.478106 [0] Epoch 00097 | Loss 0.4778
15:51:25.624791 [0] Epoch 00098 | Loss 0.4762
15:51:25.774317 [0] Epoch 00099 | Loss 0.4747
15:51:25.920865 [0] Epoch 00100 | Loss 0.4731
15:51:25.926248 [0] Epoch: 100, Train: 0.9047, Val: 0.9154, Test: 0.9124
15:51:26.072382 [0] Epoch 00101 | Loss 0.4716
15:51:26.220751 [0] Epoch 00102 | Loss 0.4702
15:51:26.370708 [0] Epoch 00103 | Loss 0.4687
15:51:26.517827 [0] Epoch 00104 | Loss 0.4673
15:51:26.664305 [0] Epoch 00105 | Loss 0.4659
15:51:26.812393 [0] Epoch 00106 | Loss 0.4645
15:51:26.959597 [0] Epoch 00107 | Loss 0.4632
15:51:27.107325 [0] Epoch 00108 | Loss 0.4619
15:51:27.259117 [0] Epoch 00109 | Loss 0.4606
15:51:27.405669 [0] Epoch 00110 | Loss 0.4593
15:51:27.409994 [0] Epoch: 110, Train: 0.9068, Val: 0.9171, Test: 0.9141
15:51:27.555579 [0] Epoch 00111 | Loss 0.4580
15:51:27.702333 [0] Epoch 00112 | Loss 0.4568
15:51:27.847989 [0] Epoch 00113 | Loss 0.4555
15:51:27.997009 [0] Epoch 00114 | Loss 0.4543
15:51:28.145649 [0] Epoch 00115 | Loss 0.4532
15:51:28.293630 [0] Epoch 00116 | Loss 0.4520
15:51:28.439366 [0] Epoch 00117 | Loss 0.4508
15:51:28.588195 [0] Epoch 00118 | Loss 0.4497
15:51:28.734422 [0] Epoch 00119 | Loss 0.4486
15:51:28.882358 [0] Epoch 00120 | Loss 0.4475
15:51:28.887923 [0] Epoch: 120, Train: 0.9090, Val: 0.9191, Test: 0.9164
15:51:29.034570 [0] Epoch 00121 | Loss 0.4464
15:51:29.182193 [0] Epoch 00122 | Loss 0.4453
15:51:29.329641 [0] Epoch 00123 | Loss 0.4443
15:51:29.480988 [0] Epoch 00124 | Loss 0.4433
15:51:29.627094 [0] Epoch 00125 | Loss 0.4422
15:51:29.773643 [0] Epoch 00126 | Loss 0.4412
15:51:29.919797 [0] Epoch 00127 | Loss 0.4403
15:51:30.066555 [0] Epoch 00128 | Loss 0.4394
15:51:30.214791 [0] Epoch 00129 | Loss 0.4385
15:51:30.364881 [0] Epoch 00130 | Loss 0.4381
15:51:30.370320 [0] Epoch: 130, Train: 0.9114, Val: 0.9206, Test: 0.9190
15:51:30.516703 [0] Epoch 00131 | Loss 0.4376
15:51:30.663993 [0] Epoch 00132 | Loss 0.4368
15:51:30.811181 [0] Epoch 00133 | Loss 0.4351
15:51:30.958083 [0] Epoch 00134 | Loss 0.4337
15:51:31.104026 [0] Epoch 00135 | Loss 0.4332
15:51:31.253030 [0] Epoch 00136 | Loss 0.4329
15:51:31.401969 [0] Epoch 00137 | Loss 0.4319
15:51:31.548635 [0] Epoch 00138 | Loss 0.4303
15:51:31.695094 [0] Epoch 00139 | Loss 0.4296
15:51:31.841148 [0] Epoch 00140 | Loss 0.4294
15:51:31.846486 [0] Epoch: 140, Train: 0.9132, Val: 0.9214, Test: 0.9200
15:51:31.991785 [0] Epoch 00141 | Loss 0.4284
15:51:32.142384 [0] Epoch 00142 | Loss 0.4271
15:51:32.288264 [0] Epoch 00143 | Loss 0.4265
15:51:32.436257 [0] Epoch 00144 | Loss 0.4259
15:51:32.585200 [0] Epoch 00145 | Loss 0.4251
15:51:32.730279 [0] Epoch 00146 | Loss 0.4241
15:51:32.874401 [0] Epoch 00147 | Loss 0.4232
15:51:33.018367 [0] Epoch 00148 | Loss 0.4227
15:51:33.165601 [0] Epoch 00149 | Loss 0.4220
15:51:33.312227 [0] Epoch 00150 | Loss 0.4211
15:51:33.317627 [0] Epoch: 150, Train: 0.9144, Val: 0.9233, Test: 0.9214
15:51:33.466355 [0] Epoch 00151 | Loss 0.4203
15:51:33.611373 [0] Epoch 00152 | Loss 0.4197
15:51:33.757887 [0] Epoch 00153 | Loss 0.4192
15:51:33.905072 [0] Epoch 00154 | Loss 0.4182
15:51:34.051161 [0] Epoch 00155 | Loss 0.4174
15:51:34.199414 [0] Epoch 00156 | Loss 0.4170
15:51:34.346171 [0] Epoch 00157 | Loss 0.4162
15:51:34.493918 [0] Epoch 00158 | Loss 0.4155
15:51:34.642527 [0] Epoch 00159 | Loss 0.4148
15:51:34.790200 [0] Epoch 00160 | Loss 0.4141
15:51:34.795423 [0] Epoch: 160, Train: 0.9154, Val: 0.9243, Test: 0.9221
15:51:34.942211 [0] Epoch 00161 | Loss 0.4136
15:51:35.088367 [0] Epoch 00162 | Loss 0.4129
15:51:35.243273 [0] Epoch 00163 | Loss 0.4122
15:51:35.391505 [0] Epoch 00164 | Loss 0.4115
15:51:35.539597 [0] Epoch 00165 | Loss 0.4109
15:51:35.685799 [0] Epoch 00166 | Loss 0.4104
15:51:35.832966 [0] Epoch 00167 | Loss 0.4097
15:51:35.979744 [0] Epoch 00168 | Loss 0.4091
15:51:36.128951 [0] Epoch 00169 | Loss 0.4085
15:51:36.277936 [0] Epoch 00170 | Loss 0.4079
15:51:36.283314 [0] Epoch: 170, Train: 0.9165, Val: 0.9246, Test: 0.9228
15:51:36.432214 [0] Epoch 00171 | Loss 0.4073
15:51:36.579976 [0] Epoch 00172 | Loss 0.4067
15:51:36.725429 [0] Epoch 00173 | Loss 0.4061
15:51:36.871449 [0] Epoch 00174 | Loss 0.4055
15:51:37.019198 [0] Epoch 00175 | Loss 0.4050
15:51:37.169376 [0] Epoch 00176 | Loss 0.4044
15:51:37.315906 [0] Epoch 00177 | Loss 0.4038
15:51:37.466479 [0] Epoch 00178 | Loss 0.4033
15:51:37.611928 [0] Epoch 00179 | Loss 0.4027
15:51:37.758313 [0] Epoch 00180 | Loss 0.4022
15:51:37.762874 [0] Epoch: 180, Train: 0.9175, Val: 0.9251, Test: 0.9236
15:51:37.909274 [0] Epoch 00181 | Loss 0.4016
15:51:38.056470 [0] Epoch 00182 | Loss 0.4011
15:51:38.203816 [0] Epoch 00183 | Loss 0.4005
15:51:38.351599 [0] Epoch 00184 | Loss 0.4001
15:51:38.499131 [0] Epoch 00185 | Loss 0.3995
15:51:38.645532 [0] Epoch 00186 | Loss 0.3990
15:51:38.791666 [0] Epoch 00187 | Loss 0.3984
15:51:38.937520 [0] Epoch 00188 | Loss 0.3980
15:51:39.083925 [0] Epoch 00189 | Loss 0.3974
15:51:39.232868 [0] Epoch 00190 | Loss 0.3970
15:51:39.238121 [0] Epoch: 190, Train: 0.9182, Val: 0.9260, Test: 0.9246
15:51:39.387308 [0] Epoch 00191 | Loss 0.3964
15:51:39.538484 [0] Epoch 00192 | Loss 0.3960
15:51:39.686238 [0] Epoch 00193 | Loss 0.3954
15:51:39.832581 [0] Epoch 00194 | Loss 0.3951
15:51:39.980203 [0] Epoch 00195 | Loss 0.3946
15:51:40.128822 [0] Epoch 00196 | Loss 0.3945
15:51:40.280661 [0] Epoch 00197 | Loss 0.3939
15:51:40.427907 [0] Epoch 00198 | Loss 0.3938
15:51:40.575154 [0] Epoch 00199 | Loss 0.3929
15:51:40.579947 [0] Epoch: 199, Train: 0.9194, Val: 0.9269, Test: 0.9255
15:51:40.581692 [0] 
timer summary:
  1.37s   0.14s   800 mm
  4.71s   1.08s  4000 broadcast
 23.55s   0.39s  4000 spmm
  0.12s   0.06s   400 all_reduce
 31.24s   0.83s   200 epoch
 66.63s   0.00s     1 total
15:52:39.818307 [0] proc begin: <DistEnv 0/2 nccl>
15:52:51.149101 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
15:52:51.152360 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| Active memory         |  736599 KB |  738421 KB |  742073 KB |    5474 KB |
|       from large pool |  735004 KB |  736825 KB |  740466 KB |    5461 KB |
|       from small pool |    1595 KB |    1597 KB |    1607 KB |      12 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  755712 KB |  755712 KB |  755712 KB |       0 B  |
|       from large pool |  753664 KB |  753664 KB |  753664 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19112 KB |   20479 KB |   25953 KB |    6841 KB |
|       from large pool |   18659 KB |   18659 KB |   24121 KB |    5461 KB |
|       from small pool |     453 KB |    1820 KB |    1832 KB |    1379 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      35    |      24    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      26    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:52:52.962711 [0] Epoch 00000 | Loss 3.7289
15:52:52.968193 [0] Epoch: 000, Train: 0.0186, Val: 0.0164, Test: 0.0175
15:52:53.109953 [0] Epoch 00001 | Loss 3.3773
15:52:53.252771 [0] Epoch 00002 | Loss 3.1051
15:52:53.396108 [0] Epoch 00003 | Loss 2.8955
15:52:53.541121 [0] Epoch 00004 | Loss 2.7210
15:52:53.683628 [0] Epoch 00005 | Loss 2.5764
15:52:53.826806 [0] Epoch 00006 | Loss 2.4377
15:52:53.970243 [0] Epoch 00007 | Loss 2.3067
15:52:54.115261 [0] Epoch 00008 | Loss 2.1905
15:52:54.261128 [0] Epoch 00009 | Loss 2.0812
15:52:54.403800 [0] Epoch 00010 | Loss 1.9746
15:52:54.407919 [0] Epoch: 010, Train: 0.6556, Val: 0.6788, Test: 0.6720
15:52:54.548501 [0] Epoch 00011 | Loss 1.8741
15:52:54.691062 [0] Epoch 00012 | Loss 1.7778
15:52:54.832076 [0] Epoch 00013 | Loss 1.6866
15:52:54.974154 [0] Epoch 00014 | Loss 1.6035
15:52:55.114755 [0] Epoch 00015 | Loss 1.5258
15:52:55.262993 [0] Epoch 00016 | Loss 1.4552
15:52:55.406559 [0] Epoch 00017 | Loss 1.3933
15:52:55.552401 [0] Epoch 00018 | Loss 1.3371
15:52:55.697974 [0] Epoch 00019 | Loss 1.2829
15:52:55.839884 [0] Epoch 00020 | Loss 1.2336
15:52:55.844740 [0] Epoch: 020, Train: 0.7726, Val: 0.7878, Test: 0.7852
15:52:55.991002 [0] Epoch 00021 | Loss 1.1870
15:52:56.133430 [0] Epoch 00022 | Loss 1.1429
15:52:56.275160 [0] Epoch 00023 | Loss 1.1038
15:52:56.422309 [0] Epoch 00024 | Loss 1.0690
15:52:56.564771 [0] Epoch 00025 | Loss 1.0370
15:52:56.707254 [0] Epoch 00026 | Loss 1.0040
15:52:56.848664 [0] Epoch 00027 | Loss 0.9741
15:52:56.990388 [0] Epoch 00028 | Loss 0.9479
15:52:57.130366 [0] Epoch 00029 | Loss 0.9210
15:52:57.273092 [0] Epoch 00030 | Loss 0.8963
15:52:57.277848 [0] Epoch: 030, Train: 0.8471, Val: 0.8621, Test: 0.8593
15:52:57.419429 [0] Epoch 00031 | Loss 0.8734
15:52:57.562895 [0] Epoch 00032 | Loss 0.8544
15:52:57.704860 [0] Epoch 00033 | Loss 0.8370
15:52:57.845706 [0] Epoch 00034 | Loss 0.8188
15:52:57.989539 [0] Epoch 00035 | Loss 0.8005
15:52:58.132866 [0] Epoch 00036 | Loss 0.7840
15:52:58.274599 [0] Epoch 00037 | Loss 0.7687
15:52:58.420169 [0] Epoch 00038 | Loss 0.7536
15:52:58.563125 [0] Epoch 00039 | Loss 0.7404
15:52:58.706190 [0] Epoch 00040 | Loss 0.7292
15:52:58.711106 [0] Epoch: 040, Train: 0.8760, Val: 0.8880, Test: 0.8866
15:52:58.853201 [0] Epoch 00041 | Loss 0.7166
15:52:58.995291 [0] Epoch 00042 | Loss 0.7052
15:52:59.136561 [0] Epoch 00043 | Loss 0.6950
15:52:59.282342 [0] Epoch 00044 | Loss 0.6846
15:52:59.425744 [0] Epoch 00045 | Loss 0.6751
15:52:59.569532 [0] Epoch 00046 | Loss 0.6666
15:52:59.713731 [0] Epoch 00047 | Loss 0.6577
15:52:59.858232 [0] Epoch 00048 | Loss 0.6488
15:53:00.002197 [0] Epoch 00049 | Loss 0.6413
15:53:00.147379 [0] Epoch 00050 | Loss 0.6342
15:53:00.151551 [0] Epoch: 050, Train: 0.8892, Val: 0.9017, Test: 0.8997
15:53:00.297673 [0] Epoch 00051 | Loss 0.6275
15:53:00.443087 [0] Epoch 00052 | Loss 0.6209
15:53:00.584226 [0] Epoch 00053 | Loss 0.6142
15:53:00.727531 [0] Epoch 00054 | Loss 0.6082
15:53:00.869906 [0] Epoch 00055 | Loss 0.6023
15:53:01.014346 [0] Epoch 00056 | Loss 0.5967
15:53:01.157284 [0] Epoch 00057 | Loss 0.5918
15:53:01.301501 [0] Epoch 00058 | Loss 0.5867
15:53:01.445412 [0] Epoch 00059 | Loss 0.5816
15:53:01.588952 [0] Epoch 00060 | Loss 0.5771
15:53:01.593675 [0] Epoch: 060, Train: 0.8954, Val: 0.9075, Test: 0.9038
15:53:01.735216 [0] Epoch 00061 | Loss 0.5726
15:53:01.879597 [0] Epoch 00062 | Loss 0.5682
15:53:02.031054 [0] Epoch 00063 | Loss 0.5641
15:53:02.180924 [0] Epoch 00064 | Loss 0.5601
15:53:02.329934 [0] Epoch 00065 | Loss 0.5563
15:53:02.482567 [0] Epoch 00066 | Loss 0.5525
15:53:02.635587 [0] Epoch 00067 | Loss 0.5489
15:53:02.783816 [0] Epoch 00068 | Loss 0.5454
15:53:02.931195 [0] Epoch 00069 | Loss 0.5421
15:53:03.078081 [0] Epoch 00070 | Loss 0.5389
15:53:03.082898 [0] Epoch: 070, Train: 0.8986, Val: 0.9098, Test: 0.9066
15:53:03.230299 [0] Epoch 00071 | Loss 0.5356
15:53:03.378128 [0] Epoch 00072 | Loss 0.5326
15:53:03.527915 [0] Epoch 00073 | Loss 0.5296
15:53:03.671960 [0] Epoch 00074 | Loss 0.5267
15:53:03.819584 [0] Epoch 00075 | Loss 0.5239
15:53:03.965807 [0] Epoch 00076 | Loss 0.5212
15:53:04.110678 [0] Epoch 00077 | Loss 0.5186
15:53:04.256474 [0] Epoch 00078 | Loss 0.5160
15:53:04.400562 [0] Epoch 00079 | Loss 0.5135
15:53:04.548245 [0] Epoch 00080 | Loss 0.5111
15:53:04.552523 [0] Epoch: 080, Train: 0.9010, Val: 0.9117, Test: 0.9083
15:53:04.696519 [0] Epoch 00081 | Loss 0.5087
15:53:04.842094 [0] Epoch 00082 | Loss 0.5064
15:53:04.987960 [0] Epoch 00083 | Loss 0.5042
15:53:05.132927 [0] Epoch 00084 | Loss 0.5020
15:53:05.279069 [0] Epoch 00085 | Loss 0.4999
15:53:05.426012 [0] Epoch 00086 | Loss 0.4978
15:53:05.573125 [0] Epoch 00087 | Loss 0.4958
15:53:05.718757 [0] Epoch 00088 | Loss 0.4938
15:53:05.863772 [0] Epoch 00089 | Loss 0.4919
15:53:06.012086 [0] Epoch 00090 | Loss 0.4900
15:53:06.016862 [0] Epoch: 090, Train: 0.9026, Val: 0.9136, Test: 0.9107
15:53:06.162942 [0] Epoch 00091 | Loss 0.4881
15:53:06.308705 [0] Epoch 00092 | Loss 0.4863
15:53:06.457212 [0] Epoch 00093 | Loss 0.4846
15:53:06.603872 [0] Epoch 00094 | Loss 0.4828
15:53:06.748472 [0] Epoch 00095 | Loss 0.4811
15:53:06.892804 [0] Epoch 00096 | Loss 0.4795
15:53:07.037670 [0] Epoch 00097 | Loss 0.4778
15:53:07.182676 [0] Epoch 00098 | Loss 0.4762
15:53:07.326875 [0] Epoch 00099 | Loss 0.4747
15:53:07.473568 [0] Epoch 00100 | Loss 0.4731
15:53:07.477853 [0] Epoch: 100, Train: 0.9047, Val: 0.9154, Test: 0.9124
15:53:07.621552 [0] Epoch 00101 | Loss 0.4716
15:53:07.766740 [0] Epoch 00102 | Loss 0.4702
15:53:07.911799 [0] Epoch 00103 | Loss 0.4687
15:53:08.059073 [0] Epoch 00104 | Loss 0.4673
15:53:08.207313 [0] Epoch 00105 | Loss 0.4659
15:53:08.353377 [0] Epoch 00106 | Loss 0.4645
15:53:08.500983 [0] Epoch 00107 | Loss 0.4632
15:53:08.648661 [0] Epoch 00108 | Loss 0.4619
15:53:08.794352 [0] Epoch 00109 | Loss 0.4606
15:53:08.940838 [0] Epoch 00110 | Loss 0.4593
15:53:08.946008 [0] Epoch: 110, Train: 0.9068, Val: 0.9171, Test: 0.9141
15:53:09.091880 [0] Epoch 00111 | Loss 0.4580
15:53:09.239857 [0] Epoch 00112 | Loss 0.4568
15:53:09.387193 [0] Epoch 00113 | Loss 0.4555
15:53:09.534335 [0] Epoch 00114 | Loss 0.4543
15:53:09.679576 [0] Epoch 00115 | Loss 0.4532
15:53:09.824434 [0] Epoch 00116 | Loss 0.4520
15:53:09.969706 [0] Epoch 00117 | Loss 0.4508
15:53:10.117972 [0] Epoch 00118 | Loss 0.4497
15:53:10.266190 [0] Epoch 00119 | Loss 0.4486
15:53:10.412490 [0] Epoch 00120 | Loss 0.4475
15:53:10.416906 [0] Epoch: 120, Train: 0.9091, Val: 0.9191, Test: 0.9164
15:53:10.564783 [0] Epoch 00121 | Loss 0.4464
15:53:10.709371 [0] Epoch 00122 | Loss 0.4453
15:53:10.855579 [0] Epoch 00123 | Loss 0.4443
15:53:11.002800 [0] Epoch 00124 | Loss 0.4433
15:53:11.147958 [0] Epoch 00125 | Loss 0.4422
15:53:11.297862 [0] Epoch 00126 | Loss 0.4412
15:53:11.444707 [0] Epoch 00127 | Loss 0.4403
15:53:11.592080 [0] Epoch 00128 | Loss 0.4394
15:53:11.737342 [0] Epoch 00129 | Loss 0.4385
15:53:11.884609 [0] Epoch 00130 | Loss 0.4381
15:53:11.889454 [0] Epoch: 130, Train: 0.9114, Val: 0.9206, Test: 0.9190
15:53:12.035316 [0] Epoch 00131 | Loss 0.4376
15:53:12.181096 [0] Epoch 00132 | Loss 0.4368
15:53:12.326219 [0] Epoch 00133 | Loss 0.4351
15:53:12.474287 [0] Epoch 00134 | Loss 0.4337
15:53:12.620681 [0] Epoch 00135 | Loss 0.4332
15:53:12.767423 [0] Epoch 00136 | Loss 0.4329
15:53:12.912662 [0] Epoch 00137 | Loss 0.4319
15:53:13.060006 [0] Epoch 00138 | Loss 0.4303
15:53:13.207206 [0] Epoch 00139 | Loss 0.4296
15:53:13.355796 [0] Epoch 00140 | Loss 0.4294
15:53:13.360084 [0] Epoch: 140, Train: 0.9132, Val: 0.9214, Test: 0.9200
15:53:13.508462 [0] Epoch 00141 | Loss 0.4284
15:53:13.656259 [0] Epoch 00142 | Loss 0.4271
15:53:13.802638 [0] Epoch 00143 | Loss 0.4265
15:53:13.947763 [0] Epoch 00144 | Loss 0.4259
15:53:14.094413 [0] Epoch 00145 | Loss 0.4251
15:53:14.239273 [0] Epoch 00146 | Loss 0.4241
15:53:14.389184 [0] Epoch 00147 | Loss 0.4232
15:53:14.534906 [0] Epoch 00148 | Loss 0.4227
15:53:14.680053 [0] Epoch 00149 | Loss 0.4220
15:53:14.826327 [0] Epoch 00150 | Loss 0.4211
15:53:14.830614 [0] Epoch: 150, Train: 0.9144, Val: 0.9233, Test: 0.9214
15:53:14.976525 [0] Epoch 00151 | Loss 0.4203
15:53:15.121936 [0] Epoch 00152 | Loss 0.4197
15:53:15.268699 [0] Epoch 00153 | Loss 0.4192
15:53:15.420790 [0] Epoch 00154 | Loss 0.4182
15:53:15.566818 [0] Epoch 00155 | Loss 0.4174
15:53:15.712133 [0] Epoch 00156 | Loss 0.4170
15:53:15.857910 [0] Epoch 00157 | Loss 0.4162
15:53:16.004326 [0] Epoch 00158 | Loss 0.4155
15:53:16.151455 [0] Epoch 00159 | Loss 0.4148
15:53:16.298490 [0] Epoch 00160 | Loss 0.4141
15:53:16.303357 [0] Epoch: 160, Train: 0.9154, Val: 0.9243, Test: 0.9222
15:53:16.451485 [0] Epoch 00161 | Loss 0.4136
15:53:16.598329 [0] Epoch 00162 | Loss 0.4129
15:53:16.744557 [0] Epoch 00163 | Loss 0.4122
15:53:16.891149 [0] Epoch 00164 | Loss 0.4115
15:53:17.039919 [0] Epoch 00165 | Loss 0.4109
15:53:17.187954 [0] Epoch 00166 | Loss 0.4104
15:53:17.338107 [0] Epoch 00167 | Loss 0.4097
15:53:17.487281 [0] Epoch 00168 | Loss 0.4091
15:53:17.633036 [0] Epoch 00169 | Loss 0.4085
15:53:17.779102 [0] Epoch 00170 | Loss 0.4079
15:53:17.783427 [0] Epoch: 170, Train: 0.9165, Val: 0.9246, Test: 0.9229
15:53:17.929517 [0] Epoch 00171 | Loss 0.4073
15:53:18.076851 [0] Epoch 00172 | Loss 0.4067
15:53:18.224077 [0] Epoch 00173 | Loss 0.4061
15:53:18.372259 [0] Epoch 00174 | Loss 0.4055
15:53:18.523495 [0] Epoch 00175 | Loss 0.4050
15:53:18.670410 [0] Epoch 00176 | Loss 0.4044
15:53:18.817243 [0] Epoch 00177 | Loss 0.4038
15:53:18.963725 [0] Epoch 00178 | Loss 0.4033
15:53:19.109351 [0] Epoch 00179 | Loss 0.4027
15:53:19.258122 [0] Epoch 00180 | Loss 0.4022
15:53:19.262400 [0] Epoch: 180, Train: 0.9175, Val: 0.9251, Test: 0.9236
15:53:19.406678 [0] Epoch 00181 | Loss 0.4016
15:53:19.552124 [0] Epoch 00182 | Loss 0.4011
15:53:19.697823 [0] Epoch 00183 | Loss 0.4005
15:53:19.842573 [0] Epoch 00184 | Loss 0.4001
15:53:19.986181 [0] Epoch 00185 | Loss 0.3995
15:53:20.129365 [0] Epoch 00186 | Loss 0.3990
15:53:20.278614 [0] Epoch 00187 | Loss 0.3984
15:53:20.427413 [0] Epoch 00188 | Loss 0.3980
15:53:20.575299 [0] Epoch 00189 | Loss 0.3974
15:53:20.721607 [0] Epoch 00190 | Loss 0.3970
15:53:20.725778 [0] Epoch: 190, Train: 0.9182, Val: 0.9260, Test: 0.9246
15:53:20.870599 [0] Epoch 00191 | Loss 0.3964
15:53:21.016183 [0] Epoch 00192 | Loss 0.3960
15:53:21.162652 [0] Epoch 00193 | Loss 0.3954
15:53:21.307898 [0] Epoch 00194 | Loss 0.3952
15:53:21.454197 [0] Epoch 00195 | Loss 0.3946
15:53:21.601952 [0] Epoch 00196 | Loss 0.3945
15:53:21.747739 [0] Epoch 00197 | Loss 0.3939
15:53:21.892818 [0] Epoch 00198 | Loss 0.3937
15:53:22.038194 [0] Epoch 00199 | Loss 0.3928
15:53:22.043092 [0] Epoch: 199, Train: 0.9194, Val: 0.9270, Test: 0.9255
15:53:22.045264 [0] 
timer summary:
  1.34s   0.13s   800 mm
  4.33s   0.01s  4000 broadcast
 23.27s   0.37s  4000 spmm
  0.11s   0.05s   400 all_reduce
 30.49s   0.42s   200 epoch
 42.22s   0.01s     1 total
17:15:10.832221 [0] proc begin: <DistEnv 0/2 nccl>
17:15:24.147976 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
17:15:24.150834 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| Active memory         |    1092 MB |    1111 MB |    1616 MB |  536649 KB |
|       from large pool |    1092 MB |    1111 MB |    1616 MB |  536632 KB |
|       from small pool |       0 MB |       0 MB |       0 MB |      16 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1198 MB |    1198 MB |    1198 MB |       0 B  |
|       from large pool |    1196 MB |    1196 MB |    1196 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  105652 KB |  304551 KB |  381081 KB |  275428 KB |
|       from large pool |  105652 KB |  304551 KB |  366735 KB |  261083 KB |
|       from small pool |       0 KB |    2047 KB |   14345 KB |   14345 KB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      36    |      25    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |      21    |      21    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |      10    |       7    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       7    |       7    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

17:15:25.805876 [0] Epoch 00000 | Loss 3.9103
17:15:25.846121 [0] Epoch: 000, Train: 0.0030, Val: 0.0038, Test: 0.0143
17:15:26.367990 [0] Epoch 00001 | Loss 3.3912
17:15:26.888893 [0] Epoch 00002 | Loss 2.9722
17:15:27.413042 [0] Epoch 00003 | Loss 2.6376
17:15:27.933416 [0] Epoch 00004 | Loss 2.3711
17:15:28.453712 [0] Epoch 00005 | Loss 2.1640
17:15:28.973881 [0] Epoch 00006 | Loss 2.0061
17:15:29.496522 [0] Epoch 00007 | Loss 1.8830
17:15:30.015749 [0] Epoch 00008 | Loss 1.7789
17:15:30.534446 [0] Epoch 00009 | Loss 1.6817
17:15:31.053774 [0] Epoch 00010 | Loss 1.5872
17:15:31.095694 [0] Epoch: 010, Train: 0.5679, Val: 0.5753, Test: 0.4665
17:15:31.613936 [0] Epoch 00011 | Loss 1.4983
17:15:32.135102 [0] Epoch 00012 | Loss 1.4197
17:15:32.652720 [0] Epoch 00013 | Loss 1.3521
17:15:33.173664 [0] Epoch 00014 | Loss 1.2924
17:15:33.690608 [0] Epoch 00015 | Loss 1.2368
17:15:34.210533 [0] Epoch 00016 | Loss 1.1840
17:15:34.733758 [0] Epoch 00017 | Loss 1.1353
17:15:35.258285 [0] Epoch 00018 | Loss 1.0916
17:15:35.779149 [0] Epoch 00019 | Loss 1.0526
17:15:36.299751 [0] Epoch 00020 | Loss 1.0174
17:15:36.342196 [0] Epoch: 020, Train: 0.8150, Val: 0.8177, Test: 0.6511
17:15:36.860047 [0] Epoch 00021 | Loss 0.9849
17:15:37.381922 [0] Epoch 00022 | Loss 0.9542
17:15:37.899458 [0] Epoch 00023 | Loss 0.9243
17:15:38.419558 [0] Epoch 00024 | Loss 0.8953
17:15:38.937005 [0] Epoch 00025 | Loss 0.8681
17:15:39.456010 [0] Epoch 00026 | Loss 0.8440
17:15:39.972699 [0] Epoch 00027 | Loss 0.8231
17:15:40.490282 [0] Epoch 00028 | Loss 0.8052
17:15:41.008346 [0] Epoch 00029 | Loss 0.7896
17:15:41.532025 [0] Epoch 00030 | Loss 0.7755
17:15:41.574192 [0] Epoch: 030, Train: 0.8366, Val: 0.8356, Test: 0.6724
17:15:42.092571 [0] Epoch 00031 | Loss 0.7621
17:15:42.613389 [0] Epoch 00032 | Loss 0.7487
17:15:43.129872 [0] Epoch 00033 | Loss 0.7355
17:15:43.645017 [0] Epoch 00034 | Loss 0.7228
17:15:44.164132 [0] Epoch 00035 | Loss 0.7112
17:15:44.680118 [0] Epoch 00036 | Loss 0.7011
17:15:45.196391 [0] Epoch 00037 | Loss 0.6924
17:15:45.715163 [0] Epoch 00038 | Loss 0.6845
17:15:46.233188 [0] Epoch 00039 | Loss 0.6770
17:15:46.748447 [0] Epoch 00040 | Loss 0.6691
17:15:46.790631 [0] Epoch: 040, Train: 0.8529, Val: 0.8518, Test: 0.6965
17:15:47.306052 [0] Epoch 00041 | Loss 0.6609
17:15:47.824225 [0] Epoch 00042 | Loss 0.6529
17:15:48.342257 [0] Epoch 00043 | Loss 0.6455
17:15:48.858634 [0] Epoch 00044 | Loss 0.6387
17:15:49.379179 [0] Epoch 00045 | Loss 0.6326
17:15:49.899770 [0] Epoch 00046 | Loss 0.6269
17:15:50.420695 [0] Epoch 00047 | Loss 0.6217
17:15:50.939476 [0] Epoch 00048 | Loss 0.6168
17:15:51.457008 [0] Epoch 00049 | Loss 0.6121
17:15:51.500233 [0] Epoch: 049, Train: 0.8634, Val: 0.8594, Test: 0.7067
17:15:51.501286 [0] 
timer summary:
  1.37s   0.02s   200 mm
 13.53s   4.03s  1000 broadcast
 11.39s   3.09s  1000 spmm
  0.13s   0.11s   100 all_reduce
 27.70s   0.85s    50 epoch
 40.66s   0.00s     1 total
17:17:31.859383 [0] proc begin: <DistEnv 0/2 nccl>
17:17:33.650466 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
17:17:33.651849 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| Active memory         |    7674 KB |    7696 KB |    7745 KB |   72704 B  |
|       from large pool |    7579 KB |    7579 KB |    7579 KB |       0 B  |
|       from small pool |      94 KB |     116 KB |     165 KB |   72704 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14854 KB |   14918 KB |   15016 KB |  166400 B  |
|       from large pool |   12900 KB |   12900 KB |   12900 KB |       0 B  |
|       from small pool |    1953 KB |    2045 KB |    2116 KB |  166400 B  |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      22    |      11    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      21    |      11    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

17:17:35.034686 [0] Epoch 00000 | Loss 1.9456
17:17:35.036511 [0] Epoch: 000, Train: 0.1000, Val: 0.1060, Test: 0.0910
17:17:35.061330 [0] Epoch 00001 | Loss 1.9239
17:17:35.089632 [0] Epoch 00002 | Loss 1.8991
17:17:35.116591 [0] Epoch 00003 | Loss 1.8680
17:17:35.137951 [0] Epoch 00004 | Loss 1.8312
17:17:35.159440 [0] Epoch 00005 | Loss 1.7899
17:17:35.189397 [0] Epoch 00006 | Loss 1.7442
17:17:35.217814 [0] Epoch 00007 | Loss 1.6940
17:17:35.242960 [0] Epoch 00008 | Loss 1.6395
17:17:35.267431 [0] Epoch 00009 | Loss 1.5806
17:17:35.289014 [0] Epoch 00010 | Loss 1.5177
17:17:35.290586 [0] Epoch: 010, Train: 0.9500, Val: 0.7540, Test: 0.7440
17:17:35.317493 [0] Epoch 00011 | Loss 1.4512
17:17:35.339742 [0] Epoch 00012 | Loss 1.3814
17:17:35.369222 [0] Epoch 00013 | Loss 1.3090
17:17:35.388567 [0] Epoch 00014 | Loss 1.2347
17:17:35.412745 [0] Epoch 00015 | Loss 1.1591
17:17:35.440126 [0] Epoch 00016 | Loss 1.0830
17:17:35.465158 [0] Epoch 00017 | Loss 1.0074
17:17:35.486621 [0] Epoch 00018 | Loss 0.9331
17:17:35.511510 [0] Epoch 00019 | Loss 0.8609
17:17:35.533143 [0] Epoch 00020 | Loss 0.7914
17:17:35.534363 [0] Epoch: 020, Train: 0.9429, Val: 0.7860, Test: 0.7880
17:17:35.558741 [0] Epoch 00021 | Loss 0.7254
17:17:35.580866 [0] Epoch 00022 | Loss 0.6632
17:17:35.605943 [0] Epoch 00023 | Loss 0.6053
17:17:35.628196 [0] Epoch 00024 | Loss 0.5518
17:17:35.649629 [0] Epoch 00025 | Loss 0.5027
17:17:35.676026 [0] Epoch 00026 | Loss 0.4580
17:17:35.697394 [0] Epoch 00027 | Loss 0.4175
17:17:35.723571 [0] Epoch 00028 | Loss 0.3809
17:17:35.745660 [0] Epoch 00029 | Loss 0.3481
17:17:35.770117 [0] Epoch 00030 | Loss 0.3185
17:17:35.773030 [0] Epoch: 030, Train: 0.9714, Val: 0.8060, Test: 0.8090
17:17:35.794562 [0] Epoch 00031 | Loss 0.2921
17:17:35.821330 [0] Epoch 00032 | Loss 0.2683
17:17:35.845552 [0] Epoch 00033 | Loss 0.2470
17:17:35.870967 [0] Epoch 00034 | Loss 0.2279
17:17:35.905236 [0] Epoch 00035 | Loss 0.2106
17:17:35.931196 [0] Epoch 00036 | Loss 0.1951
17:17:35.960529 [0] Epoch 00037 | Loss 0.1811
17:17:35.983744 [0] Epoch 00038 | Loss 0.1684
17:17:36.005318 [0] Epoch 00039 | Loss 0.1570
17:17:36.027141 [0] Epoch 00040 | Loss 0.1465
17:17:36.028522 [0] Epoch: 040, Train: 0.9786, Val: 0.7980, Test: 0.8050
17:17:36.050880 [0] Epoch 00041 | Loss 0.1371
17:17:36.065946 [0] Epoch 00042 | Loss 0.1284
17:17:36.082045 [0] Epoch 00043 | Loss 0.1205
17:17:36.101377 [0] Epoch 00044 | Loss 0.1133
17:17:36.120119 [0] Epoch 00045 | Loss 0.1067
17:17:36.144547 [0] Epoch 00046 | Loss 0.1007
17:17:36.165819 [0] Epoch 00047 | Loss 0.0952
17:17:36.188002 [0] Epoch 00048 | Loss 0.0901
17:17:36.215357 [0] Epoch 00049 | Loss 0.0854
17:17:36.216386 [0] Epoch: 049, Train: 1.0000, Val: 0.7880, Test: 0.8000
17:17:36.217328 [0] 
timer summary:
  0.93s   0.04s   200 mm
  0.34s   0.07s  1000 broadcast
  1.00s   0.01s  1000 spmm
  0.06s   0.00s   100 all_reduce
  2.54s   0.01s    50 epoch
  4.36s   0.00s     1 total
17:03:03.191006 [0] proc begin: <DistEnv 0/2 nccl>
17:03:03.823807 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
17:03:03.840294 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Active memory         |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   7670 KiB |   7691 KiB |   7736 KiB |  67724 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     91 KiB |    112 KiB |    157 KiB |  67724 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22528 KiB |  22528 KiB |  22528 KiB |      0 B   |
|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14854 KiB |  14918 KiB |  15014 KiB | 164352 B   |
|       from large pool |  12900 KiB |  12900 KiB |  12900 KiB |      0 B   |
|       from small pool |   1953 KiB |   2045 KiB |   2114 KiB | 164352 B   |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

17:03:05.913103 [0] Epoch 00000 | Loss 1.9455
17:03:05.982292 [0] Epoch: 000, Train: 0.1000, Val: 0.1120, Test: 0.1040
17:03:06.070604 [0] Epoch 00001 | Loss 1.9171
17:03:06.073755 [0] Epoch: 001, Train: 0.9786, Val: 0.5640, Test: 0.5620
17:03:06.081877 [0] Epoch 00002 | Loss 1.8858
17:03:06.084295 [0] Epoch: 002, Train: 0.9857, Val: 0.6440, Test: 0.6610
17:03:06.093296 [0] Epoch 00003 | Loss 1.8471
17:03:06.096144 [0] Epoch: 003, Train: 0.9857, Val: 0.6700, Test: 0.6860
17:03:06.103344 [0] Epoch 00004 | Loss 1.8011
17:03:06.105105 [0] Epoch: 004, Train: 0.9857, Val: 0.6860, Test: 0.6960
17:03:06.109288 [0] Epoch 00005 | Loss 1.7490
17:03:06.131102 [0] Epoch: 005, Train: 0.9857, Val: 0.6920, Test: 0.7000
17:03:06.161183 [0] Epoch 00006 | Loss 1.6910
17:03:06.164444 [0] Epoch: 006, Train: 0.9857, Val: 0.7020, Test: 0.7010
17:03:06.174292 [0] Epoch 00007 | Loss 1.6272
17:03:06.177857 [0] Epoch: 007, Train: 0.9857, Val: 0.7020, Test: 0.7050
17:03:06.199881 [0] Epoch 00008 | Loss 1.5577
17:03:06.246097 [0] Epoch: 008, Train: 0.9857, Val: 0.7000, Test: 0.7150
17:03:06.330374 [0] Epoch 00009 | Loss 1.4829
17:03:06.373536 [0] Epoch: 009, Train: 0.9857, Val: 0.7020, Test: 0.7170
17:03:06.414243 [0] Epoch 00010 | Loss 1.4032
17:03:06.417118 [0] Epoch: 010, Train: 0.9929, Val: 0.7040, Test: 0.7200
17:03:06.423268 [0] Epoch 00011 | Loss 1.3192
17:03:06.451140 [0] Epoch: 011, Train: 0.9929, Val: 0.7040, Test: 0.7220
17:03:06.552228 [0] Epoch 00012 | Loss 1.2319
17:03:06.558364 [0] Epoch: 012, Train: 0.9929, Val: 0.7080, Test: 0.7240
17:03:06.569725 [0] Epoch 00013 | Loss 1.1420
17:03:06.570959 [0] Epoch: 013, Train: 0.9929, Val: 0.7060, Test: 0.7260
17:03:06.577379 [0] Epoch 00014 | Loss 1.0506
17:03:06.578482 [0] Epoch: 014, Train: 0.9929, Val: 0.7080, Test: 0.7300
17:03:06.583145 [0] Epoch 00015 | Loss 0.9590
17:03:06.584384 [0] Epoch: 015, Train: 0.9929, Val: 0.7100, Test: 0.7350
17:03:06.623693 [0] Epoch 00016 | Loss 0.8683
17:03:06.627140 [0] Epoch: 016, Train: 0.9929, Val: 0.7120, Test: 0.7360
17:03:06.636373 [0] Epoch 00017 | Loss 0.7798
17:03:06.641303 [0] Epoch: 017, Train: 0.9929, Val: 0.7180, Test: 0.7400
17:03:06.654919 [0] Epoch 00018 | Loss 0.6949
17:03:06.658266 [0] Epoch: 018, Train: 0.9929, Val: 0.7200, Test: 0.7420
17:03:06.668809 [0] Epoch 00019 | Loss 0.6144
17:03:06.672167 [0] Epoch: 019, Train: 0.9929, Val: 0.7260, Test: 0.7540
17:03:06.684590 [0] Epoch 00020 | Loss 0.5394
17:03:06.705515 [0] Epoch: 020, Train: 0.9929, Val: 0.7300, Test: 0.7600
17:03:06.756660 [0] Epoch 00021 | Loss 0.4704
17:03:06.784129 [0] Epoch: 021, Train: 0.9929, Val: 0.7280, Test: 0.7620
17:03:06.857698 [0] Epoch 00022 | Loss 0.4078
17:03:06.912082 [0] Epoch: 022, Train: 0.9929, Val: 0.7240, Test: 0.7610
17:03:07.026085 [0] Epoch 00023 | Loss 0.3518
17:03:07.058106 [0] Epoch: 023, Train: 0.9929, Val: 0.7280, Test: 0.7630
17:03:07.142260 [0] Epoch 00024 | Loss 0.3021
17:03:07.194320 [0] Epoch: 024, Train: 0.9929, Val: 0.7340, Test: 0.7640
17:03:07.313533 [0] Epoch 00025 | Loss 0.2586
17:03:07.331221 [0] Epoch: 025, Train: 0.9929, Val: 0.7380, Test: 0.7620
17:03:07.410678 [0] Epoch 00026 | Loss 0.2207
17:03:07.447221 [0] Epoch: 026, Train: 0.9929, Val: 0.7380, Test: 0.7660
17:03:07.562602 [0] Epoch 00027 | Loss 0.1881
17:03:07.567771 [0] Epoch: 027, Train: 1.0000, Val: 0.7440, Test: 0.7740
17:03:07.656589 [0] Epoch 00028 | Loss 0.1601
17:03:07.663054 [0] Epoch: 028, Train: 1.0000, Val: 0.7440, Test: 0.7770
17:03:07.674940 [0] Epoch 00029 | Loss 0.1362
17:03:07.676206 [0] Epoch: 029, Train: 1.0000, Val: 0.7460, Test: 0.7800
17:03:07.680453 [0] Epoch 00030 | Loss 0.1159
17:03:07.681629 [0] Epoch: 030, Train: 1.0000, Val: 0.7460, Test: 0.7790
17:03:07.689107 [0] Epoch 00031 | Loss 0.0988
17:03:07.692046 [0] Epoch: 031, Train: 1.0000, Val: 0.7480, Test: 0.7780
17:03:07.700854 [0] Epoch 00032 | Loss 0.0843
17:03:07.703986 [0] Epoch: 032, Train: 1.0000, Val: 0.7480, Test: 0.7780
17:03:07.736894 [0] Epoch 00033 | Loss 0.0722
17:03:07.764535 [0] Epoch: 033, Train: 1.0000, Val: 0.7480, Test: 0.7780
17:03:07.844145 [0] Epoch 00034 | Loss 0.0620
17:03:07.871594 [0] Epoch: 034, Train: 1.0000, Val: 0.7460, Test: 0.7750
17:03:07.910458 [0] Epoch 00035 | Loss 0.0535
17:03:07.914550 [0] Epoch: 035, Train: 1.0000, Val: 0.7440, Test: 0.7730
17:03:07.921877 [0] Epoch 00036 | Loss 0.0463
17:03:07.923187 [0] Epoch: 036, Train: 1.0000, Val: 0.7440, Test: 0.7750
17:03:07.928047 [0] Epoch 00037 | Loss 0.0403
17:03:07.929251 [0] Epoch: 037, Train: 1.0000, Val: 0.7420, Test: 0.7740
17:03:07.936956 [0] Epoch 00038 | Loss 0.0352
17:03:07.938238 [0] Epoch: 038, Train: 1.0000, Val: 0.7420, Test: 0.7750
17:03:07.996279 [0] Epoch 00039 | Loss 0.0310
17:03:08.023781 [0] Epoch: 039, Train: 1.0000, Val: 0.7380, Test: 0.7730
17:03:08.065528 [0] Epoch 00040 | Loss 0.0274
17:03:08.066699 [0] Epoch: 040, Train: 1.0000, Val: 0.7400, Test: 0.7710
17:03:08.072525 [0] Epoch 00041 | Loss 0.0243
17:03:08.073668 [0] Epoch: 041, Train: 1.0000, Val: 0.7400, Test: 0.7700
17:03:08.078842 [0] Epoch 00042 | Loss 0.0218
17:03:08.079912 [0] Epoch: 042, Train: 1.0000, Val: 0.7400, Test: 0.7700
17:03:08.083944 [0] Epoch 00043 | Loss 0.0196
17:03:08.085055 [0] Epoch: 043, Train: 1.0000, Val: 0.7400, Test: 0.7660
17:03:08.090226 [0] Epoch 00044 | Loss 0.0177
17:03:08.092746 [0] Epoch: 044, Train: 1.0000, Val: 0.7400, Test: 0.7640
17:03:08.099786 [0] Epoch 00045 | Loss 0.0161
17:03:08.102113 [0] Epoch: 045, Train: 1.0000, Val: 0.7420, Test: 0.7620
17:03:08.110695 [0] Epoch 00046 | Loss 0.0147
17:03:08.113777 [0] Epoch: 046, Train: 1.0000, Val: 0.7420, Test: 0.7620
17:03:08.122162 [0] Epoch 00047 | Loss 0.0135
17:03:08.123307 [0] Epoch: 047, Train: 1.0000, Val: 0.7420, Test: 0.7610
17:03:08.128053 [0] Epoch 00048 | Loss 0.0124
17:03:08.129129 [0] Epoch: 048, Train: 1.0000, Val: 0.7420, Test: 0.7590
17:03:08.133333 [0] Epoch 00049 | Loss 0.0115
17:03:08.134445 [0] Epoch: 049, Train: 1.0000, Val: 0.7400, Test: 0.7580
17:03:08.138794 [0] Epoch 00050 | Loss 0.0107
17:03:08.139895 [0] Epoch: 050, Train: 1.0000, Val: 0.7400, Test: 0.7560
17:03:08.144750 [0] Epoch 00051 | Loss 0.0100
17:03:08.145890 [0] Epoch: 051, Train: 1.0000, Val: 0.7400, Test: 0.7560
17:03:08.149730 [0] Epoch 00052 | Loss 0.0094
17:03:08.152447 [0] Epoch: 052, Train: 1.0000, Val: 0.7400, Test: 0.7560
17:03:08.160315 [0] Epoch 00053 | Loss 0.0088
17:03:08.161572 [0] Epoch: 053, Train: 1.0000, Val: 0.7400, Test: 0.7560
17:03:08.170101 [0] Epoch 00054 | Loss 0.0083
17:03:08.173091 [0] Epoch: 054, Train: 1.0000, Val: 0.7400, Test: 0.7550
17:03:08.179016 [0] Epoch 00055 | Loss 0.0079
17:03:08.180167 [0] Epoch: 055, Train: 1.0000, Val: 0.7380, Test: 0.7550
17:03:08.185841 [0] Epoch 00056 | Loss 0.0075
17:03:08.189392 [0] Epoch: 056, Train: 1.0000, Val: 0.7380, Test: 0.7540
17:03:08.203767 [0] Epoch 00057 | Loss 0.0071
17:03:08.206951 [0] Epoch: 057, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:08.215891 [0] Epoch 00058 | Loss 0.0068
17:03:08.218977 [0] Epoch: 058, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:08.229413 [0] Epoch 00059 | Loss 0.0065
17:03:08.232785 [0] Epoch: 059, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:08.270167 [0] Epoch 00060 | Loss 0.0063
17:03:08.300197 [0] Epoch: 060, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:08.371173 [0] Epoch 00061 | Loss 0.0060
17:03:08.398656 [0] Epoch: 061, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:08.421499 [0] Epoch 00062 | Loss 0.0058
17:03:08.426254 [0] Epoch: 062, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:08.436254 [0] Epoch 00063 | Loss 0.0056
17:03:08.437646 [0] Epoch: 063, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:08.442198 [0] Epoch 00064 | Loss 0.0054
17:03:08.443883 [0] Epoch: 064, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:08.494962 [0] Epoch 00065 | Loss 0.0053
17:03:08.526965 [0] Epoch: 065, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:08.570864 [0] Epoch 00066 | Loss 0.0051
17:03:08.572099 [0] Epoch: 066, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:08.576525 [0] Epoch 00067 | Loss 0.0050
17:03:08.577680 [0] Epoch: 067, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:08.617082 [0] Epoch 00068 | Loss 0.0048
17:03:08.618319 [0] Epoch: 068, Train: 1.0000, Val: 0.7360, Test: 0.7570
17:03:08.623554 [0] Epoch 00069 | Loss 0.0047
17:03:08.624835 [0] Epoch: 069, Train: 1.0000, Val: 0.7380, Test: 0.7570
17:03:08.629326 [0] Epoch 00070 | Loss 0.0046
17:03:08.630411 [0] Epoch: 070, Train: 1.0000, Val: 0.7380, Test: 0.7570
17:03:08.634264 [0] Epoch 00071 | Loss 0.0045
17:03:08.635376 [0] Epoch: 071, Train: 1.0000, Val: 0.7380, Test: 0.7580
17:03:08.639239 [0] Epoch 00072 | Loss 0.0044
17:03:08.640300 [0] Epoch: 072, Train: 1.0000, Val: 0.7380, Test: 0.7580
17:03:08.644438 [0] Epoch 00073 | Loss 0.0043
17:03:08.645541 [0] Epoch: 073, Train: 1.0000, Val: 0.7380, Test: 0.7580
17:03:08.653793 [0] Epoch 00074 | Loss 0.0042
17:03:08.668383 [0] Epoch: 074, Train: 1.0000, Val: 0.7360, Test: 0.7580
17:03:08.688233 [0] Epoch 00075 | Loss 0.0041
17:03:08.690354 [0] Epoch: 075, Train: 1.0000, Val: 0.7380, Test: 0.7570
17:03:08.696267 [0] Epoch 00076 | Loss 0.0040
17:03:08.697449 [0] Epoch: 076, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.701619 [0] Epoch 00077 | Loss 0.0039
17:03:08.702681 [0] Epoch: 077, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.707202 [0] Epoch 00078 | Loss 0.0039
17:03:08.708283 [0] Epoch: 078, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.712573 [0] Epoch 00079 | Loss 0.0038
17:03:08.713665 [0] Epoch: 079, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.717551 [0] Epoch 00080 | Loss 0.0037
17:03:08.718654 [0] Epoch: 080, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.757691 [0] Epoch 00081 | Loss 0.0037
17:03:08.760382 [0] Epoch: 081, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.766471 [0] Epoch 00082 | Loss 0.0036
17:03:08.768178 [0] Epoch: 082, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.772929 [0] Epoch 00083 | Loss 0.0036
17:03:08.774027 [0] Epoch: 083, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.778668 [0] Epoch 00084 | Loss 0.0035
17:03:08.779743 [0] Epoch: 084, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.784214 [0] Epoch 00085 | Loss 0.0035
17:03:08.785302 [0] Epoch: 085, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.789132 [0] Epoch 00086 | Loss 0.0034
17:03:08.808344 [0] Epoch: 086, Train: 1.0000, Val: 0.7380, Test: 0.7560
17:03:08.828078 [0] Epoch 00087 | Loss 0.0034
17:03:08.830894 [0] Epoch: 087, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.838429 [0] Epoch 00088 | Loss 0.0033
17:03:08.839542 [0] Epoch: 088, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.844196 [0] Epoch 00089 | Loss 0.0033
17:03:08.845442 [0] Epoch: 089, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.850265 [0] Epoch 00090 | Loss 0.0032
17:03:08.851490 [0] Epoch: 090, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.856241 [0] Epoch 00091 | Loss 0.0032
17:03:08.857314 [0] Epoch: 091, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.879043 [0] Epoch 00092 | Loss 0.0031
17:03:08.883882 [0] Epoch: 092, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.900571 [0] Epoch 00093 | Loss 0.0031
17:03:08.901761 [0] Epoch: 093, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:08.906130 [0] Epoch 00094 | Loss 0.0031
17:03:08.907186 [0] Epoch: 094, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:08.911298 [0] Epoch 00095 | Loss 0.0030
17:03:08.912293 [0] Epoch: 095, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:08.916144 [0] Epoch 00096 | Loss 0.0030
17:03:08.917223 [0] Epoch: 096, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:08.921228 [0] Epoch 00097 | Loss 0.0029
17:03:08.922439 [0] Epoch: 097, Train: 1.0000, Val: 0.7340, Test: 0.7560
17:03:08.926997 [0] Epoch 00098 | Loss 0.0029
17:03:08.928606 [0] Epoch: 098, Train: 1.0000, Val: 0.7340, Test: 0.7560
17:03:08.950978 [0] Epoch 00099 | Loss 0.0029
17:03:08.963402 [0] Epoch: 099, Train: 1.0000, Val: 0.7340, Test: 0.7560
17:03:08.985181 [0] Epoch 00100 | Loss 0.0028
17:03:08.987041 [0] Epoch: 100, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:08.993228 [0] Epoch 00101 | Loss 0.0028
17:03:08.995051 [0] Epoch: 101, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.000910 [0] Epoch 00102 | Loss 0.0028
17:03:09.003338 [0] Epoch: 102, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.012173 [0] Epoch 00103 | Loss 0.0027
17:03:09.015596 [0] Epoch: 103, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:09.044735 [0] Epoch 00104 | Loss 0.0027
17:03:09.051744 [0] Epoch: 104, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:09.071030 [0] Epoch 00105 | Loss 0.0027
17:03:09.072136 [0] Epoch: 105, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.076421 [0] Epoch 00106 | Loss 0.0027
17:03:09.077685 [0] Epoch: 106, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.082510 [0] Epoch 00107 | Loss 0.0026
17:03:09.083755 [0] Epoch: 107, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.088680 [0] Epoch 00108 | Loss 0.0026
17:03:09.090858 [0] Epoch: 108, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.107295 [0] Epoch 00109 | Loss 0.0026
17:03:09.117811 [0] Epoch: 109, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.139520 [0] Epoch 00110 | Loss 0.0025
17:03:09.140676 [0] Epoch: 110, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.148064 [0] Epoch 00111 | Loss 0.0025
17:03:09.150002 [0] Epoch: 111, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.155061 [0] Epoch 00112 | Loss 0.0025
17:03:09.157815 [0] Epoch: 112, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.166594 [0] Epoch 00113 | Loss 0.0025
17:03:09.170664 [0] Epoch: 113, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.197985 [0] Epoch 00114 | Loss 0.0024
17:03:09.209535 [0] Epoch: 114, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.269074 [0] Epoch 00115 | Loss 0.0024
17:03:09.296655 [0] Epoch: 115, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.383874 [0] Epoch 00116 | Loss 0.0024
17:03:09.394424 [0] Epoch: 116, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.400390 [0] Epoch 00117 | Loss 0.0024
17:03:09.429351 [0] Epoch: 117, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.480684 [0] Epoch 00118 | Loss 0.0023
17:03:09.508301 [0] Epoch: 118, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.589509 [0] Epoch 00119 | Loss 0.0023
17:03:09.593348 [0] Epoch: 119, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.599202 [0] Epoch 00120 | Loss 0.0023
17:03:09.600241 [0] Epoch: 120, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.604814 [0] Epoch 00121 | Loss 0.0023
17:03:09.608090 [0] Epoch: 121, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.614105 [0] Epoch 00122 | Loss 0.0022
17:03:09.615312 [0] Epoch: 122, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:09.621795 [0] Epoch 00123 | Loss 0.0022
17:03:09.623334 [0] Epoch: 123, Train: 1.0000, Val: 0.7360, Test: 0.7560
17:03:09.671603 [0] Epoch 00124 | Loss 0.0022
17:03:09.703901 [0] Epoch: 124, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:09.792790 [0] Epoch 00125 | Loss 0.0022
17:03:09.824912 [0] Epoch: 125, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:09.858289 [0] Epoch 00126 | Loss 0.0022
17:03:09.859778 [0] Epoch: 126, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:09.930005 [0] Epoch 00127 | Loss 0.0021
17:03:09.957511 [0] Epoch: 127, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.027530 [0] Epoch 00128 | Loss 0.0021
17:03:10.032813 [0] Epoch: 128, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.048537 [0] Epoch 00129 | Loss 0.0021
17:03:10.051702 [0] Epoch: 129, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.061466 [0] Epoch 00130 | Loss 0.0021
17:03:10.062623 [0] Epoch: 130, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.067030 [0] Epoch 00131 | Loss 0.0021
17:03:10.069650 [0] Epoch: 131, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.074219 [0] Epoch 00132 | Loss 0.0020
17:03:10.077086 [0] Epoch: 132, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.134595 [0] Epoch 00133 | Loss 0.0020
17:03:10.138981 [0] Epoch: 133, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.187190 [0] Epoch 00134 | Loss 0.0020
17:03:10.230495 [0] Epoch: 134, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.305585 [0] Epoch 00135 | Loss 0.0020
17:03:10.335817 [0] Epoch: 135, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.399516 [0] Epoch 00136 | Loss 0.0020
17:03:10.427030 [0] Epoch: 136, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.493363 [0] Epoch 00137 | Loss 0.0020
17:03:10.498125 [0] Epoch: 137, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.508793 [0] Epoch 00138 | Loss 0.0019
17:03:10.509936 [0] Epoch: 138, Train: 1.0000, Val: 0.7360, Test: 0.7550
17:03:10.515831 [0] Epoch 00139 | Loss 0.0019
17:03:10.517272 [0] Epoch: 139, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.522041 [0] Epoch 00140 | Loss 0.0019
17:03:10.526110 [0] Epoch: 140, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.577512 [0] Epoch 00141 | Loss 0.0019
17:03:10.580774 [0] Epoch: 141, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.591401 [0] Epoch 00142 | Loss 0.0019
17:03:10.595042 [0] Epoch: 142, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.651186 [0] Epoch 00143 | Loss 0.0019
17:03:10.690009 [0] Epoch: 143, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.761207 [0] Epoch 00144 | Loss 0.0018
17:03:10.804719 [0] Epoch: 144, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.833013 [0] Epoch 00145 | Loss 0.0018
17:03:10.860778 [0] Epoch: 145, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.951814 [0] Epoch 00146 | Loss 0.0018
17:03:10.962223 [0] Epoch: 146, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.975625 [0] Epoch 00147 | Loss 0.0018
17:03:10.976748 [0] Epoch: 147, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.982363 [0] Epoch 00148 | Loss 0.0018
17:03:10.983587 [0] Epoch: 148, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.988572 [0] Epoch 00149 | Loss 0.0018
17:03:10.989799 [0] Epoch: 149, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:10.994374 [0] Epoch 00150 | Loss 0.0017
17:03:10.997331 [0] Epoch: 150, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:11.008314 [0] Epoch 00151 | Loss 0.0017
17:03:11.024700 [0] Epoch: 151, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:11.046741 [0] Epoch 00152 | Loss 0.0017
17:03:11.050360 [0] Epoch: 152, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:11.059908 [0] Epoch 00153 | Loss 0.0017
17:03:11.063919 [0] Epoch: 153, Train: 1.0000, Val: 0.7360, Test: 0.7540
17:03:11.074448 [0] Epoch 00154 | Loss 0.0017
17:03:11.077583 [0] Epoch: 154, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.086617 [0] Epoch 00155 | Loss 0.0017
17:03:11.089208 [0] Epoch: 155, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.100221 [0] Epoch 00156 | Loss 0.0017
17:03:11.146197 [0] Epoch: 156, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.230587 [0] Epoch 00157 | Loss 0.0016
17:03:11.258215 [0] Epoch: 157, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.318939 [0] Epoch 00158 | Loss 0.0016
17:03:11.320591 [0] Epoch: 158, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.360011 [0] Epoch 00159 | Loss 0.0016
17:03:11.405743 [0] Epoch: 159, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.458645 [0] Epoch 00160 | Loss 0.0016
17:03:11.460440 [0] Epoch: 160, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.466142 [0] Epoch 00161 | Loss 0.0016
17:03:11.467830 [0] Epoch: 161, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.473277 [0] Epoch 00162 | Loss 0.0016
17:03:11.474297 [0] Epoch: 162, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.478909 [0] Epoch 00163 | Loss 0.0016
17:03:11.481374 [0] Epoch: 163, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.514892 [0] Epoch 00164 | Loss 0.0016
17:03:11.522472 [0] Epoch: 164, Train: 1.0000, Val: 0.7340, Test: 0.7550
17:03:11.535544 [0] Epoch 00165 | Loss 0.0015
17:03:11.538689 [0] Epoch: 165, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.545430 [0] Epoch 00166 | Loss 0.0015
17:03:11.548078 [0] Epoch: 166, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.555275 [0] Epoch 00167 | Loss 0.0015
17:03:11.556322 [0] Epoch: 167, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.563810 [0] Epoch 00168 | Loss 0.0015
17:03:11.592243 [0] Epoch: 168, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.626043 [0] Epoch 00169 | Loss 0.0015
17:03:11.641047 [0] Epoch: 169, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.735426 [0] Epoch 00170 | Loss 0.0015
17:03:11.767346 [0] Epoch: 170, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.793934 [0] Epoch 00171 | Loss 0.0015
17:03:11.819235 [0] Epoch: 171, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.853470 [0] Epoch 00172 | Loss 0.0015
17:03:11.881011 [0] Epoch: 172, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.967226 [0] Epoch 00173 | Loss 0.0014
17:03:11.971921 [0] Epoch: 173, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.981439 [0] Epoch 00174 | Loss 0.0014
17:03:11.983555 [0] Epoch: 174, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.991433 [0] Epoch 00175 | Loss 0.0014
17:03:11.992572 [0] Epoch: 175, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:11.997925 [0] Epoch 00176 | Loss 0.0014
17:03:11.999633 [0] Epoch: 176, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.007831 [0] Epoch 00177 | Loss 0.0014
17:03:12.009100 [0] Epoch: 177, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.026484 [0] Epoch 00178 | Loss 0.0014
17:03:12.031904 [0] Epoch: 178, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.055238 [0] Epoch 00179 | Loss 0.0014
17:03:12.058534 [0] Epoch: 179, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.067738 [0] Epoch 00180 | Loss 0.0014
17:03:12.069387 [0] Epoch: 180, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.074405 [0] Epoch 00181 | Loss 0.0014
17:03:12.076056 [0] Epoch: 181, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.081625 [0] Epoch 00182 | Loss 0.0013
17:03:12.082930 [0] Epoch: 182, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.088664 [0] Epoch 00183 | Loss 0.0013
17:03:12.106420 [0] Epoch: 183, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.148312 [0] Epoch 00184 | Loss 0.0013
17:03:12.151726 [0] Epoch: 184, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.238754 [0] Epoch 00185 | Loss 0.0013
17:03:12.273082 [0] Epoch: 185, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.319515 [0] Epoch 00186 | Loss 0.0013
17:03:12.323929 [0] Epoch: 186, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.378169 [0] Epoch 00187 | Loss 0.0013
17:03:12.405731 [0] Epoch: 187, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.495518 [0] Epoch 00188 | Loss 0.0013
17:03:12.502720 [0] Epoch: 188, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.513575 [0] Epoch 00189 | Loss 0.0013
17:03:12.516372 [0] Epoch: 189, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.522814 [0] Epoch 00190 | Loss 0.0013
17:03:12.525213 [0] Epoch: 190, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.531066 [0] Epoch 00191 | Loss 0.0013
17:03:12.532165 [0] Epoch: 191, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.538661 [0] Epoch 00192 | Loss 0.0013
17:03:12.541479 [0] Epoch: 192, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.547405 [0] Epoch 00193 | Loss 0.0012
17:03:12.548514 [0] Epoch: 193, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.554571 [0] Epoch 00194 | Loss 0.0012
17:03:12.555778 [0] Epoch: 194, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.560654 [0] Epoch 00195 | Loss 0.0012
17:03:12.562495 [0] Epoch: 195, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.568243 [0] Epoch 00196 | Loss 0.0012
17:03:12.569358 [0] Epoch: 196, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.573763 [0] Epoch 00197 | Loss 0.0012
17:03:12.574853 [0] Epoch: 197, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.579210 [0] Epoch 00198 | Loss 0.0012
17:03:12.580257 [0] Epoch: 198, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.584161 [0] Epoch 00199 | Loss 0.0012
17:03:12.585206 [0] Epoch: 199, Train: 1.0000, Val: 0.7340, Test: 0.7540
17:03:12.587065 [0] 
timer summary:
  0.48s   0.07s   800 mm
  2.58s   1.12s   800 broadcast
  0.56s   0.03s   800 spmm
  0.70s   0.07s   400 all_reduce
  8.00s   0.08s   200 epoch
  9.39s   0.00s     1 total
14:54:06.970353 [0] proc begin: <DistEnv 0/2 nccl>
14:54:07.318906 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
14:54:07.333043 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Active memory         |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   7670 KiB |   7691 KiB |   7736 KiB |  67724 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     91 KiB |    112 KiB |    157 KiB |  67724 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22528 KiB |  22528 KiB |  22528 KiB |      0 B   |
|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14854 KiB |  14918 KiB |  15014 KiB | 164352 B   |
|       from large pool |  12900 KiB |  12900 KiB |  12900 KiB |      0 B   |
|       from small pool |   1953 KiB |   2045 KiB |   2114 KiB | 164352 B   |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:54:09.317559 [0] Epoch 00000 | Loss 1.9456
14:54:09.361438 [0] Epoch: 000, Train: 0.1286, Val: 0.1160, Test: 0.0960
14:54:09.386508 [0] Epoch 00001 | Loss 1.9204
14:54:09.387783 [0] Epoch: 001, Train: 0.9714, Val: 0.7320, Test: 0.7120
14:54:09.392999 [0] Epoch 00002 | Loss 1.8889
14:54:09.394128 [0] Epoch: 002, Train: 0.9714, Val: 0.7560, Test: 0.7550
14:54:09.399071 [0] Epoch 00003 | Loss 1.8496
14:54:09.400161 [0] Epoch: 003, Train: 0.9714, Val: 0.7500, Test: 0.7500
14:54:09.407037 [0] Epoch 00004 | Loss 1.8050
14:54:09.408127 [0] Epoch: 004, Train: 0.9714, Val: 0.7420, Test: 0.7480
14:54:09.415995 [0] Epoch 00005 | Loss 1.7555
14:54:09.418513 [0] Epoch: 005, Train: 0.9786, Val: 0.7380, Test: 0.7450
14:54:09.423212 [0] Epoch 00006 | Loss 1.7004
14:54:09.424845 [0] Epoch: 006, Train: 0.9786, Val: 0.7360, Test: 0.7440
14:54:09.433374 [0] Epoch 00007 | Loss 1.6398
14:54:09.434344 [0] Epoch: 007, Train: 0.9786, Val: 0.7400, Test: 0.7470
14:54:09.439518 [0] Epoch 00008 | Loss 1.5737
14:54:09.440809 [0] Epoch: 008, Train: 0.9786, Val: 0.7500, Test: 0.7490
14:54:09.447291 [0] Epoch 00009 | Loss 1.5024
14:54:09.449767 [0] Epoch: 009, Train: 0.9786, Val: 0.7500, Test: 0.7510
14:54:09.456754 [0] Epoch 00010 | Loss 1.4266
14:54:09.458087 [0] Epoch: 010, Train: 0.9786, Val: 0.7540, Test: 0.7530
14:54:09.464433 [0] Epoch 00011 | Loss 1.3467
14:54:09.465824 [0] Epoch: 011, Train: 0.9786, Val: 0.7600, Test: 0.7550
14:54:09.471770 [0] Epoch 00012 | Loss 1.2634
14:54:09.472909 [0] Epoch: 012, Train: 0.9786, Val: 0.7640, Test: 0.7550
14:54:09.479282 [0] Epoch 00013 | Loss 1.1775
14:54:09.480523 [0] Epoch: 013, Train: 0.9786, Val: 0.7660, Test: 0.7550
14:54:09.486757 [0] Epoch 00014 | Loss 1.0900
14:54:09.488184 [0] Epoch: 014, Train: 0.9786, Val: 0.7680, Test: 0.7580
14:54:09.494539 [0] Epoch 00015 | Loss 1.0019
14:54:09.495759 [0] Epoch: 015, Train: 0.9786, Val: 0.7680, Test: 0.7600
14:54:09.502148 [0] Epoch 00016 | Loss 0.9145
14:54:09.503360 [0] Epoch: 016, Train: 0.9786, Val: 0.7680, Test: 0.7650
14:54:09.509247 [0] Epoch 00017 | Loss 0.8290
14:54:09.510641 [0] Epoch: 017, Train: 0.9786, Val: 0.7720, Test: 0.7680
14:54:09.516616 [0] Epoch 00018 | Loss 0.7464
14:54:09.517708 [0] Epoch: 018, Train: 0.9786, Val: 0.7720, Test: 0.7700
14:54:09.523860 [0] Epoch 00019 | Loss 0.6679
14:54:09.526109 [0] Epoch: 019, Train: 0.9786, Val: 0.7740, Test: 0.7730
14:54:09.533701 [0] Epoch 00020 | Loss 0.5943
14:54:09.535420 [0] Epoch: 020, Train: 0.9786, Val: 0.7760, Test: 0.7780
14:54:09.542187 [0] Epoch 00021 | Loss 0.5263
14:54:09.543878 [0] Epoch: 021, Train: 0.9857, Val: 0.7820, Test: 0.7820
14:54:09.550965 [0] Epoch 00022 | Loss 0.4642
14:54:09.552481 [0] Epoch: 022, Train: 0.9857, Val: 0.7880, Test: 0.7830
14:54:09.559068 [0] Epoch 00023 | Loss 0.4082
14:54:09.560866 [0] Epoch: 023, Train: 0.9857, Val: 0.7880, Test: 0.7870
14:54:09.567903 [0] Epoch 00024 | Loss 0.3581
14:54:09.569576 [0] Epoch: 024, Train: 0.9857, Val: 0.7880, Test: 0.7910
14:54:09.576439 [0] Epoch 00025 | Loss 0.3138
14:54:09.578052 [0] Epoch: 025, Train: 0.9857, Val: 0.7880, Test: 0.7920
14:54:09.584640 [0] Epoch 00026 | Loss 0.2747
14:54:09.586143 [0] Epoch: 026, Train: 0.9857, Val: 0.7820, Test: 0.7930
14:54:09.592589 [0] Epoch 00027 | Loss 0.2406
14:54:09.594215 [0] Epoch: 027, Train: 0.9857, Val: 0.7820, Test: 0.7960
14:54:09.600994 [0] Epoch 00028 | Loss 0.2108
14:54:09.602518 [0] Epoch: 028, Train: 0.9857, Val: 0.7880, Test: 0.7950
14:54:09.608909 [0] Epoch 00029 | Loss 0.1849
14:54:09.610427 [0] Epoch: 029, Train: 0.9857, Val: 0.7880, Test: 0.7960
14:54:09.617683 [0] Epoch 00030 | Loss 0.1624
14:54:09.619268 [0] Epoch: 030, Train: 0.9857, Val: 0.7900, Test: 0.7980
14:54:09.626199 [0] Epoch 00031 | Loss 0.1429
14:54:09.628747 [0] Epoch: 031, Train: 0.9857, Val: 0.7900, Test: 0.7990
14:54:09.637876 [0] Epoch 00032 | Loss 0.1260
14:54:09.639559 [0] Epoch: 032, Train: 0.9857, Val: 0.7860, Test: 0.7990
14:54:09.647555 [0] Epoch 00033 | Loss 0.1112
14:54:09.648817 [0] Epoch: 033, Train: 0.9929, Val: 0.7840, Test: 0.7990
14:54:09.655525 [0] Epoch 00034 | Loss 0.0984
14:54:09.656770 [0] Epoch: 034, Train: 1.0000, Val: 0.7840, Test: 0.7990
14:54:09.662903 [0] Epoch 00035 | Loss 0.0873
14:54:09.664203 [0] Epoch: 035, Train: 1.0000, Val: 0.7820, Test: 0.8000
14:54:09.671364 [0] Epoch 00036 | Loss 0.0776
14:54:09.672562 [0] Epoch: 036, Train: 1.0000, Val: 0.7800, Test: 0.8000
14:54:09.679434 [0] Epoch 00037 | Loss 0.0692
14:54:09.680665 [0] Epoch: 037, Train: 1.0000, Val: 0.7820, Test: 0.7990
14:54:09.687035 [0] Epoch 00038 | Loss 0.0620
14:54:09.688358 [0] Epoch: 038, Train: 1.0000, Val: 0.7800, Test: 0.7950
14:54:09.695425 [0] Epoch 00039 | Loss 0.0556
14:54:09.696685 [0] Epoch: 039, Train: 1.0000, Val: 0.7840, Test: 0.7930
14:54:09.703334 [0] Epoch 00040 | Loss 0.0501
14:54:09.704595 [0] Epoch: 040, Train: 1.0000, Val: 0.7840, Test: 0.7930
14:54:09.711523 [0] Epoch 00041 | Loss 0.0453
14:54:09.712845 [0] Epoch: 041, Train: 1.0000, Val: 0.7840, Test: 0.7940
14:54:09.718931 [0] Epoch 00042 | Loss 0.0411
14:54:09.720142 [0] Epoch: 042, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:09.726491 [0] Epoch 00043 | Loss 0.0375
14:54:09.727661 [0] Epoch: 043, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:09.734706 [0] Epoch 00044 | Loss 0.0342
14:54:09.735936 [0] Epoch: 044, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.742222 [0] Epoch 00045 | Loss 0.0314
14:54:09.743437 [0] Epoch: 045, Train: 1.0000, Val: 0.7820, Test: 0.7880
14:54:09.749659 [0] Epoch 00046 | Loss 0.0289
14:54:09.750978 [0] Epoch: 046, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:09.757909 [0] Epoch 00047 | Loss 0.0267
14:54:09.759197 [0] Epoch: 047, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:09.765443 [0] Epoch 00048 | Loss 0.0247
14:54:09.766752 [0] Epoch: 048, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:09.773518 [0] Epoch 00049 | Loss 0.0230
14:54:09.774844 [0] Epoch: 049, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:09.780557 [0] Epoch 00050 | Loss 0.0215
14:54:09.781849 [0] Epoch: 050, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:09.787758 [0] Epoch 00051 | Loss 0.0209
14:54:09.789022 [0] Epoch: 051, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:09.796275 [0] Epoch 00052 | Loss 0.0188
14:54:09.797485 [0] Epoch: 052, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:09.803041 [0] Epoch 00053 | Loss 0.0184
14:54:09.804440 [0] Epoch: 053, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:09.810595 [0] Epoch 00054 | Loss 0.0167
14:54:09.811804 [0] Epoch: 054, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:09.818706 [0] Epoch 00055 | Loss 0.0164
14:54:09.821007 [0] Epoch: 055, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:09.830300 [0] Epoch 00056 | Loss 0.0150
14:54:09.831466 [0] Epoch: 056, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:09.837821 [0] Epoch 00057 | Loss 0.0147
14:54:09.839649 [0] Epoch: 057, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:09.846965 [0] Epoch 00058 | Loss 0.0136
14:54:09.848148 [0] Epoch: 058, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:09.853954 [0] Epoch 00059 | Loss 0.0133
14:54:09.855078 [0] Epoch: 059, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:09.863286 [0] Epoch 00060 | Loss 0.0123
14:54:09.865451 [0] Epoch: 060, Train: 1.0000, Val: 0.7840, Test: 0.7900
14:54:09.873186 [0] Epoch 00061 | Loss 0.0122
14:54:09.874621 [0] Epoch: 061, Train: 1.0000, Val: 0.7840, Test: 0.7900
14:54:09.880619 [0] Epoch 00062 | Loss 0.0113
14:54:09.882007 [0] Epoch: 062, Train: 1.0000, Val: 0.7840, Test: 0.7910
14:54:09.887611 [0] Epoch 00063 | Loss 0.0112
14:54:09.888720 [0] Epoch: 063, Train: 1.0000, Val: 0.7840, Test: 0.7910
14:54:09.894989 [0] Epoch 00064 | Loss 0.0105
14:54:09.896130 [0] Epoch: 064, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.901470 [0] Epoch 00065 | Loss 0.0103
14:54:09.902579 [0] Epoch: 065, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.909318 [0] Epoch 00066 | Loss 0.0097
14:54:09.910498 [0] Epoch: 066, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.916010 [0] Epoch 00067 | Loss 0.0096
14:54:09.917397 [0] Epoch: 067, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.923847 [0] Epoch 00068 | Loss 0.0091
14:54:09.926663 [0] Epoch: 068, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:09.934528 [0] Epoch 00069 | Loss 0.0090
14:54:09.935906 [0] Epoch: 069, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:09.942216 [0] Epoch 00070 | Loss 0.0085
14:54:09.943365 [0] Epoch: 070, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:09.949668 [0] Epoch 00071 | Loss 0.0084
14:54:09.950883 [0] Epoch: 071, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:09.956212 [0] Epoch 00072 | Loss 0.0080
14:54:09.957503 [0] Epoch: 072, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:09.965219 [0] Epoch 00073 | Loss 0.0080
14:54:09.966498 [0] Epoch: 073, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:09.973090 [0] Epoch 00074 | Loss 0.0076
14:54:09.974384 [0] Epoch: 074, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:09.979832 [0] Epoch 00075 | Loss 0.0075
14:54:09.981083 [0] Epoch: 075, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:09.987161 [0] Epoch 00076 | Loss 0.0072
14:54:09.988275 [0] Epoch: 076, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:09.994920 [0] Epoch 00077 | Loss 0.0072
14:54:09.996120 [0] Epoch: 077, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.001347 [0] Epoch 00078 | Loss 0.0069
14:54:10.002638 [0] Epoch: 078, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.008239 [0] Epoch 00079 | Loss 0.0068
14:54:10.009382 [0] Epoch: 079, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.016226 [0] Epoch 00080 | Loss 0.0066
14:54:10.017789 [0] Epoch: 080, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.023294 [0] Epoch 00081 | Loss 0.0065
14:54:10.024641 [0] Epoch: 081, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.030757 [0] Epoch 00082 | Loss 0.0063
14:54:10.031810 [0] Epoch: 082, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.038361 [0] Epoch 00083 | Loss 0.0062
14:54:10.039759 [0] Epoch: 083, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.045129 [0] Epoch 00084 | Loss 0.0060
14:54:10.046690 [0] Epoch: 084, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.052283 [0] Epoch 00085 | Loss 0.0060
14:54:10.053518 [0] Epoch: 085, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.060314 [0] Epoch 00086 | Loss 0.0058
14:54:10.062107 [0] Epoch: 086, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.068202 [0] Epoch 00087 | Loss 0.0058
14:54:10.069450 [0] Epoch: 087, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:10.077802 [0] Epoch 00088 | Loss 0.0056
14:54:10.078975 [0] Epoch: 088, Train: 1.0000, Val: 0.7800, Test: 0.7910
14:54:10.085491 [0] Epoch 00089 | Loss 0.0056
14:54:10.086541 [0] Epoch: 089, Train: 1.0000, Val: 0.7800, Test: 0.7910
14:54:10.092845 [0] Epoch 00090 | Loss 0.0054
14:54:10.094090 [0] Epoch: 090, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:10.099663 [0] Epoch 00091 | Loss 0.0054
14:54:10.100871 [0] Epoch: 091, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.107625 [0] Epoch 00092 | Loss 0.0052
14:54:10.108795 [0] Epoch: 092, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.114203 [0] Epoch 00093 | Loss 0.0052
14:54:10.115513 [0] Epoch: 093, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.121820 [0] Epoch 00094 | Loss 0.0050
14:54:10.123057 [0] Epoch: 094, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.128886 [0] Epoch 00095 | Loss 0.0050
14:54:10.130026 [0] Epoch: 095, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.135641 [0] Epoch 00096 | Loss 0.0049
14:54:10.136927 [0] Epoch: 096, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.142712 [0] Epoch 00097 | Loss 0.0049
14:54:10.144119 [0] Epoch: 097, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.150849 [0] Epoch 00098 | Loss 0.0047
14:54:10.152119 [0] Epoch: 098, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.157159 [0] Epoch 00099 | Loss 0.0047
14:54:10.158265 [0] Epoch: 099, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.164289 [0] Epoch 00100 | Loss 0.0046
14:54:10.165374 [0] Epoch: 100, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.171237 [0] Epoch 00101 | Loss 0.0046
14:54:10.173100 [0] Epoch: 101, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.178764 [0] Epoch 00102 | Loss 0.0045
14:54:10.179934 [0] Epoch: 102, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.185553 [0] Epoch 00103 | Loss 0.0044
14:54:10.186665 [0] Epoch: 103, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.193052 [0] Epoch 00104 | Loss 0.0043
14:54:10.194475 [0] Epoch: 104, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.200425 [0] Epoch 00105 | Loss 0.0043
14:54:10.201607 [0] Epoch: 105, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.208084 [0] Epoch 00106 | Loss 0.0042
14:54:10.209392 [0] Epoch: 106, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.214948 [0] Epoch 00107 | Loss 0.0042
14:54:10.216267 [0] Epoch: 107, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.222687 [0] Epoch 00108 | Loss 0.0041
14:54:10.223744 [0] Epoch: 108, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.229267 [0] Epoch 00109 | Loss 0.0041
14:54:10.230397 [0] Epoch: 109, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.236652 [0] Epoch 00110 | Loss 0.0040
14:54:10.237917 [0] Epoch: 110, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.244659 [0] Epoch 00111 | Loss 0.0040
14:54:10.245945 [0] Epoch: 111, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.252065 [0] Epoch 00112 | Loss 0.0039
14:54:10.253194 [0] Epoch: 112, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.258445 [0] Epoch 00113 | Loss 0.0039
14:54:10.259553 [0] Epoch: 113, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:10.267709 [0] Epoch 00114 | Loss 0.0038
14:54:10.269291 [0] Epoch: 114, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.275110 [0] Epoch 00115 | Loss 0.0038
14:54:10.276503 [0] Epoch: 115, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:10.282419 [0] Epoch 00116 | Loss 0.0037
14:54:10.283880 [0] Epoch: 116, Train: 1.0000, Val: 0.7780, Test: 0.7880
14:54:10.289828 [0] Epoch 00117 | Loss 0.0037
14:54:10.291257 [0] Epoch: 117, Train: 1.0000, Val: 0.7780, Test: 0.7880
14:54:10.298080 [0] Epoch 00118 | Loss 0.0036
14:54:10.299507 [0] Epoch: 118, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.304924 [0] Epoch 00119 | Loss 0.0036
14:54:10.306300 [0] Epoch: 119, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.312950 [0] Epoch 00120 | Loss 0.0035
14:54:10.314350 [0] Epoch: 120, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.320177 [0] Epoch 00121 | Loss 0.0035
14:54:10.321563 [0] Epoch: 121, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:10.327625 [0] Epoch 00122 | Loss 0.0034
14:54:10.329005 [0] Epoch: 122, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.335432 [0] Epoch 00123 | Loss 0.0034
14:54:10.336666 [0] Epoch: 123, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.342961 [0] Epoch 00124 | Loss 0.0033
14:54:10.344323 [0] Epoch: 124, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.349642 [0] Epoch 00125 | Loss 0.0033
14:54:10.350949 [0] Epoch: 125, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.357941 [0] Epoch 00126 | Loss 0.0033
14:54:10.359118 [0] Epoch: 126, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.364235 [0] Epoch 00127 | Loss 0.0033
14:54:10.365669 [0] Epoch: 127, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.372632 [0] Epoch 00128 | Loss 0.0032
14:54:10.374015 [0] Epoch: 128, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.380162 [0] Epoch 00129 | Loss 0.0032
14:54:10.381469 [0] Epoch: 129, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.386696 [0] Epoch 00130 | Loss 0.0031
14:54:10.388108 [0] Epoch: 130, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.394837 [0] Epoch 00131 | Loss 0.0031
14:54:10.396239 [0] Epoch: 131, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.402883 [0] Epoch 00132 | Loss 0.0031
14:54:10.404469 [0] Epoch: 132, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.409240 [0] Epoch 00133 | Loss 0.0030
14:54:10.410585 [0] Epoch: 133, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:10.416857 [0] Epoch 00134 | Loss 0.0030
14:54:10.418228 [0] Epoch: 134, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.423838 [0] Epoch 00135 | Loss 0.0030
14:54:10.425189 [0] Epoch: 135, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.431709 [0] Epoch 00136 | Loss 0.0029
14:54:10.432848 [0] Epoch: 136, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.438249 [0] Epoch 00137 | Loss 0.0029
14:54:10.439626 [0] Epoch: 137, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.445827 [0] Epoch 00138 | Loss 0.0029
14:54:10.447207 [0] Epoch: 138, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.453455 [0] Epoch 00139 | Loss 0.0029
14:54:10.454705 [0] Epoch: 139, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.459997 [0] Epoch 00140 | Loss 0.0028
14:54:10.461469 [0] Epoch: 140, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.467146 [0] Epoch 00141 | Loss 0.0028
14:54:10.468500 [0] Epoch: 141, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.474558 [0] Epoch 00142 | Loss 0.0027
14:54:10.476548 [0] Epoch: 142, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.481705 [0] Epoch 00143 | Loss 0.0027
14:54:10.483104 [0] Epoch: 143, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.489523 [0] Epoch 00144 | Loss 0.0027
14:54:10.490891 [0] Epoch: 144, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.496156 [0] Epoch 00145 | Loss 0.0027
14:54:10.499094 [0] Epoch: 145, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.508625 [0] Epoch 00146 | Loss 0.0026
14:54:10.509800 [0] Epoch: 146, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.515878 [0] Epoch 00147 | Loss 0.0026
14:54:10.517219 [0] Epoch: 147, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.523756 [0] Epoch 00148 | Loss 0.0026
14:54:10.525418 [0] Epoch: 148, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.530759 [0] Epoch 00149 | Loss 0.0026
14:54:10.531966 [0] Epoch: 149, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.538049 [0] Epoch 00150 | Loss 0.0025
14:54:10.539109 [0] Epoch: 150, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.544642 [0] Epoch 00151 | Loss 0.0025
14:54:10.545768 [0] Epoch: 151, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.553205 [0] Epoch 00152 | Loss 0.0025
14:54:10.554300 [0] Epoch: 152, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.559889 [0] Epoch 00153 | Loss 0.0025
14:54:10.561326 [0] Epoch: 153, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.567400 [0] Epoch 00154 | Loss 0.0024
14:54:10.568776 [0] Epoch: 154, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.574650 [0] Epoch 00155 | Loss 0.0024
14:54:10.575772 [0] Epoch: 155, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.580873 [0] Epoch 00156 | Loss 0.0024
14:54:10.582106 [0] Epoch: 156, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.587686 [0] Epoch 00157 | Loss 0.0024
14:54:10.588848 [0] Epoch: 157, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.594895 [0] Epoch 00158 | Loss 0.0023
14:54:10.596196 [0] Epoch: 158, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.602437 [0] Epoch 00159 | Loss 0.0023
14:54:10.603568 [0] Epoch: 159, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.609333 [0] Epoch 00160 | Loss 0.0023
14:54:10.610474 [0] Epoch: 160, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.616360 [0] Epoch 00161 | Loss 0.0023
14:54:10.617618 [0] Epoch: 161, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.624152 [0] Epoch 00162 | Loss 0.0023
14:54:10.625394 [0] Epoch: 162, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.630242 [0] Epoch 00163 | Loss 0.0022
14:54:10.631523 [0] Epoch: 163, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.637532 [0] Epoch 00164 | Loss 0.0022
14:54:10.638840 [0] Epoch: 164, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.644217 [0] Epoch 00165 | Loss 0.0022
14:54:10.645340 [0] Epoch: 165, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.652374 [0] Epoch 00166 | Loss 0.0022
14:54:10.653820 [0] Epoch: 166, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.659089 [0] Epoch 00167 | Loss 0.0022
14:54:10.660325 [0] Epoch: 167, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.666063 [0] Epoch 00168 | Loss 0.0021
14:54:10.667309 [0] Epoch: 168, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.673323 [0] Epoch 00169 | Loss 0.0021
14:54:10.674554 [0] Epoch: 169, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:10.679549 [0] Epoch 00170 | Loss 0.0021
14:54:10.680790 [0] Epoch: 170, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.686773 [0] Epoch 00171 | Loss 0.0021
14:54:10.688011 [0] Epoch: 171, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.694289 [0] Epoch 00172 | Loss 0.0021
14:54:10.696013 [0] Epoch: 172, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.701483 [0] Epoch 00173 | Loss 0.0021
14:54:10.702599 [0] Epoch: 173, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:10.708346 [0] Epoch 00174 | Loss 0.0020
14:54:10.709425 [0] Epoch: 174, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.715348 [0] Epoch 00175 | Loss 0.0020
14:54:10.716678 [0] Epoch: 175, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.723694 [0] Epoch 00176 | Loss 0.0020
14:54:10.724868 [0] Epoch: 176, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.731850 [0] Epoch 00177 | Loss 0.0020
14:54:10.733276 [0] Epoch: 177, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.739396 [0] Epoch 00178 | Loss 0.0020
14:54:10.740665 [0] Epoch: 178, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.746829 [0] Epoch 00179 | Loss 0.0020
14:54:10.747940 [0] Epoch: 179, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.753387 [0] Epoch 00180 | Loss 0.0019
14:54:10.754439 [0] Epoch: 180, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.760072 [0] Epoch 00181 | Loss 0.0019
14:54:10.761499 [0] Epoch: 181, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.767809 [0] Epoch 00182 | Loss 0.0019
14:54:10.769722 [0] Epoch: 182, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.775572 [0] Epoch 00183 | Loss 0.0019
14:54:10.776687 [0] Epoch: 183, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.782986 [0] Epoch 00184 | Loss 0.0019
14:54:10.784376 [0] Epoch: 184, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.790053 [0] Epoch 00185 | Loss 0.0019
14:54:10.791417 [0] Epoch: 185, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.798573 [0] Epoch 00186 | Loss 0.0018
14:54:10.799773 [0] Epoch: 186, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.805208 [0] Epoch 00187 | Loss 0.0018
14:54:10.806603 [0] Epoch: 187, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.812500 [0] Epoch 00188 | Loss 0.0018
14:54:10.813923 [0] Epoch: 188, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.820805 [0] Epoch 00189 | Loss 0.0018
14:54:10.822135 [0] Epoch: 189, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.827709 [0] Epoch 00190 | Loss 0.0018
14:54:10.829071 [0] Epoch: 190, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.834802 [0] Epoch 00191 | Loss 0.0018
14:54:10.836103 [0] Epoch: 191, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.842010 [0] Epoch 00192 | Loss 0.0017
14:54:10.843346 [0] Epoch: 192, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.849510 [0] Epoch 00193 | Loss 0.0017
14:54:10.850677 [0] Epoch: 193, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.856279 [0] Epoch 00194 | Loss 0.0017
14:54:10.857714 [0] Epoch: 194, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.863500 [0] Epoch 00195 | Loss 0.0017
14:54:10.865607 [0] Epoch: 195, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.872541 [0] Epoch 00196 | Loss 0.0017
14:54:10.873857 [0] Epoch: 196, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.878780 [0] Epoch 00197 | Loss 0.0017
14:54:10.880153 [0] Epoch: 197, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.886273 [0] Epoch 00198 | Loss 0.0017
14:54:10.887633 [0] Epoch: 198, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.893101 [0] Epoch 00199 | Loss 0.0017
14:54:10.894432 [0] Epoch: 199, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:10.898400 [0] 
timer summary:
  0.46s   0.21s     1 broadcast ForwardL1 0
  1.01s   0.56s  1600 broadcast
  0.14s   0.01s  1600 spmm
  0.00s   0.00s     1 broadcast ForwardL1 1
  0.13s   0.00s   800 mm
  0.04s   0.03s   125 broadcast ForwardL2 0
  0.04s   0.03s   125 broadcast ForwardL2 1
  0.30s   0.38s   200 broadcast BackwardL2 0
  0.04s   0.03s   200 broadcast BackwardL2 1
  0.15s   0.01s   400 all_reduce
  0.03s   0.01s   200 broadcast BackwardL1 0
  0.03s   0.02s   200 broadcast BackwardL1 1
  2.84s   0.21s   200 epoch
  3.93s   0.00s     1 total
14:54:28.380264 [0] proc begin: <DistEnv 0/2 nccl>
14:54:28.582725 [0] graph loaded <COO Graph: cora, |V|: 2708, |E|: 10556, masks: 140,500,1000><Local: 0, |V|: 1354, |E|: 6603>
14:54:28.597697 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Active memory         |   7674 KiB |   7696 KiB |   7743 KiB |  70656 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     94 KiB |    116 KiB |    163 KiB |  70656 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   7670 KiB |   7691 KiB |   7736 KiB |  67724 B   |
|       from large pool |   7579 KiB |   7579 KiB |   7579 KiB |      0 B   |
|       from small pool |     91 KiB |    112 KiB |    157 KiB |  67724 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22528 KiB |  22528 KiB |  22528 KiB |      0 B   |
|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14854 KiB |  14918 KiB |  15014 KiB | 164352 B   |
|       from large pool |  12900 KiB |  12900 KiB |  12900 KiB |      0 B   |
|       from small pool |   1953 KiB |   2045 KiB |   2114 KiB | 164352 B   |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      13    |      18    |       7    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |      10    |      12    |      17    |       7    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       3    |       1    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       2    |       2    |       1    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

14:54:30.883997 [0] Epoch 00000 | Loss 1.9456
14:54:30.927613 [0] Epoch: 000, Train: 0.1286, Val: 0.1160, Test: 0.0960
14:54:30.935787 [0] Epoch 00001 | Loss 1.9204
14:54:30.937373 [0] Epoch: 001, Train: 0.9714, Val: 0.7320, Test: 0.7120
14:54:30.943681 [0] Epoch 00002 | Loss 1.8889
14:54:30.945763 [0] Epoch: 002, Train: 0.9714, Val: 0.7560, Test: 0.7550
14:54:30.951945 [0] Epoch 00003 | Loss 1.8496
14:54:30.954208 [0] Epoch: 003, Train: 0.9714, Val: 0.7500, Test: 0.7500
14:54:30.960549 [0] Epoch 00004 | Loss 1.8050
14:54:30.962023 [0] Epoch: 004, Train: 0.9714, Val: 0.7420, Test: 0.7480
14:54:30.968295 [0] Epoch 00005 | Loss 1.7555
14:54:30.969684 [0] Epoch: 005, Train: 0.9786, Val: 0.7380, Test: 0.7450
14:54:30.976433 [0] Epoch 00006 | Loss 1.7004
14:54:30.978090 [0] Epoch: 006, Train: 0.9786, Val: 0.7360, Test: 0.7440
14:54:30.984536 [0] Epoch 00007 | Loss 1.6398
14:54:30.985963 [0] Epoch: 007, Train: 0.9786, Val: 0.7400, Test: 0.7470
14:54:30.992309 [0] Epoch 00008 | Loss 1.5737
14:54:30.993624 [0] Epoch: 008, Train: 0.9786, Val: 0.7500, Test: 0.7490
14:54:31.000714 [0] Epoch 00009 | Loss 1.5024
14:54:31.001971 [0] Epoch: 009, Train: 0.9786, Val: 0.7500, Test: 0.7510
14:54:31.007615 [0] Epoch 00010 | Loss 1.4266
14:54:31.008903 [0] Epoch: 010, Train: 0.9786, Val: 0.7540, Test: 0.7530
14:54:31.014683 [0] Epoch 00011 | Loss 1.3467
14:54:31.015926 [0] Epoch: 011, Train: 0.9786, Val: 0.7600, Test: 0.7550
14:54:31.021555 [0] Epoch 00012 | Loss 1.2634
14:54:31.023375 [0] Epoch: 012, Train: 0.9786, Val: 0.7640, Test: 0.7550
14:54:31.029013 [0] Epoch 00013 | Loss 1.1775
14:54:31.030285 [0] Epoch: 013, Train: 0.9786, Val: 0.7660, Test: 0.7550
14:54:31.036052 [0] Epoch 00014 | Loss 1.0900
14:54:31.043651 [0] Epoch: 014, Train: 0.9786, Val: 0.7680, Test: 0.7580
14:54:31.052641 [0] Epoch 00015 | Loss 1.0019
14:54:31.054153 [0] Epoch: 015, Train: 0.9786, Val: 0.7680, Test: 0.7600
14:54:31.060175 [0] Epoch 00016 | Loss 0.9145
14:54:31.061552 [0] Epoch: 016, Train: 0.9786, Val: 0.7680, Test: 0.7650
14:54:31.067469 [0] Epoch 00017 | Loss 0.8290
14:54:31.068766 [0] Epoch: 017, Train: 0.9786, Val: 0.7720, Test: 0.7680
14:54:31.075150 [0] Epoch 00018 | Loss 0.7464
14:54:31.076519 [0] Epoch: 018, Train: 0.9786, Val: 0.7720, Test: 0.7700
14:54:31.082280 [0] Epoch 00019 | Loss 0.6679
14:54:31.083547 [0] Epoch: 019, Train: 0.9786, Val: 0.7740, Test: 0.7730
14:54:31.089097 [0] Epoch 00020 | Loss 0.5943
14:54:31.090361 [0] Epoch: 020, Train: 0.9786, Val: 0.7760, Test: 0.7780
14:54:31.096719 [0] Epoch 00021 | Loss 0.5263
14:54:31.097982 [0] Epoch: 021, Train: 0.9857, Val: 0.7820, Test: 0.7820
14:54:31.103527 [0] Epoch 00022 | Loss 0.4642
14:54:31.104894 [0] Epoch: 022, Train: 0.9857, Val: 0.7880, Test: 0.7830
14:54:31.110658 [0] Epoch 00023 | Loss 0.4082
14:54:31.111901 [0] Epoch: 023, Train: 0.9857, Val: 0.7880, Test: 0.7870
14:54:31.117855 [0] Epoch 00024 | Loss 0.3581
14:54:31.119736 [0] Epoch: 024, Train: 0.9857, Val: 0.7880, Test: 0.7910
14:54:31.125180 [0] Epoch 00025 | Loss 0.3138
14:54:31.126552 [0] Epoch: 025, Train: 0.9857, Val: 0.7880, Test: 0.7920
14:54:31.132318 [0] Epoch 00026 | Loss 0.2747
14:54:31.133640 [0] Epoch: 026, Train: 0.9857, Val: 0.7820, Test: 0.7930
14:54:31.139197 [0] Epoch 00027 | Loss 0.2406
14:54:31.140460 [0] Epoch: 027, Train: 0.9857, Val: 0.7820, Test: 0.7960
14:54:31.146975 [0] Epoch 00028 | Loss 0.2108
14:54:31.148193 [0] Epoch: 028, Train: 0.9857, Val: 0.7880, Test: 0.7950
14:54:31.153931 [0] Epoch 00029 | Loss 0.1849
14:54:31.155271 [0] Epoch: 029, Train: 0.9857, Val: 0.7880, Test: 0.7960
14:54:31.160915 [0] Epoch 00030 | Loss 0.1624
14:54:31.162158 [0] Epoch: 030, Train: 0.9857, Val: 0.7900, Test: 0.7980
14:54:31.168564 [0] Epoch 00031 | Loss 0.1429
14:54:31.169814 [0] Epoch: 031, Train: 0.9857, Val: 0.7900, Test: 0.7990
14:54:31.175062 [0] Epoch 00032 | Loss 0.1260
14:54:31.176435 [0] Epoch: 032, Train: 0.9857, Val: 0.7860, Test: 0.7990
14:54:31.182248 [0] Epoch 00033 | Loss 0.1112
14:54:31.183480 [0] Epoch: 033, Train: 0.9929, Val: 0.7840, Test: 0.7990
14:54:31.189948 [0] Epoch 00034 | Loss 0.0984
14:54:31.192129 [0] Epoch: 034, Train: 1.0000, Val: 0.7840, Test: 0.7990
14:54:31.198232 [0] Epoch 00035 | Loss 0.0873
14:54:31.199631 [0] Epoch: 035, Train: 1.0000, Val: 0.7820, Test: 0.8000
14:54:31.206023 [0] Epoch 00036 | Loss 0.0776
14:54:31.207372 [0] Epoch: 036, Train: 1.0000, Val: 0.7800, Test: 0.8000
14:54:31.213558 [0] Epoch 00037 | Loss 0.0692
14:54:31.215122 [0] Epoch: 037, Train: 1.0000, Val: 0.7820, Test: 0.7990
14:54:31.221489 [0] Epoch 00038 | Loss 0.0620
14:54:31.222930 [0] Epoch: 038, Train: 1.0000, Val: 0.7800, Test: 0.7950
14:54:31.229294 [0] Epoch 00039 | Loss 0.0556
14:54:31.230627 [0] Epoch: 039, Train: 1.0000, Val: 0.7840, Test: 0.7930
14:54:31.236655 [0] Epoch 00040 | Loss 0.0501
14:54:31.238025 [0] Epoch: 040, Train: 1.0000, Val: 0.7840, Test: 0.7930
14:54:31.244878 [0] Epoch 00041 | Loss 0.0453
14:54:31.246159 [0] Epoch: 041, Train: 1.0000, Val: 0.7840, Test: 0.7940
14:54:31.252590 [0] Epoch 00042 | Loss 0.0411
14:54:31.253961 [0] Epoch: 042, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:31.260057 [0] Epoch 00043 | Loss 0.0375
14:54:31.261414 [0] Epoch: 043, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:31.268579 [0] Epoch 00044 | Loss 0.0342
14:54:31.269858 [0] Epoch: 044, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.276218 [0] Epoch 00045 | Loss 0.0314
14:54:31.277610 [0] Epoch: 045, Train: 1.0000, Val: 0.7820, Test: 0.7880
14:54:31.283735 [0] Epoch 00046 | Loss 0.0289
14:54:31.285047 [0] Epoch: 046, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:31.292331 [0] Epoch 00047 | Loss 0.0267
14:54:31.293610 [0] Epoch: 047, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:31.299492 [0] Epoch 00048 | Loss 0.0247
14:54:31.300861 [0] Epoch: 048, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:31.307133 [0] Epoch 00049 | Loss 0.0230
14:54:31.308411 [0] Epoch: 049, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:31.315330 [0] Epoch 00050 | Loss 0.0215
14:54:31.316679 [0] Epoch: 050, Train: 1.0000, Val: 0.7800, Test: 0.7860
14:54:31.322081 [0] Epoch 00051 | Loss 0.0209
14:54:31.323451 [0] Epoch: 051, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:31.329694 [0] Epoch 00052 | Loss 0.0188
14:54:31.331049 [0] Epoch: 052, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:31.344447 [0] Epoch 00053 | Loss 0.0184
14:54:31.345802 [0] Epoch: 053, Train: 1.0000, Val: 0.7800, Test: 0.7850
14:54:31.352336 [0] Epoch 00054 | Loss 0.0167
14:54:31.353756 [0] Epoch: 054, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:31.359427 [0] Epoch 00055 | Loss 0.0164
14:54:31.360696 [0] Epoch: 055, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:31.368033 [0] Epoch 00056 | Loss 0.0150
14:54:31.369268 [0] Epoch: 056, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:31.375143 [0] Epoch 00057 | Loss 0.0147
14:54:31.376559 [0] Epoch: 057, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:31.382798 [0] Epoch 00058 | Loss 0.0136
14:54:31.384139 [0] Epoch: 058, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:31.390174 [0] Epoch 00059 | Loss 0.0133
14:54:31.392028 [0] Epoch: 059, Train: 1.0000, Val: 0.7840, Test: 0.7870
14:54:31.399707 [0] Epoch 00060 | Loss 0.0123
14:54:31.401227 [0] Epoch: 060, Train: 1.0000, Val: 0.7840, Test: 0.7900
14:54:31.410015 [0] Epoch 00061 | Loss 0.0122
14:54:31.411464 [0] Epoch: 061, Train: 1.0000, Val: 0.7840, Test: 0.7900
14:54:31.417998 [0] Epoch 00062 | Loss 0.0113
14:54:31.419962 [0] Epoch: 062, Train: 1.0000, Val: 0.7840, Test: 0.7910
14:54:31.425354 [0] Epoch 00063 | Loss 0.0112
14:54:31.426742 [0] Epoch: 063, Train: 1.0000, Val: 0.7840, Test: 0.7910
14:54:31.433091 [0] Epoch 00064 | Loss 0.0105
14:54:31.434412 [0] Epoch: 064, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.440017 [0] Epoch 00065 | Loss 0.0103
14:54:31.441366 [0] Epoch: 065, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.448523 [0] Epoch 00066 | Loss 0.0097
14:54:31.450831 [0] Epoch: 066, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.457244 [0] Epoch 00067 | Loss 0.0096
14:54:31.458281 [0] Epoch: 067, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.463886 [0] Epoch 00068 | Loss 0.0091
14:54:31.464984 [0] Epoch: 068, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.470966 [0] Epoch 00069 | Loss 0.0090
14:54:31.472186 [0] Epoch: 069, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:31.477983 [0] Epoch 00070 | Loss 0.0085
14:54:31.479315 [0] Epoch: 070, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:31.484557 [0] Epoch 00071 | Loss 0.0084
14:54:31.485828 [0] Epoch: 071, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:31.491466 [0] Epoch 00072 | Loss 0.0080
14:54:31.492683 [0] Epoch: 072, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.498550 [0] Epoch 00073 | Loss 0.0080
14:54:31.499721 [0] Epoch: 073, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.505268 [0] Epoch 00074 | Loss 0.0076
14:54:31.506541 [0] Epoch: 074, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.511655 [0] Epoch 00075 | Loss 0.0075
14:54:31.512925 [0] Epoch: 075, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.518348 [0] Epoch 00076 | Loss 0.0072
14:54:31.519771 [0] Epoch: 076, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.525271 [0] Epoch 00077 | Loss 0.0072
14:54:31.526388 [0] Epoch: 077, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.532115 [0] Epoch 00078 | Loss 0.0069
14:54:31.533440 [0] Epoch: 078, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.538633 [0] Epoch 00079 | Loss 0.0068
14:54:31.539864 [0] Epoch: 079, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.545578 [0] Epoch 00080 | Loss 0.0066
14:54:31.547552 [0] Epoch: 080, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.552377 [0] Epoch 00081 | Loss 0.0065
14:54:31.553853 [0] Epoch: 081, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.559861 [0] Epoch 00082 | Loss 0.0063
14:54:31.561269 [0] Epoch: 082, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.566651 [0] Epoch 00083 | Loss 0.0062
14:54:31.568032 [0] Epoch: 083, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.574747 [0] Epoch 00084 | Loss 0.0060
14:54:31.576213 [0] Epoch: 084, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.581700 [0] Epoch 00085 | Loss 0.0060
14:54:31.583145 [0] Epoch: 085, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.588941 [0] Epoch 00086 | Loss 0.0058
14:54:31.590075 [0] Epoch: 086, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.596680 [0] Epoch 00087 | Loss 0.0058
14:54:31.598496 [0] Epoch: 087, Train: 1.0000, Val: 0.7780, Test: 0.7910
14:54:31.611392 [0] Epoch 00088 | Loss 0.0056
14:54:31.612478 [0] Epoch: 088, Train: 1.0000, Val: 0.7800, Test: 0.7910
14:54:31.617852 [0] Epoch 00089 | Loss 0.0056
14:54:31.618805 [0] Epoch: 089, Train: 1.0000, Val: 0.7800, Test: 0.7910
14:54:31.625102 [0] Epoch 00090 | Loss 0.0054
14:54:31.626382 [0] Epoch: 090, Train: 1.0000, Val: 0.7800, Test: 0.7900
14:54:31.631000 [0] Epoch 00091 | Loss 0.0054
14:54:31.632088 [0] Epoch: 091, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.637777 [0] Epoch 00092 | Loss 0.0052
14:54:31.638774 [0] Epoch: 092, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.643915 [0] Epoch 00093 | Loss 0.0052
14:54:31.644918 [0] Epoch: 093, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.651212 [0] Epoch 00094 | Loss 0.0050
14:54:31.652464 [0] Epoch: 094, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.657216 [0] Epoch 00095 | Loss 0.0050
14:54:31.658386 [0] Epoch: 095, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.665298 [0] Epoch 00096 | Loss 0.0049
14:54:31.666316 [0] Epoch: 096, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.671501 [0] Epoch 00097 | Loss 0.0049
14:54:31.672708 [0] Epoch: 097, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.679493 [0] Epoch 00098 | Loss 0.0047
14:54:31.680889 [0] Epoch: 098, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.686114 [0] Epoch 00099 | Loss 0.0047
14:54:31.687477 [0] Epoch: 099, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.693010 [0] Epoch 00100 | Loss 0.0046
14:54:31.694501 [0] Epoch: 100, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.700024 [0] Epoch 00101 | Loss 0.0046
14:54:31.702141 [0] Epoch: 101, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.708033 [0] Epoch 00102 | Loss 0.0045
14:54:31.709402 [0] Epoch: 102, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.714947 [0] Epoch 00103 | Loss 0.0044
14:54:31.716269 [0] Epoch: 103, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.722174 [0] Epoch 00104 | Loss 0.0043
14:54:31.723445 [0] Epoch: 104, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.729715 [0] Epoch 00105 | Loss 0.0043
14:54:31.731063 [0] Epoch: 105, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.736312 [0] Epoch 00106 | Loss 0.0042
14:54:31.737692 [0] Epoch: 106, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.743088 [0] Epoch 00107 | Loss 0.0042
14:54:31.744354 [0] Epoch: 107, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.749908 [0] Epoch 00108 | Loss 0.0041
14:54:31.751193 [0] Epoch: 108, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.757292 [0] Epoch 00109 | Loss 0.0041
14:54:31.758634 [0] Epoch: 109, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.764155 [0] Epoch 00110 | Loss 0.0040
14:54:31.765554 [0] Epoch: 110, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.771449 [0] Epoch 00111 | Loss 0.0040
14:54:31.772766 [0] Epoch: 111, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.778983 [0] Epoch 00112 | Loss 0.0039
14:54:31.780299 [0] Epoch: 112, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.786696 [0] Epoch 00113 | Loss 0.0039
14:54:31.788061 [0] Epoch: 113, Train: 1.0000, Val: 0.7780, Test: 0.7900
14:54:31.794385 [0] Epoch 00114 | Loss 0.0038
14:54:31.795755 [0] Epoch: 114, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.801339 [0] Epoch 00115 | Loss 0.0038
14:54:31.802679 [0] Epoch: 115, Train: 1.0000, Val: 0.7780, Test: 0.7890
14:54:31.809623 [0] Epoch 00116 | Loss 0.0037
14:54:31.811084 [0] Epoch: 116, Train: 1.0000, Val: 0.7780, Test: 0.7880
14:54:31.816300 [0] Epoch 00117 | Loss 0.0037
14:54:31.817632 [0] Epoch: 117, Train: 1.0000, Val: 0.7780, Test: 0.7880
14:54:31.823815 [0] Epoch 00118 | Loss 0.0036
14:54:31.825176 [0] Epoch: 118, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.830705 [0] Epoch 00119 | Loss 0.0036
14:54:31.832015 [0] Epoch: 119, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.839303 [0] Epoch 00120 | Loss 0.0035
14:54:31.840739 [0] Epoch: 120, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.846291 [0] Epoch 00121 | Loss 0.0035
14:54:31.847656 [0] Epoch: 121, Train: 1.0000, Val: 0.7800, Test: 0.7870
14:54:31.853347 [0] Epoch 00122 | Loss 0.0034
14:54:31.854660 [0] Epoch: 122, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.859853 [0] Epoch 00123 | Loss 0.0034
14:54:31.861125 [0] Epoch: 123, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.867912 [0] Epoch 00124 | Loss 0.0033
14:54:31.869236 [0] Epoch: 124, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.874288 [0] Epoch 00125 | Loss 0.0033
14:54:31.875621 [0] Epoch: 125, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.881195 [0] Epoch 00126 | Loss 0.0033
14:54:31.882426 [0] Epoch: 126, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.887416 [0] Epoch 00127 | Loss 0.0033
14:54:31.888687 [0] Epoch: 127, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.895063 [0] Epoch 00128 | Loss 0.0032
14:54:31.896350 [0] Epoch: 128, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.901498 [0] Epoch 00129 | Loss 0.0032
14:54:31.902824 [0] Epoch: 129, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.908366 [0] Epoch 00130 | Loss 0.0031
14:54:31.909655 [0] Epoch: 130, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.914650 [0] Epoch 00131 | Loss 0.0031
14:54:31.916060 [0] Epoch: 131, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.922218 [0] Epoch 00132 | Loss 0.0031
14:54:31.923505 [0] Epoch: 132, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.928626 [0] Epoch 00133 | Loss 0.0030
14:54:31.929963 [0] Epoch: 133, Train: 1.0000, Val: 0.7800, Test: 0.7880
14:54:31.937764 [0] Epoch 00134 | Loss 0.0030
14:54:31.939086 [0] Epoch: 134, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:31.945266 [0] Epoch 00135 | Loss 0.0030
14:54:31.946654 [0] Epoch: 135, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:31.952352 [0] Epoch 00136 | Loss 0.0029
14:54:31.953711 [0] Epoch: 136, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.959576 [0] Epoch 00137 | Loss 0.0029
14:54:31.960890 [0] Epoch: 137, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.967595 [0] Epoch 00138 | Loss 0.0029
14:54:31.968948 [0] Epoch: 138, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.977876 [0] Epoch 00139 | Loss 0.0029
14:54:31.979428 [0] Epoch: 139, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:31.985736 [0] Epoch 00140 | Loss 0.0028
14:54:31.987072 [0] Epoch: 140, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:31.992343 [0] Epoch 00141 | Loss 0.0028
14:54:31.993682 [0] Epoch: 141, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.000135 [0] Epoch 00142 | Loss 0.0027
14:54:32.001522 [0] Epoch: 142, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.006673 [0] Epoch 00143 | Loss 0.0027
14:54:32.007973 [0] Epoch: 143, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.014047 [0] Epoch 00144 | Loss 0.0027
14:54:32.015367 [0] Epoch: 144, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.020728 [0] Epoch 00145 | Loss 0.0027
14:54:32.022015 [0] Epoch: 145, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.028554 [0] Epoch 00146 | Loss 0.0026
14:54:32.029893 [0] Epoch: 146, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.035515 [0] Epoch 00147 | Loss 0.0026
14:54:32.036843 [0] Epoch: 147, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.042646 [0] Epoch 00148 | Loss 0.0026
14:54:32.043937 [0] Epoch: 148, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.049190 [0] Epoch 00149 | Loss 0.0026
14:54:32.050533 [0] Epoch: 149, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.057366 [0] Epoch 00150 | Loss 0.0025
14:54:32.058714 [0] Epoch: 150, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.064138 [0] Epoch 00151 | Loss 0.0025
14:54:32.065495 [0] Epoch: 151, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.071209 [0] Epoch 00152 | Loss 0.0025
14:54:32.072543 [0] Epoch: 152, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.077691 [0] Epoch 00153 | Loss 0.0025
14:54:32.079114 [0] Epoch: 153, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.085707 [0] Epoch 00154 | Loss 0.0024
14:54:32.087017 [0] Epoch: 154, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.092299 [0] Epoch 00155 | Loss 0.0024
14:54:32.093682 [0] Epoch: 155, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.099372 [0] Epoch 00156 | Loss 0.0024
14:54:32.100673 [0] Epoch: 156, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.105833 [0] Epoch 00157 | Loss 0.0024
14:54:32.107844 [0] Epoch: 157, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.114210 [0] Epoch 00158 | Loss 0.0023
14:54:32.116352 [0] Epoch: 158, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.122489 [0] Epoch 00159 | Loss 0.0023
14:54:32.123782 [0] Epoch: 159, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.129486 [0] Epoch 00160 | Loss 0.0023
14:54:32.130615 [0] Epoch: 160, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.136679 [0] Epoch 00161 | Loss 0.0023
14:54:32.138032 [0] Epoch: 161, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.143414 [0] Epoch 00162 | Loss 0.0023
14:54:32.144653 [0] Epoch: 162, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.149531 [0] Epoch 00163 | Loss 0.0022
14:54:32.150614 [0] Epoch: 163, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.156337 [0] Epoch 00164 | Loss 0.0022
14:54:32.157368 [0] Epoch: 164, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.163004 [0] Epoch 00165 | Loss 0.0022
14:54:32.164445 [0] Epoch: 165, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.169715 [0] Epoch 00166 | Loss 0.0022
14:54:32.170938 [0] Epoch: 166, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.176278 [0] Epoch 00167 | Loss 0.0022
14:54:32.177289 [0] Epoch: 167, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.182811 [0] Epoch 00168 | Loss 0.0021
14:54:32.183911 [0] Epoch: 168, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.189463 [0] Epoch 00169 | Loss 0.0021
14:54:32.191375 [0] Epoch: 169, Train: 1.0000, Val: 0.7820, Test: 0.7910
14:54:32.196700 [0] Epoch 00170 | Loss 0.0021
14:54:32.197969 [0] Epoch: 170, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.203149 [0] Epoch 00171 | Loss 0.0021
14:54:32.204460 [0] Epoch: 171, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.209990 [0] Epoch 00172 | Loss 0.0021
14:54:32.211267 [0] Epoch: 172, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.216778 [0] Epoch 00173 | Loss 0.0021
14:54:32.218780 [0] Epoch: 173, Train: 1.0000, Val: 0.7820, Test: 0.7900
14:54:32.224384 [0] Epoch 00174 | Loss 0.0020
14:54:32.226508 [0] Epoch: 174, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.233376 [0] Epoch 00175 | Loss 0.0020
14:54:32.234410 [0] Epoch: 175, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.240200 [0] Epoch 00176 | Loss 0.0020
14:54:32.241341 [0] Epoch: 176, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.247365 [0] Epoch 00177 | Loss 0.0020
14:54:32.248493 [0] Epoch: 177, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.253303 [0] Epoch 00178 | Loss 0.0020
14:54:32.254460 [0] Epoch: 178, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.259594 [0] Epoch 00179 | Loss 0.0020
14:54:32.260746 [0] Epoch: 179, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.266225 [0] Epoch 00180 | Loss 0.0019
14:54:32.267347 [0] Epoch: 180, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.272670 [0] Epoch 00181 | Loss 0.0019
14:54:32.275237 [0] Epoch: 181, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.282369 [0] Epoch 00182 | Loss 0.0019
14:54:32.284092 [0] Epoch: 182, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.289938 [0] Epoch 00183 | Loss 0.0019
14:54:32.290955 [0] Epoch: 183, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.296695 [0] Epoch 00184 | Loss 0.0019
14:54:32.297867 [0] Epoch: 184, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.303591 [0] Epoch 00185 | Loss 0.0019
14:54:32.304772 [0] Epoch: 185, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.309693 [0] Epoch 00186 | Loss 0.0018
14:54:32.310709 [0] Epoch: 186, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.315972 [0] Epoch 00187 | Loss 0.0018
14:54:32.317008 [0] Epoch: 187, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.322513 [0] Epoch 00188 | Loss 0.0018
14:54:32.323696 [0] Epoch: 188, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.329722 [0] Epoch 00189 | Loss 0.0018
14:54:32.330992 [0] Epoch: 189, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.335850 [0] Epoch 00190 | Loss 0.0018
14:54:32.336869 [0] Epoch: 190, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.341965 [0] Epoch 00191 | Loss 0.0018
14:54:32.343174 [0] Epoch: 191, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.348697 [0] Epoch 00192 | Loss 0.0017
14:54:32.349946 [0] Epoch: 192, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.355208 [0] Epoch 00193 | Loss 0.0017
14:54:32.357112 [0] Epoch: 193, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.362239 [0] Epoch 00194 | Loss 0.0017
14:54:32.363298 [0] Epoch: 194, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.368248 [0] Epoch 00195 | Loss 0.0017
14:54:32.369427 [0] Epoch: 195, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.379116 [0] Epoch 00196 | Loss 0.0017
14:54:32.380180 [0] Epoch: 196, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.386348 [0] Epoch 00197 | Loss 0.0017
14:54:32.387875 [0] Epoch: 197, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.393335 [0] Epoch 00198 | Loss 0.0017
14:54:32.394537 [0] Epoch: 198, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.399616 [0] Epoch 00199 | Loss 0.0017
14:54:32.400650 [0] Epoch: 199, Train: 1.0000, Val: 0.7820, Test: 0.7890
14:54:32.403528 [0] 
timer summary:
  0.41s   0.08s     1 broadcast ForwardL1 0
  1.04s   0.60s  1600 broadcast
  0.13s   0.01s  1600 spmm
  0.00s   0.00s     1 broadcast ForwardL1 1
  0.13s   0.01s   800 mm
  0.05s   0.04s   125 broadcast ForwardL2 0
  0.03s   0.02s   125 broadcast ForwardL2 1
  0.40s   0.53s   200 broadcast BackwardL2 0
  0.03s   0.01s   200 broadcast BackwardL2 1
  0.16s   0.01s   400 all_reduce
  0.03s   0.01s   200 broadcast BackwardL1 0
  0.03s   0.02s   200 broadcast BackwardL1 1
  2.92s   0.08s   200 epoch
  4.02s   0.01s     1 total
20:16:09.341386 [0] proc begin: <DistEnv 0/2 nccl>
20:16:18.019236 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
20:16:18.038271 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 736599 KiB | 738421 KiB | 742065 KiB |   5466 KiB |
|       from large pool | 735004 KiB | 736825 KiB | 740466 KiB |   5461 KiB |
|       from small pool |   1595 KiB |   1596 KiB |   1599 KiB |      4 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 736599 KiB | 738421 KiB | 742065 KiB |   5466 KiB |
|       from large pool | 735004 KiB | 736825 KiB | 740466 KiB |   5461 KiB |
|       from small pool |   1595 KiB |   1596 KiB |   1599 KiB |      4 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 733230 KiB | 735050 KiB | 738691 KiB |   5460 KiB |
|       from large pool | 731637 KiB | 733457 KiB | 737097 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1593 KiB |      0 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 755712 KiB | 755712 KiB | 755712 KiB |      0 B   |
|       from large pool | 753664 KiB | 753664 KiB | 753664 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  19112 KiB |  20479 KiB |  25945 KiB |   6833 KiB |
|       from large pool |  18659 KiB |  18659 KiB |  24121 KiB |   5461 KiB |
|       from small pool |    453 KiB |   1820 KiB |   1824 KiB |   1371 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      23    |      12    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      14    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      23    |      12    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      14    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:16:20.299466 [0] Epoch 00000 | Loss 3.8027
20:16:20.332218 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:16:20.713565 [0] Epoch 00001 | Loss 3.4338
20:16:20.719035 [0] Epoch: 001, Train: 0.1158, Val: 0.1019, Test: 0.0997
20:16:21.091224 [0] Epoch 00002 | Loss 3.2834
20:16:21.095502 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1946
20:16:21.466090 [0] Epoch 00003 | Loss 3.1536
20:16:21.470058 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:16:21.839021 [0] Epoch 00004 | Loss 3.0465
20:16:21.842987 [0] Epoch: 004, Train: 0.2959, Val: 0.2737, Test: 0.2732
20:16:22.213127 [0] Epoch 00005 | Loss 2.9418
20:16:22.217529 [0] Epoch: 005, Train: 0.3216, Val: 0.2997, Test: 0.2995
20:16:22.587789 [0] Epoch 00006 | Loss 2.8316
20:16:22.591753 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:16:22.961348 [0] Epoch 00007 | Loss 2.7111
20:16:22.965335 [0] Epoch: 007, Train: 0.4122, Val: 0.4161, Test: 0.4215
20:16:23.336357 [0] Epoch 00008 | Loss 2.5768
20:16:23.342182 [0] Epoch: 008, Train: 0.4969, Val: 0.4999, Test: 0.5063
20:16:23.712023 [0] Epoch 00009 | Loss 2.4295
20:16:23.715983 [0] Epoch: 009, Train: 0.5323, Val: 0.5318, Test: 0.5378
20:16:24.086682 [0] Epoch 00010 | Loss 2.2739
20:16:24.092106 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:16:24.462268 [0] Epoch 00011 | Loss 2.1082
20:16:24.466494 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:16:24.836409 [0] Epoch 00012 | Loss 1.9361
20:16:24.840861 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:16:25.211302 [0] Epoch 00013 | Loss 1.7618
20:16:25.216725 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:16:25.587178 [0] Epoch 00014 | Loss 1.6006
20:16:25.591173 [0] Epoch: 014, Train: 0.6303, Val: 0.6294, Test: 0.6291
20:16:25.960958 [0] Epoch 00015 | Loss 1.4659
20:16:25.966384 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:16:26.336537 [0] Epoch 00016 | Loss 1.3545
20:16:26.340473 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6842
20:16:26.710273 [0] Epoch 00017 | Loss 1.2612
20:16:26.716309 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:16:27.086836 [0] Epoch 00018 | Loss 1.1716
20:16:27.091477 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:16:27.461771 [0] Epoch 00019 | Loss 1.0772
20:16:27.465759 [0] Epoch: 019, Train: 0.7520, Val: 0.7491, Test: 0.7448
20:16:27.835302 [0] Epoch 00020 | Loss 0.9926
20:16:27.839296 [0] Epoch: 020, Train: 0.7803, Val: 0.7727, Test: 0.7677
20:16:28.209230 [0] Epoch 00021 | Loss 0.9228
20:16:28.214006 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7843
20:16:28.583810 [0] Epoch 00022 | Loss 0.8649
20:16:28.587834 [0] Epoch: 022, Train: 0.8194, Val: 0.8087, Test: 0.8046
20:16:28.957976 [0] Epoch 00023 | Loss 0.8176
20:16:28.962634 [0] Epoch: 023, Train: 0.8334, Val: 0.8218, Test: 0.8178
20:16:29.333572 [0] Epoch 00024 | Loss 0.7771
20:16:29.337614 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:16:29.707790 [0] Epoch 00025 | Loss 0.7397
20:16:29.711972 [0] Epoch: 025, Train: 0.8490, Val: 0.8363, Test: 0.8330
20:16:30.082220 [0] Epoch 00026 | Loss 0.7027
20:16:30.086951 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:16:30.457572 [0] Epoch 00027 | Loss 0.6648
20:16:30.461642 [0] Epoch: 027, Train: 0.8798, Val: 0.8742, Test: 0.8730
20:16:30.831959 [0] Epoch 00028 | Loss 0.6249
20:16:30.835954 [0] Epoch: 028, Train: 0.9000, Val: 0.9018, Test: 0.8999
20:16:31.206024 [0] Epoch 00029 | Loss 0.5828
20:16:31.210374 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:16:31.580323 [0] Epoch 00030 | Loss 0.5397
20:16:31.584366 [0] Epoch: 030, Train: 0.9090, Val: 0.9126, Test: 0.9106
20:16:31.954116 [0] Epoch 00031 | Loss 0.4996
20:16:31.958359 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:16:32.327929 [0] Epoch 00032 | Loss 0.4665
20:16:32.331925 [0] Epoch: 032, Train: 0.9163, Val: 0.9203, Test: 0.9185
20:16:32.702089 [0] Epoch 00033 | Loss 0.4411
20:16:32.707962 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:16:33.079203 [0] Epoch 00034 | Loss 0.4207
20:16:33.084689 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:16:33.455685 [0] Epoch 00035 | Loss 0.4035
20:16:33.459779 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:16:33.829853 [0] Epoch 00036 | Loss 0.3894
20:16:33.833801 [0] Epoch: 036, Train: 0.9274, Val: 0.9321, Test: 0.9291
20:16:34.204029 [0] Epoch 00037 | Loss 0.3779
20:16:34.208039 [0] Epoch: 037, Train: 0.9283, Val: 0.9321, Test: 0.9306
20:16:34.578223 [0] Epoch 00038 | Loss 0.3682
20:16:34.582259 [0] Epoch: 038, Train: 0.9291, Val: 0.9327, Test: 0.9308
20:16:34.952727 [0] Epoch 00039 | Loss 0.3593
20:16:34.956776 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9316
20:16:35.326890 [0] Epoch 00040 | Loss 0.3507
20:16:35.331252 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9327
20:16:35.701552 [0] Epoch 00041 | Loss 0.3426
20:16:35.705556 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:16:36.075634 [0] Epoch 00042 | Loss 0.3357
20:16:36.080537 [0] Epoch: 042, Train: 0.9339, Val: 0.9359, Test: 0.9351
20:16:36.450918 [0] Epoch 00043 | Loss 0.3306
20:16:36.456049 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:16:36.826899 [0] Epoch 00044 | Loss 0.3266
20:16:36.831039 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:16:37.201834 [0] Epoch 00045 | Loss 0.3222
20:16:37.205886 [0] Epoch: 045, Train: 0.9357, Val: 0.9372, Test: 0.9369
20:16:37.576567 [0] Epoch 00046 | Loss 0.3175
20:16:37.580633 [0] Epoch: 046, Train: 0.9364, Val: 0.9377, Test: 0.9374
20:16:37.950232 [0] Epoch 00047 | Loss 0.3132
20:16:37.954414 [0] Epoch: 047, Train: 0.9367, Val: 0.9381, Test: 0.9376
20:16:38.324998 [0] Epoch 00048 | Loss 0.3091
20:16:38.329173 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:16:38.699622 [0] Epoch 00049 | Loss 0.3050
20:16:38.703845 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:16:39.074922 [0] Epoch 00050 | Loss 0.3012
20:16:39.079027 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:16:39.449635 [0] Epoch 00051 | Loss 0.2976
20:16:39.453667 [0] Epoch: 051, Train: 0.9383, Val: 0.9383, Test: 0.9381
20:16:39.824078 [0] Epoch 00052 | Loss 0.2944
20:16:39.828044 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:16:40.198250 [0] Epoch 00053 | Loss 0.2914
20:16:40.202581 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9383
20:16:40.572559 [0] Epoch 00054 | Loss 0.2881
20:16:40.576580 [0] Epoch: 054, Train: 0.9394, Val: 0.9388, Test: 0.9386
20:16:40.946728 [0] Epoch 00055 | Loss 0.2850
20:16:40.951158 [0] Epoch: 055, Train: 0.9398, Val: 0.9392, Test: 0.9389
20:16:41.322144 [0] Epoch 00056 | Loss 0.2822
20:16:41.327451 [0] Epoch: 056, Train: 0.9402, Val: 0.9395, Test: 0.9394
20:16:41.698010 [0] Epoch 00057 | Loss 0.2796
20:16:41.703374 [0] Epoch: 057, Train: 0.9406, Val: 0.9397, Test: 0.9396
20:16:42.073566 [0] Epoch 00058 | Loss 0.2769
20:16:42.077657 [0] Epoch: 058, Train: 0.9410, Val: 0.9403, Test: 0.9401
20:16:42.447718 [0] Epoch 00059 | Loss 0.2743
20:16:42.451751 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:16:42.822190 [0] Epoch 00060 | Loss 0.2720
20:16:42.826167 [0] Epoch: 060, Train: 0.9421, Val: 0.9405, Test: 0.9404
20:16:43.196400 [0] Epoch 00061 | Loss 0.2699
20:16:43.200427 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9402
20:16:43.571332 [0] Epoch 00062 | Loss 0.2678
20:16:43.575447 [0] Epoch: 062, Train: 0.9427, Val: 0.9408, Test: 0.9404
20:16:43.946073 [0] Epoch 00063 | Loss 0.2656
20:16:43.950213 [0] Epoch: 063, Train: 0.9431, Val: 0.9412, Test: 0.9407
20:16:44.320718 [0] Epoch 00064 | Loss 0.2635
20:16:44.325459 [0] Epoch: 064, Train: 0.9433, Val: 0.9413, Test: 0.9409
20:16:44.695711 [0] Epoch 00065 | Loss 0.2615
20:16:44.700693 [0] Epoch: 065, Train: 0.9435, Val: 0.9415, Test: 0.9412
20:16:45.070775 [0] Epoch 00066 | Loss 0.2596
20:16:45.075527 [0] Epoch: 066, Train: 0.9438, Val: 0.9417, Test: 0.9413
20:16:45.446064 [0] Epoch 00067 | Loss 0.2577
20:16:45.450080 [0] Epoch: 067, Train: 0.9443, Val: 0.9419, Test: 0.9414
20:16:45.820450 [0] Epoch 00068 | Loss 0.2559
20:16:45.824467 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:16:46.194923 [0] Epoch 00069 | Loss 0.2543
20:16:46.199163 [0] Epoch: 069, Train: 0.9449, Val: 0.9423, Test: 0.9417
20:16:46.569139 [0] Epoch 00070 | Loss 0.2526
20:16:46.573185 [0] Epoch: 070, Train: 0.9450, Val: 0.9426, Test: 0.9419
20:16:46.943565 [0] Epoch 00071 | Loss 0.2510
20:16:46.947631 [0] Epoch: 071, Train: 0.9452, Val: 0.9424, Test: 0.9420
20:16:47.318107 [0] Epoch 00072 | Loss 0.2494
20:16:47.322369 [0] Epoch: 072, Train: 0.9454, Val: 0.9423, Test: 0.9422
20:16:47.693229 [0] Epoch 00073 | Loss 0.2479
20:16:47.697316 [0] Epoch: 073, Train: 0.9458, Val: 0.9428, Test: 0.9424
20:16:48.067883 [0] Epoch 00074 | Loss 0.2465
20:16:48.071947 [0] Epoch: 074, Train: 0.9461, Val: 0.9431, Test: 0.9426
20:16:48.442527 [0] Epoch 00075 | Loss 0.2451
20:16:48.447234 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:16:48.818266 [0] Epoch 00076 | Loss 0.2437
20:16:48.822265 [0] Epoch: 076, Train: 0.9464, Val: 0.9431, Test: 0.9424
20:16:49.193003 [0] Epoch 00077 | Loss 0.2423
20:16:49.197034 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:16:49.567682 [0] Epoch 00078 | Loss 0.2410
20:16:49.571778 [0] Epoch: 078, Train: 0.9469, Val: 0.9430, Test: 0.9426
20:16:49.942293 [0] Epoch 00079 | Loss 0.2397
20:16:49.946388 [0] Epoch: 079, Train: 0.9470, Val: 0.9430, Test: 0.9427
20:16:50.316964 [0] Epoch 00080 | Loss 0.2384
20:16:50.321016 [0] Epoch: 080, Train: 0.9472, Val: 0.9429, Test: 0.9428
20:16:50.691541 [0] Epoch 00081 | Loss 0.2372
20:16:50.695600 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9426
20:16:51.065326 [0] Epoch 00082 | Loss 0.2360
20:16:51.069375 [0] Epoch: 082, Train: 0.9476, Val: 0.9427, Test: 0.9427
20:16:51.439408 [0] Epoch 00083 | Loss 0.2349
20:16:51.443484 [0] Epoch: 083, Train: 0.9479, Val: 0.9429, Test: 0.9430
20:16:51.813689 [0] Epoch 00084 | Loss 0.2337
20:16:51.818950 [0] Epoch: 084, Train: 0.9480, Val: 0.9432, Test: 0.9430
20:16:52.189703 [0] Epoch 00085 | Loss 0.2326
20:16:52.193945 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9434
20:16:52.563952 [0] Epoch 00086 | Loss 0.2315
20:16:52.567992 [0] Epoch: 086, Train: 0.9482, Val: 0.9430, Test: 0.9434
20:16:52.938308 [0] Epoch 00087 | Loss 0.2304
20:16:52.942332 [0] Epoch: 087, Train: 0.9484, Val: 0.9430, Test: 0.9435
20:16:53.314697 [0] Epoch 00088 | Loss 0.2294
20:16:53.319473 [0] Epoch: 088, Train: 0.9488, Val: 0.9433, Test: 0.9437
20:16:53.689868 [0] Epoch 00089 | Loss 0.2284
20:16:53.693988 [0] Epoch: 089, Train: 0.9491, Val: 0.9436, Test: 0.9436
20:16:54.064159 [0] Epoch 00090 | Loss 0.2274
20:16:54.068263 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9436
20:16:54.438492 [0] Epoch 00091 | Loss 0.2264
20:16:54.442535 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9439
20:16:54.813264 [0] Epoch 00092 | Loss 0.2255
20:16:54.817324 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9439
20:16:55.187480 [0] Epoch 00093 | Loss 0.2245
20:16:55.192703 [0] Epoch: 093, Train: 0.9496, Val: 0.9439, Test: 0.9440
20:16:55.563526 [0] Epoch 00094 | Loss 0.2236
20:16:55.568354 [0] Epoch: 094, Train: 0.9499, Val: 0.9441, Test: 0.9440
20:16:55.938755 [0] Epoch 00095 | Loss 0.2227
20:16:55.942945 [0] Epoch: 095, Train: 0.9500, Val: 0.9442, Test: 0.9441
20:16:56.313024 [0] Epoch 00096 | Loss 0.2219
20:16:56.317498 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9442
20:16:56.688103 [0] Epoch 00097 | Loss 0.2210
20:16:56.692150 [0] Epoch: 097, Train: 0.9503, Val: 0.9444, Test: 0.9445
20:16:57.062338 [0] Epoch 00098 | Loss 0.2201
20:16:57.066413 [0] Epoch: 098, Train: 0.9504, Val: 0.9444, Test: 0.9447
20:16:57.437231 [0] Epoch 00099 | Loss 0.2193
20:16:57.441248 [0] Epoch: 099, Train: 0.9506, Val: 0.9446, Test: 0.9448
20:16:57.811363 [0] Epoch 00100 | Loss 0.2185
20:16:57.815871 [0] Epoch: 100, Train: 0.9508, Val: 0.9449, Test: 0.9449
20:16:58.186837 [0] Epoch 00101 | Loss 0.2177
20:16:58.190887 [0] Epoch: 101, Train: 0.9510, Val: 0.9450, Test: 0.9449
20:16:58.560775 [0] Epoch 00102 | Loss 0.2169
20:16:58.565092 [0] Epoch: 102, Train: 0.9511, Val: 0.9452, Test: 0.9450
20:16:58.936029 [0] Epoch 00103 | Loss 0.2161
20:16:58.940557 [0] Epoch: 103, Train: 0.9512, Val: 0.9450, Test: 0.9450
20:16:59.311241 [0] Epoch 00104 | Loss 0.2153
20:16:59.315469 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9451
20:16:59.686206 [0] Epoch 00105 | Loss 0.2145
20:16:59.690272 [0] Epoch: 105, Train: 0.9516, Val: 0.9453, Test: 0.9452
20:17:00.060484 [0] Epoch 00106 | Loss 0.2138
20:17:00.065773 [0] Epoch: 106, Train: 0.9517, Val: 0.9454, Test: 0.9452
20:17:00.436876 [0] Epoch 00107 | Loss 0.2130
20:17:00.440903 [0] Epoch: 107, Train: 0.9518, Val: 0.9456, Test: 0.9454
20:17:00.812274 [0] Epoch 00108 | Loss 0.2123
20:17:00.816369 [0] Epoch: 108, Train: 0.9520, Val: 0.9455, Test: 0.9454
20:17:01.186894 [0] Epoch 00109 | Loss 0.2116
20:17:01.190925 [0] Epoch: 109, Train: 0.9521, Val: 0.9456, Test: 0.9453
20:17:01.563332 [0] Epoch 00110 | Loss 0.2109
20:17:01.567822 [0] Epoch: 110, Train: 0.9522, Val: 0.9457, Test: 0.9454
20:17:01.941640 [0] Epoch 00111 | Loss 0.2102
20:17:01.946180 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:17:02.319917 [0] Epoch 00112 | Loss 0.2095
20:17:02.324675 [0] Epoch: 112, Train: 0.9525, Val: 0.9456, Test: 0.9454
20:17:02.699004 [0] Epoch 00113 | Loss 0.2088
20:17:02.704208 [0] Epoch: 113, Train: 0.9526, Val: 0.9455, Test: 0.9454
20:17:03.077196 [0] Epoch 00114 | Loss 0.2082
20:17:03.082017 [0] Epoch: 114, Train: 0.9527, Val: 0.9454, Test: 0.9454
20:17:03.453464 [0] Epoch 00115 | Loss 0.2075
20:17:03.458281 [0] Epoch: 115, Train: 0.9529, Val: 0.9456, Test: 0.9455
20:17:03.829685 [0] Epoch 00116 | Loss 0.2069
20:17:03.833950 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9455
20:17:04.205578 [0] Epoch 00117 | Loss 0.2062
20:17:04.209831 [0] Epoch: 117, Train: 0.9531, Val: 0.9457, Test: 0.9457
20:17:04.580462 [0] Epoch 00118 | Loss 0.2056
20:17:04.584890 [0] Epoch: 118, Train: 0.9532, Val: 0.9458, Test: 0.9457
20:17:04.956067 [0] Epoch 00119 | Loss 0.2050
20:17:04.960426 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:17:05.331554 [0] Epoch 00120 | Loss 0.2044
20:17:05.335921 [0] Epoch: 120, Train: 0.9535, Val: 0.9460, Test: 0.9458
20:17:05.707069 [0] Epoch 00121 | Loss 0.2038
20:17:05.712545 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9459
20:17:06.084682 [0] Epoch 00122 | Loss 0.2032
20:17:06.090205 [0] Epoch: 122, Train: 0.9536, Val: 0.9462, Test: 0.9459
20:17:06.461712 [0] Epoch 00123 | Loss 0.2026
20:17:06.466150 [0] Epoch: 123, Train: 0.9537, Val: 0.9461, Test: 0.9459
20:17:06.838004 [0] Epoch 00124 | Loss 0.2020
20:17:06.843425 [0] Epoch: 124, Train: 0.9538, Val: 0.9462, Test: 0.9459
20:17:07.214682 [0] Epoch 00125 | Loss 0.2014
20:17:07.218983 [0] Epoch: 125, Train: 0.9540, Val: 0.9463, Test: 0.9459
20:17:07.590066 [0] Epoch 00126 | Loss 0.2008
20:17:07.595166 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9459
20:17:07.966407 [0] Epoch 00127 | Loss 0.2003
20:17:07.972071 [0] Epoch: 127, Train: 0.9541, Val: 0.9465, Test: 0.9459
20:17:08.344776 [0] Epoch 00128 | Loss 0.1997
20:17:08.349493 [0] Epoch: 128, Train: 0.9543, Val: 0.9466, Test: 0.9459
20:17:08.720675 [0] Epoch 00129 | Loss 0.1991
20:17:08.724944 [0] Epoch: 129, Train: 0.9544, Val: 0.9466, Test: 0.9459
20:17:09.096132 [0] Epoch 00130 | Loss 0.1986
20:17:09.100903 [0] Epoch: 130, Train: 0.9546, Val: 0.9466, Test: 0.9458
20:17:09.471657 [0] Epoch 00131 | Loss 0.1981
20:17:09.475704 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9459
20:17:09.846338 [0] Epoch 00132 | Loss 0.1975
20:17:09.850388 [0] Epoch: 132, Train: 0.9547, Val: 0.9468, Test: 0.9459
20:17:10.221563 [0] Epoch 00133 | Loss 0.1970
20:17:10.225614 [0] Epoch: 133, Train: 0.9548, Val: 0.9469, Test: 0.9459
20:17:10.596602 [0] Epoch 00134 | Loss 0.1965
20:17:10.600688 [0] Epoch: 134, Train: 0.9549, Val: 0.9469, Test: 0.9460
20:17:10.971645 [0] Epoch 00135 | Loss 0.1959
20:17:10.975689 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9461
20:17:11.345732 [0] Epoch 00136 | Loss 0.1954
20:17:11.350968 [0] Epoch: 136, Train: 0.9551, Val: 0.9470, Test: 0.9461
20:17:11.723294 [0] Epoch 00137 | Loss 0.1949
20:17:11.727393 [0] Epoch: 137, Train: 0.9552, Val: 0.9470, Test: 0.9461
20:17:12.098128 [0] Epoch 00138 | Loss 0.1944
20:17:12.102313 [0] Epoch: 138, Train: 0.9552, Val: 0.9470, Test: 0.9462
20:17:12.472925 [0] Epoch 00139 | Loss 0.1939
20:17:12.476961 [0] Epoch: 139, Train: 0.9553, Val: 0.9471, Test: 0.9462
20:17:12.847918 [0] Epoch 00140 | Loss 0.1935
20:17:12.853344 [0] Epoch: 140, Train: 0.9554, Val: 0.9472, Test: 0.9464
20:17:13.224680 [0] Epoch 00141 | Loss 0.1930
20:17:13.228766 [0] Epoch: 141, Train: 0.9555, Val: 0.9473, Test: 0.9464
20:17:13.599706 [0] Epoch 00142 | Loss 0.1925
20:17:13.604518 [0] Epoch: 142, Train: 0.9555, Val: 0.9474, Test: 0.9463
20:17:13.975094 [0] Epoch 00143 | Loss 0.1920
20:17:13.979257 [0] Epoch: 143, Train: 0.9556, Val: 0.9473, Test: 0.9464
20:17:14.350076 [0] Epoch 00144 | Loss 0.1916
20:17:14.354208 [0] Epoch: 144, Train: 0.9556, Val: 0.9474, Test: 0.9463
20:17:14.724768 [0] Epoch 00145 | Loss 0.1911
20:17:14.730595 [0] Epoch: 145, Train: 0.9558, Val: 0.9473, Test: 0.9463
20:17:15.101319 [0] Epoch 00146 | Loss 0.1906
20:17:15.105432 [0] Epoch: 146, Train: 0.9558, Val: 0.9472, Test: 0.9463
20:17:15.476032 [0] Epoch 00147 | Loss 0.1902
20:17:15.480123 [0] Epoch: 147, Train: 0.9559, Val: 0.9472, Test: 0.9464
20:17:15.850387 [0] Epoch 00148 | Loss 0.1897
20:17:15.854440 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:17:16.224712 [0] Epoch 00149 | Loss 0.1893
20:17:16.228817 [0] Epoch: 149, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:17:16.599134 [0] Epoch 00150 | Loss 0.1888
20:17:16.603184 [0] Epoch: 150, Train: 0.9561, Val: 0.9473, Test: 0.9463
20:17:16.973423 [0] Epoch 00151 | Loss 0.1884
20:17:16.978870 [0] Epoch: 151, Train: 0.9562, Val: 0.9470, Test: 0.9463
20:17:17.350787 [0] Epoch 00152 | Loss 0.1880
20:17:17.356295 [0] Epoch: 152, Train: 0.9563, Val: 0.9471, Test: 0.9463
20:17:17.726985 [0] Epoch 00153 | Loss 0.1875
20:17:17.731067 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9463
20:17:18.101313 [0] Epoch 00154 | Loss 0.1871
20:17:18.105397 [0] Epoch: 154, Train: 0.9564, Val: 0.9472, Test: 0.9464
20:17:18.475618 [0] Epoch 00155 | Loss 0.1867
20:17:18.479682 [0] Epoch: 155, Train: 0.9566, Val: 0.9472, Test: 0.9465
20:17:18.850562 [0] Epoch 00156 | Loss 0.1863
20:17:18.855026 [0] Epoch: 156, Train: 0.9567, Val: 0.9472, Test: 0.9464
20:17:19.225375 [0] Epoch 00157 | Loss 0.1859
20:17:19.229452 [0] Epoch: 157, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:17:19.599336 [0] Epoch 00158 | Loss 0.1854
20:17:19.603976 [0] Epoch: 158, Train: 0.9568, Val: 0.9472, Test: 0.9464
20:17:19.973836 [0] Epoch 00159 | Loss 0.1850
20:17:19.977946 [0] Epoch: 159, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:17:20.347812 [0] Epoch 00160 | Loss 0.1846
20:17:20.353516 [0] Epoch: 160, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:17:20.723716 [0] Epoch 00161 | Loss 0.1842
20:17:20.728927 [0] Epoch: 161, Train: 0.9570, Val: 0.9472, Test: 0.9465
20:17:21.099269 [0] Epoch 00162 | Loss 0.1838
20:17:21.103316 [0] Epoch: 162, Train: 0.9571, Val: 0.9471, Test: 0.9465
20:17:21.473789 [0] Epoch 00163 | Loss 0.1834
20:17:21.477975 [0] Epoch: 163, Train: 0.9572, Val: 0.9470, Test: 0.9465
20:17:21.847691 [0] Epoch 00164 | Loss 0.1830
20:17:21.851725 [0] Epoch: 164, Train: 0.9573, Val: 0.9469, Test: 0.9464
20:17:22.221757 [0] Epoch 00165 | Loss 0.1826
20:17:22.225826 [0] Epoch: 165, Train: 0.9574, Val: 0.9470, Test: 0.9465
20:17:22.596929 [0] Epoch 00166 | Loss 0.1822
20:17:22.600988 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:17:22.971681 [0] Epoch 00167 | Loss 0.1818
20:17:22.976468 [0] Epoch: 167, Train: 0.9576, Val: 0.9469, Test: 0.9466
20:17:23.347064 [0] Epoch 00168 | Loss 0.1814
20:17:23.351108 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:17:23.722037 [0] Epoch 00169 | Loss 0.1810
20:17:23.726100 [0] Epoch: 169, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:17:24.097258 [0] Epoch 00170 | Loss 0.1806
20:17:24.102445 [0] Epoch: 170, Train: 0.9578, Val: 0.9470, Test: 0.9467
20:17:24.473143 [0] Epoch 00171 | Loss 0.1803
20:17:24.477201 [0] Epoch: 171, Train: 0.9579, Val: 0.9471, Test: 0.9467
20:17:24.847226 [0] Epoch 00172 | Loss 0.1799
20:17:24.852011 [0] Epoch: 172, Train: 0.9580, Val: 0.9472, Test: 0.9467
20:17:25.222239 [0] Epoch 00173 | Loss 0.1795
20:17:25.226469 [0] Epoch: 173, Train: 0.9581, Val: 0.9471, Test: 0.9467
20:17:25.596898 [0] Epoch 00174 | Loss 0.1791
20:17:25.601172 [0] Epoch: 174, Train: 0.9582, Val: 0.9472, Test: 0.9467
20:17:25.971105 [0] Epoch 00175 | Loss 0.1788
20:17:25.975205 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:17:26.345283 [0] Epoch 00176 | Loss 0.1784
20:17:26.349339 [0] Epoch: 176, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:17:26.720335 [0] Epoch 00177 | Loss 0.1780
20:17:26.725519 [0] Epoch: 177, Train: 0.9583, Val: 0.9473, Test: 0.9468
20:17:27.097189 [0] Epoch 00178 | Loss 0.1776
20:17:27.102623 [0] Epoch: 178, Train: 0.9583, Val: 0.9474, Test: 0.9468
20:17:27.474312 [0] Epoch 00179 | Loss 0.1773
20:17:27.479837 [0] Epoch: 179, Train: 0.9584, Val: 0.9474, Test: 0.9468
20:17:27.851088 [0] Epoch 00180 | Loss 0.1769
20:17:27.855181 [0] Epoch: 180, Train: 0.9585, Val: 0.9475, Test: 0.9468
20:17:28.226223 [0] Epoch 00181 | Loss 0.1766
20:17:28.230349 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:17:28.601481 [0] Epoch 00182 | Loss 0.1762
20:17:28.606640 [0] Epoch: 182, Train: 0.9586, Val: 0.9475, Test: 0.9467
20:17:28.978896 [0] Epoch 00183 | Loss 0.1758
20:17:28.984420 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9468
20:17:29.355562 [0] Epoch 00184 | Loss 0.1755
20:17:29.359948 [0] Epoch: 184, Train: 0.9588, Val: 0.9475, Test: 0.9468
20:17:29.731353 [0] Epoch 00185 | Loss 0.1751
20:17:29.736875 [0] Epoch: 185, Train: 0.9588, Val: 0.9474, Test: 0.9468
20:17:30.108306 [0] Epoch 00186 | Loss 0.1748
20:17:30.112455 [0] Epoch: 186, Train: 0.9589, Val: 0.9474, Test: 0.9470
20:17:30.483891 [0] Epoch 00187 | Loss 0.1744
20:17:30.489645 [0] Epoch: 187, Train: 0.9591, Val: 0.9474, Test: 0.9470
20:17:30.860802 [0] Epoch 00188 | Loss 0.1741
20:17:30.864865 [0] Epoch: 188, Train: 0.9591, Val: 0.9474, Test: 0.9471
20:17:31.235619 [0] Epoch 00189 | Loss 0.1737
20:17:31.239702 [0] Epoch: 189, Train: 0.9592, Val: 0.9475, Test: 0.9471
20:17:31.610915 [0] Epoch 00190 | Loss 0.1734
20:17:31.615545 [0] Epoch: 190, Train: 0.9593, Val: 0.9475, Test: 0.9470
20:17:31.986585 [0] Epoch 00191 | Loss 0.1730
20:17:31.991943 [0] Epoch: 191, Train: 0.9593, Val: 0.9476, Test: 0.9469
20:17:32.363109 [0] Epoch 00192 | Loss 0.1728
20:17:32.367417 [0] Epoch: 192, Train: 0.9595, Val: 0.9474, Test: 0.9469
20:17:32.738298 [0] Epoch 00193 | Loss 0.1726
20:17:32.742378 [0] Epoch: 193, Train: 0.9593, Val: 0.9477, Test: 0.9470
20:17:33.113010 [0] Epoch 00194 | Loss 0.1730
20:17:33.117266 [0] Epoch: 194, Train: 0.9592, Val: 0.9471, Test: 0.9464
20:17:33.488108 [0] Epoch 00195 | Loss 0.1729
20:17:33.492229 [0] Epoch: 195, Train: 0.9592, Val: 0.9474, Test: 0.9469
20:17:33.862351 [0] Epoch 00196 | Loss 0.1721
20:17:33.866458 [0] Epoch: 196, Train: 0.9596, Val: 0.9472, Test: 0.9469
20:17:34.237610 [0] Epoch 00197 | Loss 0.1711
20:17:34.243037 [0] Epoch: 197, Train: 0.9597, Val: 0.9475, Test: 0.9471
20:17:34.614596 [0] Epoch 00198 | Loss 0.1716
20:17:34.618731 [0] Epoch: 198, Train: 0.9596, Val: 0.9477, Test: 0.9470
20:17:34.989896 [0] Epoch 00199 | Loss 0.1711
20:17:34.994059 [0] Epoch: 199, Train: 0.9598, Val: 0.9475, Test: 0.9471
20:17:34.995817 [0] 
timer summary:
  2.97s   0.08s   200 broadcast ForwardL1 0
 10.61s   0.69s  1600 broadcast
 60.29s   1.27s  1600 spmm
  2.58s   0.15s   200 broadcast ForwardL1 1
  1.72s   0.00s   800 mm
  1.28s   0.40s   200 broadcast ForwardL2 0
  1.06s   0.01s   200 broadcast ForwardL2 1
  0.37s   0.13s   200 broadcast BackwardL2 0
  0.18s   0.03s   200 broadcast BackwardL2 1
  0.30s   0.23s   400 all_reduce
  1.06s   0.10s   200 broadcast BackwardL1 0
  1.05s   0.00s   200 broadcast BackwardL1 1
 76.15s   0.25s   200 epoch
 85.66s   0.01s     1 total
20:21:19.550060 [0] proc begin: <DistEnv 0/2 nccl>
20:21:26.654713 [0] graph loaded <COO Graph: reddit, |V|: 232965, |E|: 114615892, masks: 153431,23831,55703><Local: 0, |V|: 116483, |E|: 58355276>
20:21:26.673021 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 736599 KiB | 738421 KiB | 742065 KiB |   5466 KiB |
|       from large pool | 735004 KiB | 736825 KiB | 740466 KiB |   5461 KiB |
|       from small pool |   1595 KiB |   1596 KiB |   1599 KiB |      4 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 736599 KiB | 738421 KiB | 742065 KiB |   5466 KiB |
|       from large pool | 735004 KiB | 736825 KiB | 740466 KiB |   5461 KiB |
|       from small pool |   1595 KiB |   1596 KiB |   1599 KiB |      4 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 733230 KiB | 735050 KiB | 738691 KiB |   5460 KiB |
|       from large pool | 731637 KiB | 733457 KiB | 737097 KiB |   5460 KiB |
|       from small pool |   1592 KiB |   1592 KiB |   1593 KiB |      0 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 755712 KiB | 755712 KiB | 755712 KiB |      0 B   |
|       from large pool | 753664 KiB | 753664 KiB | 753664 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  19112 KiB |  20479 KiB |  25945 KiB |   6833 KiB |
|       from large pool |  18659 KiB |  18659 KiB |  24121 KiB |   5461 KiB |
|       from small pool |    453 KiB |   1820 KiB |   1824 KiB |   1371 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      23    |      12    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      14    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      23    |      12    |
|       from large pool |       6    |       7    |       9    |       3    |
|       from small pool |       5    |       8    |      14    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |       2    |       0    |
|       from large pool |       1    |       1    |       1    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:21:28.980370 [0] Epoch 00000 | Loss 3.8027
20:21:29.004836 [0] Epoch: 000, Train: 0.0177, Val: 0.0172, Test: 0.0172
20:21:29.374978 [0] Epoch 00001 | Loss 3.4338
20:21:29.379052 [0] Epoch: 001, Train: 0.1158, Val: 0.1019, Test: 0.0997
20:21:29.749538 [0] Epoch 00002 | Loss 3.2834
20:21:29.753578 [0] Epoch: 002, Train: 0.2129, Val: 0.2001, Test: 0.1946
20:21:30.124063 [0] Epoch 00003 | Loss 3.1536
20:21:30.128820 [0] Epoch: 003, Train: 0.2557, Val: 0.2371, Test: 0.2363
20:21:30.498393 [0] Epoch 00004 | Loss 3.0465
20:21:30.503841 [0] Epoch: 004, Train: 0.2959, Val: 0.2737, Test: 0.2732
20:21:30.874480 [0] Epoch 00005 | Loss 2.9418
20:21:30.878779 [0] Epoch: 005, Train: 0.3216, Val: 0.2997, Test: 0.2995
20:21:31.248700 [0] Epoch 00006 | Loss 2.8316
20:21:31.253376 [0] Epoch: 006, Train: 0.3548, Val: 0.3401, Test: 0.3409
20:21:31.624043 [0] Epoch 00007 | Loss 2.7111
20:21:31.629479 [0] Epoch: 007, Train: 0.4122, Val: 0.4161, Test: 0.4215
20:21:32.000954 [0] Epoch 00008 | Loss 2.5768
20:21:32.006424 [0] Epoch: 008, Train: 0.4969, Val: 0.4999, Test: 0.5063
20:21:32.377027 [0] Epoch 00009 | Loss 2.4295
20:21:32.381037 [0] Epoch: 009, Train: 0.5323, Val: 0.5318, Test: 0.5378
20:21:32.751499 [0] Epoch 00010 | Loss 2.2739
20:21:32.757219 [0] Epoch: 010, Train: 0.5473, Val: 0.5462, Test: 0.5507
20:21:33.127900 [0] Epoch 00011 | Loss 2.1082
20:21:33.132330 [0] Epoch: 011, Train: 0.5866, Val: 0.5847, Test: 0.5873
20:21:33.502173 [0] Epoch 00012 | Loss 1.9361
20:21:33.507348 [0] Epoch: 012, Train: 0.6026, Val: 0.6003, Test: 0.6020
20:21:33.877846 [0] Epoch 00013 | Loss 1.7618
20:21:33.881884 [0] Epoch: 013, Train: 0.6137, Val: 0.6124, Test: 0.6129
20:21:34.252204 [0] Epoch 00014 | Loss 1.6006
20:21:34.257651 [0] Epoch: 014, Train: 0.6303, Val: 0.6294, Test: 0.6291
20:21:34.627235 [0] Epoch 00015 | Loss 1.4659
20:21:34.631215 [0] Epoch: 015, Train: 0.6723, Val: 0.6708, Test: 0.6711
20:21:35.001790 [0] Epoch 00016 | Loss 1.3545
20:21:35.007256 [0] Epoch: 016, Train: 0.6870, Val: 0.6849, Test: 0.6842
20:21:35.377653 [0] Epoch 00017 | Loss 1.2612
20:21:35.381676 [0] Epoch: 017, Train: 0.7055, Val: 0.7029, Test: 0.7013
20:21:35.751189 [0] Epoch 00018 | Loss 1.1716
20:21:35.756285 [0] Epoch: 018, Train: 0.7196, Val: 0.7164, Test: 0.7144
20:21:36.126324 [0] Epoch 00019 | Loss 1.0772
20:21:36.131495 [0] Epoch: 019, Train: 0.7520, Val: 0.7491, Test: 0.7448
20:21:36.501848 [0] Epoch 00020 | Loss 0.9926
20:21:36.505845 [0] Epoch: 020, Train: 0.7803, Val: 0.7727, Test: 0.7677
20:21:36.875670 [0] Epoch 00021 | Loss 0.9228
20:21:36.879688 [0] Epoch: 021, Train: 0.8002, Val: 0.7885, Test: 0.7843
20:21:37.249565 [0] Epoch 00022 | Loss 0.8649
20:21:37.253805 [0] Epoch: 022, Train: 0.8194, Val: 0.8087, Test: 0.8046
20:21:37.623565 [0] Epoch 00023 | Loss 0.8176
20:21:37.628302 [0] Epoch: 023, Train: 0.8334, Val: 0.8218, Test: 0.8178
20:21:38.000204 [0] Epoch 00024 | Loss 0.7771
20:21:38.005742 [0] Epoch: 024, Train: 0.8421, Val: 0.8299, Test: 0.8268
20:21:38.382480 [0] Epoch 00025 | Loss 0.7397
20:21:38.386535 [0] Epoch: 025, Train: 0.8490, Val: 0.8363, Test: 0.8330
20:21:38.757145 [0] Epoch 00026 | Loss 0.7027
20:21:38.762082 [0] Epoch: 026, Train: 0.8569, Val: 0.8449, Test: 0.8422
20:21:39.132499 [0] Epoch 00027 | Loss 0.6648
20:21:39.137125 [0] Epoch: 027, Train: 0.8798, Val: 0.8742, Test: 0.8730
20:21:39.507455 [0] Epoch 00028 | Loss 0.6249
20:21:39.511577 [0] Epoch: 028, Train: 0.9000, Val: 0.9018, Test: 0.8999
20:21:39.881150 [0] Epoch 00029 | Loss 0.5828
20:21:39.885188 [0] Epoch: 029, Train: 0.9053, Val: 0.9088, Test: 0.9065
20:21:40.256185 [0] Epoch 00030 | Loss 0.5397
20:21:40.261672 [0] Epoch: 030, Train: 0.9090, Val: 0.9126, Test: 0.9106
20:21:40.632791 [0] Epoch 00031 | Loss 0.4996
20:21:40.638259 [0] Epoch: 031, Train: 0.9122, Val: 0.9166, Test: 0.9149
20:21:41.010363 [0] Epoch 00032 | Loss 0.4665
20:21:41.016103 [0] Epoch: 032, Train: 0.9163, Val: 0.9203, Test: 0.9185
20:21:41.387752 [0] Epoch 00033 | Loss 0.4411
20:21:41.393217 [0] Epoch: 033, Train: 0.9210, Val: 0.9250, Test: 0.9227
20:21:41.763250 [0] Epoch 00034 | Loss 0.4207
20:21:41.768425 [0] Epoch: 034, Train: 0.9239, Val: 0.9280, Test: 0.9256
20:21:42.139444 [0] Epoch 00035 | Loss 0.4035
20:21:42.144227 [0] Epoch: 035, Train: 0.9261, Val: 0.9304, Test: 0.9276
20:21:42.515270 [0] Epoch 00036 | Loss 0.3894
20:21:42.519370 [0] Epoch: 036, Train: 0.9274, Val: 0.9321, Test: 0.9291
20:21:42.890126 [0] Epoch 00037 | Loss 0.3779
20:21:42.894206 [0] Epoch: 037, Train: 0.9283, Val: 0.9321, Test: 0.9306
20:21:43.265370 [0] Epoch 00038 | Loss 0.3682
20:21:43.270879 [0] Epoch: 038, Train: 0.9291, Val: 0.9327, Test: 0.9308
20:21:43.641713 [0] Epoch 00039 | Loss 0.3593
20:21:43.646540 [0] Epoch: 039, Train: 0.9300, Val: 0.9337, Test: 0.9316
20:21:44.017370 [0] Epoch 00040 | Loss 0.3507
20:21:44.022962 [0] Epoch: 040, Train: 0.9317, Val: 0.9347, Test: 0.9327
20:21:44.394083 [0] Epoch 00041 | Loss 0.3426
20:21:44.398155 [0] Epoch: 041, Train: 0.9330, Val: 0.9355, Test: 0.9339
20:21:44.769845 [0] Epoch 00042 | Loss 0.3357
20:21:44.774172 [0] Epoch: 042, Train: 0.9339, Val: 0.9359, Test: 0.9351
20:21:45.144658 [0] Epoch 00043 | Loss 0.3306
20:21:45.150083 [0] Epoch: 043, Train: 0.9347, Val: 0.9368, Test: 0.9362
20:21:45.521261 [0] Epoch 00044 | Loss 0.3266
20:21:45.525417 [0] Epoch: 044, Train: 0.9352, Val: 0.9371, Test: 0.9366
20:21:45.896008 [0] Epoch 00045 | Loss 0.3222
20:21:45.900020 [0] Epoch: 045, Train: 0.9357, Val: 0.9372, Test: 0.9369
20:21:46.271405 [0] Epoch 00046 | Loss 0.3175
20:21:46.276931 [0] Epoch: 046, Train: 0.9364, Val: 0.9377, Test: 0.9374
20:21:46.647788 [0] Epoch 00047 | Loss 0.3132
20:21:46.651845 [0] Epoch: 047, Train: 0.9367, Val: 0.9381, Test: 0.9376
20:21:47.022958 [0] Epoch 00048 | Loss 0.3091
20:21:47.027033 [0] Epoch: 048, Train: 0.9372, Val: 0.9382, Test: 0.9378
20:21:47.398367 [0] Epoch 00049 | Loss 0.3050
20:21:47.402555 [0] Epoch: 049, Train: 0.9375, Val: 0.9384, Test: 0.9381
20:21:47.772644 [0] Epoch 00050 | Loss 0.3012
20:21:47.778100 [0] Epoch: 050, Train: 0.9377, Val: 0.9383, Test: 0.9382
20:21:48.148936 [0] Epoch 00051 | Loss 0.2976
20:21:48.153037 [0] Epoch: 051, Train: 0.9383, Val: 0.9383, Test: 0.9381
20:21:48.523784 [0] Epoch 00052 | Loss 0.2944
20:21:48.529273 [0] Epoch: 052, Train: 0.9385, Val: 0.9388, Test: 0.9383
20:21:48.900894 [0] Epoch 00053 | Loss 0.2914
20:21:48.905410 [0] Epoch: 053, Train: 0.9387, Val: 0.9386, Test: 0.9383
20:21:49.276169 [0] Epoch 00054 | Loss 0.2881
20:21:49.282036 [0] Epoch: 054, Train: 0.9394, Val: 0.9388, Test: 0.9386
20:21:49.653380 [0] Epoch 00055 | Loss 0.2850
20:21:49.657447 [0] Epoch: 055, Train: 0.9398, Val: 0.9392, Test: 0.9389
20:21:50.028024 [0] Epoch 00056 | Loss 0.2822
20:21:50.032093 [0] Epoch: 056, Train: 0.9402, Val: 0.9395, Test: 0.9394
20:21:50.402663 [0] Epoch 00057 | Loss 0.2796
20:21:50.406724 [0] Epoch: 057, Train: 0.9406, Val: 0.9398, Test: 0.9396
20:21:50.777504 [0] Epoch 00058 | Loss 0.2769
20:21:50.782714 [0] Epoch: 058, Train: 0.9410, Val: 0.9403, Test: 0.9401
20:21:51.153952 [0] Epoch 00059 | Loss 0.2743
20:21:51.158035 [0] Epoch: 059, Train: 0.9415, Val: 0.9407, Test: 0.9403
20:21:51.528809 [0] Epoch 00060 | Loss 0.2720
20:21:51.532943 [0] Epoch: 060, Train: 0.9421, Val: 0.9405, Test: 0.9404
20:21:51.903954 [0] Epoch 00061 | Loss 0.2699
20:21:51.908109 [0] Epoch: 061, Train: 0.9424, Val: 0.9407, Test: 0.9402
20:21:52.278943 [0] Epoch 00062 | Loss 0.2678
20:21:52.283008 [0] Epoch: 062, Train: 0.9427, Val: 0.9408, Test: 0.9404
20:21:52.653588 [0] Epoch 00063 | Loss 0.2656
20:21:52.657717 [0] Epoch: 063, Train: 0.9431, Val: 0.9412, Test: 0.9407
20:21:53.029821 [0] Epoch 00064 | Loss 0.2635
20:21:53.035747 [0] Epoch: 064, Train: 0.9433, Val: 0.9413, Test: 0.9409
20:21:53.406756 [0] Epoch 00065 | Loss 0.2615
20:21:53.411021 [0] Epoch: 065, Train: 0.9435, Val: 0.9415, Test: 0.9412
20:21:53.781881 [0] Epoch 00066 | Loss 0.2596
20:21:53.785985 [0] Epoch: 066, Train: 0.9438, Val: 0.9417, Test: 0.9413
20:21:54.156470 [0] Epoch 00067 | Loss 0.2577
20:21:54.161835 [0] Epoch: 067, Train: 0.9442, Val: 0.9418, Test: 0.9414
20:21:54.533623 [0] Epoch 00068 | Loss 0.2559
20:21:54.538735 [0] Epoch: 068, Train: 0.9445, Val: 0.9421, Test: 0.9416
20:21:54.909663 [0] Epoch 00069 | Loss 0.2543
20:21:54.913741 [0] Epoch: 069, Train: 0.9449, Val: 0.9423, Test: 0.9418
20:21:55.284489 [0] Epoch 00070 | Loss 0.2526
20:21:55.288773 [0] Epoch: 070, Train: 0.9450, Val: 0.9426, Test: 0.9419
20:21:55.658913 [0] Epoch 00071 | Loss 0.2510
20:21:55.662954 [0] Epoch: 071, Train: 0.9452, Val: 0.9424, Test: 0.9420
20:21:56.033713 [0] Epoch 00072 | Loss 0.2494
20:21:56.038056 [0] Epoch: 072, Train: 0.9454, Val: 0.9423, Test: 0.9422
20:21:56.409060 [0] Epoch 00073 | Loss 0.2479
20:21:56.413138 [0] Epoch: 073, Train: 0.9458, Val: 0.9428, Test: 0.9424
20:21:56.783059 [0] Epoch 00074 | Loss 0.2465
20:21:56.788361 [0] Epoch: 074, Train: 0.9461, Val: 0.9431, Test: 0.9426
20:21:57.158885 [0] Epoch 00075 | Loss 0.2451
20:21:57.163930 [0] Epoch: 075, Train: 0.9463, Val: 0.9432, Test: 0.9425
20:21:57.534471 [0] Epoch 00076 | Loss 0.2437
20:21:57.539355 [0] Epoch: 076, Train: 0.9464, Val: 0.9431, Test: 0.9424
20:21:57.911270 [0] Epoch 00077 | Loss 0.2423
20:21:57.915438 [0] Epoch: 077, Train: 0.9467, Val: 0.9430, Test: 0.9425
20:21:58.286417 [0] Epoch 00078 | Loss 0.2410
20:21:58.291095 [0] Epoch: 078, Train: 0.9469, Val: 0.9430, Test: 0.9426
20:21:58.661525 [0] Epoch 00079 | Loss 0.2397
20:21:58.665629 [0] Epoch: 079, Train: 0.9470, Val: 0.9430, Test: 0.9427
20:21:59.037335 [0] Epoch 00080 | Loss 0.2384
20:21:59.041484 [0] Epoch: 080, Train: 0.9472, Val: 0.9429, Test: 0.9428
20:21:59.411877 [0] Epoch 00081 | Loss 0.2372
20:21:59.415947 [0] Epoch: 081, Train: 0.9474, Val: 0.9427, Test: 0.9426
20:21:59.786185 [0] Epoch 00082 | Loss 0.2360
20:21:59.790226 [0] Epoch: 082, Train: 0.9476, Val: 0.9427, Test: 0.9427
20:22:00.160641 [0] Epoch 00083 | Loss 0.2348
20:22:00.164780 [0] Epoch: 083, Train: 0.9479, Val: 0.9429, Test: 0.9430
20:22:00.534694 [0] Epoch 00084 | Loss 0.2337
20:22:00.538807 [0] Epoch: 084, Train: 0.9479, Val: 0.9432, Test: 0.9431
20:22:00.909511 [0] Epoch 00085 | Loss 0.2326
20:22:00.913884 [0] Epoch: 085, Train: 0.9480, Val: 0.9431, Test: 0.9434
20:22:01.284948 [0] Epoch 00086 | Loss 0.2315
20:22:01.289510 [0] Epoch: 086, Train: 0.9482, Val: 0.9431, Test: 0.9434
20:22:01.659520 [0] Epoch 00087 | Loss 0.2304
20:22:01.664865 [0] Epoch: 087, Train: 0.9484, Val: 0.9431, Test: 0.9435
20:22:02.040685 [0] Epoch 00088 | Loss 0.2294
20:22:02.045168 [0] Epoch: 088, Train: 0.9488, Val: 0.9433, Test: 0.9437
20:22:02.419631 [0] Epoch 00089 | Loss 0.2284
20:22:02.424110 [0] Epoch: 089, Train: 0.9491, Val: 0.9436, Test: 0.9436
20:22:02.798153 [0] Epoch 00090 | Loss 0.2274
20:22:02.802855 [0] Epoch: 090, Train: 0.9492, Val: 0.9437, Test: 0.9436
20:22:03.176426 [0] Epoch 00091 | Loss 0.2264
20:22:03.182082 [0] Epoch: 091, Train: 0.9494, Val: 0.9439, Test: 0.9439
20:22:03.553207 [0] Epoch 00092 | Loss 0.2255
20:22:03.557300 [0] Epoch: 092, Train: 0.9495, Val: 0.9439, Test: 0.9439
20:22:03.928231 [0] Epoch 00093 | Loss 0.2245
20:22:03.933603 [0] Epoch: 093, Train: 0.9497, Val: 0.9439, Test: 0.9440
20:22:04.304753 [0] Epoch 00094 | Loss 0.2236
20:22:04.309200 [0] Epoch: 094, Train: 0.9498, Val: 0.9442, Test: 0.9440
20:22:04.679592 [0] Epoch 00095 | Loss 0.2227
20:22:04.683985 [0] Epoch: 095, Train: 0.9500, Val: 0.9442, Test: 0.9441
20:22:05.054408 [0] Epoch 00096 | Loss 0.2219
20:22:05.059562 [0] Epoch: 096, Train: 0.9501, Val: 0.9444, Test: 0.9442
20:22:05.430352 [0] Epoch 00097 | Loss 0.2210
20:22:05.434485 [0] Epoch: 097, Train: 0.9503, Val: 0.9445, Test: 0.9445
20:22:05.804764 [0] Epoch 00098 | Loss 0.2201
20:22:05.808817 [0] Epoch: 098, Train: 0.9504, Val: 0.9444, Test: 0.9447
20:22:06.179287 [0] Epoch 00099 | Loss 0.2193
20:22:06.183343 [0] Epoch: 099, Train: 0.9506, Val: 0.9447, Test: 0.9448
20:22:06.553670 [0] Epoch 00100 | Loss 0.2185
20:22:06.558156 [0] Epoch: 100, Train: 0.9508, Val: 0.9449, Test: 0.9449
20:22:06.928188 [0] Epoch 00101 | Loss 0.2177
20:22:06.932235 [0] Epoch: 101, Train: 0.9510, Val: 0.9450, Test: 0.9449
20:22:07.303936 [0] Epoch 00102 | Loss 0.2169
20:22:07.309733 [0] Epoch: 102, Train: 0.9511, Val: 0.9452, Test: 0.9450
20:22:07.680899 [0] Epoch 00103 | Loss 0.2161
20:22:07.685126 [0] Epoch: 103, Train: 0.9512, Val: 0.9451, Test: 0.9450
20:22:08.055264 [0] Epoch 00104 | Loss 0.2153
20:22:08.059818 [0] Epoch: 104, Train: 0.9514, Val: 0.9452, Test: 0.9451
20:22:08.430832 [0] Epoch 00105 | Loss 0.2145
20:22:08.434948 [0] Epoch: 105, Train: 0.9516, Val: 0.9454, Test: 0.9452
20:22:08.805747 [0] Epoch 00106 | Loss 0.2138
20:22:08.811285 [0] Epoch: 106, Train: 0.9517, Val: 0.9454, Test: 0.9452
20:22:09.181983 [0] Epoch 00107 | Loss 0.2130
20:22:09.187060 [0] Epoch: 107, Train: 0.9518, Val: 0.9455, Test: 0.9454
20:22:09.557305 [0] Epoch 00108 | Loss 0.2123
20:22:09.561435 [0] Epoch: 108, Train: 0.9520, Val: 0.9454, Test: 0.9453
20:22:09.931454 [0] Epoch 00109 | Loss 0.2116
20:22:09.935461 [0] Epoch: 109, Train: 0.9521, Val: 0.9456, Test: 0.9453
20:22:10.306492 [0] Epoch 00110 | Loss 0.2109
20:22:10.311939 [0] Epoch: 110, Train: 0.9522, Val: 0.9456, Test: 0.9454
20:22:10.682193 [0] Epoch 00111 | Loss 0.2102
20:22:10.686212 [0] Epoch: 111, Train: 0.9524, Val: 0.9457, Test: 0.9454
20:22:11.056600 [0] Epoch 00112 | Loss 0.2095
20:22:11.062083 [0] Epoch: 112, Train: 0.9525, Val: 0.9456, Test: 0.9454
20:22:11.433059 [0] Epoch 00113 | Loss 0.2088
20:22:11.437087 [0] Epoch: 113, Train: 0.9526, Val: 0.9455, Test: 0.9454
20:22:11.807106 [0] Epoch 00114 | Loss 0.2082
20:22:11.811954 [0] Epoch: 114, Train: 0.9527, Val: 0.9454, Test: 0.9454
20:22:12.183486 [0] Epoch 00115 | Loss 0.2075
20:22:12.187688 [0] Epoch: 115, Train: 0.9529, Val: 0.9456, Test: 0.9455
20:22:12.558197 [0] Epoch 00116 | Loss 0.2069
20:22:12.562386 [0] Epoch: 116, Train: 0.9530, Val: 0.9457, Test: 0.9456
20:22:12.932693 [0] Epoch 00117 | Loss 0.2062
20:22:12.936789 [0] Epoch: 117, Train: 0.9531, Val: 0.9458, Test: 0.9456
20:22:13.306905 [0] Epoch 00118 | Loss 0.2056
20:22:13.311710 [0] Epoch: 118, Train: 0.9532, Val: 0.9458, Test: 0.9458
20:22:13.682058 [0] Epoch 00119 | Loss 0.2050
20:22:13.686390 [0] Epoch: 119, Train: 0.9533, Val: 0.9460, Test: 0.9458
20:22:14.057639 [0] Epoch 00120 | Loss 0.2044
20:22:14.061763 [0] Epoch: 120, Train: 0.9535, Val: 0.9460, Test: 0.9458
20:22:14.432581 [0] Epoch 00121 | Loss 0.2038
20:22:14.436990 [0] Epoch: 121, Train: 0.9535, Val: 0.9461, Test: 0.9459
20:22:14.807650 [0] Epoch 00122 | Loss 0.2032
20:22:14.811823 [0] Epoch: 122, Train: 0.9536, Val: 0.9462, Test: 0.9460
20:22:15.182032 [0] Epoch 00123 | Loss 0.2026
20:22:15.187861 [0] Epoch: 123, Train: 0.9537, Val: 0.9462, Test: 0.9459
20:22:15.558162 [0] Epoch 00124 | Loss 0.2020
20:22:15.562254 [0] Epoch: 124, Train: 0.9538, Val: 0.9462, Test: 0.9459
20:22:15.932621 [0] Epoch 00125 | Loss 0.2014
20:22:15.936717 [0] Epoch: 125, Train: 0.9540, Val: 0.9463, Test: 0.9459
20:22:16.307478 [0] Epoch 00126 | Loss 0.2008
20:22:16.311602 [0] Epoch: 126, Train: 0.9540, Val: 0.9465, Test: 0.9459
20:22:16.681806 [0] Epoch 00127 | Loss 0.2003
20:22:16.686083 [0] Epoch: 127, Train: 0.9541, Val: 0.9465, Test: 0.9459
20:22:17.056281 [0] Epoch 00128 | Loss 0.1997
20:22:17.060379 [0] Epoch: 128, Train: 0.9543, Val: 0.9467, Test: 0.9459
20:22:17.430669 [0] Epoch 00129 | Loss 0.1991
20:22:17.434741 [0] Epoch: 129, Train: 0.9544, Val: 0.9467, Test: 0.9459
20:22:17.805573 [0] Epoch 00130 | Loss 0.1986
20:22:17.811141 [0] Epoch: 130, Train: 0.9546, Val: 0.9466, Test: 0.9458
20:22:18.182846 [0] Epoch 00131 | Loss 0.1981
20:22:18.188105 [0] Epoch: 131, Train: 0.9546, Val: 0.9467, Test: 0.9459
20:22:18.559121 [0] Epoch 00132 | Loss 0.1975
20:22:18.563349 [0] Epoch: 132, Train: 0.9547, Val: 0.9468, Test: 0.9459
20:22:18.934269 [0] Epoch 00133 | Loss 0.1970
20:22:18.938537 [0] Epoch: 133, Train: 0.9548, Val: 0.9468, Test: 0.9459
20:22:19.309472 [0] Epoch 00134 | Loss 0.1965
20:22:19.314875 [0] Epoch: 134, Train: 0.9549, Val: 0.9469, Test: 0.9460
20:22:19.686902 [0] Epoch 00135 | Loss 0.1959
20:22:19.691211 [0] Epoch: 135, Train: 0.9550, Val: 0.9469, Test: 0.9461
20:22:20.061996 [0] Epoch 00136 | Loss 0.1954
20:22:20.066971 [0] Epoch: 136, Train: 0.9551, Val: 0.9469, Test: 0.9461
20:22:20.438433 [0] Epoch 00137 | Loss 0.1949
20:22:20.442680 [0] Epoch: 137, Train: 0.9552, Val: 0.9470, Test: 0.9461
20:22:20.813870 [0] Epoch 00138 | Loss 0.1944
20:22:20.819388 [0] Epoch: 138, Train: 0.9552, Val: 0.9470, Test: 0.9462
20:22:21.190043 [0] Epoch 00139 | Loss 0.1939
20:22:21.194291 [0] Epoch: 139, Train: 0.9553, Val: 0.9471, Test: 0.9462
20:22:21.564954 [0] Epoch 00140 | Loss 0.1935
20:22:21.569201 [0] Epoch: 140, Train: 0.9554, Val: 0.9472, Test: 0.9464
20:22:21.939434 [0] Epoch 00141 | Loss 0.1930
20:22:21.944486 [0] Epoch: 141, Train: 0.9555, Val: 0.9473, Test: 0.9464
20:22:22.315689 [0] Epoch 00142 | Loss 0.1925
20:22:22.321497 [0] Epoch: 142, Train: 0.9555, Val: 0.9473, Test: 0.9463
20:22:22.693034 [0] Epoch 00143 | Loss 0.1920
20:22:22.697132 [0] Epoch: 143, Train: 0.9556, Val: 0.9474, Test: 0.9464
20:22:23.067741 [0] Epoch 00144 | Loss 0.1916
20:22:23.072324 [0] Epoch: 144, Train: 0.9556, Val: 0.9473, Test: 0.9463
20:22:23.443158 [0] Epoch 00145 | Loss 0.1911
20:22:23.448567 [0] Epoch: 145, Train: 0.9558, Val: 0.9473, Test: 0.9463
20:22:23.819794 [0] Epoch 00146 | Loss 0.1906
20:22:23.825275 [0] Epoch: 146, Train: 0.9558, Val: 0.9473, Test: 0.9463
20:22:24.196594 [0] Epoch 00147 | Loss 0.1902
20:22:24.200662 [0] Epoch: 147, Train: 0.9559, Val: 0.9473, Test: 0.9464
20:22:24.571209 [0] Epoch 00148 | Loss 0.1897
20:22:24.575283 [0] Epoch: 148, Train: 0.9560, Val: 0.9473, Test: 0.9463
20:22:24.945924 [0] Epoch 00149 | Loss 0.1893
20:22:24.950119 [0] Epoch: 149, Train: 0.9560, Val: 0.9473, Test: 0.9464
20:22:25.320864 [0] Epoch 00150 | Loss 0.1888
20:22:25.326044 [0] Epoch: 150, Train: 0.9561, Val: 0.9473, Test: 0.9464
20:22:25.697723 [0] Epoch 00151 | Loss 0.1884
20:22:25.703223 [0] Epoch: 151, Train: 0.9562, Val: 0.9471, Test: 0.9463
20:22:26.074080 [0] Epoch 00152 | Loss 0.1880
20:22:26.078497 [0] Epoch: 152, Train: 0.9563, Val: 0.9471, Test: 0.9463
20:22:26.449871 [0] Epoch 00153 | Loss 0.1875
20:22:26.454696 [0] Epoch: 153, Train: 0.9564, Val: 0.9472, Test: 0.9463
20:22:26.826091 [0] Epoch 00154 | Loss 0.1871
20:22:26.831565 [0] Epoch: 154, Train: 0.9565, Val: 0.9472, Test: 0.9464
20:22:27.202225 [0] Epoch 00155 | Loss 0.1867
20:22:27.207479 [0] Epoch: 155, Train: 0.9566, Val: 0.9472, Test: 0.9464
20:22:27.578453 [0] Epoch 00156 | Loss 0.1863
20:22:27.582599 [0] Epoch: 156, Train: 0.9567, Val: 0.9472, Test: 0.9464
20:22:27.953209 [0] Epoch 00157 | Loss 0.1859
20:22:27.959090 [0] Epoch: 157, Train: 0.9567, Val: 0.9473, Test: 0.9464
20:22:28.330784 [0] Epoch 00158 | Loss 0.1854
20:22:28.336296 [0] Epoch: 158, Train: 0.9568, Val: 0.9472, Test: 0.9464
20:22:28.707453 [0] Epoch 00159 | Loss 0.1850
20:22:28.712743 [0] Epoch: 159, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:22:29.083578 [0] Epoch 00160 | Loss 0.1846
20:22:29.087629 [0] Epoch: 160, Train: 0.9569, Val: 0.9472, Test: 0.9464
20:22:29.458576 [0] Epoch 00161 | Loss 0.1842
20:22:29.464042 [0] Epoch: 161, Train: 0.9570, Val: 0.9472, Test: 0.9465
20:22:29.834617 [0] Epoch 00162 | Loss 0.1838
20:22:29.839778 [0] Epoch: 162, Train: 0.9571, Val: 0.9471, Test: 0.9465
20:22:30.211166 [0] Epoch 00163 | Loss 0.1834
20:22:30.216057 [0] Epoch: 163, Train: 0.9572, Val: 0.9470, Test: 0.9464
20:22:30.586623 [0] Epoch 00164 | Loss 0.1830
20:22:30.590708 [0] Epoch: 164, Train: 0.9573, Val: 0.9469, Test: 0.9464
20:22:30.961302 [0] Epoch 00165 | Loss 0.1826
20:22:30.965367 [0] Epoch: 165, Train: 0.9573, Val: 0.9470, Test: 0.9465
20:22:31.336781 [0] Epoch 00166 | Loss 0.1822
20:22:31.342269 [0] Epoch: 166, Train: 0.9575, Val: 0.9470, Test: 0.9465
20:22:31.712717 [0] Epoch 00167 | Loss 0.1818
20:22:31.716807 [0] Epoch: 167, Train: 0.9576, Val: 0.9470, Test: 0.9466
20:22:32.087776 [0] Epoch 00168 | Loss 0.1814
20:22:32.093229 [0] Epoch: 168, Train: 0.9577, Val: 0.9470, Test: 0.9466
20:22:32.464960 [0] Epoch 00169 | Loss 0.1810
20:22:32.470420 [0] Epoch: 169, Train: 0.9577, Val: 0.9470, Test: 0.9467
20:22:32.842629 [0] Epoch 00170 | Loss 0.1806
20:22:32.848120 [0] Epoch: 170, Train: 0.9578, Val: 0.9470, Test: 0.9467
20:22:33.221194 [0] Epoch 00171 | Loss 0.1803
20:22:33.226920 [0] Epoch: 171, Train: 0.9579, Val: 0.9471, Test: 0.9467
20:22:33.598191 [0] Epoch 00172 | Loss 0.1799
20:22:33.602653 [0] Epoch: 172, Train: 0.9580, Val: 0.9472, Test: 0.9467
20:22:33.972738 [0] Epoch 00173 | Loss 0.1795
20:22:33.977020 [0] Epoch: 173, Train: 0.9581, Val: 0.9472, Test: 0.9467
20:22:34.347307 [0] Epoch 00174 | Loss 0.1791
20:22:34.351566 [0] Epoch: 174, Train: 0.9581, Val: 0.9472, Test: 0.9468
20:22:34.722922 [0] Epoch 00175 | Loss 0.1788
20:22:34.728378 [0] Epoch: 175, Train: 0.9582, Val: 0.9473, Test: 0.9468
20:22:35.099435 [0] Epoch 00176 | Loss 0.1784
20:22:35.104875 [0] Epoch: 176, Train: 0.9582, Val: 0.9474, Test: 0.9468
20:22:35.476866 [0] Epoch 00177 | Loss 0.1780
20:22:35.482596 [0] Epoch: 177, Train: 0.9583, Val: 0.9474, Test: 0.9468
20:22:35.854423 [0] Epoch 00178 | Loss 0.1777
20:22:35.859890 [0] Epoch: 178, Train: 0.9583, Val: 0.9474, Test: 0.9468
20:22:36.232033 [0] Epoch 00179 | Loss 0.1773
20:22:36.236491 [0] Epoch: 179, Train: 0.9584, Val: 0.9474, Test: 0.9469
20:22:36.607320 [0] Epoch 00180 | Loss 0.1769
20:22:36.611589 [0] Epoch: 180, Train: 0.9585, Val: 0.9474, Test: 0.9469
20:22:36.982781 [0] Epoch 00181 | Loss 0.1766
20:22:36.987033 [0] Epoch: 181, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:22:37.358407 [0] Epoch 00182 | Loss 0.1762
20:22:37.363903 [0] Epoch: 182, Train: 0.9586, Val: 0.9475, Test: 0.9468
20:22:37.735912 [0] Epoch 00183 | Loss 0.1758
20:22:37.740228 [0] Epoch: 183, Train: 0.9588, Val: 0.9475, Test: 0.9468
20:22:38.111433 [0] Epoch 00184 | Loss 0.1755
20:22:38.115748 [0] Epoch: 184, Train: 0.9588, Val: 0.9474, Test: 0.9468
20:22:38.486641 [0] Epoch 00185 | Loss 0.1751
20:22:38.491369 [0] Epoch: 185, Train: 0.9588, Val: 0.9474, Test: 0.9468
20:22:38.862575 [0] Epoch 00186 | Loss 0.1748
20:22:38.867037 [0] Epoch: 186, Train: 0.9590, Val: 0.9474, Test: 0.9470
20:22:39.237890 [0] Epoch 00187 | Loss 0.1744
20:22:39.242041 [0] Epoch: 187, Train: 0.9590, Val: 0.9474, Test: 0.9469
20:22:39.613061 [0] Epoch 00188 | Loss 0.1741
20:22:39.618400 [0] Epoch: 188, Train: 0.9591, Val: 0.9473, Test: 0.9471
20:22:39.990316 [0] Epoch 00189 | Loss 0.1738
20:22:39.995806 [0] Epoch: 189, Train: 0.9591, Val: 0.9475, Test: 0.9470
20:22:40.366324 [0] Epoch 00190 | Loss 0.1735
20:22:40.370680 [0] Epoch: 190, Train: 0.9593, Val: 0.9474, Test: 0.9469
20:22:40.741521 [0] Epoch 00191 | Loss 0.1734
20:22:40.748050 [0] Epoch: 191, Train: 0.9592, Val: 0.9476, Test: 0.9470
20:22:41.118606 [0] Epoch 00192 | Loss 0.1735
20:22:41.123481 [0] Epoch: 192, Train: 0.9591, Val: 0.9469, Test: 0.9463
20:22:41.494679 [0] Epoch 00193 | Loss 0.1732
20:22:41.500148 [0] Epoch: 193, Train: 0.9592, Val: 0.9475, Test: 0.9471
20:22:41.871906 [0] Epoch 00194 | Loss 0.1724
20:22:41.877386 [0] Epoch: 194, Train: 0.9596, Val: 0.9473, Test: 0.9470
20:22:42.248409 [0] Epoch 00195 | Loss 0.1718
20:22:42.253943 [0] Epoch: 195, Train: 0.9596, Val: 0.9475, Test: 0.9471
20:22:42.625834 [0] Epoch 00196 | Loss 0.1720
20:22:42.630202 [0] Epoch: 196, Train: 0.9595, Val: 0.9478, Test: 0.9469
20:22:43.001379 [0] Epoch 00197 | Loss 0.1716
20:22:43.005449 [0] Epoch: 197, Train: 0.9597, Val: 0.9474, Test: 0.9470
20:22:43.377120 [0] Epoch 00198 | Loss 0.1708
20:22:43.382643 [0] Epoch: 198, Train: 0.9598, Val: 0.9473, Test: 0.9470
20:22:43.754721 [0] Epoch 00199 | Loss 0.1709
20:22:43.758820 [0] Epoch: 199, Train: 0.9597, Val: 0.9477, Test: 0.9469
20:22:43.760445 [0] 
timer summary:
  3.10s   0.18s   200 broadcast ForwardL1 0
 10.70s   0.67s  1600 broadcast
 60.29s   1.28s  1600 spmm
  2.58s   0.16s   200 broadcast ForwardL1 1
  1.72s   0.00s   800 mm
  1.28s   0.41s   200 broadcast ForwardL2 0
  1.06s   0.01s   200 broadcast ForwardL2 1
  0.32s   0.20s   200 broadcast BackwardL2 0
  0.18s   0.03s   200 broadcast BackwardL2 1
  0.29s   0.24s   400 all_reduce
  1.05s   0.10s   200 broadcast BackwardL1 0
  1.06s   0.01s   200 broadcast BackwardL1 1
 76.33s   0.40s   200 epoch
 84.21s   0.00s     1 total
20:55:17.517674 [0] proc begin: <DistEnv 0/2 nccl>
20:55:42.281199 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
20:55:42.287315 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1092 MiB |   1111 MiB |   1616 MiB | 536640 KiB |
|       from large pool |   1092 MiB |   1111 MiB |   1616 MiB | 536632 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1092 MiB |   1111 MiB |   1616 MiB | 536640 KiB |
|       from large pool |   1092 MiB |   1111 MiB |   1616 MiB | 536632 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1090 MiB |   1109 MiB |   1613 MiB | 535729 KiB |
|       from large pool |   1090 MiB |   1109 MiB |   1613 MiB | 535725 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1198 MiB |   1198 MiB |   1198 MiB |      0 B   |
|       from large pool |   1196 MiB |   1196 MiB |   1196 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 105652 KiB | 304551 KiB | 372884 KiB | 267231 KiB |
|       from large pool | 105652 KiB | 304551 KiB | 366735 KiB | 261083 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |       6    |       3    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

20:55:44.340926 [0] Epoch 00000 | Loss 4.7410
20:55:44.402373 [0] Epoch: 000, Train: 0.0291, Val: 0.0280, Test: 0.0267
20:55:45.075595 [0] Epoch 00001 | Loss 3.9229
20:55:45.117346 [0] Epoch: 001, Train: 0.0636, Val: 0.0616, Test: 0.0512
20:55:45.778394 [0] Epoch 00002 | Loss 3.2705
20:55:45.820084 [0] Epoch: 002, Train: 0.2419, Val: 0.2230, Test: 0.1489
20:55:46.480795 [0] Epoch 00003 | Loss 2.8071
20:55:46.522446 [0] Epoch: 003, Train: 0.4116, Val: 0.3910, Test: 0.2628
20:55:47.184016 [0] Epoch 00004 | Loss 2.4711
20:55:47.225836 [0] Epoch: 004, Train: 0.5207, Val: 0.5033, Test: 0.3458
20:55:47.887743 [0] Epoch 00005 | Loss 2.2229
20:55:47.929963 [0] Epoch: 005, Train: 0.5857, Val: 0.5718, Test: 0.4060
20:55:48.591304 [0] Epoch 00006 | Loss 2.0293
20:55:48.633467 [0] Epoch: 006, Train: 0.6275, Val: 0.6158, Test: 0.4482
20:55:49.293570 [0] Epoch 00007 | Loss 1.8677
20:55:49.335286 [0] Epoch: 007, Train: 0.6613, Val: 0.6507, Test: 0.4781
20:55:49.997750 [0] Epoch 00008 | Loss 1.7264
20:55:50.039515 [0] Epoch: 008, Train: 0.6909, Val: 0.6792, Test: 0.5022
20:55:50.700290 [0] Epoch 00009 | Loss 1.6003
20:55:50.742245 [0] Epoch: 009, Train: 0.7199, Val: 0.7082, Test: 0.5240
20:55:51.404235 [0] Epoch 00010 | Loss 1.4872
20:55:51.445979 [0] Epoch: 010, Train: 0.7451, Val: 0.7331, Test: 0.5442
20:55:52.105458 [0] Epoch 00011 | Loss 1.3859
20:55:52.147981 [0] Epoch: 011, Train: 0.7662, Val: 0.7539, Test: 0.5626
20:55:52.809836 [0] Epoch 00012 | Loss 1.2961
20:55:52.851791 [0] Epoch: 012, Train: 0.7828, Val: 0.7717, Test: 0.5795
20:55:53.512573 [0] Epoch 00013 | Loss 1.2172
20:55:53.554840 [0] Epoch: 013, Train: 0.7969, Val: 0.7855, Test: 0.5946
20:55:54.216074 [0] Epoch 00014 | Loss 1.1486
20:55:54.258295 [0] Epoch: 014, Train: 0.8083, Val: 0.7969, Test: 0.6085
20:55:54.918409 [0] Epoch 00015 | Loss 1.0889
20:55:54.960583 [0] Epoch: 015, Train: 0.8165, Val: 0.8067, Test: 0.6201
20:55:55.622782 [0] Epoch 00016 | Loss 1.0369
20:55:55.664338 [0] Epoch: 016, Train: 0.8232, Val: 0.8128, Test: 0.6294
20:55:56.325226 [0] Epoch 00017 | Loss 0.9914
20:55:56.367021 [0] Epoch: 017, Train: 0.8291, Val: 0.8191, Test: 0.6373
20:55:57.028163 [0] Epoch 00018 | Loss 0.9510
20:55:57.069912 [0] Epoch: 018, Train: 0.8338, Val: 0.8245, Test: 0.6437
20:55:57.730068 [0] Epoch 00019 | Loss 0.9149
20:55:57.772102 [0] Epoch: 019, Train: 0.8380, Val: 0.8289, Test: 0.6491
20:55:58.432121 [0] Epoch 00020 | Loss 0.8822
20:55:58.473866 [0] Epoch: 020, Train: 0.8418, Val: 0.8331, Test: 0.6536
20:55:59.133466 [0] Epoch 00021 | Loss 0.8523
20:55:59.175359 [0] Epoch: 021, Train: 0.8454, Val: 0.8360, Test: 0.6577
20:55:59.835395 [0] Epoch 00022 | Loss 0.8247
20:55:59.877376 [0] Epoch: 022, Train: 0.8493, Val: 0.8385, Test: 0.6616
20:56:00.537579 [0] Epoch 00023 | Loss 0.7990
20:56:00.580408 [0] Epoch: 023, Train: 0.8524, Val: 0.8415, Test: 0.6650
20:56:01.240371 [0] Epoch 00024 | Loss 0.7752
20:56:01.282385 [0] Epoch: 024, Train: 0.8556, Val: 0.8445, Test: 0.6677
20:56:01.941735 [0] Epoch 00025 | Loss 0.7531
20:56:01.983602 [0] Epoch: 025, Train: 0.8581, Val: 0.8471, Test: 0.6704
20:56:02.654979 [0] Epoch 00026 | Loss 0.7329
20:56:02.698056 [0] Epoch: 026, Train: 0.8606, Val: 0.8497, Test: 0.6726
20:56:03.367907 [0] Epoch 00027 | Loss 0.7146
20:56:03.410962 [0] Epoch: 027, Train: 0.8623, Val: 0.8519, Test: 0.6746
20:56:04.073054 [0] Epoch 00028 | Loss 0.6980
20:56:04.114508 [0] Epoch: 028, Train: 0.8638, Val: 0.8539, Test: 0.6764
20:56:04.774286 [0] Epoch 00029 | Loss 0.6829
20:56:04.815795 [0] Epoch: 029, Train: 0.8647, Val: 0.8551, Test: 0.6779
20:56:05.478164 [0] Epoch 00030 | Loss 0.6688
20:56:05.519995 [0] Epoch: 030, Train: 0.8657, Val: 0.8563, Test: 0.6795
20:56:06.179646 [0] Epoch 00031 | Loss 0.6555
20:56:06.221690 [0] Epoch: 031, Train: 0.8667, Val: 0.8579, Test: 0.6810
20:56:06.882104 [0] Epoch 00032 | Loss 0.6426
20:56:06.924310 [0] Epoch: 032, Train: 0.8681, Val: 0.8587, Test: 0.6829
20:56:07.583994 [0] Epoch 00033 | Loss 0.6303
20:56:07.626329 [0] Epoch: 033, Train: 0.8699, Val: 0.8609, Test: 0.6851
20:56:08.287347 [0] Epoch 00034 | Loss 0.6187
20:56:08.329243 [0] Epoch: 034, Train: 0.8712, Val: 0.8627, Test: 0.6883
20:56:08.988528 [0] Epoch 00035 | Loss 0.6079
20:56:09.030717 [0] Epoch: 035, Train: 0.8728, Val: 0.8634, Test: 0.6917
20:56:09.690750 [0] Epoch 00036 | Loss 0.5981
20:56:09.732629 [0] Epoch: 036, Train: 0.8741, Val: 0.8635, Test: 0.6950
20:56:10.393009 [0] Epoch 00037 | Loss 0.5891
20:56:10.434922 [0] Epoch: 037, Train: 0.8753, Val: 0.8653, Test: 0.6982
20:56:11.095019 [0] Epoch 00038 | Loss 0.5808
20:56:11.136963 [0] Epoch: 038, Train: 0.8765, Val: 0.8669, Test: 0.7014
20:56:11.797196 [0] Epoch 00039 | Loss 0.5730
20:56:11.839685 [0] Epoch: 039, Train: 0.8774, Val: 0.8677, Test: 0.7044
20:56:12.499947 [0] Epoch 00040 | Loss 0.5656
20:56:12.541925 [0] Epoch: 040, Train: 0.8785, Val: 0.8687, Test: 0.7069
20:56:13.202053 [0] Epoch 00041 | Loss 0.5583
20:56:13.244198 [0] Epoch: 041, Train: 0.8797, Val: 0.8698, Test: 0.7092
20:56:13.904554 [0] Epoch 00042 | Loss 0.5511
20:56:13.946484 [0] Epoch: 042, Train: 0.8805, Val: 0.8708, Test: 0.7110
20:56:14.606379 [0] Epoch 00043 | Loss 0.5440
20:56:14.647765 [0] Epoch: 043, Train: 0.8817, Val: 0.8714, Test: 0.7124
20:56:15.309168 [0] Epoch 00044 | Loss 0.5371
20:56:15.350696 [0] Epoch: 044, Train: 0.8827, Val: 0.8733, Test: 0.7135
20:56:16.009704 [0] Epoch 00045 | Loss 0.5305
20:56:16.052476 [0] Epoch: 045, Train: 0.8836, Val: 0.8744, Test: 0.7145
20:56:16.714170 [0] Epoch 00046 | Loss 0.5242
20:56:16.756101 [0] Epoch: 046, Train: 0.8847, Val: 0.8752, Test: 0.7156
20:56:17.416171 [0] Epoch 00047 | Loss 0.5183
20:56:17.458608 [0] Epoch: 047, Train: 0.8854, Val: 0.8760, Test: 0.7163
20:56:18.119917 [0] Epoch 00048 | Loss 0.5127
20:56:18.161894 [0] Epoch: 048, Train: 0.8861, Val: 0.8772, Test: 0.7170
20:56:18.822132 [0] Epoch 00049 | Loss 0.5074
20:56:18.863873 [0] Epoch: 049, Train: 0.8870, Val: 0.8776, Test: 0.7175
20:56:19.526544 [0] Epoch 00050 | Loss 0.5023
20:56:19.568508 [0] Epoch: 050, Train: 0.8879, Val: 0.8784, Test: 0.7180
20:56:20.228640 [0] Epoch 00051 | Loss 0.4975
20:56:20.270383 [0] Epoch: 051, Train: 0.8887, Val: 0.8787, Test: 0.7186
20:56:20.932839 [0] Epoch 00052 | Loss 0.4927
20:56:20.974704 [0] Epoch: 052, Train: 0.8894, Val: 0.8798, Test: 0.7191
20:56:21.634664 [0] Epoch 00053 | Loss 0.4880
20:56:21.676725 [0] Epoch: 053, Train: 0.8904, Val: 0.8805, Test: 0.7196
20:56:22.338475 [0] Epoch 00054 | Loss 0.4835
20:56:22.380607 [0] Epoch: 054, Train: 0.8913, Val: 0.8814, Test: 0.7203
20:56:23.041246 [0] Epoch 00055 | Loss 0.4790
20:56:23.082975 [0] Epoch: 055, Train: 0.8917, Val: 0.8823, Test: 0.7210
20:56:23.745010 [0] Epoch 00056 | Loss 0.4748
20:56:23.786686 [0] Epoch: 056, Train: 0.8925, Val: 0.8831, Test: 0.7218
20:56:24.447744 [0] Epoch 00057 | Loss 0.4707
20:56:24.489797 [0] Epoch: 057, Train: 0.8933, Val: 0.8841, Test: 0.7228
20:56:25.151211 [0] Epoch 00058 | Loss 0.4669
20:56:25.193094 [0] Epoch: 058, Train: 0.8940, Val: 0.8845, Test: 0.7239
20:56:25.854045 [0] Epoch 00059 | Loss 0.4632
20:56:25.896047 [0] Epoch: 059, Train: 0.8946, Val: 0.8847, Test: 0.7251
20:56:26.558596 [0] Epoch 00060 | Loss 0.4597
20:56:26.600674 [0] Epoch: 060, Train: 0.8952, Val: 0.8851, Test: 0.7264
20:56:27.262678 [0] Epoch 00061 | Loss 0.4563
20:56:27.304385 [0] Epoch: 061, Train: 0.8959, Val: 0.8856, Test: 0.7276
20:56:27.966071 [0] Epoch 00062 | Loss 0.4530
20:56:28.007739 [0] Epoch: 062, Train: 0.8963, Val: 0.8863, Test: 0.7288
20:56:28.669952 [0] Epoch 00063 | Loss 0.4498
20:56:28.711886 [0] Epoch: 063, Train: 0.8968, Val: 0.8866, Test: 0.7300
20:56:29.372786 [0] Epoch 00064 | Loss 0.4468
20:56:29.414612 [0] Epoch: 064, Train: 0.8974, Val: 0.8869, Test: 0.7308
20:56:30.075423 [0] Epoch 00065 | Loss 0.4438
20:56:30.117532 [0] Epoch: 065, Train: 0.8979, Val: 0.8874, Test: 0.7316
20:56:30.781230 [0] Epoch 00066 | Loss 0.4409
20:56:30.822970 [0] Epoch: 066, Train: 0.8982, Val: 0.8878, Test: 0.7324
20:56:31.483929 [0] Epoch 00067 | Loss 0.4381
20:56:31.525631 [0] Epoch: 067, Train: 0.8986, Val: 0.8885, Test: 0.7330
20:56:32.187467 [0] Epoch 00068 | Loss 0.4353
20:56:32.229369 [0] Epoch: 068, Train: 0.8991, Val: 0.8887, Test: 0.7335
20:56:32.889609 [0] Epoch 00069 | Loss 0.4327
20:56:32.932119 [0] Epoch: 069, Train: 0.8995, Val: 0.8888, Test: 0.7339
20:56:33.593894 [0] Epoch 00070 | Loss 0.4301
20:56:33.636009 [0] Epoch: 070, Train: 0.8998, Val: 0.8891, Test: 0.7342
20:56:34.297206 [0] Epoch 00071 | Loss 0.4276
20:56:34.339048 [0] Epoch: 071, Train: 0.9001, Val: 0.8899, Test: 0.7344
20:56:35.002244 [0] Epoch 00072 | Loss 0.4252
20:56:35.044126 [0] Epoch: 072, Train: 0.9005, Val: 0.8900, Test: 0.7345
20:56:35.705723 [0] Epoch 00073 | Loss 0.4229
20:56:35.747870 [0] Epoch: 073, Train: 0.9008, Val: 0.8902, Test: 0.7346
20:56:36.410040 [0] Epoch 00074 | Loss 0.4207
20:56:36.451945 [0] Epoch: 074, Train: 0.9011, Val: 0.8906, Test: 0.7347
20:56:37.113113 [0] Epoch 00075 | Loss 0.4186
20:56:37.155124 [0] Epoch: 075, Train: 0.9014, Val: 0.8908, Test: 0.7348
20:56:37.816676 [0] Epoch 00076 | Loss 0.4165
20:56:37.858644 [0] Epoch: 076, Train: 0.9017, Val: 0.8913, Test: 0.7350
20:56:38.519915 [0] Epoch 00077 | Loss 0.4145
20:56:38.561678 [0] Epoch: 077, Train: 0.9019, Val: 0.8914, Test: 0.7351
20:56:39.222859 [0] Epoch 00078 | Loss 0.4125
20:56:39.264849 [0] Epoch: 078, Train: 0.9023, Val: 0.8915, Test: 0.7354
20:56:39.925725 [0] Epoch 00079 | Loss 0.4105
20:56:39.967919 [0] Epoch: 079, Train: 0.9026, Val: 0.8917, Test: 0.7357
20:56:40.631501 [0] Epoch 00080 | Loss 0.4086
20:56:40.673669 [0] Epoch: 080, Train: 0.9030, Val: 0.8919, Test: 0.7361
20:56:41.334166 [0] Epoch 00081 | Loss 0.4068
20:56:41.376026 [0] Epoch: 081, Train: 0.9033, Val: 0.8923, Test: 0.7366
20:56:42.037667 [0] Epoch 00082 | Loss 0.4050
20:56:42.079348 [0] Epoch: 082, Train: 0.9036, Val: 0.8927, Test: 0.7371
20:56:42.740713 [0] Epoch 00083 | Loss 0.4032
20:56:42.782362 [0] Epoch: 083, Train: 0.9038, Val: 0.8929, Test: 0.7376
20:56:43.444011 [0] Epoch 00084 | Loss 0.4015
20:56:43.485746 [0] Epoch: 084, Train: 0.9039, Val: 0.8931, Test: 0.7381
20:56:44.146110 [0] Epoch 00085 | Loss 0.3998
20:56:44.187951 [0] Epoch: 085, Train: 0.9040, Val: 0.8935, Test: 0.7386
20:56:44.849493 [0] Epoch 00086 | Loss 0.3981
20:56:44.891455 [0] Epoch: 086, Train: 0.9043, Val: 0.8937, Test: 0.7390
20:56:45.552443 [0] Epoch 00087 | Loss 0.3965
20:56:45.594360 [0] Epoch: 087, Train: 0.9045, Val: 0.8939, Test: 0.7394
20:56:46.258254 [0] Epoch 00088 | Loss 0.3949
20:56:46.300007 [0] Epoch: 088, Train: 0.9047, Val: 0.8945, Test: 0.7397
20:56:46.960907 [0] Epoch 00089 | Loss 0.3933
20:56:47.002675 [0] Epoch: 089, Train: 0.9049, Val: 0.8948, Test: 0.7399
20:56:47.664421 [0] Epoch 00090 | Loss 0.3918
20:56:47.706418 [0] Epoch: 090, Train: 0.9052, Val: 0.8949, Test: 0.7401
20:56:48.366314 [0] Epoch 00091 | Loss 0.3903
20:56:48.408467 [0] Epoch: 091, Train: 0.9055, Val: 0.8950, Test: 0.7402
20:56:49.069606 [0] Epoch 00092 | Loss 0.3888
20:56:49.111979 [0] Epoch: 092, Train: 0.9057, Val: 0.8953, Test: 0.7403
20:56:49.772272 [0] Epoch 00093 | Loss 0.3874
20:56:49.813918 [0] Epoch: 093, Train: 0.9059, Val: 0.8955, Test: 0.7404
20:56:50.475127 [0] Epoch 00094 | Loss 0.3860
20:56:50.516953 [0] Epoch: 094, Train: 0.9062, Val: 0.8959, Test: 0.7405
20:56:51.177354 [0] Epoch 00095 | Loss 0.3846
20:56:51.219016 [0] Epoch: 095, Train: 0.9064, Val: 0.8960, Test: 0.7406
20:56:51.880669 [0] Epoch 00096 | Loss 0.3833
20:56:51.922553 [0] Epoch: 096, Train: 0.9067, Val: 0.8962, Test: 0.7407
20:56:52.582538 [0] Epoch 00097 | Loss 0.3819
20:56:52.624542 [0] Epoch: 097, Train: 0.9071, Val: 0.8964, Test: 0.7408
20:56:53.286248 [0] Epoch 00098 | Loss 0.3806
20:56:53.328571 [0] Epoch: 098, Train: 0.9073, Val: 0.8967, Test: 0.7409
20:56:53.988341 [0] Epoch 00099 | Loss 0.3793
20:56:54.030413 [0] Epoch: 099, Train: 0.9076, Val: 0.8969, Test: 0.7410
20:56:54.691876 [0] Epoch 00100 | Loss 0.3781
20:56:54.733543 [0] Epoch: 100, Train: 0.9080, Val: 0.8970, Test: 0.7411
20:56:55.393398 [0] Epoch 00101 | Loss 0.3768
20:56:55.435338 [0] Epoch: 101, Train: 0.9083, Val: 0.8972, Test: 0.7414
20:56:56.097218 [0] Epoch 00102 | Loss 0.3756
20:56:56.138906 [0] Epoch: 102, Train: 0.9087, Val: 0.8972, Test: 0.7416
20:56:56.798729 [0] Epoch 00103 | Loss 0.3744
20:56:56.840808 [0] Epoch: 103, Train: 0.9089, Val: 0.8975, Test: 0.7419
20:56:57.502162 [0] Epoch 00104 | Loss 0.3732
20:56:57.543945 [0] Epoch: 104, Train: 0.9092, Val: 0.8976, Test: 0.7422
20:56:58.204265 [0] Epoch 00105 | Loss 0.3721
20:56:58.246118 [0] Epoch: 105, Train: 0.9094, Val: 0.8978, Test: 0.7426
20:56:58.907539 [0] Epoch 00106 | Loss 0.3709
20:56:58.949316 [0] Epoch: 106, Train: 0.9096, Val: 0.8979, Test: 0.7428
20:56:59.609714 [0] Epoch 00107 | Loss 0.3698
20:56:59.651411 [0] Epoch: 107, Train: 0.9098, Val: 0.8981, Test: 0.7430
20:57:00.312687 [0] Epoch 00108 | Loss 0.3687
20:57:00.354203 [0] Epoch: 108, Train: 0.9100, Val: 0.8983, Test: 0.7432
20:57:01.014274 [0] Epoch 00109 | Loss 0.3677
20:57:01.055936 [0] Epoch: 109, Train: 0.9102, Val: 0.8984, Test: 0.7434
20:57:01.718731 [0] Epoch 00110 | Loss 0.3666
20:57:01.761635 [0] Epoch: 110, Train: 0.9104, Val: 0.8986, Test: 0.7435
20:57:02.432657 [0] Epoch 00111 | Loss 0.3655
20:57:02.475553 [0] Epoch: 111, Train: 0.9106, Val: 0.8987, Test: 0.7436
20:57:03.146353 [0] Epoch 00112 | Loss 0.3645
20:57:03.188232 [0] Epoch: 112, Train: 0.9109, Val: 0.8987, Test: 0.7438
20:57:03.849501 [0] Epoch 00113 | Loss 0.3635
20:57:03.891164 [0] Epoch: 113, Train: 0.9111, Val: 0.8989, Test: 0.7439
20:57:04.552780 [0] Epoch 00114 | Loss 0.3625
20:57:04.594583 [0] Epoch: 114, Train: 0.9113, Val: 0.8990, Test: 0.7441
20:57:05.255232 [0] Epoch 00115 | Loss 0.3615
20:57:05.297181 [0] Epoch: 115, Train: 0.9115, Val: 0.8992, Test: 0.7442
20:57:05.959040 [0] Epoch 00116 | Loss 0.3605
20:57:06.000931 [0] Epoch: 116, Train: 0.9118, Val: 0.8995, Test: 0.7445
20:57:06.661447 [0] Epoch 00117 | Loss 0.3595
20:57:06.703978 [0] Epoch: 117, Train: 0.9120, Val: 0.8996, Test: 0.7447
20:57:07.366240 [0] Epoch 00118 | Loss 0.3586
20:57:07.408091 [0] Epoch: 118, Train: 0.9122, Val: 0.8999, Test: 0.7449
20:57:08.068670 [0] Epoch 00119 | Loss 0.3576
20:57:08.110569 [0] Epoch: 119, Train: 0.9123, Val: 0.8999, Test: 0.7451
20:57:08.771948 [0] Epoch 00120 | Loss 0.3567
20:57:08.813987 [0] Epoch: 120, Train: 0.9125, Val: 0.8999, Test: 0.7453
20:57:09.474840 [0] Epoch 00121 | Loss 0.3558
20:57:09.516750 [0] Epoch: 121, Train: 0.9127, Val: 0.9003, Test: 0.7454
20:57:10.178013 [0] Epoch 00122 | Loss 0.3549
20:57:10.220059 [0] Epoch: 122, Train: 0.9129, Val: 0.9005, Test: 0.7456
20:57:10.880800 [0] Epoch 00123 | Loss 0.3540
20:57:10.922957 [0] Epoch: 123, Train: 0.9131, Val: 0.9008, Test: 0.7457
20:57:11.584768 [0] Epoch 00124 | Loss 0.3531
20:57:11.626693 [0] Epoch: 124, Train: 0.9133, Val: 0.9009, Test: 0.7459
20:57:12.287269 [0] Epoch 00125 | Loss 0.3522
20:57:12.329221 [0] Epoch: 125, Train: 0.9135, Val: 0.9012, Test: 0.7460
20:57:12.990511 [0] Epoch 00126 | Loss 0.3514
20:57:13.032520 [0] Epoch: 126, Train: 0.9137, Val: 0.9012, Test: 0.7462
20:57:13.693408 [0] Epoch 00127 | Loss 0.3505
20:57:13.735521 [0] Epoch: 127, Train: 0.9139, Val: 0.9013, Test: 0.7463
20:57:14.397415 [0] Epoch 00128 | Loss 0.3497
20:57:14.439284 [0] Epoch: 128, Train: 0.9141, Val: 0.9014, Test: 0.7465
20:57:15.099600 [0] Epoch 00129 | Loss 0.3489
20:57:15.141898 [0] Epoch: 129, Train: 0.9143, Val: 0.9013, Test: 0.7466
20:57:15.803757 [0] Epoch 00130 | Loss 0.3480
20:57:15.845922 [0] Epoch: 130, Train: 0.9144, Val: 0.9013, Test: 0.7467
20:57:16.506596 [0] Epoch 00131 | Loss 0.3472
20:57:16.548403 [0] Epoch: 131, Train: 0.9145, Val: 0.9017, Test: 0.7468
20:57:17.210965 [0] Epoch 00132 | Loss 0.3464
20:57:17.252661 [0] Epoch: 132, Train: 0.9146, Val: 0.9017, Test: 0.7469
20:57:17.913251 [0] Epoch 00133 | Loss 0.3456
20:57:17.955003 [0] Epoch: 133, Train: 0.9147, Val: 0.9019, Test: 0.7470
20:57:18.617044 [0] Epoch 00134 | Loss 0.3448
20:57:18.659136 [0] Epoch: 134, Train: 0.9148, Val: 0.9022, Test: 0.7472
20:57:19.319773 [0] Epoch 00135 | Loss 0.3441
20:57:19.361810 [0] Epoch: 135, Train: 0.9150, Val: 0.9022, Test: 0.7473
20:57:20.023997 [0] Epoch 00136 | Loss 0.3433
20:57:20.065895 [0] Epoch: 136, Train: 0.9151, Val: 0.9024, Test: 0.7474
20:57:20.726786 [0] Epoch 00137 | Loss 0.3425
20:57:20.768382 [0] Epoch: 137, Train: 0.9151, Val: 0.9025, Test: 0.7475
20:57:21.430167 [0] Epoch 00138 | Loss 0.3418
20:57:21.471833 [0] Epoch: 138, Train: 0.9152, Val: 0.9026, Test: 0.7475
20:57:22.132303 [0] Epoch 00139 | Loss 0.3410
20:57:22.174373 [0] Epoch: 139, Train: 0.9154, Val: 0.9028, Test: 0.7476
20:57:22.836412 [0] Epoch 00140 | Loss 0.3403
20:57:22.878696 [0] Epoch: 140, Train: 0.9155, Val: 0.9029, Test: 0.7476
20:57:23.539415 [0] Epoch 00141 | Loss 0.3395
20:57:23.581395 [0] Epoch: 141, Train: 0.9157, Val: 0.9029, Test: 0.7477
20:57:24.242831 [0] Epoch 00142 | Loss 0.3388
20:57:24.284959 [0] Epoch: 142, Train: 0.9159, Val: 0.9032, Test: 0.7478
20:57:24.945763 [0] Epoch 00143 | Loss 0.3381
20:57:24.987677 [0] Epoch: 143, Train: 0.9160, Val: 0.9033, Test: 0.7478
20:57:25.649067 [0] Epoch 00144 | Loss 0.3374
20:57:25.691080 [0] Epoch: 144, Train: 0.9161, Val: 0.9034, Test: 0.7479
20:57:26.352449 [0] Epoch 00145 | Loss 0.3367
20:57:26.394558 [0] Epoch: 145, Train: 0.9162, Val: 0.9035, Test: 0.7479
20:57:27.056228 [0] Epoch 00146 | Loss 0.3360
20:57:27.098687 [0] Epoch: 146, Train: 0.9165, Val: 0.9036, Test: 0.7480
20:57:27.759507 [0] Epoch 00147 | Loss 0.3353
20:57:27.801448 [0] Epoch: 147, Train: 0.9166, Val: 0.9037, Test: 0.7481
20:57:28.464085 [0] Epoch 00148 | Loss 0.3346
20:57:28.506040 [0] Epoch: 148, Train: 0.9167, Val: 0.9038, Test: 0.7482
20:57:29.168521 [0] Epoch 00149 | Loss 0.3339
20:57:29.210464 [0] Epoch: 149, Train: 0.9169, Val: 0.9039, Test: 0.7482
20:57:29.872169 [0] Epoch 00150 | Loss 0.3332
20:57:29.914213 [0] Epoch: 150, Train: 0.9169, Val: 0.9038, Test: 0.7483
20:57:30.575613 [0] Epoch 00151 | Loss 0.3326
20:57:30.617882 [0] Epoch: 151, Train: 0.9170, Val: 0.9039, Test: 0.7484
20:57:31.279493 [0] Epoch 00152 | Loss 0.3319
20:57:31.321351 [0] Epoch: 152, Train: 0.9171, Val: 0.9040, Test: 0.7484
20:57:31.982593 [0] Epoch 00153 | Loss 0.3312
20:57:32.024204 [0] Epoch: 153, Train: 0.9172, Val: 0.9040, Test: 0.7485
20:57:32.685738 [0] Epoch 00154 | Loss 0.3306
20:57:32.727709 [0] Epoch: 154, Train: 0.9174, Val: 0.9041, Test: 0.7486
20:57:33.388235 [0] Epoch 00155 | Loss 0.3299
20:57:33.430192 [0] Epoch: 155, Train: 0.9175, Val: 0.9043, Test: 0.7486
20:57:34.091813 [0] Epoch 00156 | Loss 0.3293
20:57:34.133951 [0] Epoch: 156, Train: 0.9176, Val: 0.9044, Test: 0.7487
20:57:34.794811 [0] Epoch 00157 | Loss 0.3287
20:57:34.836695 [0] Epoch: 157, Train: 0.9178, Val: 0.9044, Test: 0.7488
20:57:35.498339 [0] Epoch 00158 | Loss 0.3280
20:57:35.540339 [0] Epoch: 158, Train: 0.9179, Val: 0.9044, Test: 0.7488
20:57:36.200948 [0] Epoch 00159 | Loss 0.3274
20:57:36.242951 [0] Epoch: 159, Train: 0.9180, Val: 0.9046, Test: 0.7489
20:57:36.904591 [0] Epoch 00160 | Loss 0.3268
20:57:36.946503 [0] Epoch: 160, Train: 0.9181, Val: 0.9045, Test: 0.7489
20:57:37.607375 [0] Epoch 00161 | Loss 0.3262
20:57:37.649442 [0] Epoch: 161, Train: 0.9183, Val: 0.9045, Test: 0.7490
20:57:38.311468 [0] Epoch 00162 | Loss 0.3255
20:57:38.353458 [0] Epoch: 162, Train: 0.9184, Val: 0.9047, Test: 0.7490
20:57:39.014197 [0] Epoch 00163 | Loss 0.3249
20:57:39.056024 [0] Epoch: 163, Train: 0.9186, Val: 0.9047, Test: 0.7491
20:57:39.716888 [0] Epoch 00164 | Loss 0.3243
20:57:39.758887 [0] Epoch: 164, Train: 0.9187, Val: 0.9049, Test: 0.7491
20:57:40.419590 [0] Epoch 00165 | Loss 0.3237
20:57:40.462204 [0] Epoch: 165, Train: 0.9189, Val: 0.9050, Test: 0.7492
20:57:41.123079 [0] Epoch 00166 | Loss 0.3231
20:57:41.165104 [0] Epoch: 166, Train: 0.9190, Val: 0.9052, Test: 0.7492
20:57:41.825811 [0] Epoch 00167 | Loss 0.3225
20:57:41.867900 [0] Epoch: 167, Train: 0.9191, Val: 0.9052, Test: 0.7493
20:57:42.529174 [0] Epoch 00168 | Loss 0.3220
20:57:42.571368 [0] Epoch: 168, Train: 0.9192, Val: 0.9052, Test: 0.7493
20:57:43.231843 [0] Epoch 00169 | Loss 0.3214
20:57:43.274070 [0] Epoch: 169, Train: 0.9194, Val: 0.9053, Test: 0.7494
20:57:43.934472 [0] Epoch 00170 | Loss 0.3208
20:57:43.976502 [0] Epoch: 170, Train: 0.9195, Val: 0.9052, Test: 0.7494
20:57:44.637211 [0] Epoch 00171 | Loss 0.3202
20:57:44.679030 [0] Epoch: 171, Train: 0.9196, Val: 0.9053, Test: 0.7494
20:57:45.340348 [0] Epoch 00172 | Loss 0.3197
20:57:45.382368 [0] Epoch: 172, Train: 0.9197, Val: 0.9053, Test: 0.7495
20:57:46.042841 [0] Epoch 00173 | Loss 0.3191
20:57:46.084616 [0] Epoch: 173, Train: 0.9197, Val: 0.9056, Test: 0.7495
20:57:46.746582 [0] Epoch 00174 | Loss 0.3185
20:57:46.788436 [0] Epoch: 174, Train: 0.9198, Val: 0.9056, Test: 0.7496
20:57:47.451061 [0] Epoch 00175 | Loss 0.3180
20:57:47.493236 [0] Epoch: 175, Train: 0.9199, Val: 0.9057, Test: 0.7496
20:57:48.156321 [0] Epoch 00176 | Loss 0.3174
20:57:48.197949 [0] Epoch: 176, Train: 0.9201, Val: 0.9058, Test: 0.7496
20:57:48.859194 [0] Epoch 00177 | Loss 0.3169
20:57:48.900894 [0] Epoch: 177, Train: 0.9201, Val: 0.9055, Test: 0.7496
20:57:49.562707 [0] Epoch 00178 | Loss 0.3163
20:57:49.604614 [0] Epoch: 178, Train: 0.9202, Val: 0.9057, Test: 0.7497
20:57:50.265136 [0] Epoch 00179 | Loss 0.3158
20:57:50.307449 [0] Epoch: 179, Train: 0.9203, Val: 0.9055, Test: 0.7497
20:57:50.969300 [0] Epoch 00180 | Loss 0.3152
20:57:51.011240 [0] Epoch: 180, Train: 0.9205, Val: 0.9055, Test: 0.7497
20:57:51.672231 [0] Epoch 00181 | Loss 0.3147
20:57:51.713881 [0] Epoch: 181, Train: 0.9205, Val: 0.9056, Test: 0.7497
20:57:52.376125 [0] Epoch 00182 | Loss 0.3142
20:57:52.417623 [0] Epoch: 182, Train: 0.9206, Val: 0.9058, Test: 0.7498
20:57:53.078503 [0] Epoch 00183 | Loss 0.3136
20:57:53.120606 [0] Epoch: 183, Train: 0.9207, Val: 0.9058, Test: 0.7498
20:57:53.782426 [0] Epoch 00184 | Loss 0.3131
20:57:53.825072 [0] Epoch: 184, Train: 0.9208, Val: 0.9059, Test: 0.7498
20:57:54.486320 [0] Epoch 00185 | Loss 0.3126
20:57:54.528265 [0] Epoch: 185, Train: 0.9209, Val: 0.9060, Test: 0.7498
20:57:55.190388 [0] Epoch 00186 | Loss 0.3121
20:57:55.232206 [0] Epoch: 186, Train: 0.9210, Val: 0.9062, Test: 0.7498
20:57:55.893244 [0] Epoch 00187 | Loss 0.3115
20:57:55.934846 [0] Epoch: 187, Train: 0.9211, Val: 0.9063, Test: 0.7499
20:57:56.597047 [0] Epoch 00188 | Loss 0.3110
20:57:56.638807 [0] Epoch: 188, Train: 0.9213, Val: 0.9063, Test: 0.7499
20:57:57.299530 [0] Epoch 00189 | Loss 0.3105
20:57:57.341442 [0] Epoch: 189, Train: 0.9214, Val: 0.9063, Test: 0.7499
20:57:58.003183 [0] Epoch 00190 | Loss 0.3100
20:57:58.045413 [0] Epoch: 190, Train: 0.9215, Val: 0.9064, Test: 0.7500
20:57:58.706374 [0] Epoch 00191 | Loss 0.3095
20:57:58.748462 [0] Epoch: 191, Train: 0.9216, Val: 0.9066, Test: 0.7500
20:57:59.410359 [0] Epoch 00192 | Loss 0.3090
20:57:59.452140 [0] Epoch: 192, Train: 0.9217, Val: 0.9067, Test: 0.7500
20:58:00.112890 [0] Epoch 00193 | Loss 0.3085
20:58:00.154857 [0] Epoch: 193, Train: 0.9218, Val: 0.9068, Test: 0.7501
20:58:00.816226 [0] Epoch 00194 | Loss 0.3080
20:58:00.858370 [0] Epoch: 194, Train: 0.9218, Val: 0.9067, Test: 0.7501
20:58:01.519552 [0] Epoch 00195 | Loss 0.3075
20:58:01.561421 [0] Epoch: 195, Train: 0.9220, Val: 0.9067, Test: 0.7501
20:58:02.225999 [0] Epoch 00196 | Loss 0.3070
20:58:02.269072 [0] Epoch: 196, Train: 0.9221, Val: 0.9068, Test: 0.7501
20:58:02.939877 [0] Epoch 00197 | Loss 0.3066
20:58:02.983224 [0] Epoch: 197, Train: 0.9222, Val: 0.9068, Test: 0.7501
20:58:03.654465 [0] Epoch 00198 | Loss 0.3061
20:58:03.696320 [0] Epoch: 198, Train: 0.9223, Val: 0.9069, Test: 0.7501
20:58:04.357635 [0] Epoch 00199 | Loss 0.3056
20:58:04.399567 [0] Epoch: 199, Train: 0.9224, Val: 0.9072, Test: 0.7502
20:58:04.401688 [0] 
timer summary:
  8.70s   5.98s   200 broadcast ForwardL1 0
 70.44s  20.16s  1600 broadcast
 53.19s  15.24s  1600 spmm
  5.27s   1.39s   200 broadcast ForwardL1 1
  4.77s   0.01s   800 mm
 11.72s   1.29s   200 broadcast ForwardL2 0
 13.40s   3.54s   200 broadcast ForwardL2 1
  4.19s   3.15s   200 broadcast BackwardL2 0
  2.50s   0.68s   200 broadcast BackwardL2 1
  1.62s   2.12s   400 all_reduce
 11.19s   0.57s   200 broadcast BackwardL1 0
 13.41s   3.55s   200 broadcast BackwardL1 1
145.68s   5.69s   200 epoch
166.89s   0.01s     1 total
15:04:47.494699 [0] proc begin: <DistEnv 0/2 nccl>
15:05:13.680985 [0] graph loaded <COO Graph: ogbn-products, |V|: 2449029, |E|: 123718280, masks: 196615,39323,2213091><Local: 0, |V|: 1224515, |E|: 77129879>
15:05:13.689458 [0] graph loaded
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1092 MiB |   1111 MiB |   1616 MiB | 536640 KiB |
|       from large pool |   1092 MiB |   1111 MiB |   1616 MiB | 536632 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1092 MiB |   1111 MiB |   1616 MiB | 536640 KiB |
|       from large pool |   1092 MiB |   1111 MiB |   1616 MiB | 536632 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      7 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1090 MiB |   1109 MiB |   1613 MiB | 535729 KiB |
|       from large pool |   1090 MiB |   1109 MiB |   1613 MiB | 535725 KiB |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      4 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1198 MiB |   1198 MiB |   1198 MiB |      0 B   |
|       from large pool |   1196 MiB |   1196 MiB |   1196 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 105652 KiB | 304551 KiB | 372884 KiB | 267231 KiB |
|       from large pool | 105652 KiB | 304551 KiB | 366735 KiB | 261083 KiB |
|       from small pool |      0 KiB |   2047 KiB |   6148 KiB |   6148 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| Active allocs         |      11    |      15    |      24    |      13    |
|       from large pool |      11    |      12    |      15    |       4    |
|       from small pool |       0    |       3    |       9    |       9    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       4    |       6    |       3    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       0    |       1    |       3    |       3    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

15:05:16.191640 [0] Epoch 00000 | Loss 4.7410
15:05:16.899783 [0] Epoch 00001 | Loss 3.9229
15:05:17.598829 [0] Epoch 00002 | Loss 3.2705
15:05:18.302623 [0] Epoch 00003 | Loss 2.8071
15:05:19.002912 [0] Epoch 00004 | Loss 2.4711
15:05:19.701825 [0] Epoch 00005 | Loss 2.2229
15:05:20.400181 [0] Epoch 00006 | Loss 2.0293
15:05:21.098338 [0] Epoch 00007 | Loss 1.8677
15:05:21.798558 [0] Epoch 00008 | Loss 1.7264
15:05:22.496827 [0] Epoch 00009 | Loss 1.6003
15:05:23.194734 [0] Epoch 00010 | Loss 1.4872
15:05:23.893514 [0] Epoch 00011 | Loss 1.3859
15:05:24.593764 [0] Epoch 00012 | Loss 1.2961
15:05:25.294301 [0] Epoch 00013 | Loss 1.2172
15:05:25.993957 [0] Epoch 00014 | Loss 1.1486
15:05:26.693816 [0] Epoch 00015 | Loss 1.0889
15:05:27.393685 [0] Epoch 00016 | Loss 1.0369
15:05:28.092729 [0] Epoch 00017 | Loss 0.9914
15:05:28.790951 [0] Epoch 00018 | Loss 0.9510
15:05:29.490705 [0] Epoch 00019 | Loss 0.9149
15:05:30.190258 [0] Epoch 00020 | Loss 0.8822
15:05:30.889133 [0] Epoch 00021 | Loss 0.8523
15:05:31.587037 [0] Epoch 00022 | Loss 0.8247
15:05:32.285386 [0] Epoch 00023 | Loss 0.7990
15:05:32.984475 [0] Epoch 00024 | Loss 0.7752
15:05:33.682552 [0] Epoch 00025 | Loss 0.7531
15:05:34.381960 [0] Epoch 00026 | Loss 0.7329
15:05:35.080769 [0] Epoch 00027 | Loss 0.7146
15:05:35.780880 [0] Epoch 00028 | Loss 0.6980
15:05:36.480218 [0] Epoch 00029 | Loss 0.6829
15:05:37.178749 [0] Epoch 00030 | Loss 0.6688
15:05:37.877738 [0] Epoch 00031 | Loss 0.6555
15:05:38.579302 [0] Epoch 00032 | Loss 0.6426
15:05:39.277874 [0] Epoch 00033 | Loss 0.6303
15:05:39.976275 [0] Epoch 00034 | Loss 0.6187
15:05:40.675318 [0] Epoch 00035 | Loss 0.6079
15:05:41.374373 [0] Epoch 00036 | Loss 0.5981
15:05:42.074429 [0] Epoch 00037 | Loss 0.5891
15:05:42.772894 [0] Epoch 00038 | Loss 0.5808
15:05:43.472684 [0] Epoch 00039 | Loss 0.5730
15:05:44.171584 [0] Epoch 00040 | Loss 0.5656
15:05:44.870924 [0] Epoch 00041 | Loss 0.5583
15:05:45.569600 [0] Epoch 00042 | Loss 0.5511
15:05:46.268612 [0] Epoch 00043 | Loss 0.5440
15:05:46.967577 [0] Epoch 00044 | Loss 0.5371
15:05:47.666103 [0] Epoch 00045 | Loss 0.5305
15:05:48.364177 [0] Epoch 00046 | Loss 0.5242
15:05:49.063211 [0] Epoch 00047 | Loss 0.5183
15:05:49.762101 [0] Epoch 00048 | Loss 0.5127
15:05:50.462033 [0] Epoch 00049 | Loss 0.5074
15:05:51.160461 [0] Epoch 00050 | Loss 0.5023
15:05:51.860495 [0] Epoch 00051 | Loss 0.4975
15:05:52.560048 [0] Epoch 00052 | Loss 0.4927
15:05:53.259244 [0] Epoch 00053 | Loss 0.4880
15:05:53.958826 [0] Epoch 00054 | Loss 0.4835
15:05:54.658209 [0] Epoch 00055 | Loss 0.4790
15:05:55.357452 [0] Epoch 00056 | Loss 0.4748
15:05:56.056367 [0] Epoch 00057 | Loss 0.4707
15:05:56.755181 [0] Epoch 00058 | Loss 0.4669
15:05:57.454022 [0] Epoch 00059 | Loss 0.4632
15:05:58.153295 [0] Epoch 00060 | Loss 0.4597
15:05:58.852460 [0] Epoch 00061 | Loss 0.4563
15:05:59.551373 [0] Epoch 00062 | Loss 0.4530
15:06:00.251941 [0] Epoch 00063 | Loss 0.4498
15:06:00.951221 [0] Epoch 00064 | Loss 0.4468
15:06:01.650033 [0] Epoch 00065 | Loss 0.4438
15:06:02.360126 [0] Epoch 00066 | Loss 0.4409
15:06:03.071349 [0] Epoch 00067 | Loss 0.4381
15:06:03.774115 [0] Epoch 00068 | Loss 0.4353
15:06:04.474883 [0] Epoch 00069 | Loss 0.4327
15:06:05.174841 [0] Epoch 00070 | Loss 0.4301
15:06:05.874853 [0] Epoch 00071 | Loss 0.4276
15:06:06.574771 [0] Epoch 00072 | Loss 0.4252
15:06:07.275007 [0] Epoch 00073 | Loss 0.4229
15:06:07.976270 [0] Epoch 00074 | Loss 0.4207
15:06:08.677048 [0] Epoch 00075 | Loss 0.4186
15:06:09.377294 [0] Epoch 00076 | Loss 0.4165
15:06:10.077570 [0] Epoch 00077 | Loss 0.4145
15:06:10.779211 [0] Epoch 00078 | Loss 0.4125
15:06:11.479975 [0] Epoch 00079 | Loss 0.4105
15:06:12.180947 [0] Epoch 00080 | Loss 0.4086
15:06:12.881481 [0] Epoch 00081 | Loss 0.4068
15:06:13.581173 [0] Epoch 00082 | Loss 0.4050
15:06:14.281445 [0] Epoch 00083 | Loss 0.4032
15:06:14.981489 [0] Epoch 00084 | Loss 0.4015
15:06:15.681447 [0] Epoch 00085 | Loss 0.3998
15:06:16.381122 [0] Epoch 00086 | Loss 0.3981
15:06:17.081018 [0] Epoch 00087 | Loss 0.3965
15:06:17.782235 [0] Epoch 00088 | Loss 0.3949
15:06:18.484546 [0] Epoch 00089 | Loss 0.3933
15:06:19.184305 [0] Epoch 00090 | Loss 0.3918
15:06:19.883649 [0] Epoch 00091 | Loss 0.3903
15:06:20.585143 [0] Epoch 00092 | Loss 0.3888
15:06:21.284420 [0] Epoch 00093 | Loss 0.3874
15:06:21.983876 [0] Epoch 00094 | Loss 0.3860
15:06:22.683501 [0] Epoch 00095 | Loss 0.3846
15:06:23.383114 [0] Epoch 00096 | Loss 0.3833
15:06:24.083198 [0] Epoch 00097 | Loss 0.3819
15:06:24.783383 [0] Epoch 00098 | Loss 0.3806
15:06:25.483091 [0] Epoch 00099 | Loss 0.3793
15:06:26.182988 [0] Epoch 00100 | Loss 0.3781
15:06:26.882653 [0] Epoch 00101 | Loss 0.3768
15:06:27.582151 [0] Epoch 00102 | Loss 0.3756
15:06:28.281138 [0] Epoch 00103 | Loss 0.3744
15:06:28.981369 [0] Epoch 00104 | Loss 0.3732
15:06:29.680642 [0] Epoch 00105 | Loss 0.3721
15:06:30.380946 [0] Epoch 00106 | Loss 0.3709
15:06:31.080265 [0] Epoch 00107 | Loss 0.3698
15:06:31.781534 [0] Epoch 00108 | Loss 0.3687
15:06:32.480779 [0] Epoch 00109 | Loss 0.3677
15:06:33.181059 [0] Epoch 00110 | Loss 0.3666
15:06:33.881563 [0] Epoch 00111 | Loss 0.3655
15:06:34.581606 [0] Epoch 00112 | Loss 0.3645
15:06:35.281889 [0] Epoch 00113 | Loss 0.3635
15:06:35.981661 [0] Epoch 00114 | Loss 0.3625
15:06:36.680589 [0] Epoch 00115 | Loss 0.3615
15:06:37.380680 [0] Epoch 00116 | Loss 0.3605
15:06:38.079707 [0] Epoch 00117 | Loss 0.3595
15:06:38.779733 [0] Epoch 00118 | Loss 0.3586
15:06:39.479280 [0] Epoch 00119 | Loss 0.3576
15:06:40.178869 [0] Epoch 00120 | Loss 0.3567
15:06:40.878468 [0] Epoch 00121 | Loss 0.3558
15:06:41.577665 [0] Epoch 00122 | Loss 0.3549
15:06:42.277448 [0] Epoch 00123 | Loss 0.3540
15:06:42.977183 [0] Epoch 00124 | Loss 0.3531
15:06:43.676468 [0] Epoch 00125 | Loss 0.3522
15:06:44.375639 [0] Epoch 00126 | Loss 0.3514
15:06:45.077231 [0] Epoch 00127 | Loss 0.3505
15:06:45.778030 [0] Epoch 00128 | Loss 0.3497
15:06:46.478514 [0] Epoch 00129 | Loss 0.3489
15:06:47.179603 [0] Epoch 00130 | Loss 0.3480
15:06:47.880244 [0] Epoch 00131 | Loss 0.3472
15:06:48.580331 [0] Epoch 00132 | Loss 0.3464
15:06:49.281856 [0] Epoch 00133 | Loss 0.3456
15:06:49.982950 [0] Epoch 00134 | Loss 0.3448
15:06:50.684815 [0] Epoch 00135 | Loss 0.3441
15:06:51.384525 [0] Epoch 00136 | Loss 0.3433
15:06:52.084403 [0] Epoch 00137 | Loss 0.3425
15:06:52.783861 [0] Epoch 00138 | Loss 0.3418
15:06:53.482549 [0] Epoch 00139 | Loss 0.3410
15:06:54.182387 [0] Epoch 00140 | Loss 0.3403
15:06:54.881224 [0] Epoch 00141 | Loss 0.3395
15:06:55.580315 [0] Epoch 00142 | Loss 0.3388
15:06:56.278756 [0] Epoch 00143 | Loss 0.3381
15:06:56.977147 [0] Epoch 00144 | Loss 0.3374
15:06:57.677638 [0] Epoch 00145 | Loss 0.3367
15:06:58.378314 [0] Epoch 00146 | Loss 0.3360
15:06:59.078687 [0] Epoch 00147 | Loss 0.3353
15:06:59.779086 [0] Epoch 00148 | Loss 0.3346
15:07:00.479223 [0] Epoch 00149 | Loss 0.3339
15:07:01.179261 [0] Epoch 00150 | Loss 0.3332
15:07:01.888695 [0] Epoch 00151 | Loss 0.3326
15:07:02.598053 [0] Epoch 00152 | Loss 0.3319
15:07:03.301699 [0] Epoch 00153 | Loss 0.3312
15:07:04.003302 [0] Epoch 00154 | Loss 0.3306
15:07:04.704523 [0] Epoch 00155 | Loss 0.3299
15:07:05.405266 [0] Epoch 00156 | Loss 0.3293
15:07:06.105724 [0] Epoch 00157 | Loss 0.3287
15:07:06.806125 [0] Epoch 00158 | Loss 0.3280
15:07:07.506399 [0] Epoch 00159 | Loss 0.3274
15:07:08.207062 [0] Epoch 00160 | Loss 0.3268
15:07:08.907817 [0] Epoch 00161 | Loss 0.3262
15:07:09.608565 [0] Epoch 00162 | Loss 0.3255
15:07:10.308754 [0] Epoch 00163 | Loss 0.3249
15:07:11.009574 [0] Epoch 00164 | Loss 0.3243
15:07:11.709890 [0] Epoch 00165 | Loss 0.3237
15:07:12.410138 [0] Epoch 00166 | Loss 0.3231
15:07:13.110425 [0] Epoch 00167 | Loss 0.3225
15:07:13.811286 [0] Epoch 00168 | Loss 0.3220
15:07:14.511911 [0] Epoch 00169 | Loss 0.3214
15:07:15.211822 [0] Epoch 00170 | Loss 0.3208
15:07:15.912419 [0] Epoch 00171 | Loss 0.3202
15:07:16.613051 [0] Epoch 00172 | Loss 0.3197
15:07:17.312888 [0] Epoch 00173 | Loss 0.3191
15:07:18.013536 [0] Epoch 00174 | Loss 0.3185
15:07:18.713977 [0] Epoch 00175 | Loss 0.3180
15:07:19.414204 [0] Epoch 00176 | Loss 0.3174
15:07:20.113956 [0] Epoch 00177 | Loss 0.3169
15:07:20.814838 [0] Epoch 00178 | Loss 0.3163
15:07:21.514760 [0] Epoch 00179 | Loss 0.3158
15:07:22.214879 [0] Epoch 00180 | Loss 0.3152
15:07:22.914708 [0] Epoch 00181 | Loss 0.3147
15:07:23.614664 [0] Epoch 00182 | Loss 0.3142
15:07:24.316865 [0] Epoch 00183 | Loss 0.3136
15:07:25.018830 [0] Epoch 00184 | Loss 0.3131
15:07:25.719640 [0] Epoch 00185 | Loss 0.3126
15:07:26.421272 [0] Epoch 00186 | Loss 0.3121
15:07:27.123634 [0] Epoch 00187 | Loss 0.3115
15:07:27.825949 [0] Epoch 00188 | Loss 0.3110
15:07:28.526898 [0] Epoch 00189 | Loss 0.3105
15:07:29.227547 [0] Epoch 00190 | Loss 0.3100
15:07:29.927350 [0] Epoch 00191 | Loss 0.3095
15:07:30.626914 [0] Epoch 00192 | Loss 0.3090
15:07:31.326441 [0] Epoch 00193 | Loss 0.3085
15:07:32.025428 [0] Epoch 00194 | Loss 0.3080
15:07:32.725256 [0] Epoch 00195 | Loss 0.3075
15:07:33.424777 [0] Epoch 00196 | Loss 0.3070
15:07:34.124268 [0] Epoch 00197 | Loss 0.3066
15:07:34.824109 [0] Epoch 00198 | Loss 0.3061
15:07:35.530737 [0] Epoch 00199 | Loss 0.3056
15:07:35.569175 [0] 
timer summary:
 11.41s   9.67s   200 broadcast ForwardL1 0
 73.38s  23.91s  1600 broadcast
 53.18s  15.19s  1600 spmm
  5.29s   1.40s   200 broadcast ForwardL1 1
  4.80s   0.03s   800 mm
 11.78s   1.30s   200 broadcast ForwardL2 0
 13.41s   3.51s   200 broadcast ForwardL2 1
  4.30s   3.29s   200 broadcast BackwardL2 0
  2.51s   0.69s   200 broadcast BackwardL2 1
  1.66s   2.16s   400 all_reduce
 11.24s   0.57s   200 broadcast BackwardL1 0
 13.38s   3.49s   200 broadcast BackwardL1 1
147.78s   9.38s   200 epoch
168.04s   0.00s     1 total
